{"translation": {"code": "void addDestination ( final int transportIndex , final ReceiveDestinationUdpTransport transport ) { imageConnections = ArrayUtil . ensureCapacity ( imageConnections , transportIndex + 1 ) ; if ( transport . isMulticast ( ) ) { imageConnections [ transportIndex ] = new ImageConnection ( cachedNanoClock . nanoTime ( ) , transport . udpChannel ( ) . remoteControl ( ) ) ; } else if ( transport . hasExplicitControl ( ) ) { imageConnections [ transportIndex ] = new ImageConnection ( cachedNanoClock . nanoTime ( ) , transport . explicitControlAddress ( ) ) ; } }", "nl": "Add a destination to this image so it can merge streams ."}}
{"translation": {"code": "public boolean matchesTag ( final UdpChannel udpChannel ) { if ( ! hasTag || ! udpChannel . hasTag ( ) || tag != udpChannel . tag ( ) ) { return false ; } if ( udpChannel . remoteData ( ) . getAddress ( ) . isAnyLocalAddress ( ) && udpChannel . remoteData ( ) . getPort ( ) == 0 && udpChannel . localData ( ) . getAddress ( ) . isAnyLocalAddress ( ) && udpChannel . localData ( ) . getPort ( ) == 0 ) { return true ; } throw new IllegalArgumentException ( \"matching tag has set endpoint or control address\" ) ; }", "nl": "Does this channel have a tag match to another channel including endpoints ."}}
{"translation": {"code": "public static long getSnapshotRecordingId ( final CountersReader counters , final int counterId , final int serviceId ) { final DirectBuffer buffer = counters . metaDataBuffer ( ) ; if ( counters . getCounterState ( counterId ) == RECORD_ALLOCATED ) { final int recordOffset = CountersReader . metaDataOffset ( counterId ) ; if ( buffer . getInt ( recordOffset + TYPE_ID_OFFSET ) == RECOVERY_STATE_TYPE_ID ) { final int serviceCount = buffer . getInt ( recordOffset + KEY_OFFSET + SERVICE_COUNT_OFFSET ) ; if ( serviceId < 0 || serviceId >= serviceCount ) { throw new ClusterException ( \"invalid serviceId \" + serviceId + \" for count of \" + serviceCount ) ; } return buffer . getLong ( recordOffset + KEY_OFFSET + SNAPSHOT_RECORDING_IDS_OFFSET + ( serviceId * SIZE_OF_LONG ) ) ; } } throw new ClusterException ( \"Active counter not found \" + counterId ) ; }", "nl": "Get the recording id of the snapshot for a service ."}}
{"translation": {"code": "public long offer ( final DirectBufferVector [ ] vectors ) { if ( headerVector != vectors [ 0 ] ) { vectors [ 0 ] = headerVector ; } return publication . offer ( vectors , null ) ; }", "nl": "Non - blocking publish by gathering buffer vectors into a message . The first vector will be replaced by the cluster ingress header so must be left unused ."}}
{"translation": {"code": "public static int findMemberIndex ( final ClusterMember [ ] clusterMembers , final int memberId ) { final int length = clusterMembers . length ; int index = ArrayUtil . UNKNOWN_INDEX ; for ( int i = 0 ; i < length ; i ++ ) { if ( clusterMembers [ i ] . id ( ) == memberId ) { index = i ; } } return index ; }", "nl": "Find the index at which a member id is present ."}}
{"translation": {"code": "public static ClusterMember [ ] removeMember ( final ClusterMember [ ] oldMembers , final int memberId ) { return ArrayUtil . remove ( oldMembers , findMemberIndex ( oldMembers , memberId ) ) ; }", "nl": "Remove a member from an array if found otherwise return the array unmodified ."}}
{"translation": {"code": "public static RecoveryPlan createRecoveryPlan ( final ArrayList < RecordingLog . Snapshot > snapshots ) { long lastLeadershipTermId = NULL_VALUE ; long lastTermBaseLogPosition = 0 ; long committedLogPosition = - 1 ; long appendedLogPosition = 0 ; final int snapshotStepsSize = snapshots . size ( ) ; if ( snapshotStepsSize > 0 ) { final Snapshot snapshot = snapshots . get ( 0 ) ; lastLeadershipTermId = snapshot . leadershipTermId ; lastTermBaseLogPosition = snapshot . termBaseLogPosition ; appendedLogPosition = snapshot . logPosition ; committedLogPosition = snapshot . logPosition ; } return new RecoveryPlan ( lastLeadershipTermId , lastTermBaseLogPosition , appendedLogPosition , committedLogPosition , snapshots , new ArrayList <> ( ) ) ; }", "nl": "Create a recovery plan that has only snapshots . Used for dynamicJoin snapshot load ."}}
{"translation": {"code": "public boolean getStopPosition ( final long recordingId , final long correlationId , final long controlSessionId ) { stopPositionRequestEncoder . wrapAndApplyHeader ( buffer , 0 , messageHeaderEncoder ) . controlSessionId ( controlSessionId ) . correlationId ( correlationId ) . recordingId ( recordingId ) ; return offer ( stopPositionRequestEncoder . encodedLength ( ) ) ; }", "nl": "Get the stop position of a recording ."}}
{"translation": {"code": "public int doWork ( ) { int workCount = 0 ; switch ( state ) { case AWAIT_INITIAL_RECORDING_POSITION : workCount += awaitInitialRecordingPosition ( ) ; break ; case AWAIT_REPLAY : workCount += awaitReplay ( ) ; break ; case AWAIT_CATCH_UP : workCount += awaitCatchUp ( ) ; break ; case AWAIT_CURRENT_RECORDING_POSITION : workCount += awaitUpdatedRecordingPosition ( ) ; break ; case AWAIT_STOP_REPLAY : workCount += awaitStopReplay ( ) ; break ; } return workCount ; }", "nl": "Process the operation of the merge . Do not call the processing of fragments on the subscription ."}}
{"translation": {"code": "public void close ( ) { final State state = this . state ; if ( State . CLOSED != state ) { if ( isReplayActive ) { isReplayActive = false ; archive . stopReplay ( replaySessionId ) ; } if ( State . MERGED != state ) { subscription . removeDestination ( replayDestination ) ; } state ( State . CLOSED ) ; } }", "nl": "Close the merge and stop any active replay . Will remove the replay destination from the subscription . Will NOT remove the live destination if it has been added ."}}
{"translation": {"code": "public static char [ ] flagsToChars ( final short flags ) { final char [ ] chars = new char [ ] { ' ' , ' ' , ' ' , ' ' , ' ' , ' ' , ' ' , ' ' } ; final int length = chars . length ; short mask = ( short ) ( 1 << ( length - 1 ) ) ; for ( int i = 0 ; i < length ; i ++ ) { if ( ( flags & mask ) == mask ) { chars [ i ] = ' ' ; } mask >>= 1 ; } return chars ; }", "nl": "Convert header flags to an array of chars to be human readable ."}}
{"translation": {"code": "public static MappedByteBuffer mapExistingFileReadOnly ( final File location ) { if ( ! location . exists ( ) ) { final String msg = \"file not found: \" + location . getAbsolutePath ( ) ; throw new IllegalStateException ( msg ) ; } MappedByteBuffer mappedByteBuffer = null ; try ( RandomAccessFile file = new RandomAccessFile ( location , \"r\" ) ; FileChannel channel = file . getChannel ( ) ) { mappedByteBuffer = channel . map ( READ_ONLY , 0 , channel . size ( ) ) ; } catch ( final IOException ex ) { LangUtil . rethrowUnchecked ( ex ) ; } return mappedByteBuffer ; }", "nl": "Map an existing file as a read only buffer ."}}
{"translation": {"code": "public Entry findLastTerm ( ) { for ( int i = entries . size ( ) - 1 ; i >= 0 ; i -- ) { final Entry entry = entries . get ( i ) ; if ( ENTRY_TYPE_TERM == entry . type ) { return entry ; } } return null ; }", "nl": "Find the last leadership term in the recording log ."}}
{"translation": {"code": "public static boolean requestDriverTermination ( final File directory , final DirectBuffer tokenBuffer , final int tokenOffset , final int tokenLength ) { final File cncFile = new File ( directory , CncFileDescriptor . CNC_FILE ) ; if ( cncFile . exists ( ) && cncFile . length ( ) > 0 ) { final MappedByteBuffer cncByteBuffer = IoUtil . mapExistingFile ( cncFile , \"CnC file\" ) ; try { final UnsafeBuffer cncMetaDataBuffer = CncFileDescriptor . createMetaDataBuffer ( cncByteBuffer ) ; final int cncVersion = cncMetaDataBuffer . getIntVolatile ( cncVersionOffset ( 0 ) ) ; if ( CncFileDescriptor . CNC_VERSION != cncVersion ) { throw new AeronException ( \"Aeron CnC version does not match: required=\" + CNC_VERSION + \" version=\" + cncVersion ) ; } final ManyToOneRingBuffer toDriverBuffer = new ManyToOneRingBuffer ( CncFileDescriptor . createToDriverBuffer ( cncByteBuffer , cncMetaDataBuffer ) ) ; final long clientId = toDriverBuffer . nextCorrelationId ( ) ; final DriverProxy driverProxy = new DriverProxy ( toDriverBuffer , clientId ) ; return driverProxy . terminateDriver ( tokenBuffer , tokenOffset , tokenLength ) ; } finally { IoUtil . unmap ( cncByteBuffer ) ; } } return false ; }", "nl": "Request a driver to run its termination hook ."}}
{"translation": {"code": "public TerminateDriverFlyweight tokenBuffer ( final DirectBuffer tokenBuffer , final int tokenOffset , final int tokenLength ) { buffer . putInt ( TOKEN_LENGTH_OFFSET , tokenLength ) ; if ( null != tokenBuffer && tokenLength > 0 ) { buffer . putBytes ( tokenBufferOffset ( ) , tokenBuffer , tokenOffset , tokenLength ) ; } return this ; }", "nl": "Fill the token buffer ."}}
{"translation": {"code": "public Map < StreamCompositeKey , StreamBacklog > snapshot ( ) { final Map < StreamCompositeKey , StreamBacklog > streams = new HashMap <> ( ) ; counters . forEach ( ( counterId , typeId , keyBuffer , label ) -> { if ( ( typeId >= PUBLISHER_LIMIT_TYPE_ID && typeId <= RECEIVER_POS_TYPE_ID ) || typeId == SENDER_LIMIT_TYPE_ID || typeId == PER_IMAGE_TYPE_ID || typeId == PUBLISHER_POS_TYPE_ID ) { final StreamCompositeKey key = new StreamCompositeKey ( keyBuffer . getInt ( SESSION_ID_OFFSET ) , keyBuffer . getInt ( STREAM_ID_OFFSET ) , keyBuffer . getStringAscii ( CHANNEL_OFFSET ) ) ; final StreamBacklog streamBacklog = streams . computeIfAbsent ( key , ( ignore ) - > new StreamBacklog ( ) ) ; final long registrationId = keyBuffer . getLong ( REGISTRATION_ID_OFFSET ) ; final long value = counters . getCounterValue ( counterId ) ; switch ( typeId ) { case PublisherLimit . PUBLISHER_LIMIT_TYPE_ID : streamBacklog . createPublisherIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createPublisherIfAbsent ( ) . limit ( value ) ; break ; case PublisherPos . PUBLISHER_POS_TYPE_ID : streamBacklog . createPublisherIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createPublisherIfAbsent ( ) . position ( value ) ; break ; case SenderPos . SENDER_POSITION_TYPE_ID : streamBacklog . createSenderIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createSenderIfAbsent ( ) . position ( value ) ; break ; case SenderLimit . SENDER_LIMIT_TYPE_ID : streamBacklog . createSenderIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createSenderIfAbsent ( ) . limit ( value ) ; break ; case ReceiverHwm . RECEIVER_HWM_TYPE_ID : streamBacklog . createReceiverIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createReceiverIfAbsent ( ) . highWaterMark ( value ) ; break ; case ReceiverPos . RECEIVER_POS_TYPE_ID : streamBacklog . createReceiverIfAbsent ( ) . registrationId ( registrationId ) ; streamBacklog . createReceiverIfAbsent ( ) . position ( value ) ; break ; case SubscriberPos . SUBSCRIBER_POSITION_TYPE_ID : streamBacklog . subscriberBacklogs ( ) . put ( registrationId , new Subscriber ( value ) ) ; break ; } } } ) ; return streams ; }", "nl": "Take a snapshot of all the backlog information and group by stream ."}}