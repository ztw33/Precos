{"translation": {"code": "public static Object getPropByPath ( Object item , String ... path ) { Object o = item ; for ( int index = 0 ; index < path . length ; index ++ ) { String propName = path [ index ] ; if ( o == null ) { return null ; } else if ( o . getClass ( ) . isArray ( ) || o instanceof Collection ) { o = getCollectionProp ( o , propName , index , path ) ; break ; } else { o = getProp ( o , propName ) ; } } return Conversions . unifyListOrArray ( o ) ; }", "nl": "This method handles walking lists of lists ."}}
{"translation": {"code": "@ Override public void tick ( long time ) { this . time . set ( time ) ; /*Foreign thread    every 20 or so mili-seconds so we don't spend too\n         much time figuring out utc time. */ approxTime . set ( Dates . utcNow ( ) ) ; }", "nl": "Calculate utc time . This gets called every 20 mili - seconds or so ."}}
{"translation": {"code": "public void putAll ( Map < K , V > values ) { Set < Map . Entry < K , V > > entries = values . entrySet ( ) ; Map < String , String > map = new HashMap <> ( values . size ( ) ) ; for ( Map . Entry < K , V > entry : entries ) { map . put ( toKeyString ( entry . getKey ( ) ) , toValueString ( entry . getValue ( ) ) ) ; } store . putAll ( map ) ; }", "nl": "Put all of these values in the key value store ."}}
{"translation": {"code": "@ Override public void removeAll ( Iterable < byte [ ] > keys ) { WriteBatch batch = database . createWriteBatch ( ) ; try { for ( byte [ ] key : keys ) { batch . delete ( key ) ; } database . write ( batch ) ; } finally { closeBatch ( batch ) ; } }", "nl": "Remove all of the keys passed ."}}
{"translation": {"code": "@ Override public KeyValueIterable < byte [ ] , byte [ ] > search ( byte [ ] startKey ) { final DBIterator iterator = database . iterator ( ) ; iterator . seek ( startKey ) ; return new KeyValueIterable < byte [ ] , byte [ ] > ( ) { @ Override public void close ( ) { closeIterator ( iterator ) ; } @ Override public Iterator < Entry < byte [ ] , byte [ ] > > iterator ( ) { return new Iterator < Entry < byte [ ] , byte [ ] > > ( ) { @ Override public boolean hasNext ( ) { return iterator . hasNext ( ) ; } @ Override public Entry < byte [ ] , byte [ ] > next ( ) { Map . Entry < byte [ ] , byte [ ] > next = iterator . next ( ) ; return new Entry <> ( next . getKey ( ) , next . getValue ( ) ) ; } @ Override public void remove ( ) { iterator . remove ( ) ; } } ; } } ; }", "nl": "Search to a certain location ."}}
{"translation": {"code": "public void start ( ) { scheduledExecutorService = Executors . newScheduledThreadPool ( 2 , new ThreadFactory ( ) { @ Override public Thread newThread ( Runnable runnable ) { Thread thread = new Thread ( runnable ) ; thread . setName ( \" DataQueue Process \" + source ) ; return thread ; } } ) ; future = scheduledExecutorService . scheduleAtFixedRate ( new Runnable ( ) { @ Override public void run ( ) { if ( stop . get ( ) ) { return ; } try { processWriteQueue ( ) ; } catch ( InterruptedException ex ) { //let it restart or stop } catch ( Exception ex ) { logger . fatal ( ex ) ; } } } , 0 , dataStoreConfig . threadErrorResumeTimeMS ( ) , TimeUnit . MILLISECONDS ) ; future = scheduledExecutorService . scheduleAtFixedRate ( new Runnable ( ) { @ Override public void run ( ) { if ( stop . get ( ) ) { return ; } try { processReadQueue ( ) ; } catch ( InterruptedException ex ) { //let it restart or stop } catch ( Exception ex ) { logger . fatal ( ex , \"Problem with base data store running scheduled job\" ) ; } } } , 0 , dataStoreConfig . threadErrorResumeTimeMS ( ) , TimeUnit . MILLISECONDS ) ; }", "nl": "Start up the queue handlers ."}}
{"translation": {"code": "protected byte [ ] toKeyBytes ( K key ) { byte [ ] keyBytes = keyCache . get ( key ) ; if ( keyBytes == null ) { keyBytes = this . keyToByteArrayConverter . apply ( key ) ; keyCache . put ( key , keyBytes ) ; } return keyBytes ; }", "nl": "Convert a String key to bytes ."}}
{"translation": {"code": "public final ByteBuffer allocateBuffer ( int size ) { if ( RECYCLE_BUFFER ) { ByteBuffer spentBuffer = recycleChannel . poll ( ) ; if ( spentBuffer == null ) { spentBuffer = ByteBuffer . allocateDirect ( size ) ; } spentBuffer . clear ( ) ; return spentBuffer ; } else { return ByteBuffer . allocateDirect ( size ) ; } }", "nl": "This gets called from the http post handler or event bus handler ."}}
{"translation": {"code": "private void manageInputWriterChannel ( ) throws InterruptedException { try { ByteBuffer dataToWriteToFile ; dataToWriteToFile = inputChannel . poll ( ) ; //no wait //If it is null, it means the inputChannel is empty and we need to flush. if ( dataToWriteToFile == null ) { queueEmptyMaybeFlush ( ) ; dataToWriteToFile = inputChannel . poll ( ) ; } //If it is still null, this means that we need to wait //for more items to show up in the inputChannel. if ( dataToWriteToFile == null ) { dataToWriteToFile = waitForNextDataToWrite ( ) ; } //We have to check for null again because we could have been interrupted. if ( dataToWriteToFile != null ) { //Write it writer . nextBufferToWrite ( dataToWriteToFile ) ; //Then give it back if ( RECYCLE_BUFFER ) { recycleChannel . offer ( dataToWriteToFile ) ; } } } catch ( InterruptedException ex ) { throw ex ; } catch ( Exception ex ) { ex . printStackTrace ( ) ; ex . printStackTrace ( System . err ) ; } }", "nl": "Queue and batch writer main logic . This is where the magic happens ."}}
{"translation": {"code": "private void queueEmptyMaybeFlush ( ) { if ( PERIODIC_FORCE_FLUSH ) { long currentTime = time . get ( ) ; /* Try not to flush more than once every x times per mili-seconds time period. */ if ( ( currentTime - lastFlushTime ) > FORCE_FLUSH_AFTER_THIS_MANY_MILI_SECONDS ) { /* If the writer had things to flush, and we flushed then\n                increment the number of flushes.\n                 */ if ( writer . syncToDisk ( ) ) { //could take 100 ms to 1 second this . numberOfFlushesTotal . incrementAndGet ( ) ; } /* We update the flush time no matter what. */ lastFlushTime = time . get ( ) ; } } }", "nl": "If we detect that the in - coming transfer outputDataQueue channel is empty then it could be an excellent time to sync to disk ."}}
{"translation": {"code": "public void tick ( long time ) { this . time . set ( time ) ; long startTime = fileStartTime . get ( ) ; long duration = time - startTime ; if ( duration > FILE_TIMEOUT_MILISECONDS ) { fileTimeOut . set ( true ) ; } }", "nl": "Recieves a tick from our clock ."}}
{"translation": {"code": "public boolean syncToDisk ( ) { /** if we have a stream and we are dirty then flush. */ if ( outputStream != null && dirty ) { try { //outputStream.flush (); if ( outputStream instanceof FileChannel ) { FileChannel channel = ( FileChannel ) outputStream ; channel . force ( true ) ; } dirty = false ; return true ; } catch ( Exception ex ) { cleanupOutputStream ( ) ; return false ; } } else { return false ; } }", "nl": "flush to disk ."}}
{"translation": {"code": "private void cleanupOutputStream ( ) { if ( outputStream != null ) { try { outputStream . close ( ) ; } catch ( IOException e ) { e . printStackTrace ( System . err ) ; } finally { outputStream = null ; } } }", "nl": "Attempts to close down log stream ."}}
{"translation": {"code": "private void initOutputStream ( ) { long time = this . time . get ( ) ; if ( error . get ( ) || this . totalBytesTransferred == 0 ) { cleanupOutputStream ( ) ; error . set ( false ) ; time = System . nanoTime ( ) / 1_000_000 ; } if ( outputStream != null ) { return ; } fileName = LogFilesConfig . getLogFileName ( FORMAT_PATTERN , outputDirPath ( ) , numFiles , time , SERVER_NAME ) ; try { fileTimeOut . set ( false ) ; outputStream = streamCreator ( ) ; fileStartTime . set ( time ) ; bytesTransferred = 0 ; bytesSinceLastFlush = 0 ; } catch ( Exception ex ) { cleanupOutputStream ( ) ; error . set ( true ) ; Exceptions . handle ( ex ) ; } finally { numFiles ++ ; } }", "nl": "Initialize the output stream ."}}
{"translation": {"code": "private void sendHttpRequest ( final Request request , final org . boon . core . Handler < Response > responseHandler ) { final HttpClientRequest httpClientRequest = httpClient . request ( request . getMethod ( ) , request . uri ( ) , handleResponse ( request , responseHandler ) ) ; final Runnable runnable = new Runnable ( ) { @ Override public void run ( ) { if ( ! request . getMethod ( ) . equals ( \"GET\" ) ) { httpClientRequest . putHeader ( \"Content-Type\" , \"application/x-www-form-urlencoded\" ) . end ( request . paramBody ( ) ) ; } else { httpClientRequest . end ( ) ; } } } ; if ( closed . get ( ) ) { this . scheduledExecutorService . schedule ( new Runnable ( ) { @ Override public void run ( ) { connect ( ) ; int retry = 0 ; while ( closed . get ( ) ) { Sys . sleep ( 1000 ) ; if ( ! closed . get ( ) ) { break ; } retry ++ ; if ( retry > 10 ) { break ; } if ( retry % 3 == 0 ) { connect ( ) ; } } if ( ! closed . get ( ) ) { runnable . run ( ) ; } else { responseHandler . handle ( new Response ( \"TIMEOUT\" , - 1 , new Error ( - 1 , \"Timeout\" , \"Timeout\" , - 1L ) ) ) ; } } } , 10 , TimeUnit . MILLISECONDS ) ; } else { runnable . run ( ) ; } }", "nl": "This actually sends the request ."}}