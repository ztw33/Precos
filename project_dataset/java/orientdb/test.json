{"translation": {"code": "public Map < String , Set < String > > getActiveDataCenterMap ( ) { Map < String , Set < String > > result = new HashMap <> ( ) ; ODistributedConfiguration cfg = getDistributedConfiguration ( ) ; Set < String > servers = cfg . getRegisteredServers ( ) ; for ( String server : servers ) { String dc = cfg . getDataCenterOfServer ( server ) ; Set < String > dcConfig = result . get ( dc ) ; if ( dcConfig == null ) { dcConfig = new HashSet <> ( ) ; result . put ( dc , dcConfig ) ; } dcConfig . add ( server ) ; } return result ; }", "nl": "returns the data center map for current deploy . The keys are data center names the values are node names per data center"}}
{"translation": {"code": "public boolean onEvent ( OLiveQueryPushRequest pushRequest ) { ODatabaseDocumentInternal old = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; try { database . activateOnCurrentThread ( ) ; if ( pushRequest . getStatus ( ) == OLiveQueryPushRequest . ERROR ) { onError ( pushRequest . getErrorCode ( ) . newException ( pushRequest . getErrorMessage ( ) , null ) ) ; return true ; } else { for ( OLiveQueryResult result : pushRequest . getEvents ( ) ) { switch ( result . getEventType ( ) ) { case OLiveQueryResult . CREATE_EVENT : listener . onCreate ( database , result . getCurrentValue ( ) ) ; break ; case OLiveQueryResult . UPDATE_EVENT : listener . onUpdate ( database , result . getOldValue ( ) , result . getCurrentValue ( ) ) ; break ; case OLiveQueryResult . DELETE_EVENT : listener . onDelete ( database , result . getCurrentValue ( ) ) ; break ; } } if ( pushRequest . getStatus ( ) == OLiveQueryPushRequest . END ) { onEnd ( ) ; return true ; } } return false ; } finally { ODatabaseRecordThreadLocal . instance ( ) . set ( old ) ; } }", "nl": "Return true if the push request require an unregister"}}
{"translation": {"code": "public void timeoutRequest ( final long msgId ) { final ODistributedResponseManager asynchMgr = responsesByRequestIds . remove ( msgId ) ; if ( asynchMgr != null ) asynchMgr . timeout ( ) ; }", "nl": "Removes a response manager because in timeout ."}}
{"translation": {"code": "private boolean isFromClusters ( ORid rid , Set < String > filterClusters , ODatabase database ) { if ( filterClusters == null ) { throw new IllegalArgumentException ( ) ; } String clusterName = database . getClusterNameById ( rid . getCluster ( ) . getValue ( ) . intValue ( ) ) ; return filterClusters . contains ( clusterName ) ; }", "nl": "checks if this RID is from one of these clusters"}}
{"translation": {"code": "public void commit ( ) { if ( ! active ) throw error ( \"Inactive micro-transaction on commit\" ) ; if ( level < 1 ) throw error ( \"Unbalanced micro-transaction, level = \" + level ) ; -- level ; if ( level == 0 ) { active = false ; doCommit ( ) ; } }", "nl": "Commits the micro - transaction if it s a top - level micro - transaction ."}}
{"translation": {"code": "public static void atomicMoveWithFallback ( Path source , Path target , Object requester ) throws IOException { try { Files . move ( source , target , StandardCopyOption . ATOMIC_MOVE ) ; } catch ( AtomicMoveNotSupportedException ignore ) { OLogManager . instance ( ) . warn ( requester , \"atomic file move is not possible, falling back to regular move (moving '%s' to '%s')\" , source , target ) ; Files . move ( source , target ) ; } }", "nl": "Tries to move a file from the source to the target atomically . If atomic move is not possible falls back to regular move ."}}
{"translation": {"code": "void truncate ( long pageIndex ) throws IOException { synchronized ( lockObject ) { lastAccessTime = System . nanoTime ( ) ; flushBuffer ( ) ; lastWrittenPageIndex = - 1 ; lastWrittenPage = null ; segChannel . truncate ( pageIndex * OWALPage . PAGE_SIZE ) ; } }", "nl": "Flushes all buffered pages and truncates file till passed in page index"}}
{"translation": {"code": "public void executeImport ( ODocument cfg , OServer server ) { OETLJob job = new OETLJob ( cfg , server , new OETLListener ( ) { @ Override public void onEnd ( OETLJob etlJob ) { currentJob = null ; } } ) ; job . validate ( ) ; currentJob = job ; pool . execute ( job ) ; }", "nl": "Executes import with configuration ;"}}
{"translation": {"code": "protected int getBestResponsesGroup ( ) { int maxCoherentResponses = 0 ; int bestGroupSoFar = 0 ; for ( int i = 0 ; i < responseGroups . size ( ) ; ++ i ) { final int currentGroupSize = responseGroups . get ( i ) . size ( ) ; if ( currentGroupSize > maxCoherentResponses ) { maxCoherentResponses = currentGroupSize ; bestGroupSoFar = i ; } } return bestGroupSoFar ; }", "nl": "Returns the biggest response group ."}}
{"translation": {"code": "protected List < ODistributedResponse > getReceivedResponses ( ) { final List < ODistributedResponse > parsed = new ArrayList < ODistributedResponse > ( ) ; for ( Object r : responses . values ( ) ) if ( r != NO_RESPONSE ) parsed . add ( ( ODistributedResponse ) r ) ; return parsed ; }", "nl": "Returns the received response objects ."}}
{"translation": {"code": "protected List < ODistributedResponse > getConflictResponses ( ) { final List < ODistributedResponse > servers = new ArrayList < ODistributedResponse > ( ) ; int bestGroupSoFar = getBestResponsesGroup ( ) ; for ( int i = 0 ; i < responseGroups . size ( ) ; ++ i ) { if ( i != bestGroupSoFar ) { for ( ODistributedResponse r : responseGroups . get ( i ) ) servers . ( r ) ; } } return servers ; }", "nl": "Returns all the responses in conflict ."}}
{"translation": {"code": "public String printExceptionStackTrace ( Exception e , String level ) { // copying the exception stack trace in the string Writer writer = new StringWriter ( ) ; e . printStackTrace ( new PrintWriter ( writer ) ) ; String s = writer . toString ( ) ; switch ( level ) { case \"debug\" : this . messageHandler . debug ( this , \"\\n\" + s + \"\\n\" ) ; break ; case \"info\" : this . messageHandler . info ( this , \"\\n\" + s + \"\\n\" ) ; break ; case \"warn\" : this . messageHandler . warn ( this , \"\\n\" + s + \"\\n\" ) ; break ; case \"error\" : this . messageHandler . error ( this , \"\\n\" + s + \"\\n\" ) ; break ; } return s ; }", "nl": "Builds the exception stack trace and prints it according to a level passed as argument ."}}
{"translation": {"code": "public static ODocument buildJsonFromFile ( String filePath ) throws IOException { if ( filePath == null ) { return null ; } File jsonFile = new File ( filePath ) ; if ( ! jsonFile . exists ( ) ) { return null ; } FileInputStream is = new FileInputStream ( jsonFile ) ; BufferedReader rd = new BufferedReader ( new InputStreamReader ( is , Charset . forName ( \"UTF-8\" ) ) ) ; ODocument json = new ODocument ( ) ; String jsonText = OFileManager . readAllTextFile ( rd ) ; json . fromJSON ( jsonText , \"noMap\" ) ; return json ; }", "nl": "It returns a ODocument starting from a json file ."}}
{"translation": {"code": "public boolean tryAcquireReadLock ( long timeout ) { final OModifiableInteger lHolds = lockHolds . get ( ) ; final int holds = lHolds . intValue ( ) ; if ( holds > 0 ) { // we have already acquire read lock lHolds . increment ( ) ; return true ; } else if ( holds < 0 ) { // write lock is acquired before, do nothing return true ; } distributedCounter . increment ( ) ; WNode wNode = tail . get ( ) ; final long start = System . nanoTime ( ) ; while ( wNode . locked ) { distributedCounter . decrement ( ) ; while ( wNode . locked && wNode == tail . get ( ) ) { wNode . waitingReaders . put ( Thread . currentThread ( ) , Boolean . TRUE ) ; if ( wNode . locked && wNode == tail . get ( ) ) { final long parkTimeout = timeout - ( System . nanoTime ( ) - start ) ; if ( parkTimeout > 0 ) { LockSupport . parkNanos ( this , parkTimeout ) ; } else { return false ; } } wNode = tail . get ( ) ; if ( System . nanoTime ( ) - start > timeout ) { return false ; } } distributedCounter . increment ( ) ; wNode = tail . get ( ) ; if ( System . nanoTime ( ) - start > timeout ) { distributedCounter . decrement ( ) ; return false ; } } lHolds . increment ( ) ; assert lHolds . intValue ( ) == 1 ; return true ; }", "nl": "Tries to acquire lock during provided interval of time and returns either if provided time interval was passed or if lock was acquired ."}}
{"translation": {"code": "protected void initSystemDatabase ( ) { final ODocument defaultCfg = getStorage ( OSystemDatabase . SYSTEM_DB_NAME ) . loadDatabaseConfiguration ( getDefaultDatabaseConfigFile ( ) ) ; defaultCfg . field ( \"autoDeploy\" , false ) ; final OModifiableDistributedConfiguration sysCfg = new OModifiableDistributedConfiguration ( defaultCfg ) ; sysCfg . removeServer ( \"<NEW_NODE>\" ) ; messageService . registerDatabase ( OSystemDatabase . SYSTEM_DB_NAME , sysCfg ) ; sysCfg . addNewNodeInServerList ( getLocalNodeName ( ) ) ; }", "nl": "Protecte system database from being replicated"}}
{"translation": {"code": "public static OExecutionPlan get ( String statement , OCommandContext ctx , ODatabaseDocumentInternal db ) { if ( db == null ) { throw new IllegalArgumentException ( \"DB cannot be null\" ) ; } if ( statement == null ) { return null ; } OExecutionPlanCache resource = db . getSharedContext ( ) . getExecutionPlanCache ( ) ; OExecutionPlan result = resource . getInternal ( statement , ctx , db ) ; return result ; }", "nl": "returns an already prepared SQL execution plan taking it from the cache if it exists or creating a new one if it doesn t"}}
{"translation": {"code": "private static boolean checkChangesFilledUpTo ( final FileChanges changesContainer , final long pageIndex ) { if ( changesContainer == null ) { return true ; } else if ( changesContainer . isNew || changesContainer . maxNewPageIndex > - 2 ) { return pageIndex < changesContainer . maxNewPageIndex + 1 ; } else return ! changesContainer . truncate ; }", "nl": "This check if a file was trimmed or trunked in the current atomic operation ."}}
{"translation": {"code": "private List < RecordInfo > getPositionsFromEmbeddedCollection ( final BytesContainer bytes , int serializerVersion ) { List < RecordInfo > retList = new ArrayList <> ( ) ; int numberOfElements = OVarIntSerializer . readAsInteger ( bytes ) ; //read collection type readByte ( bytes ) ; for ( int i = 0 ; i < numberOfElements ; i ++ ) { //read element //read data type       OType dataType = readOType ( bytes , false ) ; int fieldStart = bytes . offset ; RecordInfo fieldInfo = new RecordInfo ( ) ; fieldInfo . fieldStartOffset = fieldStart ; fieldInfo . fieldType = dataType ; //TODO find better way to skip data bytes; deserializeValue ( bytes , dataType , null , true , - 1 , serializerVersion , true ) ; fieldInfo . fieldLength = bytes . offset - fieldStart ; retList . add ( fieldInfo ) ; } return retList ; }", "nl": "returns begin position and length for each value in embedded collection"}}
{"translation": {"code": "private boolean requiresMultipleIndexLookups ( OAndBlock keyCondition ) { for ( OBooleanExpression oBooleanExpression : keyCondition . getSubBlocks ( ) ) { if ( ! ( oBooleanExpression instanceof OBinaryCondition ) ) { return true ; } } return false ; }", "nl": "checks whether the condition has CONTAINSANY or similar expressions that require multiple index evaluations"}}
{"translation": {"code": "private Tuple < Integer , OType > getFieldSizeAndTypeFromCurrentPosition ( BytesContainer bytes ) { int fieldSize = OVarIntSerializer . readAsInteger ( bytes ) ; OType type = readOType ( bytes , false ) ; return new Tuple <> ( fieldSize , type ) ; }", "nl": "use only for named fields"}}
{"translation": {"code": "public int getOpenFilesLimit ( boolean verbose , int recommended , int defLimit ) { if ( Platform . isLinux ( ) ) { final OCLibrary . Rlimit rlimit = new OCLibrary . Rlimit ( ) ; final int result = C_LIBRARY . getrlimit ( OCLibrary . RLIMIT_NOFILE , rlimit ) ; if ( result == 0 && rlimit . rlim_cur > 0 ) { if ( verbose ) { OLogManager . instance ( ) . infoNoDb ( this , \"Detected limit of amount of simultaneously open files is %d, \" + \" limit of open files for disk cache will be set to %d\" , rlimit . rlim_cur , rlimit . rlim_cur / 2 - 512 ) ; } if ( rlimit . rlim_cur < recommended ) { OLogManager . instance ( ) . warnNoDb ( this , \"Value of limit of simultaneously open files is too small, recommended value is %d\" , recommended ) ; } return ( int ) rlimit . rlim_cur / 2 - 512 ; } else { if ( verbose ) { OLogManager . instance ( ) . infoNoDb ( this , \"Can not detect value of limit of open files.\" ) ; } } } else if ( Platform . isWindows ( ) ) { if ( verbose ) { OLogManager . instance ( ) . infoNoDb ( this , \"Windows OS is detected, %d limit of open files will be set for the disk cache.\" , recommended ) ; } return recommended ; } if ( verbose ) { OLogManager . instance ( ) . infoNoDb ( this , \"Default limit of open files (%d) will be used.\" , defLimit ) ; } return defLimit ; }", "nl": "Detects limit of limit of open files ."}}
{"translation": {"code": "public boolean swap ( int index , OIdentifiable newValue ) { EntriesIterator iter = ( EntriesIterator ) rawIterator ( ) ; int currIndex = 0 ; while ( iter . hasNext ( ) ) { iter . next ( ) ; if ( index == currIndex ) { iter . swapValueOnCurrent ( newValue ) ; return true ; } currIndex ++ ; } return false ; }", "nl": "for internal use only"}}
{"translation": {"code": "@ Override public void enqueueRepairRecord ( final ORecordId rid ) { if ( ! active ) return ; if ( rid == null || ! rid . isPersistent ( ) ) return ; if ( rid . getClusterPosition ( ) < - 1 ) // SKIP TRANSACTIONAL RIDS return ; recordProcessed . incrementAndGet ( ) ; // ADD RECORD TO REPAIR records . put ( rid , Boolean . TRUE ) ; }", "nl": "Adds the record to repair int the map of records and cluster . The decision about repairing is taken by the timer task ."}}
{"translation": {"code": "public void initDatabaseInstance ( ) { if ( database == null ) { for ( int retry = 0 ; retry < 100 ; ++ retry ) { try { database = distributed . getDatabaseInstance ( ) ; // OK break ; } catch ( OStorageException e ) { // WAIT FOR A WHILE, THEN RETRY if ( ! dbNotAvailable ( retry ) ) return ; } catch ( OConfigurationException e ) { // WAIT FOR A WHILE, THEN RETRY if ( ! dbNotAvailable ( retry ) ) return ; } } if ( database == null ) { ODistributedServerLog . info ( this , manager . getLocalNodeName ( ) , null , DIRECTION . NONE , \"Database '%s' not present, shutting down database manager\" , databaseName ) ; distributed . shutdown ( ) ; throw new ODistributedException ( \"Cannot open database '\" + databaseName + \"'\" ) ; } } else if ( database . isClosed ( ) ) { // DATABASE CLOSED, REOPEN IT database . activateOnCurrentThread ( ) ; database . close ( ) ; database = distributed . getDatabaseInstance ( ) ; } }", "nl": "Opens the database ."}}
{"translation": {"code": "protected void initCheckDisconnect ( ) { disconnectTimer = new TimerTask ( ) { public void run ( ) { try { checkIfKnownServersAreAlive ( ) ; if ( running ) { initCheckDisconnect ( ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; } } } ; taskScheduler . scheduleOnce ( disconnectTimer , discoveryPingIntervalMillis ) ; }", "nl": "inits the procedure that checks if a server is no longer available ie . if he did not ping for a long time"}}
{"translation": {"code": "public ORecordHook . RESULT callbackHooks ( final ORecordHook . TYPE type , final OIdentifiable id ) { if ( id == null || hooks . isEmpty ( ) || id . getIdentity ( ) . getClusterId ( ) == 0 ) return ORecordHook . RESULT . RECORD_NOT_CHANGED ; final ORecordHook . SCOPE scope = ORecordHook . SCOPE . typeToScope ( type ) ; final int scopeOrdinal = scope . ordinal ( ) ; final ORID identity = id . getIdentity ( ) . copy ( ) ; if ( ! pushInHook ( identity ) ) return ORecordHook . RESULT . RECORD_NOT_CHANGED ; try { final ORecord rec = id . getRecord ( ) ; if ( rec == null ) return ORecordHook . RESULT . RECORD_NOT_CHANGED ; final OScenarioThreadLocal . RUN_MODE runMode = OScenarioThreadLocal . INSTANCE . getRunMode ( ) ; boolean recordChanged = false ; for ( ORecordHook hook : hooksByScope [ scopeOrdinal ] ) { switch ( runMode ) { case DEFAULT : // NON_DISTRIBUTED OR PROXIED DB if ( getStorage ( ) . isDistributed ( ) && hook . getDistributedExecutionMode ( ) == ORecordHook . DISTRIBUTED_EXECUTION_MODE . TARGET_NODE ) // SKIP continue ; break ; // TARGET NODE case RUNNING_DISTRIBUTED : if ( hook . getDistributedExecutionMode ( ) == ORecordHook . DISTRIBUTED_EXECUTION_MODE . SOURCE_NODE ) continue ; } final ORecordHook . RESULT res = hook . onTrigger ( type , rec ) ; if ( res == ORecordHook . RESULT . RECORD_CHANGED ) recordChanged = true ; else if ( res == ORecordHook . RESULT . SKIP_IO ) // SKIP IO OPERATION return res ; else if ( res == ORecordHook . RESULT . SKIP ) // SKIP NEXT HOOKS AND RETURN IT return res ; else if ( res == ORecordHook . RESULT . RECORD_REPLACED ) return res ; } return recordChanged ? ORecordHook . RESULT . RECORD_CHANGED : ORecordHook . RESULT . RECORD_NOT_CHANGED ; } finally { popInHook ( identity ) ; } }", "nl": "Callback the registered hooks if any ."}}
{"translation": {"code": "public ODatabaseDocument delete ( final ORID iRecord ) { checkOpenness ( ) ; checkIfActive ( ) ; final ORecord rec = load ( iRecord ) ; if ( rec != null ) delete ( rec ) ; return this ; }", "nl": "Deletes the record without checking the version ."}}
{"translation": {"code": "@ Override public ODocument toStream ( ) { internalAcquireExclusiveLock ( ) ; try { document . setInternalStatus ( ORecordElement . STATUS . UNMARSHALLING ) ; try { final OTrackedSet < ODocument > indexes = new OTrackedSet <> ( document ) ; for ( final OIndex < ? > i : this . indexes . values ( ) ) { indexes . add ( ( ( OIndexInternal < ? > ) i ) . updateConfiguration ( ) ) ; } document . field ( CONFIG_INDEXES , indexes , OType . EMBEDDEDSET ) ; } finally { document . setInternalStatus ( ORecordElement . STATUS . LOADED ) ; } document . setDirty ( ) ; return document ; } finally { internalReleaseExclusiveLock ( ) ; } }", "nl": "Binds POJO to ODocument ."}}
{"translation": {"code": "public ODatabase < ORecord > delete ( final ORID iRecord , final int iVersion ) { ORecord record = load ( iRecord ) ; ORecordInternal . setVersion ( record , iVersion ) ; delete ( record ) ; return this ; }", "nl": "Deletes the record checking the version ."}}
{"translation": {"code": "@ Override public OIndexFullText put ( Object key , final OIdentifiable singleValue ) { if ( key == null ) { return this ; } key = getCollatingValue ( key ) ; final Set < String > words = splitIntoWords ( key . toString ( ) ) ; // FOREACH WORD CREATE THE LINK TO THE CURRENT DOCUMENT for ( final String word : words ) { acquireSharedLock ( ) ; try { if ( apiVersion == 0 ) { doPutV0 ( singleValue , word ) ; } else if ( apiVersion == 1 ) { doPutV1 ( singleValue , word ) ; } else { throw new IllegalStateException ( \"Invalid API version, \" + apiVersion ) ; } } finally { releaseSharedLock ( ) ; } } return this ; }", "nl": "Indexes a value and save the index . Splits the value in single words and index each one . Save of the index is responsibility of the caller ."}}
{"translation": {"code": "public OUser authenticate ( final OToken authToken ) { final String dbName = getDatabase ( ) . getName ( ) ; if ( authToken . getIsValid ( ) != true ) { throw new OSecurityAccessException ( dbName , \"Token not valid\" ) ; } OUser user = authToken . getUser ( getDatabase ( ) ) ; if ( user == null && authToken . getUserName ( ) != null ) { // Token handler may not support returning an OUser so let's get username (subject) and query: user = getUser ( authToken . getUserName ( ) ) ; } if ( user == null ) { throw new OSecurityAccessException ( dbName , \"Authentication failed, could not load user from token\" ) ; } if ( user . getAccountStatus ( ) != STATUSES . ACTIVE ) throw new OSecurityAccessException ( dbName , \"User '\" + user . getName ( ) + \"' is not active\" ) ; return user ; }", "nl": "Token MUST be validated before being passed to this method ."}}
{"translation": {"code": "@ Override public boolean remove ( Object key , final OIdentifiable value ) { if ( key == null ) { return false ; } key = getCollatingValue ( key ) ; final Set < String > words = splitIntoWords ( key . toString ( ) ) ; final OModifiableBoolean removed = new OModifiableBoolean ( false ) ; for ( final String word : words ) { acquireSharedLock ( ) ; try { if ( apiVersion == 0 ) { removeV0 ( value , removed , word ) ; } else if ( apiVersion == 1 ) { removeV1 ( value , removed , word ) ; } else { throw new IllegalStateException ( \"Invalid API version, \" + apiVersion ) ; } } finally { releaseSharedLock ( ) ; } } return removed . getValue ( ) ; }", "nl": "Splits passed in key on several words and remove records with keys equals to any item of split result and values equals to passed in value ."}}
{"translation": {"code": "private void initShutdownQueue ( ) { addShutdownHandler ( new OShutdownWorkersHandler ( ) ) ; addShutdownHandler ( new OShutdownOrientDBInstancesHandler ( ) ) ; addShutdownHandler ( new OShutdownPendingThreadsHandler ( ) ) ; addShutdownHandler ( new OShutdownProfilerHandler ( ) ) ; addShutdownHandler ( new OShutdownCallListenersHandler ( ) ) ; }", "nl": "Adds shutdown handlers in order which will be used during execution of shutdown ."}}
{"translation": {"code": "public Object command ( final OCommandRequestText iCommand ) { final boolean live = iCommand instanceof OLiveQuery ; final ODatabaseDocumentInternal database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; final boolean asynch = iCommand instanceof OCommandRequestAsynch && ( ( OCommandRequestAsynch ) iCommand ) . isAsynchronous ( ) ; OCommandRequest request = new OCommandRequest ( database , asynch , iCommand , live ) ; OCommandResponse response = networkOperation ( request , \"Error on executing command: \" + iCommand ) ; return response . getResult ( ) ; }", "nl": "Execute the command remotely and get the results back ."}}
{"translation": {"code": "protected String addHost ( String host ) { if ( host . startsWith ( LOCALHOST ) ) host = LOCAL_IP + host . substring ( \"localhost\" . length ( ) ) ; if ( host . contains ( \"/\" ) ) host = host . substring ( 0 , host . indexOf ( \"/\" ) ) ; // REGISTER THE REMOTE SERVER+PORT if ( ! host . contains ( \":\" ) ) host += \":\" + ( clientConfiguration . getValueAsBoolean ( OGlobalConfiguration . CLIENT_USE_SSL ) ? getDefaultSSLPort ( ) : getDefaultPort ( ) ) ; else if ( host . split ( \":\" ) . length < 2 || host . split ( \":\" ) [ 1 ] . trim ( ) . length ( ) == 0 ) host += ( clientConfiguration . getValueAsBoolean ( OGlobalConfiguration . CLIENT_USE_SSL ) ? getDefaultSSLPort ( ) : getDefaultPort ( ) ) ; // DISABLED BECAUSE THIS DID NOT ALLOW TO CONNECT TO LOCAL HOST ANYMORE IF THE SERVER IS BOUND TO 127.0.0.1 // CONVERT 127.0.0.1 TO THE PUBLIC IP IF POSSIBLE // if (host.startsWith(LOCAL_IP)) { // try { // final String publicIP = InetAddress.getLocalHost().getHostAddress(); // host = publicIP + host.substring(LOCAL_IP.length()); // } catch (UnknownHostException e) { // // IGNORE IT // } // } synchronized ( serverURLs ) { if ( ! serverURLs . contains ( host ) ) { serverURLs . add ( host ) ; OLogManager . instance ( ) . debug ( this , \"Registered the new available server '%s'\" , host ) ; } } return host ; }", "nl": "Registers the remote server with port ."}}
{"translation": {"code": "public OChannelBinaryAsynchClient beginRequest ( final OChannelBinaryAsynchClient network , final byte iCommand , OStorageRemoteSession session ) throws IOException { network . beginRequest ( iCommand , session ) ; return network ; }", "nl": "Acquire a network channel from the pool . Don t lock the write stream since the connection usage is exclusive ."}}
{"translation": {"code": "private void reset ( ) { int count = 0 ; for ( int i = 0 ; i < table . length ; i ++ ) { count += Long . bitCount ( table [ i ] & ONE_MASK ) ; table [ i ] = ( table [ i ] >>> 1 ) & RESET_MASK ; } size = ( size >>> 1 ) - ( count >>> 2 ) ; }", "nl": "Reduces every counter by half of its original value ."}}
{"translation": {"code": "private int spread ( int x ) { x = ( ( x >>> 16 ) ^ x ) * 0x45d9f3b ; x = ( ( x >>> 16 ) ^ x ) * randomSeed ; return ( x >>> 16 ) ^ x ; }", "nl": "Applies a supplemental hash function to a given hashCode which defends against poor quality hash functions ."}}
{"translation": {"code": "public OClientConnection getConnection ( final int iChannelId , ONetworkProtocol protocol ) { // SEARCH THE CONNECTION BY ID OClientConnection connection = connections . get ( iChannelId ) ; if ( connection != null ) connection . setProtocol ( protocol ) ; return connection ; }", "nl": "Retrieves the connection by id ."}}
{"translation": {"code": "public void pushDistribCfg2Clients ( final ODocument iConfig ) { if ( iConfig == null ) return ; final Set < String > pushed = new HashSet < String > ( ) ; for ( OClientConnection c : connections . values ( ) ) { if ( ! c . getData ( ) . supportsLegacyPushMessages ) continue ; try { final String remoteAddress = c . getRemoteAddress ( ) ; if ( pushed . contains ( remoteAddress ) ) // ALREADY SENT: JUMP IT continue ; } catch ( Exception e ) { // SOCKET EXCEPTION SKIP IT continue ; } if ( ! ( c . getProtocol ( ) instanceof ONetworkProtocolBinary ) || c . getData ( ) . getSerializationImpl ( ) == null ) // INVOLVE ONLY BINARY PROTOCOLS continue ; final ONetworkProtocolBinary p = ( ONetworkProtocolBinary ) c . getProtocol ( ) ; final OChannelBinary channel = p . getChannel ( ) ; final ORecordSerializer ser = ORecordSerializerFactory . instance ( ) . getFormat ( c . getData ( ) . getSerializationImpl ( ) ) ; if ( ser == null ) return ; final byte [ ] content = ser . toStream ( iConfig , false ) ; try { // TRY ACQUIRING THE LOCK FOR MAXIMUM 3 SECS TO AVOID TO FREEZE CURRENT THREAD if ( channel . tryAcquireWriteLock ( TIMEOUT_PUSH ) ) { try { channel . writeByte ( OChannelBinaryProtocol . PUSH_DATA ) ; channel . writeInt ( Integer . MIN_VALUE ) ; channel . writeByte ( OChannelBinaryProtocol . REQUEST_PUSH_DISTRIB_CONFIG ) ; channel . writeBytes ( content ) ; channel . flush ( ) ; pushed . add ( c . getRemoteAddress ( ) ) ; OLogManager . instance ( ) . debug ( this , \"Sent updated cluster configuration to the remote client %s\" , c . getRemoteAddress ( ) ) ; } finally { channel . releaseWriteLock ( ) ; } } else { OLogManager . instance ( ) . info ( this , \"Timeout on sending updated cluster configuration to the remote client %s\" , c . getRemoteAddress ( ) ) ; } } catch ( Exception e ) { OLogManager . instance ( ) . warn ( this , \"Cannot push cluster configuration to the client %s\" , e , c . getRemoteAddress ( ) ) ; } } }", "nl": "Pushes the distributed configuration to all the connected clients ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( newRecords == null && content == null && subQuery == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final OCommandParameters commandParameters = new OCommandParameters ( iArgs ) ; if ( indexName != null ) { if ( newRecords == null ) throw new OCommandExecutionException ( \"No key/value found\" ) ; final OIndex < ? > index = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . getIndex ( indexName ) ; if ( index == null ) throw new OCommandExecutionException ( \"Target index '\" + indexName + \"' not found\" ) ; // BIND VALUES Map < String , Object > result = new HashMap < String , Object > ( ) ; for ( Map < String , Object > candidate : newRecords ) { Object indexKey = getIndexKeyValue ( commandParameters , candidate ) ; OIdentifiable indexValue = getIndexValue ( commandParameters , candidate ) ; if ( index instanceof OIndexMultiValues ) { final Collection < ORID > rids = ( ( OIndexMultiValues ) index ) . get ( indexKey ) ; if ( ! rids . contains ( indexValue . getIdentity ( ) ) ) { index . put ( indexKey , indexValue ) ; } } else { index . put ( indexKey , indexValue ) ; } result . put ( KEYWORD_KEY , indexKey ) ; result . put ( KEYWORD_RID , indexValue ) ; } // RETURN LAST ENTRY return prepareReturnItem ( new ODocument ( result ) ) ; } else { // CREATE NEW DOCUMENTS final List < ODocument > docs = new ArrayList < ODocument > ( ) ; if ( newRecords != null ) { for ( Map < String , Object > candidate : newRecords ) { final ODocument doc = className != null ? new ODocument ( className ) : new ODocument ( ) ; OSQLHelper . bindParameters ( doc , candidate , commandParameters , context ) ; saveRecord ( doc ) ; docs . add ( doc ) ; } if ( docs . size ( ) == 1 ) return prepareReturnItem ( docs . get ( 0 ) ) ; else return prepareReturnResult ( docs ) ; } else if ( content != null ) { final ODocument doc = className != null ? new ODocument ( className ) : new ODocument ( ) ; doc . merge ( content , true , false ) ; saveRecord ( doc ) ; return prepareReturnItem ( doc ) ; } else if ( subQuery != null ) { subQuery . execute ( ) ; if ( queryResult != null ) return prepareReturnResult ( queryResult ) ; return saved . longValue ( ) ; } } return null ; }", "nl": "Execute the INSERT and return the ODocument object created ."}}
{"translation": {"code": "@ SuppressWarnings ( \"rawtypes\" ) public Object execute ( final Map < Object , Object > iArgs ) { if ( indexName == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final ODatabaseDocument database = getDatabase ( ) ; final OIndex < ? > idx ; List < OCollate > collatesList = null ; if ( collates != null ) { collatesList = new ArrayList < OCollate > ( ) ; for ( String collate : collates ) { if ( collate != null ) { final OCollate col = OSQLEngine . getCollate ( collate ) ; collatesList . add ( col ) ; } else collatesList . add ( null ) ; } } if ( fields == null || fields . length == 0 ) { OIndexFactory factory = OIndexes . getFactory ( indexType . toString ( ) , null ) ; if ( keyTypes != null ) idx = database . getMetadata ( ) . getIndexManager ( ) . createIndex ( indexName , indexType . toString ( ) , new OSimpleKeyIndexDefinition ( keyTypes , collatesList ) , null , null , metadataDoc , engine ) ; else if ( serializerKeyId != 0 ) { idx = database . getMetadata ( ) . getIndexManager ( ) . createIndex ( indexName , indexType . toString ( ) , new ORuntimeKeyIndexDefinition ( serializerKeyId ) , null , null , metadataDoc , engine ) ; } else { throw new ODatabaseException ( \"Impossible to create an index without specify the key type or the associated property\" ) ; } } else { if ( ( keyTypes == null || keyTypes . length == 0 ) && collates == null ) { idx = oClass . createIndex ( indexName , indexType . toString ( ) , null , metadataDoc , engine , fields ) ; } else { final List < OType > fieldTypeList ; if ( keyTypes == null ) { for ( final String fieldName : fields ) { if ( ! fieldName . equals ( \"@rid\" ) && ! oClass . existsProperty ( fieldName ) ) throw new OIndexException ( \"Index with name : '\" + indexName + \"' cannot be created on class : '\" + oClass . getName ( ) + \"' because field: '\" + fieldName + \"' is absent in class definition.\" ) ; } fieldTypeList = ( ( OClassImpl ) oClass ) . extractFieldTypes ( fields ) ; } else fieldTypeList = Arrays . asList ( keyTypes ) ; final OIndexDefinition idxDef = OIndexDefinitionFactory . createIndexDefinition ( oClass , Arrays . asList ( fields ) , fieldTypeList , collatesList , indexType . toString ( ) , null ) ; idx = database . getMetadata ( ) . getIndexManager ( ) . createIndex ( indexName , indexType . name ( ) , idxDef , oClass . getPolymorphicClusterIds ( ) , null , metadataDoc , engine ) ; } } if ( idx != null ) return idx . getSize ( ) ; return null ; }", "nl": "Execute the CREATE INDEX ."}}
{"translation": {"code": "private void processBrokenRids ( Set < ORID > brokenRids ) throws IOException , ParseException { if ( exporterVersion >= 12 ) { listener . onMessage ( \"Reading of set of RIDs of records which were detected as broken during database export\\n\" ) ; jsonReader . readNext ( OJSONReader . BEGIN_COLLECTION ) ; while ( true ) { jsonReader . readNext ( OJSONReader . NEXT_IN_ARRAY ) ; final ORecordId recordId = new ORecordId ( jsonReader . getValue ( ) ) ; brokenRids . add ( recordId ) ; if ( jsonReader . lastChar ( ) == ' ' ) break ; } } if ( migrateLinks ) { if ( exporterVersion >= 12 ) listener . onMessage ( brokenRids . size ( ) + \" were detected as broken during database export, links on those records will be removed from\" + \" result database\" ) ; migrateLinksInImportedDocuments ( brokenRids ) ; } }", "nl": "just read collection so import process can continue"}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) public < T > OBinarySerializer < T > getObjectSerializer ( final OType type ) { return ( OBinarySerializer < T > ) serializerTypeMap . get ( type ) ; }", "nl": "Obtain OBinarySerializer realization for the OType"}}