{"translation": {"code": "public int getAsByteArrayOffset ( ) { if ( position >= length ) return - 1 ; final int begin = position ; final int size = OBinaryProtocol . bytes2int ( buffer , position ) ; position += OBinaryProtocol . SIZE_INT + size ; return begin ; }", "nl": "Browse the stream but just return the begin of the byte array . This is used to lazy load the information only when needed ."}}
{"translation": {"code": "@ Override public void close ( ) { if ( isClosed ( ) ) return ; checkOpenness ( ) ; if ( ownerPool != null && ownerPool . getConnectionsInCurrentThread ( getURL ( ) , userName ) > 1 ) { ownerPool . release ( this ) ; return ; } try { commit ( true ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error on releasing database '%s' in pool\" , e , getName ( ) ) ; } try { callOnCloseListeners ( ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error on releasing database '%s' in pool\" , e , getName ( ) ) ; } getLocalCache ( ) . clear ( ) ; if ( ownerPool != null ) { final ODatabaseDocumentPool localCopy = ownerPool ; ownerPool = null ; localCopy . release ( this ) ; } ODatabaseRecordThreadLocal . instance ( ) . remove ( ) ; }", "nl": "Avoid to close it but rather release itself to the owner pool ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( className == null ) { throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; } final ODatabaseDocument database = getDatabase ( ) ; if ( ifExists && ! database . getMetadata ( ) . getSchema ( ) . existsClass ( className ) ) { return true ; } final OClass cls = database . getMetadata ( ) . getSchema ( ) . getClass ( className ) ; if ( cls == null ) { return null ; } final long records = cls . count ( true ) ; if ( records > 0 && ! unsafe ) { // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r if ( cls . isSubClassOf ( \"V\" ) ) { // FOUND VERTEX CLASS\r throw new OCommandExecutionException ( \"'DROP CLASS' command cannot drop class '\" + className + \"' because it contains Vertices. Use 'DELETE VERTEX' command first to avoid broken edges in a database, or apply the 'UNSAFE' keyword to force it\" ) ; } else if ( cls . isSubClassOf ( \"E\" ) ) { // FOUND EDGE CLASS\r throw new OCommandExecutionException ( \"'DROP CLASS' command cannot drop class '\" + className + \"' because it contains Edges. Use 'DELETE EDGE' command first to avoid broken vertices in a database, or apply the 'UNSAFE' keyword to force it\" ) ; } } database . getMetadata ( ) . getSchema ( ) . dropClass ( className ) ; if ( records > 0 && unsafe ) { // NOT EMPTY, CHECK IF CLASS IS OF VERTEX OR EDGES\r if ( cls . isSubClassOf ( \"V\" ) ) { // FOUND VERTICES\r if ( unsafe ) OLogManager . instance ( ) . warn ( this , \"Dropped class '%s' containing %d vertices using UNSAFE mode. Database could contain broken edges\" , className , records ) ; } else if ( cls . isSubClassOf ( \"E\" ) ) { // FOUND EDGES\r OLogManager . instance ( ) . warn ( this , \"Dropped class '%s' containing %d edges using UNSAFE mode. Database could contain broken vertices\" , className , records ) ; } } return true ; }", "nl": "Execute the DROP CLASS ."}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) public boolean result ( final Object iRecord ) { final ODocument record = ( ( OIdentifiable ) iRecord ) . getRecord ( ) ; if ( isUpdateEdge ( ) && ! isRecordInstanceOf ( iRecord , \"E\" ) ) { throw new OCommandExecutionException ( \"Using UPDATE EDGE on a record that is not an instance of E\" ) ; } if ( compiledFilter != null ) { // ADDITIONAL FILTERING\r if ( ! ( Boolean ) compiledFilter . evaluate ( record , null , context ) ) return false ; } parameters . reset ( ) ; returnHandler . beforeUpdate ( record ) ; boolean updated = handleContent ( record ) ; updated |= handleMerge ( record ) ; updated |= handleSetEntries ( record ) ; updated |= handleIncrementEntries ( record ) ; updated |= handleAddEntries ( record ) ; updated |= handlePutEntries ( record ) ; updated |= handleRemoveEntries ( record ) ; if ( updated ) { handleUpdateEdge ( record ) ; record . setDirty ( ) ; record . save ( ) ; returnHandler . afterUpdate ( record ) ; this . updated = true ; } return true ; }", "nl": "Update current record ."}}
{"translation": {"code": "public boolean result ( final Object iRecord ) { final ORecordAbstract record = ( ( OIdentifiable ) iRecord ) . getRecord ( ) ; if ( record instanceof ODocument && compiledFilter != null && ! Boolean . TRUE . equals ( this . compiledFilter . evaluate ( record , ( ODocument ) record , getContext ( ) ) ) ) { return true ; } try { if ( record . getIdentity ( ) . isValid ( ) ) { if ( returning . equalsIgnoreCase ( \"BEFORE\" ) ) allDeletedRecords . add ( record ) ; // RESET VERSION TO DISABLE MVCC AVOIDING THE CONCURRENT EXCEPTION IF LOCAL CACHE IS NOT UPDATED\r //        ORecordInternal.setVersion(record, -1);\r if ( ! unsafe && record instanceof ODocument ) { // CHECK IF ARE VERTICES OR EDGES\r final OClass cls = ( ( ODocument ) record ) . getSchemaClass ( ) ; if ( cls != null ) { if ( cls . isSubClassOf ( \"V\" ) ) // FOUND VERTEX\r throw new OCommandExecutionException ( \"'DELETE' command cannot delete vertices. Use 'DELETE VERTEX' command instead, or apply the 'UNSAFE' keyword to force it\" ) ; else if ( cls . isSubClassOf ( \"E\" ) ) // FOUND EDGE\r throw new OCommandExecutionException ( \"'DELETE' command cannot delete edges. Use 'DELETE EDGE' command instead, or apply the 'UNSAFE' keyword to force it\" ) ; } } record . delete ( ) ; recordCount ++ ; return true ; } return false ; } finally { if ( lockStrategy . equalsIgnoreCase ( \"RECORD\" ) ) ( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) ) . releaseWriteLock ( record . getIdentity ( ) ) ; } }", "nl": "Deletes the current record ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( recordIds . isEmpty ( ) && subQuery == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; if ( subQuery != null ) { final List < OIdentifiable > result = new OCommandSQL ( subQuery . toString ( ) ) . execute ( ) ; for ( OIdentifiable id : result ) recordIds . ( id . getIdentity ( ) ) ; } return OFindReferenceHelper . findReferences ( recordIds , classList ) ; }", "nl": "Execute the FIND REFERENCES ."}}
{"translation": {"code": "@ Override public ORecordIteratorClusters < REC > last ( ) { if ( clusterIds . length == 0 ) return this ; browsedRecords = 0 ; currentClusterIdx = clusterIds . length - 1 ; updateClusterRange ( ) ; current . setClusterId ( clusterIds [ currentClusterIdx ] ) ; resetCurrentPosition ( ) ; prevPosition ( ) ; final ORecord record = getRecord ( ) ; currentRecord = readCurrentRecord ( record , 0 ) ; if ( currentRecord != null && ! include ( currentRecord ) ) { currentRecord = null ; hasPrevious ( ) ; } return this ; }", "nl": "Move the iterator to the end of the range . If no range was specified move to the last record of the cluster ."}}
{"translation": {"code": "protected boolean parseStrategy ( final String w ) throws OCommandSQLParsingException { if ( ! w . equals ( KEYWORD_STRATEGY ) ) return false ; final String strategyWord = parserNextWord ( true ) ; try { traverse . setStrategy ( OTraverse . STRATEGY . valueOf ( strategyWord . toUpperCase ( Locale . ENGLISH ) ) ) ; } catch ( IllegalArgumentException ignore ) { throwParsingException ( \"Invalid \" + KEYWORD_STRATEGY + \". Use one between \" + Arrays . toString ( OTraverse . STRATEGY . values ( ) ) ) ; } return true ; }", "nl": "Parses the strategy keyword if found ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( type == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final ODatabaseDocument database = getDatabase ( ) ; final OClassEmbedded sourceClass = ( OClassEmbedded ) database . getMetadata ( ) . getSchema ( ) . getClass ( className ) ; if ( sourceClass == null ) throw new OCommandExecutionException ( \"Source class '\" + className + \"' not found\" ) ; OPropertyImpl prop = ( OPropertyImpl ) sourceClass . getProperty ( fieldName ) ; if ( prop != null ) { if ( ifNotExists ) { return sourceClass . properties ( ) . size ( ) ; } throw new OCommandExecutionException ( \"Property '\" + className + \".\" + fieldName + \"' already exists. Remove it before to retry.\" ) ; } // CREATE THE PROPERTY\r OClass linkedClass = null ; OType linkedType = null ; if ( linked != null ) { // FIRST SEARCH BETWEEN CLASSES\r linkedClass = database . getMetadata ( ) . getSchema ( ) . getClass ( linked ) ; if ( linkedClass == null ) // NOT FOUND: SEARCH BETWEEN TYPES\r linkedType = OType . valueOf ( linked . toUpperCase ( Locale . ENGLISH ) ) ; } // CREATE IT LOCALLY\r OPropertyImpl internalProp = sourceClass . addPropertyInternal ( fieldName , type , linkedType , linkedClass , unsafe ) ; if ( readonly ) { internalProp . setReadonly ( true ) ; } if ( mandatory ) { internalProp . setMandatory ( true ) ; } if ( notnull ) { internalProp . setNotNull ( true ) ; } if ( max != null ) { internalProp . setMax ( max ) ; } if ( min != null ) { internalProp . setMin ( min ) ; } if ( defaultValue != null ) { internalProp . setDefaultValue ( defaultValue ) ; } return sourceClass . properties ( ) . size ( ) ; }", "nl": "Execute the CREATE PROPERTY ."}}
{"translation": {"code": "public void bindParameters ( final Map < Object , Object > iArgs ) { if ( parameterItems == null || iArgs == null || iArgs . size ( ) == 0 ) return ; for ( int i = 0 ; i < parameterItems . size ( ) ; i ++ ) { OSQLFilterItemParameter value = parameterItems . get ( i ) ; if ( \"?\" . equals ( value . getName ( ) ) ) { value . setValue ( iArgs . get ( i ) ) ; } else { value . setValue ( iArgs . get ( value . getName ( ) ) ) ; } } }", "nl": "Binds parameters ."}}
{"translation": {"code": "public void addIndexEntry ( final OIndex < ? > delegate , final String iIndexName , final OTransactionIndexChanges . OPERATION iOperation , final Object key , final OIdentifiable iValue , boolean clientTrackOnly ) { OTransactionIndexChanges indexEntry = indexEntries . get ( iIndexName ) ; if ( indexEntry == null ) { indexEntry = new OTransactionIndexChanges ( ) ; indexEntries . put ( iIndexName , indexEntry ) ; } if ( iOperation == OPERATION . CLEAR ) indexEntry . setCleared ( ) ; else { OTransactionIndexChangesPerKey changes = indexEntry . getChangesPerKey ( key ) ; changes . clientTrackOnly = clientTrackOnly ; changes . add ( iValue , iOperation ) ; if ( iValue == null ) return ; List < OTransactionRecordIndexOperation > transactionIndexOperations = recordIndexOperations . get ( iValue . getIdentity ( ) ) ; if ( transactionIndexOperations == null ) { transactionIndexOperations = new ArrayList < OTransactionRecordIndexOperation > ( ) ; recordIndexOperations . put ( iValue . getIdentity ( ) . copy ( ) , transactionIndexOperations ) ; } transactionIndexOperations . add ( new OTransactionRecordIndexOperation ( iIndexName , key , iOperation ) ) ; } }", "nl": "Bufferizes index changes to be flushed at commit time ."}}
{"translation": {"code": "public List < ORecordOperation > getNewRecordEntriesByClusterIds ( final int [ ] iIds ) { final List < ORecordOperation > result = new ArrayList < ORecordOperation > ( ) ; if ( iIds == null ) // RETURN ALL THE RECORDS\r for ( ORecordOperation entry : allEntries . values ( ) ) { if ( entry . type == ORecordOperation . CREATED ) result . add ( entry ) ; } else // FILTER RECORDS BY ID\r for ( ORecordOperation entry : allEntries . values ( ) ) { for ( int id : iIds ) { if ( entry . getRecord ( ) != null && entry . getRecord ( ) . getIdentity ( ) . getClusterId ( ) == id && entry . type == ORecordOperation . CREATED ) { result . add ( entry ) ; break ; } } } return result ; }", "nl": "Called by cluster iterator ."}}
{"translation": {"code": "public List < ORecordOperation > getNewRecordEntriesByClass ( final OClass iClass , final boolean iPolymorphic ) { final List < ORecordOperation > result = new ArrayList < ORecordOperation > ( ) ; if ( iClass == null ) // RETURN ALL THE RECORDS\r for ( ORecordOperation entry : allEntries . values ( ) ) { if ( entry . type == ORecordOperation . CREATED ) result . add ( entry ) ; } else { // FILTER RECORDS BY CLASSNAME\r for ( ORecordOperation entry : allEntries . values ( ) ) { if ( entry . type == ORecordOperation . CREATED ) if ( entry . getRecord ( ) != null && entry . getRecord ( ) instanceof ODocument ) { if ( iPolymorphic ) { if ( iClass . isSuperClassOf ( ( ( ODocument ) entry . getRecord ( ) ) . getSchemaClass ( ) ) ) result . add ( entry ) ; } else if ( iClass . getName ( ) . equals ( ( ( ODocument ) entry . getRecord ( ) ) . getClassName ( ) ) ) result . add ( entry ) ; } } } return result ; }", "nl": "Called by class iterator ."}}
{"translation": {"code": "public OClass getLinkedClass ( ) { acquireSchemaReadLock ( ) ; try { if ( linkedClass == null && linkedClassName != null ) linkedClass = owner . owner . getClass ( linkedClassName ) ; return linkedClass ; } finally { releaseSchemaReadLock ( ) ; } }", "nl": "Returns the linked class in lazy mode because while unmarshalling the class could be not loaded yet ."}}
{"translation": {"code": "@ Deprecated public OPropertyImpl dropIndexes ( ) { getDatabase ( ) . checkSecurity ( ORule . ResourceGeneric . SCHEMA , ORole . PERMISSION_DELETE ) ; acquireSchemaReadLock ( ) ; try { final OIndexManager indexManager = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) ; final ArrayList < OIndex < ? > > relatedIndexes = new ArrayList < OIndex < ? > > ( ) ; for ( final OIndex < ? > index : indexManager . getClassIndexes ( owner . getName ( ) ) ) { final OIndexDefinition definition = index . getDefinition ( ) ; if ( OCollections . indexOf ( definition . getFields ( ) , globalRef . getName ( ) , new OCaseInsentiveComparator ( ) ) > - 1 ) { if ( definition instanceof OPropertyIndexDefinition ) { relatedIndexes . add ( index ) ; } else { throw new IllegalArgumentException ( \"This operation applicable only for property indexes. \" + index . getName ( ) + \" is \" + index . getDefinition ( ) ) ; } } } for ( final OIndex < ? > index : relatedIndexes ) getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( index . getName ( ) ) ; return this ; } finally { releaseSchemaReadLock ( ) ; } }", "nl": "Remove the index on property"}}
{"translation": {"code": "public OIndex < ? > createIndex ( final String iType ) { acquireSchemaReadLock ( ) ; try { return owner . createIndex ( getFullName ( ) , iType , globalRef . getName ( ) ) ; } finally { releaseSchemaReadLock ( ) ; } }", "nl": "Creates an index on this property . Indexes speed up queries but slow down insert and update operations . For massive inserts we suggest to remove the index make the massive insert and recreate it ."}}
{"translation": {"code": "@ Deprecated public OIndex < ? > getIndex ( ) { acquireSchemaReadLock ( ) ; try { Set < OIndex < ? > > indexes = owner . getInvolvedIndexes ( globalRef . getName ( ) ) ; if ( indexes != null && ! indexes . isEmpty ( ) ) return indexes . iterator ( ) . next ( ) ; return null ; } finally { releaseSchemaReadLock ( ) ; } }", "nl": "Returns the first index defined for the property ."}}
{"translation": {"code": "@ Deprecated public synchronized Map < String , String > listDatabases ( ) throws IOException { OListDatabasesRequest request = new OListDatabasesRequest ( ) ; OListDatabasesResponse response = networkAdminOperation ( request , \"Cannot retrieve the configuration list\" ) ; return response . getDatabases ( ) ; }", "nl": "Returns the list of databases on the connected remote server ."}}
{"translation": {"code": "@ Deprecated public synchronized OServerAdmin connect ( final String iUserName , final String iUserPassword ) throws IOException { final String username ; final String password ; OCredentialInterceptor ci = OSecurityManager . instance ( ) . newCredentialInterceptor ( ) ; if ( ci != null ) { ci . intercept ( storage . getURL ( ) , iUserName , iUserPassword ) ; username = ci . getUsername ( ) ; password = ci . getPassword ( ) ; } else { username = iUserName ; password = iUserPassword ; } OConnect37Request request = new OConnect37Request ( username , password ) ; networkAdminOperation ( ( network , session ) -> { OStorageRemoteNodeSession nodeSession = session . getOrCreateServerSession ( network . getServerURL ( ) ) ; try { network . beginRequest ( request . getCommand ( ) , session ) ; request . write ( network , session ) ; } finally { network . endRequest ( ) ; } OConnectResponse response = request . createResponse ( ) ; try { network . beginResponse ( nodeSession . getSessionId ( ) , true ) ; response . read ( network , session ) ; } finally { storage . endResponse ( network ) ; } return null ; } , \"Cannot connect to the remote server/database '\" + storage . getURL ( ) + \"'\" ) ; return this ; }", "nl": "Connects to a remote server ."}}
{"translation": {"code": "public ODocument clusterStatus ( ) { ODistributedStatusRequest request = new ODistributedStatusRequest ( ) ; ODistributedStatusResponse response = storage . networkOperation ( request , \"Error on executing Cluster status \" ) ; OLogManager . instance ( ) . debug ( this , \"Cluster status %s\" , response . getClusterConfig ( ) . toJSON ( \"prettyPrint\" ) ) ; return response . getClusterConfig ( ) ; }", "nl": "Gets the cluster status ."}}
{"translation": {"code": "public synchronized boolean existsDatabase ( final String iDatabaseName , final String storageType ) throws IOException { OExistsDatabaseRequest request = new OExistsDatabaseRequest ( iDatabaseName , storageType ) ; OExistsDatabaseResponse response = networkAdminOperation ( request , \"Error on checking existence of the remote storage: \" + storage . getName ( ) ) ; return response . isExists ( ) ; }", "nl": "Checks if a database exists in the remote server ."}}
{"translation": {"code": "public synchronized OServerAdmin freezeDatabase ( final String storageType ) throws IOException { OFreezeDatabaseRequest request = new OFreezeDatabaseRequest ( storage . getName ( ) , storageType ) ; OFreezeDatabaseResponse response = networkAdminOperation ( request , \"Cannot freeze the remote storage: \" + storage . getName ( ) ) ; return this ; }", "nl": "Freezes the database by locking it in exclusive mode ."}}
{"translation": {"code": "public void shutdown ( ) { underlying . shutdown ( ) ; if ( Orient . instance ( ) . getProfiler ( ) != null ) { Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + \"enabled\" ) ; Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + \"current\" ) ; Orient . instance ( ) . getProfiler ( ) . unregisterHookValue ( profilerPrefix + \"max\" ) ; } }", "nl": "All operations running at cache destruction stage"}}
{"translation": {"code": "public void startup ( ) { underlying . startup ( ) ; Orient . instance ( ) . getProfiler ( ) . registerHookValue ( profilerPrefix + \"current\" , \"Number of entries in cache\" , METRIC_TYPE . SIZE , new OProfilerHookValue ( ) { public Object getValue ( ) { return getSize ( ) ; } } , profilerMetadataPrefix + \"current\" ) ; }", "nl": "All operations running at cache initialization stage"}}
{"translation": {"code": "public void freeCluster ( final int cid ) { final Set < ORID > toRemove = new HashSet < ORID > ( underlying . size ( ) / 2 ) ; final Set < ORID > keys = new HashSet < ORID > ( underlying . keys ( ) ) ; for ( final ORID id : keys ) if ( id . getClusterId ( ) == cid ) toRemove . add ( id ) ; for ( final ORID ridToRemove : toRemove ) underlying . remove ( ridToRemove ) ; }", "nl": "Remove all records belonging to specified cluster"}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) public List < T > run ( final Object ... iArgs ) { final ODatabaseDocumentInternal database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; if ( database == null ) throw new OQueryParsingException ( \"No database configured\" ) ; ( ( OMetadataInternal ) database . getMetadata ( ) ) . makeThreadLocalSchemaSnapshot ( ) ; try { setParameters ( iArgs ) ; Object o = database . getStorage ( ) . command ( this ) ; if ( o instanceof List ) { return ( List < T > ) o ; } else { return ( List < T > ) Collections . singletonList ( o ) ; } } finally { ( ( OMetadataInternal ) database . getMetadata ( ) ) . clearThreadLocalSchemaSnapshot ( ) ; } }", "nl": "Delegates to the OQueryExecutor the query execution ."}}
{"translation": {"code": "public OIndexCursor executeIndexQuery ( OCommandContext iContext , OIndex < ? > index , final List < Object > keyParams , boolean ascSortOrder ) { return null ; }", "nl": "Performs index query and returns index cursor which presents subset of index data which corresponds to result of execution of given operator ."}}
{"translation": {"code": "public T runFirst ( final Object ... iArgs ) { setLimit ( 1 ) ; final List < T > result = execute ( iArgs ) ; return result != null && ! result . isEmpty ( ) ? result . get ( 0 ) : null ; }", "nl": "Returns only the first record if any ."}}
{"translation": {"code": "public ORecord saveRecord ( final ORecord iRecord , final String iClusterName , final OPERATION_MODE iMode , boolean iForceCreate , final ORecordCallback < ? extends Number > iRecordCreatedCallback , ORecordCallback < Integer > iRecordUpdatedCallback ) { try { return database . saveAll ( iRecord , iClusterName , iMode , iForceCreate , iRecordCreatedCallback , iRecordUpdatedCallback ) ; } catch ( Exception e ) { // REMOVE IT FROM THE CACHE TO AVOID DIRTY RECORDS\r final ORecordId rid = ( ORecordId ) iRecord . getIdentity ( ) ; if ( rid . isValid ( ) ) database . getLocalCache ( ) . freeRecord ( rid ) ; if ( e instanceof ONeedRetryException ) throw ( ONeedRetryException ) e ; throw OException . wrapException ( new ODatabaseException ( \"Error during saving of record\" + ( iRecord != null ? \" with rid \" + iRecord . getIdentity ( ) : \"\" ) ) , e ) ; } }", "nl": "Update the record ."}}
{"translation": {"code": "public void deleteRecord ( final ORecord iRecord , final OPERATION_MODE iMode ) { if ( ! iRecord . getIdentity ( ) . isPersistent ( ) ) return ; try { database . executeDeleteRecord ( iRecord , iRecord . getVersion ( ) , true , iMode , false ) ; } catch ( Exception e ) { // REMOVE IT FROM THE CACHE TO AVOID DIRTY RECORDS\r final ORecordId rid = ( ORecordId ) iRecord . getIdentity ( ) ; if ( rid . isValid ( ) ) database . getLocalCache ( ) . freeRecord ( rid ) ; if ( e instanceof RuntimeException ) throw ( RuntimeException ) e ; throw OException . wrapException ( new ODatabaseException ( \"Error during deletion of record\" + ( iRecord != null ? \" with rid \" + iRecord . getIdentity ( ) : \"\" ) ) , e ) ; } }", "nl": "Deletes the record ."}}
{"translation": {"code": "public DB acquire ( final String iName , final String iUserName , final String iUserPassword , final Map < String , Object > iOptionalParams ) { setup ( ) ; return dbPool . acquire ( iName , iUserName , iUserPassword , iOptionalParams ) ; }", "nl": "Acquires a connection from the pool specifying options . If the pool is empty then the caller thread will wait for it ."}}
{"translation": {"code": "public DB acquire ( final String iName , final String iUserName , final String iUserPassword ) { setup ( ) ; return dbPool . acquire ( iName , iUserName , iUserPassword ) ; }", "nl": "Acquires a connection from the pool . If the pool is empty then the caller thread will wait for it ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( clusterName == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final ODatabaseDocumentInternal database = getDatabase ( ) ; // CHECK IF ANY CLASS IS USING IT\r final int clusterId = database . getStorage ( ) . getClusterIdByName ( clusterName ) ; for ( OClass iClass : database . getMetadata ( ) . getSchema ( ) . getClasses ( ) ) { for ( int i : iClass . getClusterIds ( ) ) { if ( i == clusterId ) // IN USE\r return false ; } } // REMOVE CACHE OF COMMAND RESULTS IF ACTIVE\r database . getMetadata ( ) . getCommandCache ( ) . invalidateResultsOfCluster ( clusterName ) ; database . dropCluster ( clusterId , true ) ; return true ; }", "nl": "Execute the DROP CLUSTER ."}}
{"translation": {"code": "protected void removeListener ( final ORecordListener listener ) { if ( _listeners != null ) { _listeners . remove ( listener ) ; if ( _listeners . isEmpty ( ) ) _listeners = null ; } }", "nl": "Remove the current event listener ."}}
{"translation": {"code": "public ORole grant ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { ORule rule = rules . get ( resourceGeneric ) ; if ( rule == null ) { rule = new ORule ( resourceGeneric , null , null ) ; rules . put ( resourceGeneric , rule ) ; } rule . grantAccess ( resourceSpecific , iOperation ) ; rules . put ( resourceGeneric , rule ) ; updateRolesDocumentContent ( ) ; return this ; }", "nl": "Grant a permission to the resource ."}}
{"translation": {"code": "public ORole revoke ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { if ( iOperation == PERMISSION_NONE ) return this ; ORule rule = rules . get ( resourceGeneric ) ; if ( rule == null ) { rule = new ORule ( resourceGeneric , null , null ) ; rules . put ( resourceGeneric , rule ) ; } rule . revokeAccess ( resourceSpecific , iOperation ) ; rules . put ( resourceGeneric , rule ) ; updateRolesDocumentContent ( ) ; return this ; }", "nl": "Revoke a permission to the resource ."}}
{"translation": {"code": "public OQueryAbstract setFetchPlan ( final String fetchPlan ) { OFetchHelper . checkFetchPlanValid ( fetchPlan ) ; if ( fetchPlan != null && fetchPlan . length ( ) == 0 ) this . fetchPlan = null ; else this . fetchPlan = fetchPlan ; return this ; }", "nl": "Sets the fetch plan to use ."}}
{"translation": {"code": "public synchronized OServerAdmin dropDatabase ( final String iDatabaseName , final String storageType ) throws IOException { ODropDatabaseRequest request = new ODropDatabaseRequest ( iDatabaseName , storageType ) ; ODropDatabaseResponse response = networkAdminOperation ( request , \"Cannot delete the remote storage: \" + storage . getName ( ) ) ; OURLConnection connection = OURLHelper . parse ( getURL ( ) ) ; OrientDBRemote remote = ( OrientDBRemote ) ODatabaseDocumentTxInternal . getOrCreateRemoteFactory ( connection . getPath ( ) ) ; remote . forceDatabaseClose ( iDatabaseName ) ; ODatabaseRecordThreadLocal . instance ( ) . remove ( ) ; return this ; }", "nl": "Drops a database from a remote server instance ."}}
{"translation": {"code": "public void addIndex ( final OIndexDefinition indexDefinition ) { indexDefinitions . add ( indexDefinition ) ; if ( indexDefinition instanceof OIndexDefinitionMultiValue ) { if ( multiValueDefinitionIndex == - 1 ) multiValueDefinitionIndex = indexDefinitions . size ( ) - 1 ; else throw new OIndexException ( \"Composite key cannot contain more than one collection item\" ) ; } collate . addCollate ( indexDefinition . getCollate ( ) ) ; }", "nl": "Add new indexDefinition in current composite ."}}
{"translation": {"code": "public void move ( final int iFrom , final int iPosition ) { if ( iPosition == 0 ) return ; final int to = iFrom + iPosition ; final int size = iPosition > 0 ? buffer . length - to : buffer . length - iFrom ; System . arraycopy ( buffer , iFrom , buffer , to , size ) ; }", "nl": "Move bytes left or right of an offset ."}}
{"translation": {"code": "public void fill ( final int iLength , final byte iFiller ) { assureSpaceFor ( iLength ) ; Arrays . fill ( buffer , position , position + iLength , iFiller ) ; position += iLength ; }", "nl": "Fills the stream from current position writing iLength times the iFiller byte"}}
{"translation": {"code": "@ Override public Object evaluateRecord ( final OIdentifiable iRecord , ODocument iCurrentResult , final OSQLFilterCondition iCondition , final Object iLeft , final Object iRight , OCommandContext iContext , final ODocumentSerializer serializer ) { return true ; }", "nl": "At run - time the evaluation per record must return always true since the recordset are filtered at the beginning unless an operator can work in both modes . In this case sub - class must extend it ."}}
{"translation": {"code": "public String createHash ( final String iInput , final String iAlgorithm , final boolean iIncludeAlgorithm ) { if ( iInput == null ) throw new IllegalArgumentException ( \"Input string is null\" ) ; if ( iAlgorithm == null ) throw new IllegalArgumentException ( \"Algorithm is null\" ) ; final StringBuilder buffer = new StringBuilder ( 128 ) ; final String algorithm = validateAlgorithm ( iAlgorithm ) ; if ( iIncludeAlgorithm ) { buffer . append ( ' ' ) ; buffer . append ( algorithm ) ; buffer . append ( ' ' ) ; } final String transformed ; if ( HASH_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { transformed = createSHA256 ( iInput ) ; } else if ( PBKDF2_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { transformed = createHashWithSalt ( iInput , OGlobalConfiguration . SECURITY_USER_PASSWORD_SALT_ITERATIONS . getValueAsInteger ( ) , algorithm ) ; } else if ( PBKDF2_SHA256_ALGORITHM . equalsIgnoreCase ( algorithm ) ) { transformed = createHashWithSalt ( iInput , OGlobalConfiguration . SECURITY_USER_PASSWORD_SALT_ITERATIONS . getValueAsInteger ( ) , algorithm ) ; } else throw new IllegalArgumentException ( \"Algorithm '\" + algorithm + \"' is not supported\" ) ; buffer . append ( transformed ) ; return buffer . toString ( ) ; }", "nl": "Hashes the input string ."}}
{"translation": {"code": "public boolean checkPassword ( final String iPassword , final String iHash ) { if ( iHash . startsWith ( HASH_ALGORITHM_PREFIX ) ) { final String s = iHash . substring ( HASH_ALGORITHM_PREFIX . length ( ) ) ; return createSHA256 ( iPassword ) . equals ( s ) ; } else if ( iHash . startsWith ( PBKDF2_ALGORITHM_PREFIX ) ) { final String s = iHash . substring ( PBKDF2_ALGORITHM_PREFIX . length ( ) ) ; return checkPasswordWithSalt ( iPassword , s , PBKDF2_ALGORITHM ) ; } else if ( iHash . startsWith ( PBKDF2_SHA256_ALGORITHM_PREFIX ) ) { final String s = iHash . substring ( PBKDF2_SHA256_ALGORITHM_PREFIX . length ( ) ) ; return checkPasswordWithSalt ( iPassword , s , PBKDF2_SHA256_ALGORITHM ) ; } // Do not compare raw strings against each other, to avoid timing attacks.\r // Instead, hash them both with a cryptographic hash function and\r // compare their hashes with a constant-time comparison method.\r return MessageDigest . isEqual ( digestSHA256 ( iPassword ) , digestSHA256 ( iHash ) ) ; }", "nl": "Checks if an hash string matches a password based on the algorithm found on hash string ."}}
{"translation": {"code": "protected ORecord readCurrentRecord ( ORecord iRecord , final int iMovement ) { if ( limit > - 1 && browsedRecords >= limit ) // LIMIT REACHED\r return null ; do { final boolean moveResult ; switch ( iMovement ) { case 1 : moveResult = nextPosition ( ) ; break ; case - 1 : moveResult = prevPosition ( ) ; break ; case 0 : moveResult = checkCurrentPosition ( ) ; break ; default : throw new IllegalStateException ( \"Invalid movement value : \" + iMovement ) ; } if ( ! moveResult ) return null ; try { if ( iRecord != null ) { ORecordInternal . setIdentity ( iRecord , new ORecordId ( current . getClusterId ( ) , current . getClusterPosition ( ) ) ) ; iRecord = database . load ( iRecord , fetchPlan , false ) ; } else iRecord = database . load ( current , fetchPlan , false ) ; } catch ( ODatabaseException e ) { if ( Thread . interrupted ( ) || database . isClosed ( ) ) // THREAD INTERRUPTED: RETURN\r throw e ; if ( e . getCause ( ) instanceof OSecurityException ) throw e ; brokenRIDs . add ( current . copy ( ) ) ; OLogManager . instance ( ) . error ( this , \"Error on fetching record during browsing. The record has been skipped\" , e ) ; } if ( iRecord != null ) { browsedRecords ++ ; return iRecord ; } } while ( iMovement != 0 ) ; return null ; }", "nl": "Read the current record and increment the counter if the record was found ."}}
{"translation": {"code": "public < RET > RET detach ( final Object iPojo , boolean returnNonProxiedInstance ) { return ( RET ) OObjectEntitySerializer . detach ( iPojo , this , returnNonProxiedInstance ) ; }", "nl": "Method that detaches all fields contained in the document to the given object ."}}
{"translation": {"code": "public int getVersion ( final Object iPojo ) { checkOpenness ( ) ; final ODocument record = getRecordByUserObject ( iPojo , false ) ; if ( record != null ) return record . getVersion ( ) ; return OObjectSerializerHelper . getObjectVersion ( iPojo ) ; }", "nl": "Returns the version number of the object . Version starts from 0 assigned on creation ."}}
{"translation": {"code": "public void releaseDatabaseEngine ( final String iLanguage , final String iDatabaseName , final OPartitionedObjectPool . PoolEntry < ScriptEngine > poolEntry ) { final ODatabaseScriptManager dbManager = dbManagers . get ( iDatabaseName ) ; // We check if there is still a valid pool because it could be removed by the function reload\r if ( dbManager != null ) { dbManager . releaseEngine ( iLanguage , poolEntry ) ; } }", "nl": "Acquires a database engine from the pool . Once finished using it the instance MUST be returned in the pool by calling the method"}}
{"translation": {"code": "public String getLibrary ( final ODatabase < ? > db , final String iLanguage ) { if ( db == null ) // NO DB = NO LIBRARY\r return null ; final StringBuilder code = new StringBuilder ( ) ; final Set < String > functions = db . getMetadata ( ) . getFunctionLibrary ( ) . getFunctionNames ( ) ; for ( String fName : functions ) { final OFunction f = db . getMetadata ( ) . getFunctionLibrary ( ) . getFunction ( fName ) ; if ( f . getLanguage ( ) == null ) throw new OConfigurationException ( \"Database function '\" + fName + \"' has no language\" ) ; if ( f . getLanguage ( ) . equalsIgnoreCase ( iLanguage ) ) { final String def = getFunctionDefinition ( f ) ; if ( def != null ) { code . append ( def ) ; code . append ( \"\\n\" ) ; } } } return code . length ( ) == 0 ? null : code . toString ( ) ; }", "nl": "Formats the library of functions for a language ."}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) public static Object getMapEntry ( final Map < String , ? > iMap , final Object iKey ) { if ( iMap == null || iKey == null ) return null ; if ( iKey instanceof String ) { String iName = ( String ) iKey ; int pos = iName . indexOf ( ' ' ) ; if ( pos > - 1 ) iName = iName . substring ( 0 , pos ) ; final Object value = iMap . get ( iName ) ; if ( value == null ) return null ; if ( pos > - 1 ) { final String restFieldName = iName . substring ( pos + 1 ) ; if ( value instanceof ODocument ) return getFieldValue ( value , restFieldName ) ; else if ( value instanceof Map < ? , ? > ) return getMapEntry ( ( Map < String , ? > ) value , restFieldName ) ; } return value ; } else return iMap . get ( iKey ) ; }", "nl": "Retrieves the value crossing the map with the dotted notation"}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) public < RET > RET execute ( final Object ... iArgs ) { setParameters ( iArgs ) ; OExecutionThreadLocal . INSTANCE . get ( ) . onAsyncReplicationOk = onAsyncReplicationOk ; OExecutionThreadLocal . INSTANCE . get ( ) . onAsyncReplicationError = onAsyncReplicationError ; return ( RET ) ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getStorage ( ) . command ( this ) ; }", "nl": "Delegates the execution to the configured command executor ."}}
{"translation": {"code": "protected void convertAll ( ) { if ( converted ) return ; for ( java . util . Map . Entry < Object , Object > e : underlying . entrySet ( ) ) { if ( e . getValue ( ) instanceof Number ) super . put ( e . getKey ( ) , enumClass . getEnumConstants ( ) [ ( ( Number ) e . getValue ( ) ) . intValue ( ) ] ) ; else super . put ( e . getKey ( ) , Enum . valueOf ( enumClass , e . getValue ( ) . toString ( ) ) ) ; } converted = true ; }", "nl": "Converts all the items"}}
{"translation": {"code": "private void convert ( final Object iKey ) { if ( converted ) return ; if ( super . containsKey ( iKey ) ) return ; Object o = underlying . get ( String . valueOf ( iKey ) ) ; if ( o instanceof Number ) super . put ( iKey , enumClass . getEnumConstants ( ) [ ( ( Number ) o ) . intValue ( ) ] ) ; else super . put ( iKey , Enum . valueOf ( enumClass , o . toString ( ) ) ) ; }", "nl": "Assure that the requested key is converted ."}}
{"translation": {"code": "public int nextChar ( ) throws IOException { if ( missedChar != null ) { // RETURNS THE PREVIOUS PARSED CHAR\r c = missedChar . charValue ( ) ; missedChar = null ; } else { int read = in . read ( ) ; if ( read == - 1 ) return - 1 ; c = ( char ) read ; if ( c == ' ' ) { read = in . read ( ) ; if ( read == - 1 ) return - 1 ; char c2 = ( char ) read ; if ( c2 == ' ' ) { // DECODE UNICODE CHAR\r final StringBuilder buff = new StringBuilder ( 8 ) ; for ( int i = 0 ; i < 4 ; ++ i ) { read = in . read ( ) ; if ( read == - 1 ) return - 1 ; buff . append ( ( char ) read ) ; } cursor += 6 ; return ( char ) Integer . parseInt ( buff . toString ( ) , 16 ) ; } else { // REMEMBER THE CURRENT CHAR TO RETURN NEXT TIME\r missedChar = c2 ; } } } cursor ++ ; if ( c == NEW_LINE ) { ++ lineNumber ; columnNumber = 0 ; } else ++ columnNumber ; return ( char ) c ; }", "nl": "Returns the next character from the input stream . Handles Unicode decoding ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( className == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final ODatabaseDocument database = getDatabase ( ) ; boolean alreadyExists = database . getMetadata ( ) . getSchema ( ) . existsClass ( className ) ; if ( ! alreadyExists || ! ifNotExists ) { if ( clusters != null ) database . getMetadata ( ) . getSchema ( ) . createClass ( className , clusters , superClasses . toArray ( new OClass [ 0 ] ) ) ; else database . getMetadata ( ) . getSchema ( ) . createClass ( className , clusterIds , superClasses . toArray ( new OClass [ 0 ] ) ) ; } return database . getMetadata ( ) . getSchema ( ) . getClasses ( ) . size ( ) ; }", "nl": "Execute the CREATE CLASS ."}}
{"translation": {"code": "public ORole allow ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific , final int iOperation ) { if ( roles == null || roles . isEmpty ( ) ) { if ( document . field ( \"roles\" ) != null && ! ( ( Collection < OIdentifiable > ) document . field ( \"roles\" ) ) . isEmpty ( ) ) { final ODocument doc = document ; document = null ; fromStream ( doc ) ; } else throw new OSecurityAccessException ( document . getDatabase ( ) . getName ( ) , \"User '\" + document . field ( \"name\" ) + \"' has no role defined\" ) ; } final ORole role = checkIfAllowed ( resourceGeneric , resourceSpecific , iOperation ) ; if ( role == null ) throw new OSecurityAccessException ( document . getDatabase ( ) . getName ( ) , \"User '\" + document . field ( \"name\" ) + \"' does not have permission to execute the operation '\" + ORole . permissionToString ( iOperation ) + \"' against the resource: \" + resourceGeneric + \".\" + resourceSpecific ) ; return role ; }", "nl": "Checks if the user has the permission to access to the requested resource for the requested operation ."}}
{"translation": {"code": "public boolean isRuleDefined ( final ORule . ResourceGeneric resourceGeneric , String resourceSpecific ) { for ( ORole r : roles ) if ( r == null ) OLogManager . instance ( ) . warn ( this , \"User '%s' has a null role, bypass it. Consider to fix this user roles before to continue\" , getName ( ) ) ; else if ( r . hasRule ( resourceGeneric , resourceSpecific ) ) return true ; return false ; }", "nl": "Checks if a rule was defined for the user ."}}
{"translation": {"code": "public OCommandContext setChild ( final OCommandContext iContext ) { if ( iContext == null ) { if ( child != null ) { // REMOVE IT\r child . setParent ( null ) ; child = null ; } } else if ( child != iContext ) { // ADD IT\r child = iContext ; iContext . setParent ( this ) ; } return this ; }", "nl": "Set the inherited context avoiding to copy all the values every time ."}}
{"translation": {"code": "@ Override protected boolean handleResult ( final OIdentifiable iRecord , final OCommandContext iContext ) { lastRecord = iRecord ; if ( ( orderedFields . isEmpty ( ) || fullySortedByIndex || isRidOnlySort ( ) ) && skip > 0 && this . unwindFields == null && this . expandTarget == null ) { lastRecord = null ; skip -- ; return true ; } if ( ! addResult ( lastRecord , iContext ) ) { return false ; } return continueSearching ( ) ; }", "nl": "Handles the record in result ."}}
{"translation": {"code": "@ Override public Set < String > getInvolvedClusters ( ) { final Set < String > clusters = new HashSet < String > ( ) ; if ( parsedTarget != null ) { final ODatabaseDocument db = getDatabase ( ) ; if ( parsedTarget . getTargetQuery ( ) != null && parsedTarget . getTargetRecords ( ) instanceof OCommandExecutorSQLResultsetDelegate ) { // SUB-QUERY: EXECUTE IT LOCALLY\r // SUB QUERY, PROPAGATE THE CALL\r final Set < String > clIds = ( ( OCommandExecutorSQLResultsetDelegate ) parsedTarget . getTargetRecords ( ) ) . getInvolvedClusters ( ) ; for ( String c : clIds ) { // FILTER THE CLUSTER WHERE THE USER HAS THE RIGHT ACCESS\r if ( checkClusterAccess ( db , c ) ) { clusters . add ( c ) ; } } } else if ( parsedTarget . getTargetRecords ( ) != null ) { // SINGLE RECORDS: BROWSE ALL (COULD BE EXPENSIVE).\r for ( OIdentifiable identifiable : parsedTarget . getTargetRecords ( ) ) { final String c = db . getClusterNameById ( identifiable . getIdentity ( ) . getClusterId ( ) ) . toLowerCase ( Locale . ENGLISH ) ; // FILTER THE CLUSTER WHERE THE USER HAS THE RIGHT ACCESS\r if ( checkClusterAccess ( db , c ) ) { clusters . add ( c ) ; } } } if ( parsedTarget . getTargetClasses ( ) != null ) { return getInvolvedClustersOfClasses ( parsedTarget . getTargetClasses ( ) . values ( ) ) ; } if ( parsedTarget . getTargetClusters ( ) != null ) { return getInvolvedClustersOfClusters ( parsedTarget . getTargetClusters ( ) . keySet ( ) ) ; } if ( parsedTarget . getTargetIndex ( ) != null ) { // EXTRACT THE CLASS NAME -> CLUSTERS FROM THE INDEX DEFINITION\r return getInvolvedClustersOfIndex ( parsedTarget . getTargetIndex ( ) ) ; } } return clusters ; }", "nl": "Determine clusters that are used in select operation"}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { if ( clusterName == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; final ODatabaseDocument database = getDatabase ( ) ; final int clusterId = database . getClusterIdByName ( clusterName ) ; if ( clusterId > - 1 ) throw new OCommandSQLParsingException ( \"Cluster '\" + clusterName + \"' already exists\" ) ; if ( blob ) { if ( requestedId == - 1 ) { return database . addBlobCluster ( clusterName ) ; } else { throw new OCommandExecutionException ( \"Request id not supported by blob cluster creation.\" ) ; } } else { if ( requestedId == - 1 ) { return database . addCluster ( clusterName ) ; } else { return database . addCluster ( clusterName , requestedId , null ) ; } } }", "nl": "Execute the CREATE CLUSTER ."}}
{"translation": {"code": "@ Override public Object evaluateRecord ( final OIdentifiable iRecord , ODocument iCurrentResult , final OSQLFilterCondition iCondition , final Object iLeft , final Object iRight , OCommandContext iContext , final ODocumentSerializer serializer ) { if ( iLeft == null || iRight == null ) return false ; return iLeft . toString ( ) . indexOf ( iRight . toString ( ) ) > - 1 ; }", "nl": "This is executed on non - indexed fields ."}}
{"translation": {"code": "public void truncate ( ) throws IOException { ODatabaseDocumentInternal db = getDatabase ( ) ; db . checkSecurity ( ORule . ResourceGeneric . CLASS , ORole . PERMISSION_UPDATE ) ; if ( isSubClassOf ( OSecurityShared . RESTRICTED_CLASSNAME ) ) { throw new OSecurityException ( \"Class '\" + getName ( ) + \"' cannot be truncated because has record level security enabled (extends '\" + OSecurityShared . RESTRICTED_CLASSNAME + \"')\" ) ; } final OStorage storage = db . getStorage ( ) ; acquireSchemaReadLock ( ) ; try { for ( int id : clusterIds ) { OCluster cl = storage . getClusterById ( id ) ; db . checkForClusterPermissions ( cl . getName ( ) ) ; cl . truncate ( ) ; } for ( OIndex < ? > index : getClassIndexes ( ) ) index . clear ( ) ; Set < OIndex < ? > > superclassIndexes = new HashSet < OIndex < ? > > ( ) ; superclassIndexes . addAll ( getIndexes ( ) ) ; superclassIndexes . removeAll ( getClassIndexes ( ) ) ; for ( OIndex index : superclassIndexes ) { index . rebuild ( ) ; } } finally { releaseSchemaReadLock ( ) ; } }", "nl": "Truncates all the clusters the class uses ."}}
{"translation": {"code": "public synchronized OServerAdmin releaseDatabase ( final String storageType ) throws IOException { OReleaseDatabaseRequest request = new OReleaseDatabaseRequest ( storage . getName ( ) , storageType ) ; OReleaseDatabaseResponse response = networkAdminOperation ( request , \"Cannot release the remote storage: \" + storage . getName ( ) ) ; return this ; }", "nl": "Releases a frozen database ."}}
{"translation": {"code": "protected boolean parseTimeout ( final String w ) throws OCommandSQLParsingException { if ( ! w . equals ( KEYWORD_TIMEOUT ) ) return false ; String word = parserNextWord ( true ) ; try { timeoutMs = Long . parseLong ( word ) ; } catch ( NumberFormatException ignore ) { throwParsingException ( \"Invalid \" + KEYWORD_TIMEOUT + \" value set to '\" + word + \"' but it should be a valid long. Example: \" + KEYWORD_TIMEOUT + \" 3000\" ) ; } if ( timeoutMs < 0 ) throwParsingException ( \"Invalid \" + KEYWORD_TIMEOUT + \": value set minor than ZERO. Example: \" + KEYWORD_TIMEOUT + \" 10000\" ) ; word = parserNextWord ( true ) ; if ( word != null ) if ( word . equals ( TIMEOUT_STRATEGY . EXCEPTION . toString ( ) ) ) timeoutStrategy = TIMEOUT_STRATEGY . EXCEPTION ; else if ( word . equals ( TIMEOUT_STRATEGY . RETURN . toString ( ) ) ) timeoutStrategy = TIMEOUT_STRATEGY . RETURN ; else parserGoBack ( ) ; return true ; }", "nl": "Parses the timeout keyword if found ."}}
{"translation": {"code": "public static Set < String > getCommandNames ( ) { final Set < String > types = new HashSet < String > ( ) ; final Iterator < OCommandExecutorSQLFactory > ite = getCommandFactories ( ) ; while ( ite . hasNext ( ) ) { types . addAll ( ite . next ( ) . getCommandNames ( ) ) ; } return types ; }", "nl": "Iterates on all factories and append all command names ."}}
{"translation": {"code": "public static Set < String > getFunctionNames ( ) { final Set < String > types = new HashSet < String > ( ) ; final Iterator < OSQLFunctionFactory > ite = getFunctionFactories ( ) ; while ( ite . hasNext ( ) ) { types . addAll ( ite . next ( ) . getFunctionNames ( ) ) ; } return types ; }", "nl": "Iterates on all factories and append all function names ."}}
{"translation": {"code": "public synchronized void setClassHandler ( final OEntityManagerClassHandler iClassHandler ) { Iterator < Entry < String , Class < ? > > > iterator = classHandler . getClassesEntrySet ( ) . iterator ( ) ; while ( iterator . hasNext ( ) ) { Entry < String , Class < ? > > entry = iterator . next ( ) ; boolean forceSchemaReload = ! iterator . hasNext ( ) ; iClassHandler . registerEntityClass ( entry . getValue ( ) , forceSchemaReload ) ; } this . classHandler = iClassHandler ; }", "nl": "Sets the received handler as default and merges the classes all together ."}}
{"translation": {"code": "public synchronized Object createPojo ( final String iClassName ) throws OConfigurationException { if ( iClassName == null ) throw new IllegalArgumentException ( \"Cannot create the object: class name is empty\" ) ; final Class < ? > entityClass = classHandler . getEntityClass ( iClassName ) ; try { if ( entityClass != null ) return createInstance ( entityClass ) ; } catch ( Exception e ) { throw OException . wrapException ( new OConfigurationException ( \"Error while creating new pojo of class '\" + iClassName + \"'\" ) , e ) ; } try { // TRY TO INSTANTIATE THE CLASS DIRECTLY BY ITS NAME\r return createInstance ( Class . forName ( iClassName ) ) ; } catch ( Exception e ) { throw OException . wrapException ( new OConfigurationException ( \"The class '\" + iClassName + \"' was not found between the entity classes. Ensure registerEntityClasses(package) has been called first\" ) , e ) ; } }", "nl": "Create a POJO by its class name ."}}
{"translation": {"code": "public static int bytes2int ( final byte [ ] b , final int offset ) { return ( b [ offset ] ) << 24 | ( 0xff & b [ offset + 1 ] ) << 16 | ( 0xff & b [ offset + 2 ] ) << 8 | ( ( 0xff & b [ offset + 3 ] ) ) ; }", "nl": "Convert the byte array to an int starting from the given offset ."}}
{"translation": {"code": "public OIndexInternal < ? > create ( final OIndexDefinition indexDefinition , final String clusterIndexName , final Set < String > clustersToIndex , boolean rebuild , final OProgressListener progressListener , final OBinarySerializer valueSerializer ) { acquireExclusiveLock ( ) ; try { configuration = indexConfigurationInstance ( new ODocument ( ) . setTrackingChanges ( false ) ) ; this . indexDefinition = indexDefinition ; if ( clustersToIndex != null ) this . clustersToIndex = new HashSet <> ( clustersToIndex ) ; else this . clustersToIndex = new HashSet <> ( ) ; // do not remove this, it is needed to remove index garbage if such one exists try { if ( apiVersion == 0 ) { removeValuesContainer ( ) ; } } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error during deletion of index '%s'\" , e , name ) ; } indexId = storage . addIndexEngine ( name , algorithm , type , indexDefinition , valueSerializer , isAutomatic ( ) , true , version , 1 , this instanceof OIndexMultiValues , getEngineProperties ( ) , clustersToIndex , metadata ) ; apiVersion = OAbstractPaginatedStorage . extractEngineAPIVersion ( indexId ) ; assert indexId >= 0 ; assert apiVersion >= 0 ; onIndexEngineChange ( indexId ) ; if ( rebuild ) fillIndex ( progressListener , false ) ; updateConfiguration ( ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Exception during index '%s' creation\" , e , name ) ; while ( true ) try { if ( indexId >= 0 ) storage . deleteIndexEngine ( indexId ) ; break ; } catch ( OInvalidIndexEngineIdException ignore ) { doReloadIndexEngine ( ) ; } catch ( Exception ex ) { OLogManager . instance ( ) . error ( this , \"Exception during index '%s' deletion\" , ex , name ) ; } if ( e instanceof OIndexException ) throw ( OIndexException ) e ; throw OException . wrapException ( new OIndexException ( \"Cannot create the index '\" + name + \"'\" ) , e ) ; } finally { releaseExclusiveLock ( ) ; } return this ; }", "nl": "Creates the index ."}}
{"translation": {"code": "public OHttpResponseWrapper send ( final int iCode , final String iReason , final String iContentType , final Object iContent ) throws IOException { response . send ( iCode , iReason , iContentType , iContent , null ) ; return this ; }", "nl": "Sends the complete HTTP response in one call ."}}
{"translation": {"code": "public OHttpResponseWrapper writeRecord ( final ORecord iRecord , final String iFetchPlan ) throws IOException { response . writeRecord ( iRecord , iFetchPlan , null ) ; return this ; }", "nl": "Writes a record as response . The record is serialized in JSON format ."}}
{"translation": {"code": "public OHttpResponseWrapper writeRecords ( final Object iRecords , final String iFetchPlan ) throws IOException { response . writeRecords ( iRecords , iFetchPlan ) ; return this ; }", "nl": "Writes records as response specifying a fetch - plan to serialize nested records . The records are serialized in JSON format ."}}
{"translation": {"code": "public OHttpResponseWrapper writeHeaders ( final String iContentType , final boolean iKeepAlive ) throws IOException { response . writeHeaders ( iContentType , iKeepAlive ) ; return this ; }", "nl": "Sets the response s headers specifying when using the keep - alive or not ."}}
{"translation": {"code": "public OHttpResponseWrapper writeStatus ( final int iHttpCode , final String iReason ) throws IOException { response . writeStatus ( iHttpCode , iReason ) ; return this ; }", "nl": "Sets the response s status as HTTP code and reason ."}}
{"translation": {"code": "public OHttpResponseWrapper sendStream ( final int iCode , final String iReason , final String iContentType , final InputStream iContent , final long iSize ) throws IOException { response . sendStream ( iCode , iReason , iContentType , iContent , iSize ) ; return this ; }", "nl": "Sends the complete HTTP response in one call specifying a stream as content ."}}
{"translation": {"code": "private void convertLink2Record ( final Object iKey ) { if ( status == MULTIVALUE_CONTENT_TYPE . ALL_RECORDS ) return ; final Object value ; if ( iKey instanceof ORID ) value = iKey ; else value = super . get ( iKey ) ; if ( value != null && value instanceof ORID ) { final ORID rid = ( ORID ) value ; marshalling = true ; try { try { // OVERWRITE IT\r ORecord record = rid . getRecord ( ) ; if ( record != null ) { ORecordInternal . unTrack ( sourceRecord , rid ) ; ORecordInternal . track ( sourceRecord , record ) ; } super . put ( iKey , record ) ; } catch ( ORecordNotFoundException ignore ) { // IGNORE THIS\r } } finally { marshalling = false ; } } }", "nl": "Convert the item with the received key to a record ."}}
{"translation": {"code": "public void changeMaximumAmountOfMemory ( final long readCacheMaxMemory ) throws IllegalStateException { MemoryData memoryData ; MemoryData newMemoryData ; final int newMemorySize = normalizeMemory ( readCacheMaxMemory , pageSize ) ; do { memoryData = memoryDataContainer . get ( ) ; if ( memoryData . maxSize == newMemorySize ) { return ; } if ( ( 100 * memoryData . pinnedPages / newMemorySize ) > percentOfPinnedPages ) { throw new IllegalStateException ( \"Cannot decrease amount of memory used by disk cache \" + \"because limit of pinned pages will be more than allowed limit \" + percentOfPinnedPages ) ; } newMemoryData = new MemoryData ( newMemorySize , memoryData . pinnedPages ) ; } while ( ! memoryDataContainer . compareAndSet ( memoryData , newMemoryData ) ) ; //    if (newMemorySize < memoryData.maxSize) //      removeColdestPagesIfNeeded(); OLogManager . instance ( ) . info ( this , \"Disk cache size was changed from \" + memoryData . maxSize + \" pages to \" + newMemorySize + \" pages\" ) ; }", "nl": "Changes amount of memory which may be used by given cache . This method may consume many resources if amount of memory provided in parameter is much less than current amount of memory ."}}
{"translation": {"code": "public synchronized void synchronizeSchema ( ) { OObjectDatabaseTx database = ( ( OObjectDatabaseTx ) ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getDatabaseOwner ( ) ) ; Collection < Class < ? > > registeredEntities = database . getEntityManager ( ) . getRegisteredEntities ( ) ; boolean automaticSchemaGeneration = database . isAutomaticSchemaGeneration ( ) ; boolean reloadSchema = false ; for ( Class < ? > iClass : registeredEntities ) { if ( Proxy . class . isAssignableFrom ( iClass ) || iClass . isEnum ( ) || OReflectionHelper . isJavaType ( iClass ) || iClass . isAnonymousClass ( ) ) return ; if ( ! database . getMetadata ( ) . getSchema ( ) . existsClass ( iClass . getSimpleName ( ) ) ) { database . getMetadata ( ) . getSchema ( ) . createClass ( iClass . getSimpleName ( ) ) ; reloadSchema = true ; } for ( Class < ? > currentClass = iClass ; currentClass != Object . class ; ) { if ( automaticSchemaGeneration && ! currentClass . equals ( Object . class ) && ! currentClass . equals ( ODocument . class ) ) { ( ( OSchemaProxyObject ) database . getMetadata ( ) . getSchema ( ) ) . generateSchema ( currentClass , database . getUnderlying ( ) ) ; } String iClassName = currentClass . getSimpleName ( ) ; currentClass = currentClass . getSuperclass ( ) ; if ( currentClass == null || currentClass . equals ( ODocument . class ) ) // POJO EXTENDS ODOCUMENT: SPECIAL CASE: AVOID TO CONSIDER // ODOCUMENT FIELDS currentClass = Object . class ; if ( database != null && ! database . isClosed ( ) && ! currentClass . equals ( Object . class ) ) { OClass oSuperClass ; OClass currentOClass = database . getMetadata ( ) . getSchema ( ) . getClass ( iClassName ) ; if ( ! database . getMetadata ( ) . getSchema ( ) . existsClass ( currentClass . getSimpleName ( ) ) ) { oSuperClass = database . getMetadata ( ) . getSchema ( ) . createClass ( currentClass . getSimpleName ( ) ) ; reloadSchema = true ; } else { oSuperClass = database . getMetadata ( ) . getSchema ( ) . getClass ( currentClass . getSimpleName ( ) ) ; reloadSchema = true ; } if ( ! currentOClass . getSuperClasses ( ) . contains ( oSuperClass ) ) { currentOClass . setSuperClasses ( Arrays . asList ( oSuperClass ) ) ; reloadSchema = true ; } } } } if ( database != null && ! database . isClosed ( ) && reloadSchema ) { database . getMetadata ( ) . getSchema ( ) . reload ( ) ; } }", "nl": "Checks if all registered entities has schema generated if not it generates it"}}
{"translation": {"code": "private static Set < String > getIndexTypes ( ) { final Set < String > types = new HashSet <> ( ) ; final Iterator < OIndexFactory > ite = getAllFactories ( ) ; while ( ite . hasNext ( ) ) { types . addAll ( ite . next ( ) . getTypes ( ) ) ; } return types ; }", "nl": "Iterates on all factories and append all index types ."}}
{"translation": {"code": "public boolean isReplicationActive ( final String iClusterName , final String iLocalNode ) { final Collection < String > servers = getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; if ( servers != null && ! servers . isEmpty ( ) ) { return true ; } return false ; }", "nl": "Returns true if the replication is active otherwise false ."}}
{"translation": {"code": "public Map < String , Collection < String > > getServerClusterMap ( Collection < String > iClusterNames , final String iLocalNode , final boolean optimizeForLocalOnly ) { if ( iClusterNames == null || iClusterNames . isEmpty ( ) ) iClusterNames = DEFAULT_CLUSTER_NAME ; final Map < String , Collection < String > > servers = new HashMap < String , Collection < String > > ( iClusterNames . size ( ) ) ; // TRY TO SEE IF IT CAN BE EXECUTED ON LOCAL NODE ONLY boolean canUseLocalNode = true ; for ( String p : iClusterNames ) { final List < String > serverList = getClusterConfiguration ( p ) . field ( SERVERS ) ; if ( serverList != null && ! serverList . contains ( iLocalNode ) ) { canUseLocalNode = false ; break ; } } if ( optimizeForLocalOnly && canUseLocalNode ) { // USE LOCAL NODE ONLY (MUCH FASTER) servers . put ( iLocalNode , iClusterNames ) ; return servers ; } // GROUP BY SERVER WITH THE NUMBER OF CLUSTERS final Map < String , Collection < String > > serverMap = new HashMap < String , Collection < String > > ( ) ; for ( String p : iClusterNames ) { final List < String > serverList = getClusterConfiguration ( p ) . field ( SERVERS ) ; for ( String s : serverList ) { if ( NEW_NODE_TAG . equalsIgnoreCase ( s ) ) continue ; Collection < String > clustersInServer = serverMap . get ( s ) ; if ( clustersInServer == null ) { clustersInServer = new HashSet < String > ( ) ; serverMap . put ( s , clustersInServer ) ; } clustersInServer . add ( p ) ; } } if ( serverMap . size ( ) == 1 ) // RETURN THE ONLY SERVER INVOLVED return serverMap ; if ( ! optimizeForLocalOnly ) return serverMap ; // ORDER BY NUMBER OF CLUSTERS final List < String > orderedServers = new ArrayList < String > ( serverMap . keySet ( ) ) ; Collections . sort ( orderedServers , new Comparator < String > ( ) { @ Override public int compare ( final String o1 , final String o2 ) { return ( ( Integer ) serverMap . get ( o2 ) . size ( ) ) . compareTo ( ( Integer ) serverMap . get ( o1 ) . size ( ) ) ; } } ) ; // BROWSER ORDERED SERVER MAP PUTTING THE MINIMUM SERVER TO COVER ALL THE CLUSTERS final Set < String > remainingClusters = new HashSet < String > ( iClusterNames ) ; // KEEPS THE REMAINING CLUSTER TO ADD IN FINAL // RESULT final Set < String > includedClusters = new HashSet < String > ( iClusterNames . size ( ) ) ; // KEEPS THE COLLECTION OF ALREADY INCLUDED // CLUSTERS for ( String s : orderedServers ) { final Collection < String > clusters = serverMap . get ( s ) ; if ( ! servers . isEmpty ( ) ) { // FILTER CLUSTER LIST AVOIDING TO REPEAT CLUSTERS ALREADY INCLUDED ON PREVIOUS NODES clusters . removeAll ( includedClusters ) ; } servers . put ( s , clusters ) ; remainingClusters . removeAll ( clusters ) ; includedClusters . addAll ( clusters ) ; if ( remainingClusters . isEmpty ( ) ) // FOUND ALL CLUSTERS break ; } return servers ; }", "nl": "Returns the list of servers that can manage a list of clusters . The algorithm makes its best to involve the less servers as it can ."}}
{"translation": {"code": "public List < String > getConfiguredServers ( final String iClusterName ) { final Collection < ? extends String > list = ( Collection < ? extends String > ) getClusterConfiguration ( iClusterName ) . field ( SERVERS ) ; return list != null ? new ArrayList < String > ( list ) : null ; }", "nl": "Returns the configured server list for the requested cluster ."}}
{"translation": {"code": "public Set < String > getServers ( Collection < String > iClusterNames ) { if ( iClusterNames == null || iClusterNames . isEmpty ( ) ) return getAllConfiguredServers ( ) ; final Set < String > partitions = new HashSet < String > ( iClusterNames . size ( ) ) ; for ( String p : iClusterNames ) { final List < String > serverList = getClusterConfiguration ( p ) . field ( SERVERS ) ; if ( serverList != null ) { for ( String s : serverList ) if ( ! s . equals ( NEW_NODE_TAG ) ) partitions . add ( s ) ; } } return partitions ; }", "nl": "Returns the set of server names involved on the passed cluster collection ."}}
{"translation": {"code": "public String getConfiguredClusterOwner ( final String iClusterName ) { String owner = null ; final ODocument clusters = getConfiguredClusters ( ) ; // GET THE CLUSTER CFG final ODocument cfg = clusters . field ( iClusterName ) ; if ( cfg != null ) owner = cfg . field ( OWNER ) ; return owner ; }", "nl": "Returns the static owner server for the given cluster ."}}
{"translation": {"code": "@ Override public List < String > backup ( OutputStream out , Map < String , Object > options , Callable < Object > callable , final OCommandOutputListener iListener , int compressionLevel , int bufferSize ) throws IOException { return underlying . backup ( out , options , callable , iListener , compressionLevel , bufferSize ) ; }", "nl": "Executes a backup of the database . During the backup the database will be frozen in read - only mode ."}}
{"translation": {"code": "public Boolean isReadYourWrites ( final String iClusterName ) { Object value = getClusterConfiguration ( iClusterName ) . field ( READ_YOUR_WRITES ) ; if ( value == null ) { value = configuration . field ( READ_YOUR_WRITES ) ; if ( value == null ) { OLogManager . instance ( ) . warn ( this , \"%s setting not found for cluster=%s in distributed-config.json\" , READ_YOUR_WRITES , iClusterName ) ; return true ; } } return ( Boolean ) value ; }", "nl": "Reads your writes ."}}
{"translation": {"code": "public synchronized void registerEntityClasses ( final Collection < String > iClassNames , final ClassLoader iClassLoader ) { OLogManager . instance ( ) . debug ( this , \"Discovering entity classes for class names: %s\" , iClassNames ) ; try { registerEntityClasses ( OReflectionHelper . getClassesFor ( iClassNames , iClassLoader ) ) ; } catch ( ClassNotFoundException e ) { throw OException . wrapException ( new ODatabaseException ( \"Entity class cannot be found\" ) , e ) ; } }", "nl": "Registers provided classes"}}
{"translation": {"code": "protected void setBucketPointer ( int pageOffset , OBonsaiBucketPointer value ) throws IOException { setLongValue ( pageOffset , value . getPageIndex ( ) ) ; setIntValue ( pageOffset + OLongSerializer . LONG_SIZE , value . getPageOffset ( ) ) ; }", "nl": "Write a bucket pointer to specific location ."}}
{"translation": {"code": "protected OBonsaiBucketPointer getBucketPointer ( int offset ) { final long pageIndex = getLongValue ( offset ) ; final int pageOffset = getIntValue ( offset + OLongSerializer . LONG_SIZE ) ; return new OBonsaiBucketPointer ( pageIndex , pageOffset ) ; }", "nl": "Read bucket pointer from page ."}}
{"translation": {"code": "public void close ( ) { lock ( ) ; try { if ( this . evictionTask != null ) { this . evictionTask . cancel ( ) ; } for ( Entry < String , OReentrantResourcePool < String , DB > > pool : pools . entrySet ( ) ) { for ( DB db : pool . getValue ( ) . getResources ( ) ) { pool . getValue ( ) . close ( ) ; try { OLogManager . instance ( ) . debug ( this , \"Closing pooled database '%s'...\" , db . getName ( ) ) ; ( ( ODatabasePooled ) db ) . forceClose ( ) ; OLogManager . instance ( ) . debug ( this , \"OK\" , db . getName ( ) ) ; } catch ( Exception e ) { OLogManager . instance ( ) . debug ( this , \"Error: %d\" , e . toString ( ) ) ; } } } } finally { unlock ( ) ; } }", "nl": "Closes all the databases ."}}
{"translation": {"code": "public void onStorageUnregistered ( final OStorage iStorage ) { final String storageURL = iStorage . getURL ( ) ; lock ( ) ; try { Set < String > poolToClose = null ; for ( Entry < String , OReentrantResourcePool < String , DB > > e : pools . entrySet ( ) ) { final int pos = e . getKey ( ) . indexOf ( \"@\" ) ; final String dbName = e . getKey ( ) . substring ( pos + 1 ) ; if ( storageURL . equals ( dbName ) ) { if ( poolToClose == null ) poolToClose = new HashSet < String > ( ) ; poolToClose . add ( e . getKey ( ) ) ; } } if ( poolToClose != null ) for ( String pool : poolToClose ) remove ( pool ) ; } finally { unlock ( ) ; } }", "nl": "Removes from memory the pool associated to the closed storage . This avoids pool open against closed storages ."}}
{"translation": {"code": "private Set < Comparable > prepareKeys ( OIndex < ? > index , Object keys ) { final OIndexDefinition indexDefinition = index . getDefinition ( ) ; if ( keys instanceof Collection ) { final Set < Comparable > newKeys = new TreeSet < Comparable > ( ) ; for ( Object o : ( ( Collection ) keys ) ) { newKeys . add ( ( Comparable ) indexDefinition . createValue ( o ) ) ; } return newKeys ; } else { return Collections . singleton ( ( Comparable ) indexDefinition . createValue ( keys ) ) ; } }", "nl": "Make type conversion of keys for specific index ."}}
{"translation": {"code": "public static Set < String > getCollateNames ( ) { final Set < String > types = new HashSet < String > ( ) ; final Iterator < OCollateFactory > ite = getCollateFactories ( ) ; while ( ite . hasNext ( ) ) { types . addAll ( ite . next ( ) . getNames ( ) ) ; } return types ; }", "nl": "Iterates on all factories and append all collate names ."}}
{"translation": {"code": "public OLogSequenceNumber endAtomicOperation ( boolean rollback ) throws IOException { final OAtomicOperation operation = currentOperation . get ( ) ; if ( operation == null ) { OLogManager . instance ( ) . error ( this , \"There is no atomic operation active\" , null ) ; throw new ODatabaseException ( \"There is no atomic operation active\" ) ; } int counter = operation . getCounter ( ) ; operation . decrementCounter ( ) ; assert counter > 0 ; final OLogSequenceNumber lsn ; try { if ( rollback ) { operation . rollback ( ) ; } if ( counter == 1 ) { try { final boolean useWal = useWal ( ) ; if ( ! operation . isRollback ( ) ) { lsn = operation . commitChanges ( useWal ? writeAheadLog : null ) ; } else { lsn = null ; } if ( trackAtomicOperations ) { activeAtomicOperations . remove ( operation . getOperationUnitId ( ) ) ; } } finally { final Iterator < String > lockedObjectIterator = operation . lockedObjects ( ) . iterator ( ) ; while ( lockedObjectIterator . hasNext ( ) ) { final String lockedObject = lockedObjectIterator . next ( ) ; lockedObjectIterator . remove ( ) ; lockManager . releaseLock ( this , lockedObject , OOneEntryPerKeyLockManager . LOCK . EXCLUSIVE ) ; } currentOperation . set ( null ) ; } } else { lsn = null ; } } catch ( Error e ) { final OAbstractPaginatedStorage st = storage ; if ( st != null ) { st . handleJVMError ( e ) ; } counter = 1 ; throw e ; } finally { if ( counter == 1 ) { atomicOperationsCount . decrement ( ) ; } } return lsn ; }", "nl": "Ends the current atomic operation on this manager ."}}
{"translation": {"code": "public void acquireExclusiveLockTillOperationComplete ( OAtomicOperation operation , String lockName ) { if ( operation . containsInLockedObjects ( lockName ) ) { return ; } lockManager . acquireLock ( lockName , OOneEntryPerKeyLockManager . LOCK . EXCLUSIVE ) ; operation . addLockedObject ( lockName ) ; }", "nl": "Acquires exclusive lock with the given lock name in the given atomic operation ."}}
{"translation": {"code": "private int updateSize ( ) { int size = 0 ; if ( collectionPointer != null ) { final OSBTreeBonsai < OIdentifiable , Integer > tree = loadTree ( ) ; if ( tree == null ) { throw new IllegalStateException ( \"RidBag is not properly initialized, can not load tree implementation\" ) ; } try { size = tree . getRealBagSize ( changes ) ; } finally { releaseTree ( ) ; } } else { for ( Change change : changes . values ( ) ) { size += change . applyTo ( 0 ) ; } } for ( OModifiableInteger diff : newEntries . values ( ) ) { size += diff . getValue ( ) ; } this . size = size ; return size ; }", "nl": "Recalculates real bag size ."}}
{"translation": {"code": "@ Override public void close ( ) { for ( Map . Entry < ORID , LockedRecordMetadata > lock : locks . entrySet ( ) ) { try { final LockedRecordMetadata lockedRecordMetadata = lock . getValue ( ) ; if ( lockedRecordMetadata . strategy . equals ( OStorage . LOCKING_STRATEGY . EXCLUSIVE_LOCK ) ) { ( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ) . releaseWriteLock ( lock . getKey ( ) ) ; } else if ( lockedRecordMetadata . strategy . equals ( OStorage . LOCKING_STRATEGY . SHARED_LOCK ) ) { ( ( OAbstractPaginatedStorage ) getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ) . releaseReadLock ( lock . getKey ( ) ) ; } } catch ( Exception e ) { OLogManager . instance ( ) . debug ( this , \"Error on releasing lock against record \" + lock . getKey ( ) , e ) ; } } locks . clear ( ) ; }", "nl": "Closes the transaction and releases all the acquired locks ."}}
{"translation": {"code": "public static OrientGraph getGraph ( final boolean autoStartTx , OModifiableBoolean shouldBeShutDown ) { final ODatabaseDocumentInternal database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; final OrientBaseGraph result = OrientBaseGraph . getActiveGraph ( ) ; if ( result != null && ( result instanceof OrientGraph ) ) { final ODatabaseDocumentInternal graphDb = result . getRawGraph ( ) ; // CHECK IF THE DATABASE + USER IN TL IS THE SAME IN ORDER TO USE IT if ( canReuseActiveGraph ( graphDb , database ) ) { if ( ! graphDb . isClosed ( ) ) { ODatabaseRecordThreadLocal . instance ( ) . set ( graphDb ) ; if ( autoStartTx && autoTxStartRequired ( graphDb ) ) ( ( OrientGraph ) result ) . begin ( ) ; shouldBeShutDown . setValue ( false ) ; return ( OrientGraph ) result ; } } } // Set it again on ThreadLocal because the getRawGraph() may have set a closed db in the thread-local ODatabaseRecordThreadLocal . instance ( ) . set ( database ) ; shouldBeShutDown . setValue ( true ) ; final OrientGraph g = ( OrientGraph ) OrientGraphFactory . getTxGraphImplFactory ( ) . getGraph ( database , false ) ; if ( autoStartTx && autoTxStartRequired ( database ) ) g . begin ( ) ; return g ; }", "nl": "Returns a Transactional OrientGraph implementation from the current database in thread local ."}}
{"translation": {"code": "@ SuppressWarnings ( \"unchecked\" ) @ Override public < T extends Element > Index < T > getIndex ( final String indexName , final Class < T > indexClass ) { makeActive ( ) ; final OIndexManager indexManager = getDatabase ( ) . getMetadata ( ) . getIndexManager ( ) ; final OIndex idx = indexManager . getIndex ( indexName ) ; if ( idx == null || ! hasIndexClass ( idx ) ) return null ; final Index < ? extends Element > index = new OrientIndex ( this , idx ) ; if ( indexClass . isAssignableFrom ( index . getIndexClass ( ) ) ) return ( Index < T > ) index ; else throw ExceptionFactory . indexDoesNotSupportClass ( indexName , indexClass ) ; }", "nl": "Returns an index by name and class"}}
{"translation": {"code": "void removeRecord ( ) { checkIfAttached ( ) ; final OrientBaseGraph graph = getGraph ( ) ; graph . setCurrentGraphInThreadLocal ( ) ; graph . autoStartTransaction ( ) ; if ( checkDeletedInTx ( ) ) graph . throwRecordNotFoundException ( getIdentity ( ) , \"The graph element with id \" + getIdentity ( ) + \" not found\" ) ; try { getRecord ( ) . load ( ) ; } catch ( ORecordNotFoundException e ) { graph . throwRecordNotFoundException ( getIdentity ( ) , e . getMessage ( ) ) ; } getRecord ( ) . delete ( ) ; }", "nl": "Removes the Element from the Graph . In case the element is a Vertex all the incoming and outgoing edges are automatically removed too ."}}
{"translation": {"code": "public void dropIndex ( final String indexName ) { makeActive ( ) ; executeOutsideTx ( new OCallable < Object , OrientBaseGraph > ( ) { @ Override public Object call ( OrientBaseGraph g ) { try { final OIndexManager indexManager = getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) ; final OIndex index = indexManager . getIndex ( indexName ) ; ODocument metadata = index . getConfiguration ( ) . field ( \"metadata\" ) ; String recordMapIndexName = null ; if ( metadata != null ) { recordMapIndexName = metadata . field ( OrientIndex . CONFIG_RECORD_MAP_NAME ) ; } indexManager . dropIndex ( indexName ) ; if ( recordMapIndexName != null ) getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( recordMapIndexName ) ; saveIndexConfiguration ( ) ; return null ; } catch ( Exception e ) { g . rollback ( ) ; throw new RuntimeException ( e . getMessage ( ) , e ) ; } } } , \"drop index '\" , indexName , \"'\" ) ; }", "nl": "Drops an index by name ."}}
{"translation": {"code": "@ Override public OrientVertex addVertex ( final Object id ) { makeActive ( ) ; return addVertex ( id , ( Object [ ] ) null ) ; }", "nl": "Creates a new unconnected vertex with no fields in the Graph ."}}
{"translation": {"code": "public OrientEdge addEdge ( final String label , final OrientVertex inVertex , final String iClassName ) { return addEdge ( label , inVertex , iClassName , null , ( Object [ ] ) null ) ; }", "nl": "Creates an edge between current Vertex and a target Vertex setting label as Edge s label . iClassName is the Edge s class used if different by label ."}}
{"translation": {"code": "@ Override public Edge addEdge ( final String label , Vertex inVertex ) { if ( inVertex instanceof PartitionVertex ) // WRAPPED: GET THE BASE VERTEX inVertex = ( ( PartitionVertex ) inVertex ) . getBaseVertex ( ) ; return addEdge ( label , ( OrientVertex ) inVertex , null , null , ( Object [ ] ) null ) ; }", "nl": "Creates an edge between current Vertex and a target Vertex setting label as Edge s label ."}}
{"translation": {"code": "@ Override public void remove ( ) { checkClass ( ) ; final OrientBaseGraph graph = checkIfAttached ( ) ; graph . setCurrentGraphInThreadLocal ( ) ; graph . autoStartTransaction ( ) ; final ODocument doc = getRecord ( ) ; if ( doc == null ) throw ExceptionFactory . vertexWithIdDoesNotExist ( this . getId ( ) ) ; Map < String , List < ODocument > > treeRidbagEdgesToRemove = new HashMap < String , List < ODocument > > ( ) ; if ( ! graph . getRawGraph ( ) . getTransaction ( ) . isActive ( ) ) { for ( String fieldName : doc . fieldNames ( ) ) { final OPair < Direction , String > connection = getConnection ( Direction . BOTH , fieldName ) ; if ( connection == null ) // SKIP THIS FIELD continue ; Object fv = doc . field ( fieldName ) ; if ( fv instanceof ORidBag && ! ( ( ORidBag ) fv ) . isEmbedded ( ) ) { List < ODocument > docs = new ArrayList < ODocument > ( ) ; for ( OIdentifiable id : ( ORidBag ) fv ) docs . ( OrientBaseGraph . getDocument ( id , true ) ) ; treeRidbagEdgesToRemove . put ( fieldName , docs ) ; } } } // REMOVE THE VERTEX RECORD FIRST TO CATCH CME BEFORE EDGES ARE REMOVED super . removeRecord ( ) ; // REMOVE THE VERTEX FROM MANUAL INDEXES final Iterator < Index < ? extends Element > > it = graph . getIndices ( ) . iterator ( ) ; if ( it . hasNext ( ) ) { final Set < Edge > allEdges = new HashSet < Edge > ( ) ; for ( Edge e : getEdges ( Direction . BOTH ) ) allEdges . ( ) ; while ( it . hasNext ( ) ) { final Index < ? extends Element > index = it . next ( ) ; if ( Vertex . class . isAssignableFrom ( index . getIndexClass ( ) ) ) { OrientIndex < OrientVertex > idx = ( OrientIndex < OrientVertex > ) index ; idx . removeElement ( this ) ; } if ( Edge . class . isAssignableFrom ( index . getIndexClass ( ) ) ) { OrientIndex < OrientEdge > idx = ( OrientIndex < OrientEdge > ) index ; for ( Edge e : allEdges ) idx . removeElement ( ( OrientEdge ) ) ; } } } for ( Map . Entry < String , List < ODocument > > entry : treeRidbagEdgesToRemove . entrySet ( ) ) { doc . removeField ( entry . getKey ( ) ) ; Iterator < ODocument > iter = entry . getValue ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { ODocument docEdge = iter . next ( ) ; OrientBaseGraph . deleteEdgeIfAny ( docEdge , false ) ; } } graph . removeEdgesInternal ( this , doc , null , true , settings . isUseVertexFieldsForEdgeLabels ( ) , settings . isAutoScaleEdgeType ( ) ) ; }", "nl": "Removes the current Vertex from the Graph . all the incoming and outgoing edges are automatically removed too ."}}
{"translation": {"code": "@ Override public Iterable < Vertex > getVertices ( final Direction iDirection , final String ... iLabels ) { setCurrentGraphInThreadLocal ( ) ; OrientBaseGraph . getEdgeClassNames ( getGraph ( ) , iLabels ) ; OrientBaseGraph . encodeClassNames ( iLabels ) ; final ODocument doc = getRecord ( ) ; final OMultiCollectionIterator < Vertex > iterable = new OMultiCollectionIterator < Vertex > ( ) ; for ( OTriple < String , Direction , String > connectionField : getConnectionFields ( iDirection , iLabels ) ) { String fieldName = connectionField . getKey ( ) ; OPair < Direction , String > connection = connectionField . getValue ( ) ; final Object fieldValue = doc . rawField ( fieldName ) ; if ( fieldValue != null ) if ( fieldValue instanceof OIdentifiable ) { addSingleVertex ( doc , iterable , fieldName , connection , fieldValue , iLabels ) ; } else if ( fieldValue instanceof Collection < ? > ) { Collection < ? > coll = ( Collection < ? > ) fieldValue ; if ( coll . size ( ) == 1 ) { // SINGLE ITEM: AVOID CALLING ITERATOR if ( coll instanceof ORecordLazyMultiValue ) addSingleVertex ( doc , iterable , fieldName , connection , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) . next ( ) , iLabels ) ; else if ( coll instanceof List < ? > ) addSingleVertex ( doc , iterable , fieldName , connection , ( ( List < ? > ) coll ) . get ( 0 ) , iLabels ) ; else addSingleVertex ( doc , iterable , fieldName , connection , coll . iterator ( ) . next ( ) , iLabels ) ; } else { // CREATE LAZY Iterable AGAINST COLLECTION FIELD if ( coll instanceof ORecordLazyMultiValue ) iterable . add ( new OrientVertexIterator ( this , coll , ( ( ORecordLazyMultiValue ) coll ) . rawIterator ( ) , connection , iLabels , coll . size ( ) ) ) ; else iterable . add ( new OrientVertexIterator ( this , coll , coll . iterator ( ) , connection , iLabels , - 1 ) ) ; } } else if ( fieldValue instanceof ORidBag ) { iterable . add ( new OrientVertexIterator ( this , fieldValue , ( ( ORidBag ) fieldValue ) . rawIterator ( ) , connection , iLabels , - 1 ) ) ; } } return iterable ; }", "nl": "Returns a lazy iterable instance against vertices ."}}
{"translation": {"code": "protected String checkForClassInSchema ( final String className ) { if ( className == null ) return null ; OrientBaseGraph graph = getGraph ( ) ; if ( graph == null ) return className ; final OSchema schema = graph . getRawGraph ( ) . getMetadata ( ) . getSchema ( ) ; if ( ! schema . existsClass ( className ) ) { // CREATE A NEW CLASS AT THE FLY try { graph . executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { @ Override public OClass call ( final OrientBaseGraph g ) { return schema . createClass ( className , schema . getClass ( getBaseClassName ( ) ) ) ; } } , \"Committing the active transaction to create the new type '\" , className , \"' as subclass of '\" , getBaseClassName ( ) , \"'. The transaction will be reopen right after that. To avoid this behavior create the classes outside the transaction\" ) ; } catch ( OSchemaException e ) { if ( ! schema . existsClass ( className ) ) throw e ; } } else { // CHECK THE CLASS INHERITANCE final OClass cls = schema . getClass ( className ) ; if ( ! cls . isSubClassOf ( getBaseClassName ( ) ) ) throw new IllegalArgumentException ( \"Class '\" + className + \"' is not an instance of \" + getBaseClassName ( ) ) ; } return className ; }", "nl": "Check if a class already exists otherwise create it at the fly . If a transaction is running commit changes create the class and begin a new transaction ."}}
{"translation": {"code": "@ Override public < T > T removeProperty ( final String key ) { if ( checkDeletedInTx ( ) ) throw new IllegalStateException ( \"The vertex \" + getIdentity ( ) + \" has been deleted\" ) ; final OrientBaseGraph graph = getGraph ( ) ; if ( graph != null ) graph . autoStartTransaction ( ) ; final Object oldValue = getRecord ( ) . removeField ( key ) ; if ( graph != null ) save ( ) ; return ( T ) oldValue ; }", "nl": "Removes a Property ."}}
{"translation": {"code": "@ Override public void setProperty ( final String key , final Object value ) { if ( checkDeletedInTx ( ) ) graph . throwRecordNotFoundException ( getIdentity ( ) , \"The graph element \" + getIdentity ( ) + \" has been deleted\" ) ; validateProperty ( this , key , value ) ; final OrientBaseGraph graph = getGraph ( ) ; if ( graph != null ) graph . autoStartTransaction ( ) ; getRecord ( ) . field ( key , value ) ; if ( graph != null ) save ( ) ; }", "nl": "Sets a Property value ."}}
{"translation": {"code": "protected OPair < Direction , String > getConnection ( final Direction iDirection , final String iFieldName , String ... iClassNames ) { if ( iClassNames != null && iClassNames . length == 1 && iClassNames [ 0 ] . equalsIgnoreCase ( \"E\" ) ) // DEFAULT CLASS, TREAT IT AS NO CLASS/LABEL iClassNames = null ; final OrientBaseGraph graph = getGraph ( ) ; if ( iDirection == Direction . OUT || iDirection == Direction . BOTH ) { if ( settings . isUseVertexFieldsForEdgeLabels ( ) ) { // FIELDS THAT STARTS WITH \"out_\" if ( iFieldName . startsWith ( CONNECTION_OUT_PREFIX ) ) { String connClass = getConnectionClass ( Direction . OUT , iFieldName ) ; if ( iClassNames == null || iClassNames . length == 0 ) return new OPair < Direction , String > ( Direction . OUT , connClass ) ; // CHECK AGAINST ALL THE CLASS NAMES OrientEdgeType edgeType = graph . getEdgeType ( connClass ) ; if ( edgeType != null ) { for ( String clsName : iClassNames ) { if ( edgeType . isSubClassOf ( clsName ) ) return new OPair < Direction , String > ( Direction . OUT , connClass ) ; } } } } else if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_OUT ) ) // CHECK FOR \"out\" return new OPair < Direction , String > ( Direction . OUT , null ) ; } if ( iDirection == Direction . IN || iDirection == Direction . BOTH ) { if ( settings . isUseVertexFieldsForEdgeLabels ( ) ) { // FIELDS THAT STARTS WITH \"in_\" if ( iFieldName . startsWith ( CONNECTION_IN_PREFIX ) ) { String connClass = getConnectionClass ( Direction . IN , iFieldName ) ; if ( iClassNames == null || iClassNames . length == 0 ) return new OPair < Direction , String > ( Direction . IN , connClass ) ; // CHECK AGAINST ALL THE CLASS NAMES OrientEdgeType edgeType = graph . getEdgeType ( connClass ) ; if ( edgeType != null ) { for ( String clsName : iClassNames ) { if ( edgeType . isSubClassOf ( clsName ) ) return new OPair < Direction , String > ( Direction . IN , connClass ) ; } } } } else if ( iFieldName . equals ( OrientBaseGraph . CONNECTION_IN ) ) // CHECK FOR \"in\" return new OPair < Direction , String > ( Direction . IN , null ) ; } // NOT FOUND return null ; }", "nl": "Determines if a field is a connections or not ."}}
{"translation": {"code": "@ Override public OrientEdge addEdge ( final Object id , Vertex outVertex , Vertex inVertex , final String label ) { makeActive ( ) ; String className = null ; String clusterName = null ; if ( id != null ) { if ( id instanceof String ) { // PARSE ARGUMENTS final String [ ] args = ( ( String ) id ) . split ( \",\" ) ; for ( String s : args ) { if ( s . startsWith ( CLASS_PREFIX ) ) // GET THE CLASS NAME className = s . substring ( CLASS_PREFIX . length ( ) ) ; else if ( s . startsWith ( CLUSTER_PREFIX ) ) // GET THE CLASS NAME clusterName = s . substring ( CLUSTER_PREFIX . length ( ) ) ; } } } // SAVE THE ID TOO? final Object [ ] fields = isSaveOriginalIds ( ) && id != null ? new Object [ ] { OrientElement . DEF_ORIGINAL_ID_FIELDNAME , id } : null ; if ( outVertex instanceof PartitionVertex ) // WRAPPED: GET THE BASE VERTEX outVertex = ( ( PartitionVertex ) outVertex ) . getBaseVertex ( ) ; if ( inVertex instanceof PartitionVertex ) // WRAPPED: GET THE BASE VERTEX inVertex = ( ( PartitionVertex ) inVertex ) . getBaseVertex ( ) ; return ( ( OrientVertex ) outVertex ) . addEdge ( label , ( OrientVertex ) inVertex , className , clusterName , fields ) ; }", "nl": "Creates an edge between a source Vertex and a destination Vertex setting label as Edge s label ."}}
{"translation": {"code": "@ SuppressWarnings ( \"deprecation\" ) @ Override public void stopTransaction ( final Conclusion conclusion ) { makeActive ( ) ; if ( getDatabase ( ) . isClosed ( ) || getDatabase ( ) . getTransaction ( ) instanceof OTransactionNoTx || getDatabase ( ) . getTransaction ( ) . getStatus ( ) != TXSTATUS . BEGUN ) return ; if ( Conclusion . SUCCESS == conclusion ) commit ( ) ; else rollback ( ) ; }", "nl": "Closes a transaction ."}}
{"translation": {"code": "public OrientVertexType getVertexBaseType ( ) { makeActive ( ) ; return new OrientVertexType ( this , getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( OrientVertexType . CLASS_NAME ) ) ; }", "nl": "Returns the V persistent class as OrientVertexType instance ."}}
{"translation": {"code": "public OrientVertexType getVertexType ( final String iTypeName ) { makeActive ( ) ; final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iTypeName ) ; if ( cls == null ) return null ; OrientVertexType . checkType ( cls ) ; return new OrientVertexType ( this , cls ) ; }", "nl": "Returns the persistent class for type iTypeName as OrientVertexType instance ."}}
{"translation": {"code": "public Features getFeatures ( ) { makeActive ( ) ; if ( ! featuresInitialized ) { FEATURES . supportsDuplicateEdges = true ; FEATURES . supportsSelfLoops = true ; FEATURES . isPersistent = true ; FEATURES . supportsVertexIteration = true ; FEATURES . supportsVertexIndex = true ; FEATURES . ignoresSuppliedIds = true ; FEATURES . supportsTransactions = true ; FEATURES . supportsVertexKeyIndex = true ; FEATURES . supportsKeyIndices = true ; FEATURES . isWrapper = false ; FEATURES . supportsIndices = true ; FEATURES . supportsVertexProperties = true ; FEATURES . supportsEdgeProperties = true ; // For more information on supported types, please see: // http://code.google.com/p/orient/wiki/Types FEATURES . supportsSerializableObjectProperty = true ; FEATURES . supportsBooleanProperty = true ; FEATURES . supportsDoubleProperty = true ; FEATURES . supportsFloatProperty = true ; FEATURES . supportsIntegerProperty = true ; FEATURES . supportsPrimitiveArrayProperty = true ; FEATURES . supportsUniformListProperty = true ; FEATURES . supportsMixedListProperty = true ; FEATURES . supportsLongProperty = true ; FEATURES . supportsMapProperty = true ; FEATURES . supportsStringProperty = true ; FEATURES . supportsThreadedTransactions = false ; FEATURES . supportsThreadIsolatedTransactions = false ; // DYNAMIC FEATURES BASED ON CONFIGURATION FEATURES . supportsEdgeIndex = ! isUseLightweightEdges ( ) ; FEATURES . supportsEdgeKeyIndex = ! isUseLightweightEdges ( ) ; FEATURES . supportsEdgeIteration = ! isUseLightweightEdges ( ) ; FEATURES . supportsEdgeRetrieval = ! isUseLightweightEdges ( ) ; featuresInitialized = true ; } return FEATURES ; }", "nl": "Returns the current Graph settings ."}}
{"translation": {"code": "public OrientVertex getVertex ( final Object id ) { makeActive ( ) ; if ( null == id ) throw ExceptionFactory . vertexIdCanNotBeNull ( ) ; if ( id instanceof OrientVertex ) return ( OrientVertex ) id ; else if ( id instanceof ODocument ) return getVertexInstance ( ( OIdentifiable ) id ) ; setCurrentGraphInThreadLocal ( ) ; ORID rid ; if ( id instanceof OIdentifiable ) rid = ( ( OIdentifiable ) id ) . getIdentity ( ) ; else { try { rid = new ORecordId ( id . toString ( ) ) ; } catch ( IllegalArgumentException iae ) { // orientdb throws IllegalArgumentException: Argument 'xxxx' is // not a RecordId in form of string. Format must be: // <cluster-id>:<cluster-position> return null ; } } if ( ! rid . isValid ( ) ) return null ; final ORecord rec = rid . getRecord ( ) ; if ( rec == null || ! ( rec instanceof ODocument ) ) return null ; final OClass cls = ( ( ODocument ) rec ) . getSchemaClass ( ) ; if ( cls != null && cls . isEdgeType ( ) ) throw new IllegalArgumentException ( \"Cannot retrieve a vertex with the RID \" + rid + \" because it is an edge\" ) ; return getVertexInstance ( rec ) ; }", "nl": "Returns a vertex by an ID ."}}
{"translation": {"code": "@ Override public Iterable < Edge > edges ( ) { if ( limit == 0 ) return Collections . emptyList ( ) ; if ( ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . getTransaction ( ) . isActive ( ) || hasCustomPredicate ( ) ) // INSIDE TRANSACTION QUERY DOESN'T SEE IN MEMORY CHANGES, UNTIL // SUPPORTED USED THE BASIC IMPL return new OrientGraphQueryIterable < Edge > ( false , labels ) ; if ( ( ( OrientBaseGraph ) graph ) . isUseLightweightEdges ( ) ) return new OrientGraphQueryIterable < Edge > ( false , labels ) ; final StringBuilder text = new StringBuilder ( 512 ) ; // GO DIRECTLY AGAINST E CLASS AND SUB-CLASSES text . append ( QUERY_SELECT_FROM ) ; if ( ( ( OrientBaseGraph ) graph ) . isUseClassForEdgeLabel ( ) && labels != null && labels . length > 0 ) { // FILTER PER CLASS SAVING CHECKING OF LABEL PROPERTY if ( labels . length == 1 ) // USE THE CLASS NAME text . append ( OrientBaseGraph . encodeClassName ( labels [ 0 ] ) ) ; else { // MULTIPLE CLASSES NOT SUPPORTED DIRECTLY: CREATE A SUB-QUERY return new OrientGraphQueryIterable < Edge > ( false , labels ) ; } } else text . append ( OrientEdgeType . CLASS_NAME ) ; List < Object > queryParams = manageFilters ( text ) ; if ( ! ( ( OrientBaseGraph ) graph ) . isUseClassForEdgeLabel ( ) ) manageLabels ( queryParams . size ( ) > 0 , text ) ; final OSQLSynchQuery < OIdentifiable > query = new OSQLSynchQuery < OIdentifiable > ( text . toString ( ) ) ; if ( fetchPlan != null ) query . setFetchPlan ( fetchPlan ) ; if ( limit > 0 && limit < Integer . MAX_VALUE ) query . setLimit ( limit ) ; return new OrientElementIterable < Edge > ( ( ( OrientBaseGraph ) graph ) , ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . query ( query , queryParams . toArray ( ) ) ) ; }", "nl": "Returns the result set of the query as iterable edges ."}}
{"translation": {"code": "@ Override public Iterable < Vertex > vertices ( ) { if ( limit == 0 ) return Collections . emptyList ( ) ; OTransaction transaction = ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . getTransaction ( ) ; if ( transaction . isActive ( ) && transaction . getEntryCount ( ) > 0 || hasCustomPredicate ( ) ) { // INSIDE TRANSACTION QUERY DOESN'T SEE IN MEMORY CHANGES, UNTIL // SUPPORTED USED THE BASIC IMPL String [ ] classes = allSubClassesLabels ( ) ; return new OrientGraphQueryIterable < Vertex > ( true , classes ) ; } final StringBuilder text = new StringBuilder ( 512 ) ; // GO DIRECTLY AGAINST E CLASS AND SUB-CLASSES text . append ( QUERY_SELECT_FROM ) ; if ( ( ( OrientBaseGraph ) graph ) . isUseClassForVertexLabel ( ) && labels != null && labels . length > 0 ) { // FILTER PER CLASS SAVING CHECKING OF LABEL PROPERTY if ( labels . length == 1 ) // USE THE CLASS NAME text . append ( OrientBaseGraph . encodeClassName ( labels [ 0 ] ) ) ; else { // MULTIPLE CLASSES NOT SUPPORTED DIRECTLY: CREATE A SUB-QUERY String [ ] classes = allSubClassesLabels ( ) ; return new OrientGraphQueryIterable < Vertex > ( true , classes ) ; } } else text . append ( OrientVertexType . CLASS_NAME ) ; final List < Object > queryParams = manageFilters ( text ) ; if ( ! ( ( OrientBaseGraph ) graph ) . isUseClassForVertexLabel ( ) ) manageLabels ( queryParams . size ( ) > 0 , text ) ; if ( orderBy . length ( ) > 1 ) { text . append ( ORDERBY ) ; text . append ( orderBy ) ; text . append ( \" \" ) . append ( orderByDir ) . append ( \" \" ) ; } if ( skip > 0 && skip < Integer . MAX_VALUE ) { text . append ( SKIP ) ; text . append ( skip ) ; } if ( limit > 0 && limit < Integer . MAX_VALUE ) { text . append ( LIMIT ) ; text . append ( limit ) ; } final OSQLSynchQuery < OIdentifiable > query = new OSQLSynchQuery < OIdentifiable > ( text . toString ( ) ) ; if ( fetchPlan != null ) query . setFetchPlan ( fetchPlan ) ; return new OrientElementIterable < Vertex > ( ( ( OrientBaseGraph ) graph ) , ( ( OrientBaseGraph ) graph ) . getRawGraph ( ) . query ( query , queryParams . toArray ( ) ) ) ; }", "nl": "Returns the result set of the query as iterable vertices ."}}
{"translation": {"code": "@ Override public OrientVertex getVertex ( final Direction direction ) { final OrientBaseGraph graph = setCurrentGraphInThreadLocal ( ) ; if ( direction . equals ( Direction . OUT ) ) return graph . getVertex ( getOutVertex ( ) ) ; else if ( direction . equals ( Direction . IN ) ) return graph . getVertex ( getInVertex ( ) ) ; else throw ExceptionFactory . bothIsNotSupported ( ) ; }", "nl": "Returns the connected incoming or outgoing vertex ."}}
{"translation": {"code": "@ Override public Object getId ( ) { if ( rawElement == null ) // CREATE A TEMPORARY ID return vOut . getIdentity ( ) + \"->\" + vIn . getIdentity ( ) ; setCurrentGraphInThreadLocal ( ) ; return super . getId ( ) ; }", "nl": "Returns the Edge Id assuring to save it if it s transient yet ."}}
{"translation": {"code": "@ Override public void setProperty ( final String key , final Object value ) { setCurrentGraphInThreadLocal ( ) ; if ( rawElement == null ) // LIGHTWEIGHT EDGE convertToDocument ( ) ; super . setProperty ( key , value ) ; }", "nl": "Set a Property value . If the edge is lightweight it s transparently transformed into a regular edge ."}}
{"translation": {"code": "@ Override public < T > T removeProperty ( String key ) { setCurrentGraphInThreadLocal ( ) ; if ( rawElement != null ) // NON LIGHTWEIGHT EDGE return super . removeProperty ( key ) ; return null ; }", "nl": "Removed a Property ."}}
{"translation": {"code": "public void shutdown ( boolean closeDb , boolean commitTx ) { makeActive ( ) ; try { if ( ! isClosed ( ) ) { if ( commitTx ) { final OStorage storage = getDatabase ( ) . getStorage ( ) . getUnderlying ( ) ; if ( storage instanceof OAbstractPaginatedStorage ) { if ( ( ( OAbstractPaginatedStorage ) storage ) . getWALInstance ( ) != null ) getDatabase ( ) . commit ( ) ; } else { getDatabase ( ) . commit ( ) ; } } else if ( closeDb ) { getDatabase ( ) . rollback ( ) ; } } } catch ( ONeedRetryException e ) { throw e ; } catch ( RuntimeException e ) { OLogManager . instance ( ) . error ( this , \"Error during context close for db \" + url , e ) ; throw e ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error during context close for db \" + url , e ) ; throw OException . wrapException ( new ODatabaseException ( \"Error during context close for db \" + url ) , e ) ; } finally { try { if ( closeDb ) { getDatabase ( ) . close ( ) ; if ( getDatabase ( ) . isPooled ( ) ) { database = null ; } } pollGraphFromStack ( closeDb ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error during context close for db \" + url , e ) ; } } url = null ; username = null ; password = null ; if ( ! closeDb ) getDatabase ( ) . activateOnCurrentThread ( ) ; }", "nl": "Closes the Graph . After closing the Graph cannot be used ."}}
{"translation": {"code": "public OrientEdgeType getEdgeType ( final String iTypeName ) { makeActive ( ) ; final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iTypeName ) ; if ( cls == null ) return null ; OrientEdgeType . checkType ( cls ) ; return new OrientEdgeType ( this , cls ) ; }", "nl": "Returns the persistent class for type iTypeName as OrientEdgeType instance ."}}
{"translation": {"code": "public < T extends Element > void dropKeyIndex ( final String key , final Class < T > elementClass ) { makeActive ( ) ; if ( elementClass == null ) throw ExceptionFactory . classForElementCannotBeNull ( ) ; executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { @ Override public OClass call ( final OrientBaseGraph g ) { final String className = getClassName ( elementClass ) ; getRawGraph ( ) . getMetadata ( ) . getIndexManager ( ) . dropIndex ( className + \".\" + key ) ; return null ; } } , \"drop key index '\" , elementClass . getSimpleName ( ) , \".\" , key , \"'\" ) ; }", "nl": "Drops the index against a field name ."}}
{"translation": {"code": "public OrientBaseGraph reuse ( final ODatabaseDocumentInternal iDatabase ) { ODatabaseRecordThreadLocal . instance ( ) . set ( iDatabase ) ; this . url = iDatabase . getURL ( ) ; database = iDatabase ; makeActive ( ) ; return this ; }", "nl": "Reuses the underlying database avoiding to create and open it every time ."}}
{"translation": {"code": "public OrientEdge getEdge ( final Object id ) { makeActive ( ) ; if ( null == id ) throw ExceptionFactory . edgeIdCanNotBeNull ( ) ; if ( id instanceof OrientEdge ) return ( OrientEdge ) id ; else if ( id instanceof ODocument ) return new OrientEdge ( this , ( OIdentifiable ) id ) ; final OIdentifiable rec ; if ( id instanceof OIdentifiable ) rec = ( OIdentifiable ) id ; else { final String str = id . toString ( ) ; int pos = str . indexOf ( \"->\" ) ; if ( pos > - 1 ) { // DUMMY EDGE: CREATE IT IN MEMORY final String from = str . substring ( 0 , pos ) ; final String to = str . substring ( pos + 2 ) ; return getEdgeInstance ( new ORecordId ( from ) , new ORecordId ( to ) , null ) ; } try { rec = new ORecordId ( str ) ; } catch ( IllegalArgumentException iae ) { // orientdb throws IllegalArgumentException: Argument 'xxxx' is // not a RecordId in form of string. Format must be: // [#]<cluster-id>:<cluster-position> return null ; } } final ODocument doc = rec . getRecord ( ) ; if ( doc == null ) return null ; final OClass cls = doc . getSchemaClass ( ) ; if ( cls != null ) { if ( cls . isVertexType ( ) ) throw new IllegalArgumentException ( \"Cannot retrieve an edge with the RID \" + id + \" because it is a vertex\" ) ; if ( ! cls . isEdgeType ( ) ) throw new IllegalArgumentException ( \"Class '\" + doc . getClassName ( ) + \"' is not an edge class\" ) ; } return new OrientEdge ( this , rec ) ; }", "nl": "Returns a edge by an ID ."}}
{"translation": {"code": "public Iterable < Edge > getEdgesOfClass ( final String iClassName , final boolean iPolymorphic ) { makeActive ( ) ; final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iClassName ) ; if ( cls == null ) throw new IllegalArgumentException ( \"Cannot find class '\" + iClassName + \"' in database schema\" ) ; if ( ! cls . isSubClassOf ( OrientEdgeType . CLASS_NAME ) ) throw new IllegalArgumentException ( \"Class '\" + iClassName + \"' is not an edge class\" ) ; return new OrientElementScanIterable < Edge > ( this , iClassName , iPolymorphic ) ; }", "nl": "Get all the Edges in Graph of a specific edges class and all sub - classes only if iPolymorphic is true ."}}
{"translation": {"code": "public Iterable < Vertex > getVerticesOfClass ( final String iClassName , final boolean iPolymorphic ) { makeActive ( ) ; final OClass cls = getRawGraph ( ) . getMetadata ( ) . getSchema ( ) . getClass ( iClassName ) ; if ( cls == null ) throw new IllegalArgumentException ( \"Cannot find class '\" + iClassName + \"' in database schema\" ) ; if ( ! cls . isSubClassOf ( OrientVertexType . CLASS_NAME ) ) throw new IllegalArgumentException ( \"Class '\" + iClassName + \"' is not a vertex class\" ) ; return new OrientElementScanIterable < Vertex > ( this , iClassName , iPolymorphic ) ; }", "nl": "Get all the Vertices in Graph of a specific vertex class and all sub - classes only if iPolymorphic is true ."}}
{"translation": {"code": "@ SuppressWarnings ( { \"rawtypes\" } ) @ Override public < T extends Element > void createKeyIndex ( final String key , final Class < T > elementClass , final Parameter ... indexParameters ) { makeActive ( ) ; if ( elementClass == null ) throw ExceptionFactory . classForElementCannotBeNull ( ) ; executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { @ Override public OClass call ( final OrientBaseGraph g ) { String indexType = OClass . INDEX_TYPE . NOTUNIQUE . name ( ) ; OType keyType = OType . STRING ; String className = null ; String collate = null ; ODocument metadata = null ; final String ancestorClassName = getClassName ( elementClass ) ; // READ PARAMETERS for ( Parameter < ? , ? > p : indexParameters ) { if ( p . getKey ( ) . equals ( \"type\" ) ) indexType = p . getValue ( ) . toString ( ) . toUpperCase ( Locale . ENGLISH ) ; else if ( p . getKey ( ) . equals ( \"keytype\" ) ) keyType = OType . valueOf ( p . getValue ( ) . toString ( ) . toUpperCase ( Locale . ENGLISH ) ) ; else if ( p . getKey ( ) . equals ( \"class\" ) ) className = p . getValue ( ) . toString ( ) ; else if ( p . getKey ( ) . equals ( \"collate\" ) ) collate = p . getValue ( ) . toString ( ) ; else if ( p . getKey ( ) . toString ( ) . startsWith ( \"metadata.\" ) ) { if ( metadata == null ) metadata = new ODocument ( ) ; metadata . field ( p . getKey ( ) . toString ( ) . substring ( \"metadata.\" . length ( ) ) , p . getValue ( ) ) ; } } if ( className == null ) className = ancestorClassName ; final ODatabaseDocument db = getRawGraph ( ) ; final OSchema schema = db . getMetadata ( ) . getSchema ( ) ; final OClass cls = schema . getOrCreateClass ( className , schema . getClass ( ancestorClassName ) ) ; final OProperty property = cls . getProperty ( key ) ; if ( property != null ) keyType = property . getType ( ) ; OPropertyIndexDefinition indexDefinition = new OPropertyIndexDefinition ( className , key , keyType ) ; if ( collate != null ) indexDefinition . setCollate ( collate ) ; db . getMetadata ( ) . getIndexManager ( ) . createIndex ( className + \".\" + key , indexType , indexDefinition , cls . getPolymorphicClusterIds ( ) , null , metadata ) ; return null ; } } , \"create key index on '\" , elementClass . getSimpleName ( ) , \".\" , key , \"'\" ) ; }", "nl": "Creates an automatic indexing structure for indexing provided key for element class ."}}
{"translation": {"code": "public OrientElement getElement ( final Object id ) { makeActive ( ) ; if ( null == id ) throw new IllegalArgumentException ( \"id cannot be null\" ) ; if ( id instanceof OrientElement ) return ( OrientElement ) id ; OIdentifiable rec ; if ( id instanceof OIdentifiable ) rec = ( OIdentifiable ) id ; else try { rec = new ORecordId ( id . toString ( ) ) ; } catch ( IllegalArgumentException iae ) { // orientdb throws IllegalArgumentException: Argument 'xxxx' is // not a RecordId in form of string. Format must be: // <cluster-id>:<cluster-position> return null ; } final ODocument doc = rec . getRecord ( ) ; if ( doc != null ) { final OImmutableClass schemaClass = ODocumentInternal . getImmutableSchemaClass ( doc ) ; if ( schemaClass != null && schemaClass . isEdgeType ( ) ) return getEdge ( doc ) ; else return getVertexInstance ( doc ) ; } return null ; }", "nl": "Returns a graph element vertex or edge starting from an ID ."}}
{"translation": {"code": "public void dropVertexType ( final String iTypeName ) { makeActive ( ) ; if ( getDatabase ( ) . countClass ( iTypeName ) > 0 ) throw new OCommandExecutionException ( \"cannot drop vertex type '\" + iTypeName + \"' because it contains Vertices. Use 'DELETE VERTEX' command first to remove data\" ) ; executeOutsideTx ( new OCallable < OClass , OrientBaseGraph > ( ) { @ Override public OClass call ( final OrientBaseGraph g ) { ODatabaseDocument rawGraph = getRawGraph ( ) ; rawGraph . getMetadata ( ) . getSchema ( ) . dropClass ( iTypeName ) ; return null ; } } , \"drop vertex type '\" , iTypeName , \"'\" ) ; }", "nl": "Drop a vertex class ."}}
{"translation": {"code": "@ Override public void clear ( ) throws IOException { boolean rollback = false ; final OAtomicOperation atomicOperation = startAtomicOperation ( true ) ; try { final Lock lock = FILE_LOCK_MANAGER . acquireExclusiveLock ( fileId ) ; try { final Queue < OBonsaiBucketPointer > subTreesToDelete = new LinkedList <> ( ) ; final OCacheEntry cacheEntry = loadPageForWrite ( atomicOperation , fileId , rootBucketPointer . getPageIndex ( ) , false , true ) ; try { OSBTreeBonsaiBucket < K , V > rootBucket = new OSBTreeBonsaiBucket <> ( cacheEntry , rootBucketPointer . getPageOffset ( ) , keySerializer , valueSerializer , this ) ; addChildrenToQueue ( subTreesToDelete , rootBucket ) ; rootBucket . shrink ( 0 ) ; rootBucket = new OSBTreeBonsaiBucket <> ( cacheEntry , rootBucketPointer . getPageOffset ( ) , true , keySerializer , valueSerializer , this ) ; rootBucket . setTreeSize ( 0 ) ; } finally { releasePageFromWrite ( atomicOperation , cacheEntry ) ; } recycleSubTrees ( subTreesToDelete , atomicOperation ) ; } finally { lock . unlock ( ) ; } } catch ( final Exception e ) { rollback = true ; throw e ; } finally { endAtomicOperation ( rollback ) ; } }", "nl": "Removes all entries from bonsai tree . Put all but the root page to free list for further reuse ."}}
{"translation": {"code": "@ Override public void delete ( ) throws IOException { boolean rollback = false ; final OAtomicOperation atomicOperation = startAtomicOperation ( false ) ; try { final Lock lock = FILE_LOCK_MANAGER . acquireExclusiveLock ( fileId ) ; try { final Queue < OBonsaiBucketPointer > subTreesToDelete = new LinkedList <> ( ) ; subTreesToDelete . add ( rootBucketPointer ) ; recycleSubTrees ( subTreesToDelete , atomicOperation ) ; } finally { lock . unlock ( ) ; } } catch ( final Exception e ) { rollback = true ; throw e ; } finally { endAtomicOperation ( rollback ) ; } }", "nl": "Deletes a whole tree . Puts all its pages to free list for further reusage ."}}
{"translation": {"code": "@ Override public UUID listenForChanges ( ORidBag collection ) { UUID ownerUUID = collection . getTemporaryId ( ) ; if ( ownerUUID != null ) { final OBonsaiCollectionPointer pointer = collection . getPointer ( ) ; Map < UUID , OBonsaiCollectionPointer > changedPointers = collectionPointerChanges . get ( ) ; if ( pointer != null && pointer . isValid ( ) ) { changedPointers . put ( ownerUUID , pointer ) ; } } return null ; }", "nl": "Change UUID to null to prevent its serialization to disk ."}}
{"translation": {"code": "public OrientGraph getTx ( ) { final OrientGraph g ; if ( pool == null ) { g = ( OrientGraph ) getTxGraphImplFactory ( ) . getGraph ( getDatabase ( ) , user , password , settings ) ; } else { // USE THE POOL g = ( OrientGraph ) getTxGraphImplFactory ( ) . getGraph ( pool , settings ) ; } initGraph ( g ) ; return g ; }", "nl": "Gets transactional graph with the database from pool if pool is configured . Otherwise creates a graph with new db instance . The Graph instance inherits the factory s configuration ."}}
{"translation": {"code": "public OrientGraphNoTx getNoTx ( ) { final OrientGraphNoTx g ; if ( pool == null ) { g = ( OrientGraphNoTx ) getNoTxGraphImplFactory ( ) . getGraph ( getDatabase ( ) , user , password , settings ) ; } else { // USE THE POOL g = ( OrientGraphNoTx ) getNoTxGraphImplFactory ( ) . getGraph ( pool , settings ) ; } initGraph ( g ) ; return g ; }", "nl": "Gets non transactional graph with the database from pool if pool is configured . Otherwise creates a graph with new db instance . The Graph instance inherits the factory s configuration ."}}
{"translation": {"code": "public OrientGraphFactory setupPool ( final int iMin , final int iMax ) { if ( pool != null ) { pool . close ( ) ; } pool = new OPartitionedDatabasePool ( url , user , password , 8 , iMax ) . setAutoCreate ( true ) ; properties . entrySet ( ) . forEach ( p -> pool . setProperty ( p . getKey ( ) , p . getValue ( ) ) ) ; return this ; }", "nl": "Setting up the factory to use database pool instead of creation a new instance of database connection each time ."}}
{"translation": {"code": "protected String parseLock ( ) throws OCommandSQLParsingException { final String lockStrategy = parserNextWord ( true ) ; if ( ! lockStrategy . equalsIgnoreCase ( \"DEFAULT\" ) && ! lockStrategy . equalsIgnoreCase ( \"NONE\" ) && ! lockStrategy . equalsIgnoreCase ( \"RECORD\" ) ) throwParsingException ( \"Invalid \" + KEYWORD_LOCK + \" value set to '\" + lockStrategy + \"' but it should be NONE (default) or RECORD. Example: \" + KEYWORD_LOCK + \" RECORD\" ) ; return lockStrategy ; }", "nl": "Parses the lock keyword if found ."}}
{"translation": {"code": "protected boolean parseFetchplan ( final String w ) throws OCommandSQLParsingException { if ( ! w . equals ( KEYWORD_FETCHPLAN ) ) { return false ; } parserSkipWhiteSpaces ( ) ; int start = parserGetCurrentPosition ( ) ; parserNextWord ( true ) ; int end = parserGetCurrentPosition ( ) ; parserSkipWhiteSpaces ( ) ; int position = parserGetCurrentPosition ( ) ; while ( ! parserIsEnded ( ) ) { final String word = OIOUtils . getStringContent ( parserNextWord ( true ) ) ; if ( ! OPatternConst . PATTERN_FETCH_PLAN . matcher ( word ) . matches ( ) ) { break ; } end = parserGetCurrentPosition ( ) ; parserSkipWhiteSpaces ( ) ; position = parserGetCurrentPosition ( ) ; } parserSetCurrentPosition ( position ) ; if ( end < 0 ) { fetchPlan = OIOUtils . getStringContent ( parserText . substring ( start ) ) ; } else { fetchPlan = OIOUtils . getStringContent ( parserText . substring ( start , end ) ) ; } request . setFetchPlan ( fetchPlan ) ; return true ; }", "nl": "Parses the fetchplan keyword if found ."}}
{"translation": {"code": "public int getAvailableConnections ( final String name , final String userName ) { setup ( ) ; return dbPool . getAvailableConnections ( name , userName ) ; }", "nl": "Returns amount of available connections which you can acquire for given source and user name . Source id is consist of source name and source user name ."}}
{"translation": {"code": "protected OClass addBaseClass ( final OClassImpl iBaseClass ) { checkRecursion ( iBaseClass ) ; if ( subclasses == null ) subclasses = new ArrayList < OClass > ( ) ; if ( subclasses . contains ( iBaseClass ) ) return this ; subclasses . add ( iBaseClass ) ; addPolymorphicClusterIdsWithInheritance ( iBaseClass ) ; return this ; }", "nl": "Adds a base class to the current one . It adds also the base class cluster ids to the polymorphic cluster ids array ."}}
{"translation": {"code": "protected void addPolymorphicClusterIds ( final OClassImpl iBaseClass ) { Set < Integer > clusters = new TreeSet < Integer > ( ) ; for ( int clusterId : polymorphicClusterIds ) { clusters . add ( clusterId ) ; } for ( int clusterId : iBaseClass . polymorphicClusterIds ) { if ( clusters . add ( clusterId ) ) { try { addClusterIdToIndexes ( clusterId ) ; } catch ( RuntimeException e ) { OLogManager . instance ( ) . warn ( this , \"Error adding clusterId '%d' to index of class '%s'\" , e , clusterId , getName ( ) ) ; clusters . remove ( clusterId ) ; } } } polymorphicClusterIds = new int [ clusters . size ( ) ] ; int i = 0 ; for ( Integer cluster : clusters ) { polymorphicClusterIds [ i ] = cluster ; i ++ ; } }", "nl": "Add different cluster id to the polymorphic cluster ids array ."}}
{"translation": {"code": "public String getConnectionClass ( final Direction iDirection , final String iFieldName ) { if ( iDirection == Direction . OUT ) { if ( iFieldName . length ( ) > CONNECTION_OUT_PREFIX . length ( ) ) return iFieldName . substring ( CONNECTION_OUT_PREFIX . length ( ) ) ; } else if ( iDirection == Direction . IN ) { if ( iFieldName . length ( ) > CONNECTION_IN_PREFIX . length ( ) ) return iFieldName . substring ( CONNECTION_IN_PREFIX . length ( ) ) ; } return OrientEdgeType . CLASS_NAME ; }", "nl": "Used to extract the class name from the vertex s field ."}}
{"translation": {"code": "protected void parseRetry ( ) throws OCommandSQLParsingException { retry = Integer . parseInt ( parserNextWord ( true ) ) ; String temp = parseOptionalWord ( true ) ; if ( temp . equals ( \"WAIT\" ) ) { wait = Integer . parseInt ( parserNextWord ( true ) ) ; } else parserGoBack ( ) ; }", "nl": "Parses the RETRY number of times"}}
{"translation": {"code": "private boolean optimizeSort ( OClass iSchemaClass ) { OIndexCursor cursor = getOptimizedSortCursor ( iSchemaClass ) ; if ( cursor != null ) { fetchValuesFromIndexCursor ( cursor ) ; return true ; } return false ; }", "nl": "Use index to order documents by provided fields ."}}
{"translation": {"code": "private static OIdentifiable linkToStream ( final StringBuilder buffer , final ODocument iParentRecord , Object iLinked ) { if ( iLinked == null ) // NULL REFERENCE\r return null ; OIdentifiable resultRid = null ; ORID rid ; if ( iLinked instanceof ORID ) { // JUST THE REFERENCE\r rid = ( ORID ) iLinked ; assert rid . getIdentity ( ) . isValid ( ) || ( ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getStorage ( ) instanceof OStorageProxy ) : \"Impossible to serialize invalid link \" + rid . getIdentity ( ) ; resultRid = rid ; } else { if ( iLinked instanceof String ) iLinked = new ORecordId ( ( String ) iLinked ) ; if ( ! ( iLinked instanceof OIdentifiable ) ) throw new IllegalArgumentException ( \"Invalid object received. Expected a OIdentifiable but received type=\" + iLinked . getClass ( ) . getName ( ) + \" and value=\" + iLinked ) ; // RECORD\r ORecord iLinkedRecord = ( ( OIdentifiable ) iLinked ) . getRecord ( ) ; rid = iLinkedRecord . getIdentity ( ) ; assert rid . getIdentity ( ) . isValid ( ) || ( ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getStorage ( ) instanceof OStorageProxy ) : \"Impossible to serialize invalid link \" + rid . getIdentity ( ) ; final ODatabaseDocument database = ODatabaseRecordThreadLocal . instance ( ) . get ( ) ; if ( iParentRecord != null ) { if ( ! database . isRetainRecords ( ) ) // REPLACE CURRENT RECORD WITH ITS ID: THIS SAVES A LOT OF MEMORY\r resultRid = iLinkedRecord . getIdentity ( ) ; } } if ( rid . isValid ( ) ) rid . toString ( buffer ) ; return resultRid ; }", "nl": "Serialize the link ."}}
{"translation": {"code": "public static Object transformResult ( Object result ) { if ( java8MethodIsArray == null || ! ( result instanceof Map ) ) { return result ; } // PATCH BY MAT ABOUT NASHORN RETURNING VALUE FOR ARRAYS. try { if ( ( Boolean ) java8MethodIsArray . invoke ( result ) ) { List < ? > partial = new ArrayList ( ( ( Map ) result ) . values ( ) ) ; List < Object > finalResult = new ArrayList < Object > ( ) ; for ( Object o : partial ) { finalResult . add ( transformResult ( o ) ) ; } return finalResult ; } else { Map < Object , Object > mapResult = ( Map ) result ; List < Object > keys = new ArrayList < Object > ( mapResult . keySet ( ) ) ; for ( Object key : keys ) { mapResult . put ( key , transformResult ( mapResult . get ( key ) ) ) ; } return mapResult ; } } catch ( Exception e ) { OLogManager . instance ( ) . error ( OCommandExecutorUtility . class , \"\" , e ) ; } return result ; }", "nl": "Manages cross compiler compatibility issues ."}}
{"translation": {"code": "private Object getValueAsObjectOrMap ( ODocument iRecord , String iFieldValue , OType iType , OType iLinkedType , Map < String , Character > iFieldTypes , boolean iNoMap , String iOptions ) { final String [ ] fields = OStringParser . getWords ( iFieldValue . substring ( 1 , iFieldValue . length ( ) - 1 ) , \":,\" , true ) ; if ( fields == null || fields . length == 0 ) if ( iNoMap ) { ODocument res = new ODocument ( ) ; ODocumentInternal . addOwner ( res , iRecord ) ; return res ; } else return new HashMap < String , Object > ( ) ; if ( iNoMap || hasTypeField ( fields ) ) { return getValueAsRecord ( iRecord , iFieldValue , iType , iOptions , fields ) ; } else { return getValueAsMap ( iRecord , iFieldValue , iLinkedType , iFieldTypes , false , iOptions , fields ) ; } }", "nl": "OBJECT OR MAP . CHECK THE TYPE ATTRIBUTE TO KNOW IT ."}}
{"translation": {"code": "public List < OIndexSearchResult > analyzeCondition ( OSQLFilterCondition condition , final OClass schemaClass , OCommandContext context ) { final List < OIndexSearchResult > indexSearchResults = new ArrayList < OIndexSearchResult > ( ) ; OIndexSearchResult lastCondition = analyzeFilterBranch ( schemaClass , condition , indexSearchResults , context ) ; if ( indexSearchResults . isEmpty ( ) && lastCondition != null ) { indexSearchResults . add ( lastCondition ) ; } Collections . sort ( indexSearchResults , new Comparator < OIndexSearchResult > ( ) { public int compare ( final OIndexSearchResult searchResultOne , final OIndexSearchResult searchResultTwo ) { return searchResultTwo . getFieldCount ( ) - searchResultOne . getFieldCount ( ) ; } } ) ; return indexSearchResults ; }", "nl": "Analyzes a query filter for a possible indexation options . The results are sorted by amount of fields . So the most specific items go first ."}}
{"translation": {"code": "private OIndexSearchResult createIndexedProperty ( final OSQLFilterCondition iCondition , final Object iItem , OCommandContext ctx ) { if ( iItem == null || ! ( iItem instanceof OSQLFilterItemField ) ) { return null ; } if ( iCondition . getLeft ( ) instanceof OSQLFilterItemField && iCondition . getRight ( ) instanceof OSQLFilterItemField ) { return null ; } final OSQLFilterItemField item = ( OSQLFilterItemField ) iItem ; if ( item . hasChainOperators ( ) && ! item . isFieldChain ( ) ) { return null ; } boolean inverted = iCondition . getRight ( ) == iItem ; final Object origValue = inverted ? iCondition . getLeft ( ) : iCondition . getRight ( ) ; OQueryOperator operator = iCondition . getOperator ( ) ; if ( inverted ) { if ( operator instanceof OQueryOperatorIn ) { operator = new OQueryOperatorContains ( ) ; } else if ( operator instanceof OQueryOperatorContains ) { operator = new OQueryOperatorIn ( ) ; } else if ( operator instanceof OQueryOperatorMajor ) { operator = new OQueryOperatorMinor ( ) ; } else if ( operator instanceof OQueryOperatorMinor ) { operator = new OQueryOperatorMajor ( ) ; } else if ( operator instanceof OQueryOperatorMajorEquals ) { operator = new OQueryOperatorMinorEquals ( ) ; } else if ( operator instanceof OQueryOperatorMinorEquals ) { operator = new OQueryOperatorMajorEquals ( ) ; } } if ( iCondition . getOperator ( ) instanceof OQueryOperatorBetween || operator instanceof OQueryOperatorIn ) { return new OIndexSearchResult ( operator , item . getFieldChain ( ) , origValue ) ; } final Object value = OSQLHelper . getValue ( origValue , null , ctx ) ; return new OIndexSearchResult ( operator , item . getFieldChain ( ) , value ) ; }", "nl": "Add SQL filter field to the search candidate list ."}}
{"translation": {"code": "public void updateRecord ( final ORecord record ) { if ( record . getIdentity ( ) . getClusterId ( ) != excludedCluster && record . getIdentity ( ) . isValid ( ) && ! record . isDirty ( ) && ! ORecordVersionHelper . isTombstone ( record . getVersion ( ) ) ) { if ( underlying . get ( record . getIdentity ( ) ) != record ) underlying . put ( record ) ; } }", "nl": "Pushes record to cache . Identifier of record used as access key"}}
{"translation": {"code": "public ORecord findRecord ( final ORID rid ) { ORecord record ; record = underlying . get ( rid ) ; if ( record != null ) Orient . instance ( ) . getProfiler ( ) . updateCounter ( CACHE_HIT , \"Record found in Level1 Cache\" , 1L , \"db.*.cache.level1.cache.found\" ) ; else Orient . instance ( ) . getProfiler ( ) . updateCounter ( CACHE_MISS , \"Record not found in Level1 Cache\" , 1L , \"db.*.cache.level1.cache.notFound\" ) ; return record ; }", "nl": "Looks up for record in cache by it s identifier . Optionally look up in secondary cache and update primary with found record"}}
{"translation": {"code": "public boolean tryMerge ( final ORidBag otherValue , boolean iMergeSingleItemsOfMultiValueFields ) { if ( ! isEmbedded ( ) && ! otherValue . isEmbedded ( ) ) { final OSBTreeRidBag thisTree = ( OSBTreeRidBag ) delegate ; final OSBTreeRidBag otherTree = ( OSBTreeRidBag ) otherValue . delegate ; if ( thisTree . getCollectionPointer ( ) . equals ( otherTree . getCollectionPointer ( ) ) ) { thisTree . mergeChanges ( otherTree ) ; uuid = otherValue . uuid ; return true ; } } else if ( iMergeSingleItemsOfMultiValueFields ) { final Iterator < OIdentifiable > iter = otherValue . rawIterator ( ) ; while ( iter . hasNext ( ) ) { final OIdentifiable value = iter . next ( ) ; if ( value != null ) { final Iterator < OIdentifiable > localIter = rawIterator ( ) ; boolean found = false ; while ( localIter . hasNext ( ) ) { final OIdentifiable v = localIter . next ( ) ; if ( value . equals ( v ) ) { found = true ; break ; } } if ( ! found ) add ( value ) ; } } return true ; } return false ; }", "nl": "IMPORTANT! Only for internal usage ."}}
{"translation": {"code": "private void replaceWithSBTree ( OBonsaiCollectionPointer pointer ) { delegate . requestDelete ( ) ; final OSBTreeRidBag treeBag = new OSBTreeRidBag ( ) ; treeBag . setCollectionPointer ( pointer ) ; treeBag . setOwner ( delegate . getOwner ( ) ) ; for ( OMultiValueChangeListener < OIdentifiable , OIdentifiable > listener : delegate . getChangeListeners ( ) ) treeBag . addChangeListener ( listener ) ; delegate = treeBag ; }", "nl": "Silently replace delegate by tree implementation ."}}
{"translation": {"code": "public static Set < String > getIndexEngines ( ) { final Set < String > engines = new HashSet <> ( ) ; final Iterator < OIndexFactory > ite = getAllFactories ( ) ; while ( ite . hasNext ( ) ) { engines . addAll ( ite . next ( ) . getAlgorithms ( ) ) ; } return engines ; }", "nl": "Iterates on all factories and append all index engines ."}}
{"translation": {"code": "private int registerCluster ( final OCluster cluster ) { final int id ; if ( cluster != null ) { // CHECK FOR DUPLICATION OF NAMES if ( clusterMap . containsKey ( cluster . getName ( ) . toLowerCase ( configuration . getLocaleInstance ( ) ) ) ) { throw new OConfigurationException ( \"Cannot add cluster '\" + cluster . getName ( ) + \"' because it is already registered in database '\" + name + \"'\" ) ; } // CREATE AND ADD THE NEW REF SEGMENT clusterMap . put ( cluster . getName ( ) . toLowerCase ( configuration . getLocaleInstance ( ) ) , cluster ) ; id = cluster . getId ( ) ; } else { id = clusters . size ( ) ; } setCluster ( id , cluster ) ; return id ; }", "nl": "Register the cluster internally ."}}
{"translation": {"code": "public static ORecordAbstract fill ( final ORecord record , final ORID iRid , final int iVersion , final byte [ ] iBuffer , final boolean iDirty ) { final ORecordAbstract rec = ( ORecordAbstract ) record ; rec . fill ( iRid , iVersion , iBuffer , iDirty ) ; return rec ; }", "nl": "Internal only . Fills in one shot the record ."}}
{"translation": {"code": "public static void setVersion ( final ORecord record , final int iVersion ) { final ORecordAbstract rec = ( ORecordAbstract ) record ; rec . setVersion ( iVersion ) ; }", "nl": "Internal only . Sets the version ."}}
{"translation": {"code": "public static byte getRecordType ( final ORecord record ) { if ( record instanceof ORecordAbstract ) { return ( ( ORecordAbstract ) record ) . getRecordType ( ) ; } final ORecordAbstract rec = ( ORecordAbstract ) record . getRecord ( ) ; return rec . getRecordType ( ) ; }", "nl": "Internal only . Return the record type ."}}
{"translation": {"code": "protected Map < Method , Object > getConsoleMethods ( ) { if ( methods != null ) return methods ; // search for declared command collections final Iterator < OConsoleCommandCollection > ite = ServiceLoader . load ( OConsoleCommandCollection . class ) . iterator ( ) ; final Collection < Object > candidates = new ArrayList < Object > ( ) ; candidates . add ( this ) ; while ( ite . hasNext ( ) ) { try { // make a copy and set it's context final OConsoleCommandCollection cc = ite . next ( ) . getClass ( ) . newInstance ( ) ; cc . setContext ( this ) ; candidates . add ( cc ) ; } catch ( InstantiationException ex ) { Logger . getLogger ( OConsoleApplication . class . getName ( ) ) . log ( Level . WARNING , ex . getMessage ( ) ) ; } catch ( IllegalAccessException ex ) { Logger . getLogger ( OConsoleApplication . class . getName ( ) ) . log ( Level . WARNING , ex . getMessage ( ) ) ; } } methods = new TreeMap < Method , Object > ( new Comparator < Method > ( ) { public int compare ( Method o1 , Method o2 ) { final ConsoleCommand ann1 = o1 . getAnnotation ( ConsoleCommand . class ) ; final ConsoleCommand ann2 = o2 . getAnnotation ( ConsoleCommand . class ) ; if ( ann1 != null && ann2 != null ) { if ( ann1 . priority ( ) != ann2 . priority ( ) ) // PRIORITY WINS return ann1 . priority ( ) - ann2 . priority ( ) ; } int res = o1 . getName ( ) . compareTo ( o2 . getName ( ) ) ; if ( res == 0 ) res = o1 . toString ( ) . compareTo ( o2 . toString ( ) ) ; return res ; } } ) ; for ( final Object candidate : candidates ) { final Method [ ] classMethods = candidate . getClass ( ) . getMethods ( ) ; for ( Method m : classMethods ) { if ( Modifier . isAbstract ( m . getModifiers ( ) ) || Modifier . isStatic ( m . getModifiers ( ) ) || ! Modifier . isPublic ( m . getModifiers ( ) ) ) { continue ; } if ( m . getReturnType ( ) != Void . TYPE ) { continue ; } methods . put ( m , candidate ) ; } } return methods ; }", "nl": "Returns a map of all console method and the object they can be called on ."}}
{"translation": {"code": "protected void updateMetadata ( final String iName , final String iDescription , final METRIC_TYPE iType ) { if ( iDescription != null && dictionary . putIfAbsent ( iName , iDescription ) == null ) types . put ( iName , iType ) ; }", "nl": "Updates the metric metadata ."}}
{"translation": {"code": "public static short mergeShortFromBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 ) { short result = 0 ; result = ( short ) ( result | ( buffer . get ( ) & MASK ) ) ; result = ( short ) ( result << SIZE_OF_BYTE_IN_BITS ) ; result = ( short ) ( result | ( buffer1 . get ( ) & MASK ) ) ; return result ; }", "nl": "Merge short value from two byte buffer . First byte of short will be extracted from first byte buffer and second from second one ."}}
{"translation": {"code": "private boolean parserCheckSeparator ( final char c , final String iSeparatorChars ) { for ( int sepIndex = 0 ; sepIndex < iSeparatorChars . length ( ) ; ++ sepIndex ) { if ( iSeparatorChars . charAt ( sepIndex ) == c ) { parserLastSeparator = c ; return true ; } } return false ; }", "nl": "Check for a separator"}}
{"translation": {"code": "public static void splitShortToBuffers ( final ByteBuffer buffer , final ByteBuffer buffer1 , final short iValue ) { buffer . put ( ( byte ) ( MASK & ( iValue >>> SIZE_OF_BYTE_IN_BITS ) ) ) ; buffer1 . put ( ( byte ) ( MASK & iValue ) ) ; }", "nl": "Split short value into two byte buffer . First byte of short will be written to first byte buffer and second to second one ."}}
{"translation": {"code": "public static int jumpWhiteSpaces ( final CharSequence iText , final int iCurrentPosition , final int iMaxPosition ) { return jump ( iText , iCurrentPosition , iMaxPosition , COMMON_JUMP ) ; }", "nl": "Jump white spaces ."}}
{"translation": {"code": "protected int parserNextChars ( final boolean iUpperCase , final boolean iMandatory , final String ... iCandidateWords ) { parserPreviousPos = parserCurrentPos ; parserSkipWhiteSpaces ( ) ; parserEscapeSequenceCount = 0 ; parserLastWord . setLength ( 0 ) ; final String [ ] processedWords = Arrays . copyOf ( iCandidateWords , iCandidateWords . length ) ; // PARSE THE CHARS final String text2Use = iUpperCase ? parserTextUpperCase : parserText ; final int max = text2Use . length ( ) ; parserCurrentPos = parserCurrentPos + parserTextUpperCase . length ( ) - parserText . length ( ) ; // PARSE TILL 1 CHAR AFTER THE END TO SIMULATE A SEPARATOR AS EOF for ( int i = 0 ; parserCurrentPos <= max ; ++ i ) { final char ch = parserCurrentPos < max ? text2Use . charAt ( parserCurrentPos ) : ' ' ; final boolean separator = ch == ' ' || ch == ' ' || ch == ' ' || ch == ' ' || ch == ' ' ; if ( ! separator ) parserLastWord . append ( ch ) ; // CLEAR CANDIDATES int candidatesWordsCount = 0 ; int candidatesWordsPos = - 1 ; for ( int c = 0 ; c < processedWords . length ; ++ c ) { final String w = processedWords [ c ] ; if ( w != null ) { final int wordSize = w . length ( ) ; if ( ( separator && wordSize > i ) || ( ! separator && ( i > wordSize - 1 || w . charAt ( i ) != ch ) ) ) // DISCARD IT processedWords [ c ] = null ; else { candidatesWordsCount ++ ; if ( candidatesWordsCount == 1 ) // REMEMBER THE POSITION candidatesWordsPos = c ; } } } if ( candidatesWordsCount == 1 ) { // ONE RESULT, CHECKING IF FOUND final String w = processedWords [ candidatesWordsPos ] ; if ( w . length ( ) == i + ( separator ? 0 : 1 ) && ! Character . isLetter ( ch ) ) // FOUND! return candidatesWordsPos ; } if ( candidatesWordsCount == 0 || separator ) break ; parserCurrentPos ++ ; } if ( iMandatory ) throwSyntaxErrorException ( \"Found unexpected keyword '\" + parserLastWord + \"' while it was expected '\" + Arrays . toString ( iCandidateWords ) + \"'\" ) ; return - 1 ; }", "nl": "Parses the next sequence of chars ."}}
{"translation": {"code": "protected String parserOptionalWord ( final boolean iUpperCase ) { parserPreviousPos = parserCurrentPos ; parserNextWord ( iUpperCase ) ; if ( parserLastWord . length ( ) == 0 ) return null ; return parserLastWord . toString ( ) ; }", "nl": "Parses the next word . It returns the word parsed if any ."}}
{"translation": {"code": "public static int indexOfOutsideStrings ( final String iText , final char iToFind , int iFrom , int iTo ) { if ( iTo == - 1 ) iTo = iText . length ( ) - 1 ; if ( iFrom == - 1 ) iFrom = iText . length ( ) - 1 ; char c ; char stringChar = ' ' ; boolean escape = false ; final StringBuilder buffer = new StringBuilder ( 1024 ) ; int i = iFrom ; while ( true ) { c = iText . charAt ( i ) ; if ( ! escape && c == ' ' && ( ( i + 1 ) < iText . length ( ) ) ) { if ( iText . charAt ( i + 1 ) == ' ' ) { i = readUnicode ( iText , i + 2 , buffer ) ; } else escape = true ; } else { if ( c == ' ' || c == ' ' ) { // BEGIN/END STRING if ( stringChar == ' ' ) { // BEGIN stringChar = c ; } else { // END if ( ! escape && c == stringChar ) stringChar = ' ' ; } } if ( c == iToFind && stringChar == ' ' ) return i ; if ( escape ) escape = false ; } if ( iFrom < iTo ) { // MOVE FORWARD if ( ++ i > iTo ) break ; } else { // MOVE BACKWARD if ( -- i < iFrom ) break ; } } return - 1 ; }", "nl": "Finds a character inside a string specyfing the limits and direction . If iFrom is minor than iTo then it moves forward otherwise backward ."}}
{"translation": {"code": "private static List < Class < ? > > findClasses ( final File iDirectory , String iPackageName , ClassLoader iClassLoader ) throws ClassNotFoundException { final List < Class < ? > > classes = new ArrayList < Class < ? > > ( ) ; if ( ! iDirectory . exists ( ) ) return classes ; iPackageName += \".\" + iDirectory . getName ( ) ; String className ; final File [ ] files = iDirectory . listFiles ( ) ; if ( files != null ) for ( File file : files ) { if ( file . isDirectory ( ) ) { if ( file . getName ( ) . contains ( \".\" ) ) continue ; classes . addAll ( findClasses ( file , iPackageName , iClassLoader ) ) ; } else if ( file . getName ( ) . endsWith ( CLASS_EXTENSION ) ) { className = file . getName ( ) . substring ( 0 , file . getName ( ) . length ( ) - CLASS_EXTENSION . length ( ) ) ; classes . add ( Class . forName ( iPackageName + ' ' + className , true , iClassLoader ) ) ; } } return classes ; }", "nl": "Recursive method used to find all classes in a given directory and subdirs ."}}
{"translation": {"code": "public static List < Class < ? > > getClassessOfInterface ( String thePackage , Class < ? > theInterface , final ClassLoader iClassLoader ) { List < Class < ? > > classList = new ArrayList < Class < ? > > ( ) ; try { for ( Class < ? > discovered : getClassesFor ( thePackage , iClassLoader ) ) { if ( Arrays . asList ( discovered . getInterfaces ( ) ) . contains ( theInterface ) ) { classList . add ( discovered ) ; } } } catch ( ClassNotFoundException ex ) { OLogManager . instance ( ) . error ( null , \"Error finding classes\" , ex ) ; } return classList ; }", "nl": "Filters discovered classes to see if they implement a given interface ."}}
{"translation": {"code": "public static Class < ? > getGenericMultivalueType ( final Field p ) { if ( p . getType ( ) instanceof Class < ? > ) { final Type genericType = p . getGenericType ( ) ; if ( genericType != null && genericType instanceof ParameterizedType ) { final ParameterizedType pt = ( ParameterizedType ) genericType ; if ( pt . getActualTypeArguments ( ) != null && pt . getActualTypeArguments ( ) . length > 0 ) { if ( ( ( Class < ? > ) pt . getRawType ( ) ) . isAssignableFrom ( Map . class ) ) { if ( pt . getActualTypeArguments ( ) [ 1 ] instanceof Class < ? > ) { return ( Class < ? > ) pt . getActualTypeArguments ( ) [ 1 ] ; } else if ( pt . getActualTypeArguments ( ) [ 1 ] instanceof ParameterizedType ) return ( Class < ? > ) ( ( ParameterizedType ) pt . getActualTypeArguments ( ) [ 1 ] ) . getRawType ( ) ; } else if ( pt . getActualTypeArguments ( ) [ 0 ] instanceof Class < ? > ) { return ( Class < ? > ) pt . getActualTypeArguments ( ) [ 0 ] ; } else if ( pt . getActualTypeArguments ( ) [ 0 ] instanceof ParameterizedType ) return ( Class < ? > ) ( ( ParameterizedType ) pt . getActualTypeArguments ( ) [ 0 ] ) . getRawType ( ) ; } } else if ( p . getType ( ) . isArray ( ) ) return p . getType ( ) . getComponentType ( ) ; } return null ; }", "nl": "Returns the generic class of multi - value objects ."}}
{"translation": {"code": "protected boolean parserOptionalKeyword ( final String ... iWords ) { parserNextWord ( true , \" \\r\\n,\" ) ; if ( parserLastWord . length ( ) == 0 ) return false ; // FOUND: CHECK IF IT'S IN RANGE boolean found = iWords . length == 0 ; for ( String w : iWords ) { if ( parserLastWord . toString ( ) . equals ( w ) ) { found = true ; break ; } } if ( ! found ) throwSyntaxErrorException ( \"Found unexpected keyword '\" + parserLastWord + \"' while it was expected '\" + Arrays . toString ( iWords ) + \"'\" ) ; return true ; }", "nl": "Parses optional keywords between the iWords . If a keyword is found but doesn t match with iWords then a SyntaxError is raised ."}}
{"translation": {"code": "public static int jump ( final CharSequence iText , int iCurrentPosition , final int iMaxPosition , final String iJumpChars ) { if ( iCurrentPosition < 0 ) return - 1 ; final int size = iMaxPosition > - 1 ? Math . min ( iMaxPosition , iText . length ( ) ) : iText . length ( ) ; final int jumpCharSize = iJumpChars . length ( ) ; boolean found = true ; char c ; for ( ; iCurrentPosition < size ; ++ iCurrentPosition ) { found = false ; c = iText . charAt ( iCurrentPosition ) ; for ( int jumpIndex = 0 ; jumpIndex < jumpCharSize ; ++ jumpIndex ) { if ( iJumpChars . charAt ( jumpIndex ) == c ) { found = true ; break ; } } if ( ! found ) break ; } return iCurrentPosition >= size ? - 1 : iCurrentPosition ; }", "nl": "Jump some characters reading from an offset of a String ."}}
{"translation": {"code": "protected String parserRequiredWord ( final boolean iUpperCase , final String iCustomMessage , String iSeparators ) { if ( iSeparators == null ) iSeparators = \" ()=><,\\r\\n\" ; parserNextWord ( iUpperCase , iSeparators ) ; if ( parserLastWord . length ( ) == 0 ) throwSyntaxErrorException ( iCustomMessage ) ; if ( parserLastWord . charAt ( 0 ) == ' ' && parserLastWord . charAt ( parserLastWord . length ( ) - 1 ) == ' ' ) { return parserLastWord . substring ( 1 , parserLastWord . length ( ) - 1 ) ; } return parserLastWord . toString ( ) ; }", "nl": "Parses the next word . If no word is found or the parsed word is not present in the word array received as parameter then a SyntaxError exception with the custom message received as parameter is thrown . It returns the word parsed if any ."}}
{"translation": {"code": "public Boolean isExecutionModeSynchronous ( final String iClusterName ) { Object value = getClusterConfiguration ( iClusterName ) . field ( EXECUTION_MODE ) ; if ( value == null ) { value = configuration . field ( EXECUTION_MODE ) ; if ( value == null ) return null ; } if ( value . toString ( ) . equalsIgnoreCase ( \"undefined\" ) ) return null ; return value . toString ( ) . equalsIgnoreCase ( EXECUTION_MODE_SYNCHRONOUS ) ; }", "nl": "Returns the execution mode if synchronous ."}}
{"translation": {"code": "public String getArgument ( final int iPosition ) { return args != null && args . length > iPosition ? args [ iPosition ] : null ; }", "nl": "Returns the argument by position"}}
{"translation": {"code": "public int hasParameters ( final String ... iNames ) { int found = 0 ; if ( iNames != null && request . parameters != null ) for ( String name : iNames ) found += request . parameters . containsKey ( name ) ? 1 : 0 ; return found ; }", "nl": "Checks how many parameters have been received ."}}
{"translation": {"code": "public ParseException generateParseException ( ) { jj_expentries . clear ( ) ; boolean [ ] la1tokens = new boolean [ 279 ] ; if ( jj_kind >= 0 ) { la1tokens [ jj_kind ] = true ; jj_kind = - 1 ; } for ( int i = 0 ; i < 424 ; i ++ ) { if ( jj_la1 [ i ] == jj_gen ) { for ( int j = 0 ; j < 32 ; j ++ ) { if ( ( jj_la1_0 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ j ] = true ; } if ( ( jj_la1_1 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 32 + j ] = true ; } if ( ( jj_la1_2 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 64 + j ] = true ; } if ( ( jj_la1_3 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 96 + j ] = true ; } if ( ( jj_la1_4 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 128 + j ] = true ; } if ( ( jj_la1_5 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 160 + j ] = true ; } if ( ( jj_la1_6 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 192 + j ] = true ; } if ( ( jj_la1_7 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 224 + j ] = true ; } if ( ( jj_la1_8 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ 256 + j ] = true ; } } } } for ( int i = 0 ; i < 279 ; i ++ ) { if ( la1tokens [ i ] ) { jj_expentry = new int [ 1 ] ; jj_expentry [ 0 ] = i ; jj_expentries . add ( jj_expentry ) ; } } jj_endpos = 0 ; jj_rescan_token ( ) ; jj_add_error_token ( 0 , 0 ) ; int [ ] [ ] exptokseq = new int [ jj_expentries . size ( ) ] [  ] ; for ( int i = 0 ; i < jj_expentries . size ( ) ; i ++ ) { exptokseq [ i ] = jj_expentries . get ( i ) ; } return new ParseException ( token , exptokseq , tokenImage ) ; }", "nl": "Generate ParseException ."}}
{"translation": {"code": "final public Token getToken ( int index ) { Token t = token ; for ( int i = 0 ; i < index ; i ++ ) { if ( t . next != null ) t = t . next ; else t = t . next = token_source . getNextToken ( ) ; } return t ; }", "nl": "Get the specific Token ."}}
{"translation": {"code": "final public Token getNextToken ( ) { if ( token . next != null ) token = token . next ; else token = token . next = token_source . getNextToken ( ) ; jj_ntk = - 1 ; jj_gen ++ ; return token ; }", "nl": "Get the next Token ."}}
{"translation": {"code": "final public OStatement parse ( ) throws ParseException { /*@bgen(jjtree) parse */ Oparse jjtn000 = new Oparse ( JJTPARSE ) ; boolean jjtc000 = true ; jjtree . openNodeScope ( jjtn000 ) ; jjtn000 . jjtSetFirstToken ( getToken ( 1 ) ) ; OStatement result ; try { result = Statement ( ) ; jj_consume_token ( 0 ) ; jjtree . closeNodeScope ( jjtn000 , true ) ; jjtc000 = false ; jjtn000 . jjtSetLastToken ( getToken ( 0 ) ) ; { if ( true ) return result ; } } catch ( Throwable jjte000 ) { if ( jjtc000 ) { jjtree . clearNodeScope ( jjtn000 ) ; jjtc000 = false ; } else { jjtree . popNode ( ) ; } if ( jjte000 instanceof RuntimeException ) { { if ( true ) throw ( RuntimeException ) jjte000 ; } } if ( jjte000 instanceof ParseException ) { { if ( true ) throw ( ParseException ) jjte000 ; } } { if ( true ) throw ( Error ) jjte000 ; } } finally { if ( jjtc000 ) { jjtree . closeNodeScope ( jjtn000 , true ) ; jjtn000 . jjtSetLastToken ( getToken ( 0 ) ) ; } } throw new Error ( \"Missing return statement in function\" ) ; }", "nl": "Root productions ."}}
{"translation": {"code": "private void listen ( final String iHostName , final String iHostPortRange , final String iProtocolName , Class < ? extends ONetworkProtocol > protocolClass ) { for ( int port : getPorts ( iHostPortRange ) ) { inboundAddr = new InetSocketAddress ( iHostName , port ) ; try { serverSocket = socketFactory . createServerSocket ( port , 0 , InetAddress . getByName ( iHostName ) ) ; if ( serverSocket . isBound ( ) ) { OLogManager . instance ( ) . info ( this , \"Listening $ANSI{green \" + iProtocolName + \"} connections on $ANSI{green \" + inboundAddr . getAddress ( ) . getHostAddress ( ) + \":\" + inboundAddr . getPort ( ) + \"} (protocol v.\" + protocolVersion + \", socket=\" + socketFactory . getName ( ) + \")\" ) ; return ; } } catch ( BindException be ) { OLogManager . instance ( ) . warn ( this , \"Port %s:%d busy, trying the next available...\" , iHostName , port ) ; } catch ( SocketException se ) { OLogManager . instance ( ) . error ( this , \"Unable to create socket\" , se ) ; throw new RuntimeException ( se ) ; } catch ( IOException ioe ) { OLogManager . instance ( ) . error ( this , \"Unable to read data from an open socket\" , ioe ) ; System . err . println ( \"Unable to read data from an open socket.\" ) ; throw new RuntimeException ( ioe ) ; } } OLogManager . instance ( ) . error ( this , \"Unable to listen for connections using the configured ports '%s' on host '%s'\" , null , iHostPortRange , iHostName ) ; throw new OSystemException ( \"Unable to listen for connections using the configured ports '%s' on host '%s'\" ) ; }", "nl": "Initialize a server socket for communicating with the client ."}}
{"translation": {"code": "private void readParameters ( final OContextConfiguration iServerConfig , final OServerParameterConfiguration [ ] iParameters ) { configuration = new OContextConfiguration ( iServerConfig ) ; // SET PARAMETERS\r if ( iParameters != null && iParameters . length > 0 ) { // CONVERT PARAMETERS IN MAP TO INTIALIZE THE CONTEXT-CONFIGURATION\r for ( OServerParameterConfiguration param : iParameters ) configuration . setValue ( param . name , param . value ) ; } socketBufferSize = configuration . getValueAsInteger ( OGlobalConfiguration . NETWORK_SOCKET_BUFFER_SIZE ) ; }", "nl": "Initializes connection parameters by the reading XML configuration . If not specified get the parameters defined as global configuration ."}}
{"translation": {"code": "protected ORecord getRecord ( ) { final ORecord record ; if ( reusedRecord != null ) { // REUSE THE SAME RECORD AFTER HAVING RESETTED IT\r record = reusedRecord ; record . reset ( ) ; } else record = null ; return record ; }", "nl": "Return the record to use for the operation ."}}
{"translation": {"code": "protected static OObjectDatabaseTx getDatabase ( ) { ODatabaseInternal < ? > databaseOwner = ODatabaseRecordThreadLocal . instance ( ) . get ( ) . getDatabaseOwner ( ) ; if ( databaseOwner instanceof OObjectDatabaseTx ) { return ( OObjectDatabaseTx ) databaseOwner ; } else if ( databaseOwner instanceof ODatabaseDocumentInternal ) { return new OObjectDatabaseTx ( ( ODatabaseDocumentInternal ) databaseOwner ) ; } throw new IllegalStateException ( \"Current database not of expected type\" ) ; }", "nl": "Gets the current thread database as a ODatabasePojoAbstract wrapping it where necessary ."}}
{"translation": {"code": "protected String authenticate ( final String username , final String password , final String iDatabaseName ) throws IOException { ODatabaseDocument db = null ; String userRid = null ; try { db = ( ODatabaseDocument ) server . openDatabase ( iDatabaseName , username , password ) ; userRid = ( db . getUser ( ) == null ? \"<server user>\" : db . getUser ( ) . getDocument ( ) . getIdentity ( ) . toString ( ) ) ; } catch ( OSecurityAccessException e ) { // WRONG USER/PASSWD } catch ( OLockException e ) { OLogManager . instance ( ) . error ( this , \"Cannot access to the database '\" + iDatabaseName + \"'\" , e ) ; } finally { if ( db != null ) { db . close ( ) ; } } return userRid ; }", "nl": "null is returned in all other cases and means authentication was unsuccessful ."}}
{"translation": {"code": "public void createVertex ( final Long v ) { last = last < v ? v : last ; final List < Long > outList = out . get ( v ) ; if ( outList == null ) { out . put ( v , new ArrayList < Long > ( averageEdgeNumberPerNode <= 0 ? 4 : averageEdgeNumberPerNode ) ) ; } }", "nl": "Creates a new vertex"}}
{"translation": {"code": "public void end ( ) { final OClass vClass = db . getMetadata ( ) . getSchema ( ) . getClass ( vertexClass ) ; try { runningThreads = new AtomicInteger ( parallel ) ; for ( int i = 0 ; i < parallel - 1 ; i ++ ) { Thread t = new BatchImporterJob ( i , vClass ) ; t . start ( ) ; } Thread t = new BatchImporterJob ( parallel - 1 , vClass ) ; t . run ( ) ; if ( runningThreads . get ( ) > 0 ) { synchronized ( runningThreads ) { while ( runningThreads . get ( ) > 0 ) { try { runningThreads . wait ( ) ; } catch ( InterruptedException e ) { } } } } } finally { db . activateOnCurrentThread ( ) ; db . declareIntent ( null ) ; db . close ( ) ; if ( walActive ) OGlobalConfiguration . USE_WAL . setValue ( true ) ; } }", "nl": "Flushes data to db and closes the db . Call this once after vertices and edges creation ."}}
{"translation": {"code": "public static void clearInitStack ( ) { final ThreadLocal < Deque < OrientBaseGraph > > is = initializationStack ; if ( is != null ) is . get ( ) . clear ( ) ; final ThreadLocal < OrientBaseGraph > ag = activeGraph ; if ( ag != null ) ag . remove ( ) ; }", "nl": "Internal use only ."}}
{"translation": {"code": "@ Override public final Object command ( final OCommandRequestText iCommand ) { try { while ( true ) { try { final OCommandExecutor executor = OCommandManager . instance ( ) . getExecutor ( iCommand ) ; // COPY THE CONTEXT FROM THE REQUEST executor . setContext ( iCommand . getContext ( ) ) ; executor . setProgressListener ( iCommand . getProgressListener ( ) ) ; executor . parse ( iCommand ) ; return executeCommand ( iCommand , executor ) ; } catch ( final ORetryQueryException ignore ) { if ( iCommand instanceof OQueryAbstract ) { final OQueryAbstract query = ( OQueryAbstract ) iCommand ; query . reset ( ) ; } } } } catch ( final RuntimeException ee ) { throw logAndPrepareForRethrow ( ee ) ; } catch ( final Error ee ) { throw logAndPrepareForRethrow ( ee , false ) ; } catch ( final Throwable t ) { throw logAndPrepareForRethrow ( t ) ; } }", "nl": "Executes the command request and return the result back ."}}
{"translation": {"code": "protected boolean parseNoCache ( final String w ) throws OCommandSQLParsingException { if ( ! w . equals ( KEYWORD_NOCACHE ) ) return false ; noCache = true ; return true ; }", "nl": "Parses the NOCACHE keyword if found ."}}
{"translation": {"code": "public static synchronized < T extends Object > Iterator < T > lookupProviderWithOrientClassLoader ( Class < T > clazz ) { return lookupProviderWithOrientClassLoader ( clazz , OClassLoaderHelper . class . getClassLoader ( ) ) ; }", "nl": "Switch to the OrientDb classloader before lookups on ServiceRegistry for implementation of the given Class . Useful under OSGI and generally under applications where jars are loaded by another class loader"}}
{"translation": {"code": "private int getRelativeIndex ( long pos ) { int currentSize = 0 ; currentChunkIndex = 0 ; // loop until we find the chuks holding the given position\r while ( pos >= ( currentSize += binaryDataChunks . get ( currentChunkIndex ) . length ) ) currentChunkIndex ++ ; currentChunk = binaryDataChunks . get ( currentChunkIndex ) ; currentSize -= currentChunk . length ; // the position referred to the target binary chunk\r int relativePosition = ( int ) ( pos - currentSize ) ; // the index of the first byte to be returned\r return relativePosition - 1 ; }", "nl": "Calculates the index within a binary chunk corresponding to the given absolute position within this BLOB"}}
{"translation": {"code": "protected void reportTip ( final String iMessage ) { Orient . instance ( ) . getProfiler ( ) . reportTip ( iMessage ) ; List < String > tips = ( List < String > ) context . getVariable ( \"tips\" ) ; if ( tips == null ) { tips = new ArrayList < String > ( 3 ) ; context . setVariable ( \"tips\" , tips ) ; } tips . add ( iMessage ) ; }", "nl": "Report the tip to the profiler and collect it in context to be reported by tools like Studio"}}
{"translation": {"code": "public synchronized void registerEntityClasses ( Class < ? > aClass , boolean recursive ) { if ( recursive ) { classHandler . registerEntityClass ( aClass ) ; Field [ ] declaredFields = aClass . getDeclaredFields ( ) ; for ( Field declaredField : declaredFields ) { Class < ? > declaredFieldType = declaredField . getType ( ) ; if ( ! classHandler . containsEntityClass ( declaredFieldType ) ) { registerEntityClasses ( declaredFieldType , recursive ) ; } } } else { classHandler . registerEntityClass ( aClass ) ; } }", "nl": "Scans all classes accessible from the context class loader which belong to the given class and all it s attributes - classes ."}}
{"translation": {"code": "public int getTemporaryRIDCounter ( final OCommandContext iContext ) { final OTemporaryRidGenerator parentQuery = ( OTemporaryRidGenerator ) iContext . getVariable ( \"parentQuery\" ) ; return parentQuery != null && parentQuery != this ? parentQuery . getTemporaryRIDCounter ( iContext ) : serialTempRID . getAndIncrement ( ) ; }", "nl": "Returns the temporary RID counter assuring it s unique per query tree ."}}
{"translation": {"code": "public void adjustBeginLineColumn ( int newLine , int newCol ) { int start = tokenBegin ; int len ; if ( bufpos >= tokenBegin ) { len = bufpos - tokenBegin + inBuf + 1 ; } else { len = bufsize - tokenBegin + bufpos + 1 + inBuf ; } int i = 0 , j = 0 , k = 0 ; int nextColDiff = 0 , columnDiff = 0 ; while ( i < len && bufline [ j = start % bufsize ] == bufline [ k = ++ start % bufsize ] ) { bufline [ j ] = newLine ; nextColDiff = columnDiff + bufcolumn [ k ] - bufcolumn [ j ] ; bufcolumn [ j ] = newCol + columnDiff ; columnDiff = nextColDiff ; i ++ ; } if ( i < len ) { bufline [ j ] = newLine ++ ; bufcolumn [ j ] = newCol + columnDiff ; while ( i ++ < len ) { if ( bufline [ j = start % bufsize ] != bufline [ ++ start % bufsize ] ) bufline [ j ] = newLine ++ ; else bufline [ j ] = newLine ; } } line = bufline [ j ] ; column = bufcolumn [ j ] ; }", "nl": "Method to adjust line and column numbers for the start of a token ."}}
{"translation": {"code": "protected void waitForNextRetry ( ) { try { Thread . sleep ( new Random ( ) . nextInt ( MAX_DELAY - 1 ) + 1 ) ; } catch ( InterruptedException e ) { OLogManager . instance ( ) . error ( this , \"Wait was interrupted\" , e ) ; } }", "nl": "Wait before to retry"}}
{"translation": {"code": "@ Override public < RET extends OCommandExecutor > RET parse ( OCommandRequest iRequest ) { final OCommandRequestText textRequest = ( OCommandRequestText ) iRequest ; if ( iRequest instanceof OSQLSynchQuery ) { request = ( OSQLSynchQuery < ODocument > ) iRequest ; } else if ( iRequest instanceof OSQLAsynchQuery ) { request = ( OSQLAsynchQuery < ODocument > ) iRequest ; } else { // BUILD A QUERY OBJECT FROM THE COMMAND REQUEST request = new OSQLSynchQuery < ODocument > ( textRequest . getText ( ) ) ; if ( textRequest . getResultListener ( ) != null ) { request . setResultListener ( textRequest . getResultListener ( ) ) ; } } String queryText = textRequest . getText ( ) ; // please, do not look at this... refactor this ASAP with new executor structure final InputStream is = new ByteArrayInputStream ( queryText . getBytes ( ) ) ; OrientSql osql = null ; try { ODatabaseDocumentInternal db = getDatabase ( ) ; if ( db == null ) { osql = new OrientSql ( is ) ; } else { osql = new OrientSql ( is , db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; } } catch ( UnsupportedEncodingException e ) { OLogManager . instance ( ) . warn ( this , \"Invalid charset for database \" + getDatabase ( ) + \" \" + getDatabase ( ) . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; osql = new OrientSql ( is ) ; } try { OMatchStatement result = ( OMatchStatement ) osql . parse ( ) ; this . matchExpressions = result . matchExpressions ; this . notMatchExpressions = result . notMatchExpressions ; this . returnItems = result . returnItems ; this . returnAliases = result . returnAliases ; this . limit = result . limit ; } catch ( ParseException e ) { OCommandSQLParsingException ex = new OCommandSQLParsingException ( e , queryText ) ; OErrorCode . QUERY_PARSE_ERROR . throwException ( ex . getMessage ( ) , ex ) ; } buildPatterns ( ) ; pattern . validate ( ) ; return ( RET ) this ; }", "nl": "this method parses the statement"}}
{"translation": {"code": "@ Override public Object execute ( Map < Object , Object > iArgs ) { this . context . setInputParameters ( iArgs ) ; return execute ( this . request , this . context , this . progressListener ) ; }", "nl": "this method works statefully using request and context variables from current Match statement . This method will be deprecated in next releases"}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { final ODatabaseDocumentInternal database = getDatabase ( ) ; database . checkSecurity ( ORule . ResourceGeneric . DATABASE , \"sync\" , ORole . PERMISSION_UPDATE ) ; final OStorage stg = database . getStorage ( ) ; if ( ! ( stg instanceof ODistributedStorage ) ) throw new ODistributedException ( \"SYNC DATABASE command cannot be executed against a non distributed server\" ) ; final ODistributedStorage dStg = ( ODistributedStorage ) stg ; final OHazelcastPlugin dManager = ( OHazelcastPlugin ) dStg . getDistributedManager ( ) ; if ( dManager == null || ! dManager . isEnabled ( ) ) throw new OCommandExecutionException ( \"OrientDB is not started in distributed mode\" ) ; final String databaseName = database . getName ( ) ; return dManager . installDatabase ( true , databaseName , parsedStatement . isForce ( ) , ! parsedStatement . isFull ( ) ) ; }", "nl": "Execute the SYNC DATABASE ."}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { final ODatabaseDocumentInternal database = getDatabase ( ) ; database . checkSecurity ( ORule . ResourceGeneric . CLUSTER , \"sync\" , ORole . PERMISSION_UPDATE ) ; if ( ! ( database instanceof ODatabaseDocumentDistributed ) ) { throw new OCommandExecutionException ( \"OrientDB is not started in distributed mode\" ) ; } final OHazelcastPlugin dManager = ( OHazelcastPlugin ) ( ( ODatabaseDocumentDistributed ) database ) . getDistributedManager ( ) ; if ( dManager == null || ! dManager . isEnabled ( ) ) throw new OCommandExecutionException ( \"OrientDB is not started in distributed mode\" ) ; final String databaseName = database . getName ( ) ; try { if ( this . parsedStatement . modeFull ) { return replaceCluster ( dManager , database , dManager . getServerInstance ( ) , databaseName , this . parsedStatement . clusterName . getStringValue ( ) ) ; } // else { // int merged = 0; // return String.format(\"Merged %d records\", merged); // } } catch ( Exception e ) { throw OException . wrapException ( new OCommandExecutionException ( \"Cannot execute synchronization of cluster\" ) , e ) ; } return \"Mode not supported\" ; }", "nl": "Execute the SYNC CLUSTER ."}}
{"translation": {"code": "public Set < String > getClustersOnServer ( final String iNodeName ) { final Set < String > clusters = new HashSet < String > ( ) ; for ( String cl : getClusterNames ( ) ) { final List < String > servers = getServers ( cl , null ) ; if ( servers . contains ( iNodeName ) ) clusters . add ( cl ) ; } return clusters ; }", "nl": "Returns the set of clusters managed by a server ."}}
{"translation": {"code": "public void registerCommand ( final OServerCommand iServerCommandInstance ) { for ( String name : iServerCommandInstance . getNames ( ) ) if ( OStringSerializerHelper . contains ( name , ' ' ) ) { restCommands . put ( name , iServerCommandInstance ) ; } else if ( OStringSerializerHelper . contains ( name , ' ' ) ) wildcardCommands . put ( name , iServerCommandInstance ) ; else exactCommands . put ( name , iServerCommandInstance ) ; iServerCommandInstance . configure ( server ) ; }", "nl": "Register all the names for the same instance ."}}
{"translation": {"code": "public OGraphMLReader defineEdgeAttributeStrategy ( final String iAttributeName , final OGraphMLImportStrategy iStrategy ) { edgePropsStrategy . put ( iAttributeName , iStrategy ) ; return this ; }", "nl": "Define custom strategy to use for edge attribute ."}}
{"translation": {"code": "public OGraphMLReader defineVertexAttributeStrategy ( final String iAttributeName , final OGraphMLImportStrategy iStrategy ) { vertexPropsStrategy . put ( iAttributeName , iStrategy ) ; return this ; }", "nl": "Define custom strategy to use for vertex attribute ."}}
{"translation": {"code": "public long estimate ( OClass oClass , long threshold , OCommandContext ctx ) { long count = oClass . count ( ) ; if ( count > 1 ) { count = count / 2 ; } if ( count < threshold ) { return count ; } long indexesCount = 0l ; List < OAndBlock > flattenedConditions = flatten ( ) ; Set < OIndex < ? > > indexes = oClass . getIndexes ( ) ; for ( OAndBlock condition : flattenedConditions ) { List < OBinaryCondition > indexedFunctConditions = condition . getIndexedFunctionConditions ( oClass , ( ODatabaseDocumentInternal ) ctx . getDatabase ( ) ) ; long conditionEstimation = Long . MAX_VALUE ; if ( indexedFunctConditions != null ) { for ( OBinaryCondition cond : indexedFunctConditions ) { OFromClause from = new OFromClause ( - 1 ) ; OFromItem item = new OFromItem ( - 1 ) ; from . item = item ; from . item . setIdentifier ( new OIdentifier ( oClass . getName ( ) ) ) ; long newCount = cond . estimateIndexed ( from , ctx ) ; if ( newCount < conditionEstimation ) { conditionEstimation = newCount ; } } } else { Map < String , Object > conditions = getEqualityOperations ( condition , ctx ) ; for ( OIndex index : indexes ) { if ( index . getType ( ) . equals ( OClass . INDEX_TYPE . FULLTEXT . name ( ) ) || index . getType ( ) . equals ( OClass . INDEX_TYPE . FULLTEXT_HASH_INDEX . name ( ) ) ) { continue ; } List < String > indexedFields = index . getDefinition ( ) . getFields ( ) ; int nMatchingKeys = 0 ; for ( String indexedField : indexedFields ) { if ( conditions . containsKey ( indexedField ) ) { nMatchingKeys ++ ; } else { break ; } } if ( nMatchingKeys > 0 ) { long newCount = estimateFromIndex ( index , conditions , nMatchingKeys ) ; if ( newCount < conditionEstimation ) { conditionEstimation = newCount ; } } } } if ( conditionEstimation > count ) { return count ; } indexesCount += conditionEstimation ; } return Math . min ( indexesCount , count ) ; }", "nl": "estimates how many items of this class will be returned applying this filter"}}
{"translation": {"code": "private void updateScheduleStartingAt ( PatternNode startNode , Set < PatternNode > visitedNodes , Set < PatternEdge > visitedEdges , Map < String , Set < String > > remainingDependencies , List < EdgeTraversal > resultingSchedule ) { // OrientDB requires the schedule to contain all edges present in the query, which is a stronger condition // than simply visiting all nodes in the query. Consider the following example query: //     MATCH { //         class: A, //         as: foo //     }.in() { //         as: bar //     }, { //         class: B, //         as: bar //     }.out() { //         as: foo //     } RETURN $matches // The schedule for the above query must have two edges, even though there are only two nodes and they can both // be visited with the traversal of a single edge. // // To satisfy it, we obey the following for each non-optional node: // - ignore edges to neighboring nodes which have unsatisfied dependencies; // - for visited neighboring nodes, add their edge if it wasn't already present in the schedule, but do not //   recurse into the neighboring node; // - for unvisited neighboring nodes with satisfied dependencies, add their edge and recurse into them. visitedNodes . add ( startNode ) ; for ( Set < String > dependencies : remainingDependencies . values ( ) ) { dependencies . remove ( startNode . alias ) ; } Map < PatternEdge , Boolean > edges = new LinkedHashMap < PatternEdge , Boolean > ( ) ; for ( PatternEdge outEdge : startNode . out ) { edges . put ( outEdge , true ) ; } for ( PatternEdge inEdge : startNode . in ) { edges . put ( inEdge , false ) ; } for ( Map . Entry < PatternEdge , Boolean > edgeData : edges . entrySet ( ) ) { PatternEdge edge = edgeData . getKey ( ) ; boolean isOutbound = edgeData . getValue ( ) ; PatternNode neighboringNode = isOutbound ? edge . in : edge . out ; if ( ! remainingDependencies . get ( neighboringNode . alias ) . isEmpty ( ) ) { // Unsatisfied dependencies, ignore this neighboring node. continue ; } if ( visitedNodes . contains ( neighboringNode ) ) { if ( ! visitedEdges . contains ( edge ) ) { // If we are executing in this block, we are in the following situation: // - the startNode has not been visited yet; // - it has a neighboringNode that has already been visited; // - the edge between the startNode and the neighboringNode has not been scheduled yet. // // The isOutbound value shows us whether the edge is outbound from the point of view of the startNode. // However, if there are edges to the startNode, we must visit the startNode from an already-visited // neighbor, to preserve the validity of the traversal. Therefore, we negate the value of isOutbound // to ensure that the edge is always scheduled in the direction from the already-visited neighbor // toward the startNode. Notably, this is also the case when evaluating \"optional\" nodes -- we always // visit the optional node from its non-optional and already-visited neighbor. // // The only exception to the above is when we have edges with \"while\" conditions. We are not allowed // to flip their directionality, so we leave them as-is. boolean traversalDirection ; if ( startNode . optional || edge . item . isBidirectional ( ) ) { traversalDirection = ! isOutbound ; } else { traversalDirection = isOutbound ; } visitedEdges . add ( edge ) ; resultingSchedule . add ( new EdgeTraversal ( edge , traversalDirection ) ) ; } } else if ( ! startNode . optional ) { // If the neighboring node wasn't visited, we don't expand the optional node into it, hence the above check. // Instead, we'll allow the neighboring node to add the edge we failed to visit, via the above block. if ( visitedEdges . contains ( edge ) ) { // Should never happen. throw new AssertionError ( \"The edge was visited, but the neighboring vertex was not: \" + edge + \" \" + neighboringNode ) ; } visitedEdges . add ( edge ) ; resultingSchedule . add ( new EdgeTraversal ( edge , isOutbound ) ) ; updateScheduleStartingAt ( neighboringNode , visitedNodes , visitedEdges , remainingDependencies , resultingSchedule ) ; } } }", "nl": "Start a depth - first traversal from the starting node adding all viable unscheduled edges and vertices ."}}
{"translation": {"code": "public String getProperty ( final String iName , final String iDefaultValue ) { if ( properties == null ) return null ; for ( OServerEntryConfiguration p : properties ) { if ( p . name . equals ( iName ) ) return p . value ; } return null ; }", "nl": "Returns the property value configured if any ."}}
{"translation": {"code": "protected static OStatement parse ( String statement ) throws OCommandSQLParsingException { try { ODatabaseDocumentInternal db = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; InputStream is ; if ( db == null ) { is = new ByteArrayInputStream ( statement . getBytes ( ) ) ; } else { try { is = new ByteArrayInputStream ( statement . getBytes ( db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ) ; } catch ( UnsupportedEncodingException e2 ) { OLogManager . instance ( ) . warn ( null , \"Unsupported charset for database \" + db + \" \" + db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; is = new ByteArrayInputStream ( statement . getBytes ( ) ) ; } } OrientSql osql = null ; if ( db == null ) { osql = new OrientSql ( is ) ; } else { try { osql = new OrientSql ( is , db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; } catch ( UnsupportedEncodingException e2 ) { OLogManager . instance ( ) . warn ( null , \"Unsupported charset for database \" + db + \" \" + db . getStorage ( ) . getConfiguration ( ) . getCharset ( ) ) ; osql = new OrientSql ( is ) ; } } OStatement result = osql . parse ( ) ; result . originalStatement = statement ; return result ; } catch ( ParseException e ) { throwParsingException ( e , statement ) ; } catch ( TokenMgrError e2 ) { throwParsingException ( e2 , statement ) ; } return null ; }", "nl": "parses an SQL statement and returns the corresponding executor"}}
{"translation": {"code": "public void register ( final OEncryption iEncryption ) { try { final String name = iEncryption . name ( ) ; if ( instances . containsKey ( name ) ) throw new IllegalArgumentException ( \"Encryption with name '\" + name + \"' was already registered\" ) ; if ( classes . containsKey ( name ) ) throw new IllegalArgumentException ( \"Encryption with name '\" + name + \"' was already registered\" ) ; instances . put ( name , iEncryption ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Cannot register storage encryption algorithm '%s'\" , e , iEncryption ) ; } }", "nl": "Registers a stateful implementations a new instance will be created for each storage ."}}
{"translation": {"code": "public Set < String > getAllConfiguredServers ( ) { final Set < String > servers = new HashSet < String > ( ) ; for ( String p : getClusterNames ( ) ) { final List < String > serverList = getClusterConfiguration ( p ) . field ( SERVERS ) ; if ( serverList != null ) { for ( String s : serverList ) if ( ! s . equals ( NEW_NODE_TAG ) ) servers . add ( s ) ; } } return servers ; }", "nl": "Returns the complete list of servers found in configuration ."}}
{"translation": {"code": "@ Deprecated public synchronized ODocument getServerInfo ( ) throws IOException { OServerInfoRequest request = new OServerInfoRequest ( ) ; OServerInfoResponse response = networkAdminOperation ( request , \"Cannot retrieve server information\" ) ; ODocument res = new ODocument ( ) ; res . fromJSON ( response . getResult ( ) ) ; return res ; }", "nl": "Returns the server information in form of document ."}}
{"translation": {"code": "public synchronized boolean addToUniqueResult ( Object o ) { Object toAdd = o ; if ( o instanceof ODocument && ( ( ODocument ) o ) . getIdentity ( ) . isNew ( ) ) { toAdd = new ODocumentEqualityWrapper ( ( ODocument ) o ) ; } return this . uniqueResult . add ( toAdd ) ; }", "nl": "adds an item to the unique result set"}}
{"translation": {"code": "@ Override public OCommandRequestAbstract onAsyncReplicationError ( final OAsyncReplicationError iCallback ) { if ( iCallback != null ) { onAsyncReplicationError = new OAsyncReplicationError ( ) { int retry = 0 ; @ Override public ACTION onAsyncReplicationError ( Throwable iException , final int iRetry ) { switch ( iCallback . onAsyncReplicationError ( iException , ++ retry ) ) { case RETRY : execute ( ) ; break ; case IGNORE : } return ACTION . IGNORE ; } } ; } else onAsyncReplicationError = null ; return this ; }", "nl": "Defines a callback to call in case of error during the asynchronous replication ."}}
{"translation": {"code": "protected boolean fixLink ( final Object fieldValue ) { if ( fieldValue instanceof OIdentifiable ) { final ORID id = ( ( OIdentifiable ) fieldValue ) . getIdentity ( ) ; if ( id . getClusterId ( ) == 0 && id . getClusterPosition ( ) == 0 ) return true ; if ( id . isValid ( ) ) if ( id . isPersistent ( ) ) { final ORecord connected = ( ( OIdentifiable ) fieldValue ) . getRecord ( ) ; if ( connected == null ) return true ; } else return true ; } return false ; }", "nl": "Checks if the link must be fixed ."}}
{"translation": {"code": "public void stopCommitTimer ( ) { final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; performanceCountersHolder . commitTime += timeDiff ; performanceCountersHolder . commitCount ++ ; makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops and records results of timer which counts how much time was spent on atomic operation commit ."}}
{"translation": {"code": "public void completeComponentOperation ( ) { final Component currentComponent = componentsStack . peek ( ) ; if ( currentComponent == null ) return ; currentComponent . operationCount -- ; if ( currentComponent . operationCount == 0 ) { final String componentName = currentComponent . name ; PerformanceCountersHolder cHolder = countersByComponent . computeIfAbsent ( componentName , k -> currentComponent . type . newCountersHolder ( ) ) ; cHolder . operationsCount ++ ; componentsStack . pop ( ) ; makeSnapshotIfNeeded ( - 1 ) ; } }", "nl": "Indicates that the most earliest component in stack of components has completed it s operation so performance data for this component is stopped to be gathered ."}}
{"translation": {"code": "@ Override public Object execute ( OSQLAsynchQuery < ODocument > request , OCommandContext context , OProgressListener progressListener ) { try { ODatabaseDocumentInternal db = getDatabase ( ) ; final OStorage storage = db . getStorage ( ) ; if ( on ) { // activate the profiler ( ( OAbstractPaginatedStorage ) storage ) . startGatheringPerformanceStatisticForCurrentThread ( ) ; ODocument result = new ODocument ( ) ; result . field ( \"result\" , \"OK\" ) ; request . getResultListener ( ) . result ( result ) ; } else { // stop the profiler and return the stats final OSessionStoragePerformanceStatistic performanceStatistic = ( ( OAbstractPaginatedStorage ) storage ) . completeGatheringPerformanceStatisticForCurrentThread ( ) ; if ( performanceStatistic != null ) request . getResultListener ( ) . result ( performanceStatistic . toDocument ( ) ) ; else { ODocument result = new ODocument ( ) ; result . field ( \"result\" , \"Error: profiling of storage was not started.\" ) ; request . getResultListener ( ) . result ( result ) ; } } return getResult ( request ) ; } finally { if ( request . getResultListener ( ) != null ) { request . getResultListener ( ) . end ( ) ; } } }", "nl": "old execution logic"}}
{"translation": {"code": "public String getClusterOwner ( final String iClusterName ) { String owner ; final ODocument clusters = getConfiguredClusters ( ) ; // GET THE CLUSTER CFG final ODocument cfg = iClusterName != null ? ( ODocument ) clusters . field ( iClusterName ) : null ; if ( cfg != null ) { owner = cfg . field ( OWNER ) ; if ( owner != null ) return owner ; final List < String > serverList = cfg . field ( SERVERS ) ; if ( serverList != null && ! serverList . isEmpty ( ) ) { // RETURN THE FIRST ONE owner = serverList . get ( 0 ) ; if ( NEW_NODE_TAG . equals ( owner ) && serverList . size ( ) > 1 ) // DON'T RETURN <NEW_NODE> owner = serverList . get ( 1 ) ; } } else // RETURN THE OWNER OF * return getClusterOwner ( ALL_WILDCARD ) ; return owner ; }", "nl": "Returns the owner server for the given cluster excluding the passed node . The Owner server is the first in server list ."}}
{"translation": {"code": "boolean canBeUsedByOrderByAfterFilter ( OIndex < ? > index , List < String > equalsFilterFields , List < OPair < String , String > > orderedFields ) { if ( orderedFields . isEmpty ( ) ) return false ; if ( ! index . supportsOrderedIterations ( ) ) return false ; final OIndexDefinition definition = index . getDefinition ( ) ; final List < String > indexFields = definition . getFields ( ) ; int endIndex = Math . min ( indexFields . size ( ) , equalsFilterFields . size ( ) ) ; final String firstOrder = orderedFields . get ( 0 ) . getValue ( ) ; //check that all the \"equals\" clauses are a prefix for the index for ( int i = 0 ; i < endIndex ; i ++ ) { final String equalsFieldName = equalsFilterFields . get ( i ) ; final String indexFieldName = indexFields . get ( i ) ; if ( ! equalsFieldName . equals ( indexFieldName ) ) return false ; } endIndex = Math . min ( indexFields . size ( ) , orderedFields . size ( ) + equalsFilterFields . size ( ) ) ; if ( endIndex == equalsFilterFields . size ( ) ) { //the index is used only for filtering return false ; } //check that after that prefix there all the Order By fields in the right order for ( int i = equalsFilterFields . size ( ) ; i < endIndex ; i ++ ) { int fieldOrderInOrderByClause = i - equalsFilterFields . size ( ) ; final OPair < String , String > pair = orderedFields . get ( fieldOrderInOrderByClause ) ; if ( ! firstOrder . equals ( pair . getValue ( ) ) ) return false ; final String orderFieldName = pair . getKey ( ) ; final String indexFieldName = indexFields . get ( i ) ; if ( ! orderFieldName . equals ( indexFieldName ) ) return false ; } return true ; }", "nl": "checks if given a list of = conditions and a set of ORDER BY fields"}}
{"translation": {"code": "public static OIndexCursor wrap ( OIndex < ? > source , OIndexCursor cursor , long indexRebuildVersion ) { if ( cursor instanceof OIndexChangesWrapper ) return cursor ; if ( cursor instanceof OSizeable ) { return new OIndexChangesSizeable ( source , cursor , indexRebuildVersion ) ; } return new OIndexChangesWrapper ( source , cursor , indexRebuildVersion ) ; }", "nl": "Wraps courser only if it is not already wrapped ."}}
{"translation": {"code": "public int getWriteQuorum ( final String clusterName , final int totalConfiguredMasterServers , final String server ) { Integer overWrite = overwriteWriteQuorum . get ( ) ; if ( overWrite != null ) return overWrite . intValue ( ) ; else return getQuorum ( \"writeQuorum\" , clusterName , totalConfiguredMasterServers , DEFAULT_WRITE_QUORUM , server ) ; }", "nl": "Returns the write quorum ."}}
{"translation": {"code": "public Set < String > getClustersOwnedByServer ( final String iNodeName ) { final Set < String > clusters = new HashSet < String > ( ) ; for ( String cl : getClusterNames ( ) ) { if ( iNodeName . equals ( getClusterOwner ( cl ) ) ) clusters . add ( cl ) ; } return clusters ; }", "nl": "Returns the set of clusters where server is the owner ."}}
{"translation": {"code": "private void clearConfigurationFiles ( ) throws IOException { final Path file = storagePath . resolve ( NAME ) ; Files . deleteIfExists ( file ) ; final Path backupFile = storagePath . resolve ( BACKUP_NAME ) ; Files . deleteIfExists ( backupFile ) ; }", "nl": "Remove both backup and primary configuration files on delete"}}
{"translation": {"code": "public boolean isConnected ( ) { final Socket s = socket ; return s != null && ! s . isClosed ( ) && s . isConnected ( ) && ! s . isInputShutdown ( ) && ! s . isOutputShutdown ( ) ; }", "nl": "Tells if the channel is connected ."}}
{"translation": {"code": "public void stopMonitoring ( ) { switchLock . acquireWriteLock ( ) ; try { enabled = false ; final PerformanceCountersHolder countersHolder = ComponentType . GENERAL . newCountersHolder ( ) ; final Map < String , PerformanceCountersHolder > componentCountersHolder = new HashMap <> ( ) ; WritCacheCountersHolder writCacheCountersHolder = deadThreadsStatistic . writCacheCountersHolder ; StorageCountersHolder storageCountersHolder = deadThreadsStatistic . storageCountersHolder ; WALCountersHolder walCountersHolder = deadThreadsStatistic . walCountersHolder ; deadThreadsStatistic . countersHolder . pushData ( countersHolder ) ; componentCountersHolder . putAll ( deadThreadsStatistic . countersByComponents ) ; deadThreadsStatistic = null ; for ( OSessionStoragePerformanceStatistic statistic : statistics . values ( ) ) { statistic . pushSystemCounters ( countersHolder ) ; statistic . pushComponentCounters ( componentCountersHolder ) ; writCacheCountersHolder = statistic . pushWriteCacheCounters ( writCacheCountersHolder ) ; storageCountersHolder = statistic . pushStorageCounters ( storageCountersHolder ) ; walCountersHolder = statistic . pushWALCounters ( walCountersHolder ) ; } statistics . clear ( ) ; postMeasurementStatistic = new ImmutableStatistic ( countersHolder , componentCountersHolder , writCacheCountersHolder , storageCountersHolder , walCountersHolder ) ; } finally { switchLock . releaseWriteLock ( ) ; } }", "nl": "Stops monitoring of performance statistic for whole system ."}}
{"translation": {"code": "public void pushComponentCounters ( Map < String , PerformanceCountersHolder > counters ) { if ( snapshot == null ) return ; for ( Map . Entry < String , PerformanceCountersHolder > entry : snapshot . countersByComponent . entrySet ( ) ) { final String componentName = entry . getKey ( ) ; PerformanceCountersHolder holder = counters . computeIfAbsent ( componentName , k -> entry . getValue ( ) . newInstance ( ) ) ; entry . getValue ( ) . pushData ( holder ) ; } }", "nl": "Takes performance data are split by components from last snapshot and aggregates them with data passed inside method as parameter . Result of aggregation of performance data is returned inside of passed in performance data ."}}
{"translation": {"code": "public void pushComponentCounters ( String name , PerformanceCountersHolder holder ) { if ( snapshot == null ) return ; final PerformanceCountersHolder countersHolder = snapshot . countersByComponent . get ( name ) ; if ( countersHolder != null ) { countersHolder . pushData ( holder ) ; } }", "nl": "Takes performance data for component from last snapshot and aggregates them with data passed inside method as parameter . Result of aggregation of performance data is returned inside of passed in performance data ."}}
{"translation": {"code": "private void fetchComponentCounters ( String componentName , PerformanceCountersHolder componentCountersHolder ) { //go through all threads and accumulate statistic only for live threads //all dead threads will be removed and statistics from them will be //later accumulated in #deadThreadsStatistic field, then result statistic from this field //will be aggregated to componentCountersHolder //To decrease inter thread communication delay we fetch snapshots first //and only after that we aggregate data from immutable snapshots final Collection < ORawPair < Thread , PerformanceSnapshot > > snapshots = new ArrayList <> ( statistics . size ( ) ) ; final List < Thread > threadsToRemove = new ArrayList <> ( ) ; for ( Map . Entry < Thread , OSessionStoragePerformanceStatistic > entry : statistics . entrySet ( ) ) { final Thread thread = entry . getKey ( ) ; final OSessionStoragePerformanceStatistic statistic = entry . getValue ( ) ; snapshots . add ( new ORawPair <> ( thread , statistic . getSnapshot ( ) ) ) ; } for ( ORawPair < Thread , PerformanceSnapshot > pair : snapshots ) { final Thread thread = pair . getFirst ( ) ; if ( thread . isAlive ( ) ) { final PerformanceSnapshot snapshot = pair . getSecond ( ) ; final PerformanceCountersHolder holder = snapshot . countersByComponent . get ( componentName ) ; if ( holder != null ) holder . pushData ( componentCountersHolder ) ; } else { threadsToRemove . add ( thread ) ; } } if ( ! threadsToRemove . isEmpty ( ) ) { updateDeadThreadsStatistic ( threadsToRemove ) ; } final ImmutableStatistic ds = deadThreadsStatistic ; if ( ds != null ) { final PerformanceCountersHolder dch = ds . countersByComponents . get ( componentName ) ; if ( dch != null ) { dch . pushData ( componentCountersHolder ) ; } } }", "nl": "Iterates over all live threads and accumulates performance statics gathered form threads for provided component also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started ."}}
{"translation": {"code": "public OrientEdgeType createEdgeType ( final String iClassName , final int clusters ) { makeActive ( ) ; return createEdgeType ( iClassName , ( String ) null , clusters ) ; }", "nl": "Creates a new Edge persistent class ."}}
{"translation": {"code": "public OrientVertexType createVertexType ( final String iClassName , final int clusters ) { makeActive ( ) ; return createVertexType ( iClassName , ( String ) null , clusters ) ; }", "nl": "Creates a new Vertex persistent class ."}}
{"translation": {"code": "private void fetchSystemCounters ( PerformanceCountersHolder countersHolder ) { //go through all threads and accumulate statistic only for live threads //all dead threads will be removed and statistics from them will be //later accumulated in #deadThreadsStatistic field, then result statistic from this field //will be aggregated to countersHolder //To decrease inter thread communication delay we fetch snapshots first //and only after that we aggregate data from immutable snapshots final Collection < ORawPair < Thread , PerformanceSnapshot > > snapshots = new ArrayList <> ( statistics . size ( ) ) ; final Collection < Thread > threadsToRemove = new ArrayList <> ( ) ; for ( Map . Entry < Thread , OSessionStoragePerformanceStatistic > entry : statistics . entrySet ( ) ) { final Thread thread = entry . getKey ( ) ; final OSessionStoragePerformanceStatistic statistic = entry . getValue ( ) ; snapshots . add ( new ORawPair <> ( thread , statistic . getSnapshot ( ) ) ) ; } for ( ORawPair < Thread , PerformanceSnapshot > pair : snapshots ) { final Thread thread = pair . getFirst ( ) ; if ( thread . isAlive ( ) ) { final PerformanceSnapshot snapshot = pair . getSecond ( ) ; snapshot . performanceCountersHolder . pushData ( countersHolder ) ; } else { threadsToRemove . add ( thread ) ; } } if ( ! threadsToRemove . isEmpty ( ) ) { updateDeadThreadsStatistic ( threadsToRemove ) ; } final ImmutableStatistic ds = deadThreadsStatistic ; if ( ds != null ) { final PerformanceCountersHolder dch = ds . countersHolder ; dch . pushData ( countersHolder ) ; } }", "nl": "Iterates over all live threads and accumulates performance statics gathered form threads on system level also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started ."}}
{"translation": {"code": "public ODistributedDatabaseImpl registerDatabase ( final String iDatabaseName , ODistributedConfiguration cfg ) { final ODistributedDatabaseImpl ddb = databases . get ( iDatabaseName ) ; if ( ddb != null ) return ddb ; return new ODistributedDatabaseImpl ( manager , this , iDatabaseName , cfg , manager . getServerInstance ( ) ) ; }", "nl": "Creates a distributed database instance if not defined yet ."}}
{"translation": {"code": "@ Override public void onOpen ( final ODatabaseInternal iDatabase ) { if ( ! isRelatedToLocalServer ( iDatabase ) ) return ; if ( isOffline ( ) && status != NODE_STATUS . STARTING ) return ; final ODatabaseDocumentInternal currDb = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; try { final String dbName = iDatabase . getName ( ) ; final ODistributedConfiguration cfg = getDatabaseConfiguration ( dbName ) ; if ( cfg == null ) return ; } catch ( HazelcastException e ) { throw OException . wrapException ( new OOfflineNodeException ( \"Hazelcast instance is not available\" ) , e ) ; } catch ( HazelcastInstanceNotActiveException e ) { throw OException . wrapException ( new OOfflineNodeException ( \"Hazelcast instance is not available\" ) , e ) ; } finally { // RESTORE ORIGINAL DATABASE INSTANCE IN TL ODatabaseRecordThreadLocal . instance ( ) . set ( currDb ) ; } }", "nl": "Auto register myself as hook ."}}
{"translation": {"code": "private static boolean isAlgorithmSupported ( final String algorithm ) { // Java 7 specific checks.\r if ( Runtime . class . getPackage ( ) != null && Runtime . class . getPackage ( ) . getImplementationVersion ( ) != null ) { if ( Runtime . class . getPackage ( ) . getImplementationVersion ( ) . startsWith ( \"1.7\" ) ) { // Java 7 does not support the PBKDF2_SHA256_ALGORITHM.\r if ( algorithm != null && algorithm . equals ( PBKDF2_SHA256_ALGORITHM ) ) { return false ; } } } return true ; }", "nl": "Returns true if the algorithm is supported by the current version of Java"}}
{"translation": {"code": "public void unregisterMBean ( String storageName , int storageId ) { if ( storageName == null ) { OLogManager . instance ( ) . warnNoDb ( this , \"Can not unregister MBean for performance statistics, storage name is null\" ) ; } if ( mbeanIsRegistered . compareAndSet ( true , false ) ) { try { final MBeanServer server = ManagementFactory . getPlatformMBeanServer ( ) ; final ObjectName mbeanName = new ObjectName ( getMBeanName ( storageName , storageId ) ) ; server . unregisterMBean ( mbeanName ) ; } catch ( MalformedObjectNameException | InstanceNotFoundException | MBeanRegistrationException e ) { throw OException . wrapException ( new OStorageException ( \"Error during unregistration of profiler MBean\" ) , e ) ; } } }", "nl": "Deregisters JMX bean for current manager ."}}
{"translation": {"code": "public void registerMBean ( String storageName , int storageId ) { if ( mbeanIsRegistered . compareAndSet ( false , true ) ) { try { final MBeanServer server = ManagementFactory . getPlatformMBeanServer ( ) ; final ObjectName mbeanName = new ObjectName ( getMBeanName ( storageName , storageId ) ) ; if ( ! server . isRegistered ( mbeanName ) ) { server . registerMBean ( new OPerformanceStatisticManagerMBean ( this ) , mbeanName ) ; } else { mbeanIsRegistered . set ( false ) ; OLogManager . instance ( ) . warn ( this , \"MBean with name %s has already registered. Probably your system was not shutdown correctly\" + \" or you have several running applications which use OrientDB engine inside\" , mbeanName . getCanonicalName ( ) ) ; } } catch ( MalformedObjectNameException | InstanceAlreadyExistsException | NotCompliantMBeanException | MBeanRegistrationException e ) { throw OException . wrapException ( new OStorageException ( \"Error during registration of profiler MBean\" ) , e ) ; } } }", "nl": "Registers JMX bean for current manager ."}}
{"translation": {"code": "public OCollate getCollate ( Object doc ) { if ( collate != null || operationsChain == null || ! isFieldChain ( ) ) { return collate ; } if ( ! ( doc instanceof OIdentifiable ) ) { return null ; } FieldChain chain = getFieldChain ( ) ; ODocument lastDoc = ( ( OIdentifiable ) doc ) . getRecord ( ) ; for ( int i = 0 ; i < chain . getItemCount ( ) - 1 ; i ++ ) { if ( lastDoc == null ) { return null ; } Object nextDoc = lastDoc . field ( chain . getItemName ( i ) ) ; if ( nextDoc == null || ! ( nextDoc instanceof OIdentifiable ) ) { return null ; } lastDoc = ( ( OIdentifiable ) nextDoc ) . getRecord ( ) ; } if ( lastDoc == null ) { return null ; } OClass schemaClass = lastDoc . getSchemaClass ( ) ; if ( schemaClass == null ) { return null ; } OProperty property = schemaClass . getProperty ( chain . getItemName ( chain . getItemCount ( ) - 1 ) ) ; if ( property == null ) { return null ; } return property . getCollate ( ) ; }", "nl": "get the collate of this expression based on the fully evaluated field chain starting from the passed object ."}}
{"translation": {"code": "protected OServerUserConfiguration createServerUser ( final ODocument userDoc ) { OServerUserConfiguration userCfg = null ; if ( userDoc . containsField ( \"username\" ) && userDoc . containsField ( \"resources\" ) ) { final String user = userDoc . field ( \"username\" ) ; final String resources = userDoc . field ( \"resources\" ) ; String password = userDoc . field ( \"password\" ) ; if ( password == null ) password = \"\" ; userCfg = new OServerUserConfiguration ( user , password , resources ) ; } return userCfg ; }", "nl": "Derived implementations can override this method to provide new server user implementations ."}}
{"translation": {"code": "public String getAuthenticationHeader ( String databaseName ) { String header ; // Default to Basic. if ( databaseName != null ) header = \"WWW-Authenticate: Basic realm=\\\"OrientDB db-\" + databaseName + \"\\\"\" ; else header = \"WWW-Authenticate: Basic realm=\\\"OrientDB Server\\\"\" ; return header ; }", "nl": "databaseName may be null ."}}
{"translation": {"code": "public void stopWriteCacheFlushTimer ( int pagesFlushed ) { // lazy initialization to prevent memory consumption if ( writCacheCountersHolder == null ) writCacheCountersHolder = new WritCacheCountersHolder ( ) ; final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; writCacheCountersHolder . flushOperationsCount ++ ; writCacheCountersHolder . amountOfPagesFlushed += pagesFlushed ; writCacheCountersHolder . flushOperationsTime += timeDiff ; makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops and records results of timer which counts how much time was spent on operation of flush pages in write cache ."}}
{"translation": {"code": "public void stopFuzzyCheckpointTimer ( ) { if ( writCacheCountersHolder == null ) writCacheCountersHolder = new WritCacheCountersHolder ( ) ; final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; writCacheCountersHolder . fuzzyCheckpointCount ++ ; writCacheCountersHolder . fuzzyCheckpointTime += timeDiff ; makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops and records results of timer which counts how much time was spent on fuzzy checkpoint operation ."}}
{"translation": {"code": "public void stopWALRecordTimer ( boolean isStartRecord , boolean isStopRecord ) { final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; if ( walCountersHolder == null ) walCountersHolder = new WALCountersHolder ( ) ; walCountersHolder . logRecordCount ++ ; walCountersHolder . logRecordTime += timeDiff ; if ( isStartRecord ) { walCountersHolder . startRecordCount ++ ; walCountersHolder . startRecordTime += timeDiff ; } else if ( isStopRecord ) { walCountersHolder . stopRecordCount ++ ; walCountersHolder . stopRecordTime += timeDiff ; } makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops and records results of timer which counts how much time was spent on logging of single write ahead log record ."}}
{"translation": {"code": "public WALCountersHolder pushWALCounters ( WALCountersHolder holder ) { if ( snapshot == null ) return holder ; if ( snapshot . walCountersHolder == null ) return holder ; if ( holder == null ) holder = new WALCountersHolder ( ) ; snapshot . walCountersHolder . pushData ( holder ) ; return holder ; }", "nl": "Takes write ahead log data from last snapshot and aggregates them with data passed inside method as parameter . Result of aggregation of performance data is returned inside of passed in performance data and as result of this method call ."}}
{"translation": {"code": "public void stopWALFlushTimer ( ) { final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; if ( walCountersHolder == null ) walCountersHolder = new WALCountersHolder ( ) ; walCountersHolder . flushCount ++ ; walCountersHolder . flushTime += timeDiff ; makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops timer and records how much time was spent on flushing of data from write ahead log cache ."}}
{"translation": {"code": "public StorageCountersHolder pushStorageCounters ( StorageCountersHolder holder ) { if ( snapshot == null ) return holder ; if ( snapshot . storageCountersHolder == null ) return holder ; if ( holder == null ) holder = new StorageCountersHolder ( ) ; snapshot . storageCountersHolder . pushData ( holder ) ; return holder ; }", "nl": "Takes storage performance data from last snapshot and aggregates them with data passed inside method as parameter . Result of aggregation of performance data is returned inside of passed in performance data and as result of this method call ."}}
{"translation": {"code": "public void stopFullCheckpointTimer ( ) { final long endTs = nanoTimer . getNano ( ) ; final long timeDiff = ( endTs - timeStamps . pop ( ) ) ; if ( storageCountersHolder == null ) storageCountersHolder = new StorageCountersHolder ( ) ; storageCountersHolder . fullCheckpointOperationsCount ++ ; storageCountersHolder . fullCheckpointOperationsTime += timeDiff ; makeSnapshotIfNeeded ( endTs ) ; }", "nl": "Stops and records results of timer which counts how much time was spent on full checkpoint operation ."}}
{"translation": {"code": "public WritCacheCountersHolder pushWriteCacheCounters ( WritCacheCountersHolder holder ) { if ( snapshot == null ) return holder ; if ( snapshot . writCacheCountersHolder == null ) return holder ; if ( holder == null ) holder = new WritCacheCountersHolder ( ) ; snapshot . writCacheCountersHolder . pushData ( holder ) ; return holder ; }", "nl": "Takes write cache performance data from last snapshot and aggregates them with data passed inside method as parameter . Result of aggregation of performance data is returned inside of passed in performance data and as result of this method call ."}}
{"translation": {"code": "private WritCacheCountersHolder fetchWriteCacheCounters ( ) { //go through all threads and accumulate statistic only for live threads //all dead threads will be removed and statistics from them will be //later accumulated in #deadThreadsStatistic field, then result statistic from this field //will be aggregated to countersHolder //To decrease inter thread communication delay we fetch snapshots first //and only after that we aggregate data from immutable snapshots final Collection < ORawPair < Thread , PerformanceSnapshot > > snapshots = new ArrayList <> ( statistics . size ( ) ) ; final Collection < Thread > threadsToRemove = new ArrayList <> ( ) ; for ( Map . Entry < Thread , OSessionStoragePerformanceStatistic > entry : statistics . entrySet ( ) ) { final Thread thread = entry . getKey ( ) ; final OSessionStoragePerformanceStatistic statistic = entry . getValue ( ) ; snapshots . add ( new ORawPair <> ( thread , statistic . getSnapshot ( ) ) ) ; } WritCacheCountersHolder holder = null ; for ( ORawPair < Thread , PerformanceSnapshot > pair : snapshots ) { final Thread thread = pair . getFirst ( ) ; if ( thread . isAlive ( ) ) { final PerformanceSnapshot snapshot = pair . getSecond ( ) ; if ( snapshot . writCacheCountersHolder != null ) { if ( holder == null ) holder = new WritCacheCountersHolder ( ) ; snapshot . writCacheCountersHolder . pushData ( holder ) ; } } else { threadsToRemove . add ( thread ) ; } } if ( ! threadsToRemove . isEmpty ( ) ) { updateDeadThreadsStatistic ( threadsToRemove ) ; } final ImmutableStatistic ds = deadThreadsStatistic ; if ( ds != null ) { final WritCacheCountersHolder wch = ds . writCacheCountersHolder ; if ( wch != null ) { if ( holder == null ) holder = new WritCacheCountersHolder ( ) ; wch . pushData ( holder ) ; } } return holder ; }", "nl": "Iterates over all live threads and accumulates write performance statics gathered form threads also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started ."}}
{"translation": {"code": "public static void checkCacheMemoryConfiguration ( ) { final long maxHeapSize = Runtime . getRuntime ( ) . maxMemory ( ) ; final long maxCacheSize = getMaxCacheMemorySize ( ) ; final ONative . MemoryLimitResult physicalMemory = ONative . instance ( ) . getMemoryLimit ( false ) ; if ( maxHeapSize != Long . MAX_VALUE && physicalMemory != null && maxHeapSize + maxCacheSize > physicalMemory . memoryLimit ) OLogManager . instance ( ) . warnNoDb ( OMemory . class , \"The sum of the configured JVM maximum heap size (\" + maxHeapSize + \" bytes) \" + \"and the OrientDB maximum cache size (\" + maxCacheSize + \" bytes) is larger than the available physical memory size \" + \"(\" + physicalMemory + \" bytes). That may cause out of memory errors, please tune the configuration up. Use the \" + \"-Xmx JVM option to lower the JVM maximum heap memory size or storage.diskCache.bufferSize OrientDB option to \" + \"lower memory requirements of the cache.\" ) ; }", "nl": "Checks the OrientDB cache memory configuration and emits a warning if configuration is invalid ."}}
{"translation": {"code": "public String getStringValue ( ) { if ( value == null ) { return null ; } if ( value . contains ( \"`\" ) ) { return value . replaceAll ( \"\\\\\\\\`\" , \"`\" ) ; } return value ; }", "nl": "returns the plain string representation of this identifier with quoting removed from back - ticks"}}
{"translation": {"code": "@ Override public void memberRemoved ( final MembershipEvent iEvent ) { try { updateLastClusterChange ( ) ; if ( iEvent . getMember ( ) == null ) return ; final String nodeLeftName = getNodeName ( iEvent . getMember ( ) ) ; if ( nodeLeftName == null ) return ; removeServer ( nodeLeftName , true ) ; } catch ( HazelcastInstanceNotActiveException | RetryableHazelcastException e ) { OLogManager . instance ( ) . error ( this , \"Hazelcast is not running\" , e ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Error on removing the server '%s'\" , e , getNodeName ( iEvent . getMember ( ) ) ) ; } }", "nl": "Removes the node map entry ."}}
{"translation": {"code": "public boolean installClustersOfClass ( final ODatabaseInternal iDatabase , final OClass iClass , OModifiableDistributedConfiguration cfg ) { final String databaseName = iDatabase . getName ( ) ; if ( iClass . isAbstract ( ) ) return false ; // INIT THE DATABASE IF NEEDED getMessageService ( ) . registerDatabase ( databaseName , cfg ) ; return executeInDistributedDatabaseLock ( databaseName , 20000 , cfg , new OCallable < Boolean , OModifiableDistributedConfiguration > ( ) { @ Override public Boolean call ( final OModifiableDistributedConfiguration lastCfg ) { final Set < String > availableNodes = getAvailableNodeNames ( iDatabase . getName ( ) ) ; final List < String > cluster2Create = clusterAssignmentStrategy . assignClusterOwnershipOfClass ( iDatabase , lastCfg , iClass , availableNodes , true ) ; final Map < OClass , List < String > > cluster2CreateMap = new HashMap < OClass , List < String > > ( 1 ) ; cluster2CreateMap . put ( iClass , cluster2Create ) ; createClusters ( iDatabase , cluster2CreateMap , lastCfg ) ; return true ; } } ) ; }", "nl": "Guarantees that each class has own master cluster ."}}
{"translation": {"code": "protected void loadLocalDatabases ( ) { final List < String > dbs = new ArrayList < String > ( serverInstance . getAvailableStorageNames ( ) . keySet ( ) ) ; Collections . sort ( dbs ) ; for ( final String databaseName : dbs ) { if ( messageService . getDatabase ( databaseName ) == null ) { ODistributedServerLog . info ( this , nodeName , null , DIRECTION . NONE , \"Opening database '%s'...\" , databaseName ) ; // INIT THE STORAGE final ODistributedStorage stg = getStorage ( databaseName ) ; executeInDistributedDatabaseLock ( databaseName , 60000 , null , new OCallable < Object , OModifiableDistributedConfiguration > ( ) { @ Override public Object call ( OModifiableDistributedConfiguration cfg ) { ODistributedServerLog . info ( this , nodeName , null , DIRECTION . NONE , \"Current node started as %s for database '%s'\" , cfg . getServerRole ( nodeName ) , databaseName ) ; final ODistributedDatabaseImpl ddb = messageService . registerDatabase ( databaseName , cfg ) ; ddb . resume ( ) ; // 1ST NODE TO HAVE THE DATABASE cfg . addNewNodeInServerList ( nodeName ) ; // COLLECT ALL THE CLUSTERS WITH REMOVED NODE AS OWNER reassignClustersOwnership ( nodeName , databaseName , cfg , true ) ; try { ddb . getSyncConfiguration ( ) . setLastLSN ( nodeName , ( ( OAbstractPaginatedStorage ) stg . getUnderlying ( ) ) . getLSN ( ) , false ) ; } catch ( IOException e ) { ODistributedServerLog . error ( this , nodeName , null , DIRECTION . NONE , \"Error on saving distributed LSN for database '%s' (err=%s).\" , databaseName , e . getMessage ( ) ) ; } ddb . setOnline ( ) ; return null ; } } ) ; } } }", "nl": "Initializes all the available server s databases as distributed ."}}
{"translation": {"code": "protected void dumpServersStatus ( ) { final ODocument cfg = getClusterConfiguration ( ) ; final String compactStatus = ODistributedOutput . getCompactServerStatus ( this , cfg ) ; if ( ! lastServerDump . equals ( compactStatus ) ) { lastServerDump = compactStatus ; ODistributedServerLog . info ( this , getLocalNodeName ( ) , null , DIRECTION . NONE , \"Distributed servers status (*=current @=lockmgr[%s]):\\n%s\" , getLockManagerServer ( ) , ODistributedOutput . formatServerStatus ( this , cfg ) ) ; } }", "nl": "Avoids to dump the same configuration twice if it s unchanged since the last time ."}}
{"translation": {"code": "public String authenticate ( final String username , final String password ) { String principal = null ; try { if ( getServer ( ) != null ) { // dbName parameter is null because we don't need to filter any roles for this. OUser user = getServer ( ) . getSecurity ( ) . getSystemUser ( username , null ) ; if ( user != null && user . getAccountStatus ( ) == OSecurityUser . STATUSES . ACTIVE ) { if ( user . checkPassword ( password ) ) principal = username ; } } } catch ( Exception ex ) { OLogManager . instance ( ) . error ( this , \"authenticate()\" , ex ) ; } return principal ; }", "nl": "This will authenticate username using the system database ."}}
{"translation": {"code": "public boolean isAuthorized ( final String username , final String resource ) { if ( username == null || resource == null ) return false ; try { if ( getServer ( ) != null ) { OUser user = getServer ( ) . getSecurity ( ) . getSystemUser ( username , null ) ; if ( user != null && user . getAccountStatus ( ) == OSecurityUser . STATUSES . ACTIVE ) { ORole role = null ; ORule . ResourceGeneric rg = ORule . mapLegacyResourceToGenericResource ( resource ) ; if ( rg != null ) { String specificResource = ORule . mapLegacyResourceToSpecificResource ( resource ) ; if ( specificResource == null || specificResource . equals ( \"*\" ) ) { specificResource = null ; } role = user . checkIfAllowed ( rg , specificResource , ORole . PERMISSION_EXECUTE ) ; } return role != null ; } } } catch ( Exception ex ) { OLogManager . instance ( ) . error ( this , \"isAuthorized()\" , ex ) ; } return false ; }", "nl": "Checks to see if a"}}
{"translation": {"code": "protected ODocument getClusterConfiguration ( String iClusterName ) { final ODocument clusters = getConfiguredClusters ( ) ; if ( iClusterName == null ) iClusterName = ALL_WILDCARD ; final ODocument cfg ; if ( ! clusters . containsField ( iClusterName ) ) // NO CLUSTER IN CFG: GET THE DEFAULT ONE cfg = clusters . field ( ALL_WILDCARD ) ; else // GET THE CLUSTER CFG cfg = clusters . field ( iClusterName ) ; if ( cfg == null ) return new ODocument ( ) ; return cfg ; }", "nl": "Gets the document representing the cluster configuration ."}}
{"translation": {"code": "public void createCluster ( final String className , final String clusterName ) { final ODatabaseDocumentInternal currentDB = ODatabaseRecordThreadLocal . instance ( ) . getIfDefined ( ) ; try { final ODatabaseDocumentInternal sysdb = openSystemDatabase ( ) ; try { if ( ! sysdb . existsCluster ( clusterName ) ) { OSchema schema = sysdb . getMetadata ( ) . getSchema ( ) ; OClass cls = schema . getClass ( className ) ; if ( cls != null ) { cls . addCluster ( clusterName ) ; } else { OLogManager . instance ( ) . error ( this , \"createCluster() Class name %s does not exist\" , null , className ) ; } } } finally { sysdb . close ( ) ; } } finally { if ( currentDB != null ) ODatabaseRecordThreadLocal . instance ( ) . set ( currentDB ) ; else ODatabaseRecordThreadLocal . instance ( ) . remove ( ) ; } }", "nl": "Adds the specified cluster to the class if it doesn t already exist ."}}
{"translation": {"code": "public static String getCompactServerStatus ( final ODistributedServerManager manager , final ODocument distribCfg ) { final StringBuilder buffer = new StringBuilder ( ) ; final Collection < ODocument > members = distribCfg . field ( \"members\" ) ; if ( members != null ) { buffer . append ( members . size ( ) ) ; buffer . append ( \":[\" ) ; int memberCount = 0 ; for ( ODocument m : members ) { if ( m == null ) continue ; if ( memberCount ++ > 0 ) buffer . append ( \",\" ) ; final String serverName = m . field ( \"name\" ) ; buffer . append ( serverName ) ; buffer . append ( ( Object ) m . field ( \"status\" ) ) ; final Collection < String > databases = m . field ( \"databases\" ) ; if ( databases != null ) { buffer . append ( \"{\" ) ; int dbCount = 0 ; for ( String dbName : databases ) { final ODistributedConfiguration dbCfg = manager . getDatabaseConfiguration ( dbName , false ) ; if ( dbCfg == null ) continue ; if ( dbCount ++ > 0 ) buffer . append ( \",\" ) ; buffer . append ( dbName ) ; buffer . append ( \"=\" ) ; buffer . append ( manager . getDatabaseStatus ( serverName , dbName ) ) ; buffer . append ( \" (\" ) ; buffer . append ( dbCfg . getServerRole ( serverName ) ) ; buffer . append ( \")\" ) ; } buffer . append ( \"}\" ) ; } } buffer . append ( \"]\" ) ; } return buffer . toString ( ) ; }", "nl": "Create a compact string with all the relevant information ."}}
{"translation": {"code": "public ODatabaseDocumentInternal copy ( ) { ODatabaseDocumentEmbedded database = new ODatabaseDocumentEmbedded ( getSharedContext ( ) . getStorage ( ) ) ; database . init ( config , this . sharedContext ) ; String user ; if ( getUser ( ) != null ) { user = getUser ( ) . getName ( ) ; } else { user = null ; } database . internalOpen ( user , null , false ) ; database . callOnOpenListeners ( ) ; this . activateOnCurrentThread ( ) ; return database ; }", "nl": "Returns a copy of current database if it s open . The returned instance can be used by another thread without affecting current instance . The database copy is not set in thread local ."}}
{"translation": {"code": "public OClosableEntry < K , V > acquire ( K key ) throws InterruptedException { checkOpenFilesLimit ( ) ; final OClosableEntry < K , V > entry = data . get ( key ) ; if ( entry == null ) return null ; boolean logOpen = false ; entry . acquireStateLock ( ) ; try { if ( entry . isRetired ( ) || entry . isDead ( ) ) { return null ; } else if ( entry . isClosed ( ) ) { entry . makeAcquiredFromClosed ( entry . get ( ) ) ; logOpen = true ; } else if ( entry . isOpen ( ) ) { entry . makeAcquiredFromOpen ( ) ; } else { entry . incrementAcquired ( ) ; } } finally { entry . releaseStateLock ( ) ; } if ( logOpen ) { logOpen ( entry ) ; } else { logAcquire ( entry ) ; } assert entry . get ( ) . isOpen ( ) ; return entry ; }", "nl": "Acquires item associated with passed in key in container . It is guarantied that item will not be closed if limit of open items will be exceeded and container will close rarely used items ."}}
{"translation": {"code": "private static int closestPowerOfTwo ( int value ) { int n = value - 1 ; n |= n >>> 1 ; n |= n >>> 2 ; n |= n >>> 4 ; n |= n >>> 8 ; n |= n >>> 16 ; return ( n < 0 ) ? 1 : ( n >= ( 1 << 30 ) ) ? 1 << 30 : n + 1 ; }", "nl": "Finds closest power of two for given integer value . Idea is simple duplicate the most significant bit to the lowest bits for the smallest number of iterations possible and then increment result value by 1 ."}}
{"translation": {"code": "public V remove ( K key ) { final OClosableEntry < K , V > removed = data . remove ( key ) ; if ( removed != null ) { long preStatus = removed . makeRetired ( ) ; if ( OClosableEntry . isOpen ( preStatus ) ) { countClosedFiles ( ) ; } logRemoved ( removed ) ; return removed . get ( ) ; } return null ; }", "nl": "Removes item associated with passed in key ."}}
{"translation": {"code": "private void afterWrite ( Runnable task ) { stateBuffer . add ( task ) ; drainStatus . lazySet ( DrainStatus . REQUIRED ) ; tryToDrainBuffers ( ) ; }", "nl": "Method is used to log operations which change content of the container . Such changes should be flushed immediately to update content of LRU list ."}}
{"translation": {"code": "private long putEntryInReadBuffer ( OClosableEntry < K , V > entry , int bufferIndex ) { //next index to write for this buffer AtomicLong writeCounter = readBufferWriteCount [ bufferIndex ] ; final long counter = writeCounter . get ( ) ; //we do not use CAS operations to limit contention between threads //it is normal that because of duplications of indexes some of items will be lost writeCounter . lazySet ( counter + 1 ) ; final AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ bufferIndex ] ; AtomicReference < OClosableEntry < K , V > > bufferEntry = buffer [ ( int ) ( counter & READ_BUFFER_INDEX_MASK ) ] ; bufferEntry . lazySet ( entry ) ; return counter + 1 ; }", "nl": "Adds entry to the read buffer with selected index and returns amount of writes to this buffer since creation of this container ."}}
{"translation": {"code": "private void afterRead ( OClosableEntry < K , V > entry ) { final int bufferIndex = readBufferIndex ( ) ; final long writeCount = putEntryInReadBuffer ( entry , bufferIndex ) ; drainReadBuffersIfNeeded ( bufferIndex , writeCount ) ; }", "nl": "Method is used to log operations which do not change LRU list content but affect order of items inside of LRU list . Such changes may be delayed till buffer will be full ."}}
{"translation": {"code": "private void emptyReadBuffers ( ) { for ( int n = 0 ; n < NUMBER_OF_READ_BUFFERS ; n ++ ) { AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ n ] ; long writeCount = readBufferDrainAtWriteCount [ n ] . get ( ) ; long counter = readBufferReadCount [ n ] ; while ( true ) { final int bufferIndex = ( int ) ( counter & READ_BUFFER_INDEX_MASK ) ; final AtomicReference < OClosableEntry < K , V > > eref = buffer [ bufferIndex ] ; final OClosableEntry < K , V > entry = eref . get ( ) ; if ( entry == null ) break ; applyRead ( entry ) ; counter ++ ; eref . lazySet ( null ) ; } readBufferReadCount [ n ] = counter ; readBufferDrainAtWriteCount [ n ] . lazySet ( writeCount ) ; } }", "nl": "Read content of all read buffers and reorder elements inside of LRU list to update internal statistic . Method has to be wrapped by LRU lock ."}}
{"translation": {"code": "public boolean close ( K key ) { emptyBuffers ( ) ; final OClosableEntry < K , V > entry = data . get ( key ) ; if ( entry == null ) return true ; if ( entry . makeClosed ( ) ) { countClosedFiles ( ) ; return true ; } return false ; }", "nl": "Closes item related to passed in key . Item will be closed if it exists and is not acquired ."}}
{"translation": {"code": "public void clear ( ) { lruLock . lock ( ) ; try { data . clear ( ) ; openFiles . set ( 0 ) ; for ( int n = 0 ; n < NUMBER_OF_READ_BUFFERS ; n ++ ) { final AtomicReference < OClosableEntry < K , V > > [ ] buffer = readBuffers [ n ] ; for ( int i = 0 ; i < READ_BUFFER_SIZE ; i ++ ) { buffer [ i ] . set ( null ) ; } readBufferReadCount [ n ] = 0 ; readBufferWriteCount [ n ] . set ( 0 ) ; readBufferDrainAtWriteCount [ n ] . set ( 0 ) ; } stateBuffer . clear ( ) ; while ( lruList . poll ( ) != null ) ; } finally { lruLock . unlock ( ) ; } }", "nl": "Clears all content ."}}
{"translation": {"code": "public void add ( K key , V item ) throws InterruptedException { if ( ! item . isOpen ( ) ) throw new IllegalArgumentException ( \"All passed in items should be in open state\" ) ; checkOpenFilesLimit ( ) ; final OClosableEntry < K , V > closableEntry = new OClosableEntry < K , V > ( item ) ; final OClosableEntry < K , V > oldEntry = data . putIfAbsent ( key , closableEntry ) ; if ( oldEntry != null ) { throw new IllegalStateException ( \"Item with key \" + key + \" already exists\" ) ; } logAdd ( closableEntry ) ; }", "nl": "Adds item to the container . Item should be in open state ."}}
{"translation": {"code": "public V get ( K key ) { final OClosableEntry < K , V > entry = data . get ( key ) ; if ( entry != null ) return entry . get ( ) ; return null ; }", "nl": "Returns item without acquiring it . State of item is not guarantied in such case ."}}
{"translation": {"code": "public boolean isServerContainingAllClusters ( final String server , Collection < String > clusters ) { if ( clusters == null || clusters . isEmpty ( ) ) clusters = DEFAULT_CLUSTER_NAME ; for ( String cluster : clusters ) { final List < String > serverList = getClusterConfiguration ( cluster ) . field ( SERVERS ) ; if ( serverList != null ) { if ( ! serverList . contains ( server ) ) return false ; } } return true ; }", "nl": "Returns true if the local server has all the requested clusters ."}}
{"translation": {"code": "public Set < String > getDataCenters ( ) { final ODocument dcs = configuration . field ( DCS ) ; if ( dcs == null ) return Collections . EMPTY_SET ; final Set < String > result = new HashSet < String > ( ) ; for ( String dc : dcs . fieldNames ( ) ) { result . add ( dc ) ; } return result ; }", "nl": "Returns all the configured data centers names if any ."}}
{"translation": {"code": "public int getDataCenterWriteQuorum ( final String dataCenter ) { final ODocument dc = getDataCenterConfiguration ( dataCenter ) ; Object wq = dc . field ( WRITE_QUORUM ) ; if ( wq instanceof String ) { if ( wq . toString ( ) . equalsIgnoreCase ( ODistributedConfiguration . QUORUM_MAJORITY ) ) { final List < String > servers = dc . field ( SERVERS ) ; wq = servers . size ( ) / 2 + 1 ; } else if ( wq . toString ( ) . equalsIgnoreCase ( ODistributedConfiguration . QUORUM_ALL ) ) { final List < String > servers = dc . field ( SERVERS ) ; wq = servers . size ( ) ; } } return ( Integer ) wq ; }", "nl": "Returns the data center write quorum ."}}
{"translation": {"code": "public List < String > getDataCenterServers ( final String dataCenter ) { final ODocument dc = getDataCenterConfiguration ( dataCenter ) ; final List < String > servers = dc . field ( SERVERS ) ; if ( servers == null || servers . isEmpty ( ) ) throw new OConfigurationException ( \"Data center '\" + dataCenter + \"' does not contain any server in distributed database configuration\" ) ; return new ArrayList < String > ( servers ) ; }", "nl": "Returns the list of servers in a data center ."}}
{"translation": {"code": "public String getDataCenterOfServer ( final String server ) { final ODocument dcs = configuration . field ( DCS ) ; if ( dcs != null ) { for ( String dc : dcs . fieldNames ( ) ) { final ODocument dcConfig = dcs . field ( dc ) ; if ( dcConfig != null ) { final List < String > dcServers = dcConfig . field ( \"servers\" ) ; if ( dcServers != null && ! dcServers . isEmpty ( ) ) { if ( dcServers . contains ( server ) ) // FOUND return dc ; } } } } // NOT FOUND return null ; }", "nl": "Returns the data center where the server belongs ."}}
{"translation": {"code": "public Object getGlobalReadQuorum ( final String iClusterName ) { Object value = getClusterConfiguration ( iClusterName ) . field ( READ_QUORUM ) ; if ( value == null ) value = configuration . field ( READ_QUORUM ) ; return value ; }", "nl": "Returns the global read quorum ."}}
{"translation": {"code": "private ODocument getDataCenterConfiguration ( final String dataCenter ) { final ODocument dcs = configuration . field ( DCS ) ; if ( dcs != null ) return dcs . field ( dataCenter ) ; throw new OConfigurationException ( \"Cannot find the data center '\" + dataCenter + \"' in distributed database configuration\" ) ; }", "nl": "Gets the document representing the dc configuration ."}}
{"translation": {"code": "@ Override public void removeBackgroundExceptionListener ( final OBackgroundExceptionListener listener ) { final List < WeakReference < OBackgroundExceptionListener > > itemsToRemove = new ArrayList <> ( 1 ) ; for ( final WeakReference < OBackgroundExceptionListener > ref : backgroundExceptionListeners ) { final OBackgroundExceptionListener l = ref . get ( ) ; if ( l != null && l . equals ( listener ) ) { itemsToRemove . add ( ref ) ; } } backgroundExceptionListeners . removeAll ( itemsToRemove ) ; }", "nl": "Removes listener which is triggered if exception is cast inside background flush data thread ."}}
{"translation": {"code": "private void fireBackgroundDataFlushExceptionEvent ( final Throwable e ) { for ( final WeakReference < OBackgroundExceptionListener > ref : backgroundExceptionListeners ) { final OBackgroundExceptionListener listener = ref . get ( ) ; if ( listener != null ) { listener . onException ( e ) ; } } }", "nl": "Fires event about exception is thrown in data flush thread"}}
{"translation": {"code": "private static void extractSubQueries ( QueryPlanningInfo info ) { SubQueryCollector collector = new SubQueryCollector ( ) ; if ( info . perRecordLetClause != null ) { info . perRecordLetClause . extractSubQueries ( collector ) ; } int i = 0 ; int j = 0 ; for ( Map . Entry < OIdentifier , OStatement > entry : collector . getSubQueries ( ) . entrySet ( ) ) { OIdentifier alias = entry . getKey ( ) ; OStatement query = entry . getValue ( ) ; if ( query . refersToParent ( ) ) { addRecordLevelLet ( info , alias , query , j ++ ) ; } else { addGlobalLet ( info , alias , query , i ++ ) ; } } collector . reset ( ) ; if ( info . whereClause != null ) { info . whereClause . extractSubQueries ( collector ) ; } if ( info . projection != null ) { info . projection . extractSubQueries ( collector ) ; } if ( info . orderBy != null ) { info . orderBy . extractSubQueries ( collector ) ; } if ( info . groupBy != null ) { info . groupBy . extractSubQueries ( collector ) ; } for ( Map . Entry < OIdentifier , OStatement > entry : collector . getSubQueries ( ) . entrySet ( ) ) { OIdentifier alias = entry . getKey ( ) ; OStatement query = entry . getValue ( ) ; if ( query . refersToParent ( ) ) { addRecordLevelLet ( info , alias , query ) ; } else { addGlobalLet ( info , alias , query ) ; } } }", "nl": "translates subqueries to LET statements"}}
{"translation": {"code": "public boolean isServerContainingCluster ( final String server , String cluster ) { if ( cluster == null ) cluster = ALL_WILDCARD ; final List < String > serverList = getClusterConfiguration ( cluster ) . field ( SERVERS ) ; if ( serverList != null ) { return serverList . contains ( server ) ; } return true ; }", "nl": "Returns true if the local server has the requested cluster ."}}
{"translation": {"code": "public OProjectionItem splitForAggregation ( AggregateProjectionSplit aggregateSplit , OCommandContext ctx ) { if ( isAggregate ( ) ) { OProjectionItem result = new OProjectionItem ( - 1 ) ; result . alias = getProjectionAlias ( ) ; result . expression = expression . splitForAggregation ( aggregateSplit , ctx ) ; result . nestedProjection = nestedProjection ; return result ; } else { return this ; } }", "nl": "INTERNAL USE ONLY this has to be invoked ONLY if the item is aggregate!!!"}}
{"translation": {"code": "public Object setProperty ( final String iName , final Object iValue ) { if ( iValue != null ) { return properties . put ( iName . toLowerCase ( Locale . ENGLISH ) , iValue ) ; } else { return properties . remove ( iName . toLowerCase ( Locale . ENGLISH ) ) ; } }", "nl": "Sets a property value"}}
{"translation": {"code": "public Object getProperty ( final String iName ) { return properties . get ( iName . toLowerCase ( Locale . ENGLISH ) ) ; }", "nl": "Gets the property value ."}}
{"translation": {"code": "public boolean isSharded ( ) { final ODocument allCluster = getClusterConfiguration ( ALL_WILDCARD ) ; if ( allCluster != null ) { final List < String > allServers = allCluster . field ( SERVERS ) ; if ( allServers != null && ! allServers . isEmpty ( ) ) { for ( String cl : getClusterNames ( ) ) { final List < String > servers = getServers ( cl , null ) ; if ( servers != null && ! servers . isEmpty ( ) && ! allServers . containsAll ( servers ) ) return false ; } } } return false ; }", "nl": "Returns true if the database is sharded across servers . False if it s completely replicated ."}}
{"translation": {"code": "private List < IndexSearchDescriptor > commonFactor ( List < IndexSearchDescriptor > indexSearchDescriptors ) { //index, key condition, additional filter (to aggregate in OR) Map < OIndex , Map < IndexCondPair , OOrBlock > > aggregation = new HashMap <> ( ) ; for ( IndexSearchDescriptor item : indexSearchDescriptors ) { Map < IndexCondPair , OOrBlock > filtersForIndex = aggregation . get ( item . idx ) ; if ( filtersForIndex == null ) { filtersForIndex = new HashMap <> ( ) ; aggregation . put ( item . idx , filtersForIndex ) ; } IndexCondPair extendedCond = new IndexCondPair ( item . keyCondition , item . additionalRangeCondition ) ; OOrBlock existingAdditionalConditions = filtersForIndex . get ( extendedCond ) ; if ( existingAdditionalConditions == null ) { existingAdditionalConditions = new OOrBlock ( - 1 ) ; filtersForIndex . put ( extendedCond , existingAdditionalConditions ) ; } existingAdditionalConditions . getSubBlocks ( ) . add ( item . remainingCondition ) ; } List < IndexSearchDescriptor > result = new ArrayList <> ( ) ; for ( Map . Entry < OIndex , Map < IndexCondPair , OOrBlock > > item : aggregation . entrySet ( ) ) { for ( Map . Entry < IndexCondPair , OOrBlock > filters : item . getValue ( ) . entrySet ( ) ) { result . add ( new IndexSearchDescriptor ( item . getKey ( ) , filters . getKey ( ) . mainCondition , filters . getKey ( ) . additionalRange , filters . getValue ( ) ) ) ; } } return result ; }", "nl": "aggregates multiple index conditions that refer to the same key search"}}
{"translation": {"code": "private static void addOrderByProjections ( QueryPlanningInfo info ) { if ( info . orderApplied || info . expand || info . unwind != null || info . orderBy == null || info . orderBy . getItems ( ) . size ( ) == 0 || info . projection == null || info . projection . getItems ( ) == null || ( info . projection . getItems ( ) . size ( ) == 1 && info . projection . getItems ( ) . get ( 0 ) . isAll ( ) ) ) { return ; } OOrderBy newOrderBy = info . orderBy == null ? null : info . orderBy . copy ( ) ; List < OProjectionItem > additionalOrderByProjections = calculateAdditionalOrderByProjections ( info . projection . getAllAliases ( ) , newOrderBy ) ; if ( additionalOrderByProjections . size ( ) > 0 ) { info . orderBy = newOrderBy ; //the ORDER BY has changed } if ( additionalOrderByProjections . size ( ) > 0 ) { info . projectionAfterOrderBy = new OProjection ( - 1 ) ; info . projectionAfterOrderBy . setItems ( new ArrayList <> ( ) ) ; for ( String alias : info . projection . getAllAliases ( ) ) { info . projectionAfterOrderBy . getItems ( ) . add ( projectionFromAlias ( new OIdentifier ( alias ) ) ) ; } for ( OProjectionItem item : additionalOrderByProjections ) { if ( info . preAggregateProjection != null ) { info . preAggregateProjection . getItems ( ) . add ( item ) ; info . aggregateProjection . getItems ( ) . add ( projectionFromAlias ( item . getAlias ( ) ) ) ; info . projection . getItems ( ) . add ( projectionFromAlias ( item . getAlias ( ) ) ) ; } else { info . projection . getItems ( ) . add ( item ) ; } } } }", "nl": "creates additional projections for ORDER BY"}}
{"translation": {"code": "private static List < OAndBlock > moveFlattededEqualitiesLeft ( List < OAndBlock > flattenedWhereClause ) { if ( flattenedWhereClause == null ) { return null ; } List < OAndBlock > result = new ArrayList <> ( ) ; for ( OAndBlock block : flattenedWhereClause ) { List < OBooleanExpression > equalityExpressions = new ArrayList <> ( ) ; List < OBooleanExpression > nonEqualityExpressions = new ArrayList <> ( ) ; OAndBlock newBlock = block . copy ( ) ; for ( OBooleanExpression exp : newBlock . getSubBlocks ( ) ) { if ( exp instanceof OBinaryCondition ) { if ( ( ( OBinaryCondition ) exp ) . getOperator ( ) instanceof OEqualsCompareOperator ) { equalityExpressions . add ( exp ) ; } else { nonEqualityExpressions . add ( exp ) ; } } else { nonEqualityExpressions . add ( exp ) ; } } OAndBlock newAnd = new OAndBlock ( - 1 ) ; newAnd . getSubBlocks ( ) . addAll ( equalityExpressions ) ; newAnd . getSubBlocks ( ) . addAll ( nonEqualityExpressions ) ; result . add ( newAnd ) ; } return result ; }", "nl": "re - writes a list of flat AND conditions moving left all the equality operations"}}
{"translation": {"code": "private boolean isDiamondHierarchy ( OClass clazz ) { Set < OClass > traversed = new HashSet <> ( ) ; List < OClass > stack = new ArrayList <> ( ) ; stack . add ( clazz ) ; while ( ! stack . isEmpty ( ) ) { OClass current = stack . remove ( 0 ) ; traversed . add ( current ) ; for ( OClass sub : current . getSubclasses ( ) ) { if ( traversed . contains ( sub ) ) { return true ; } stack . add ( sub ) ; traversed . add ( sub ) ; } } return false ; }", "nl": "checks if a class is the top of a diamond hierarchy"}}
{"translation": {"code": "private Boolean getOrderDirection ( QueryPlanningInfo info ) { if ( info . orderBy == null ) { return null ; } String result = null ; for ( OOrderByItem item : info . orderBy . getItems ( ) ) { if ( result == null ) { result = item . getType ( ) == null ? OOrderByItem . ASC : item . getType ( ) ; } else { String newType = item . getType ( ) == null ? OOrderByItem . ASC : item . getType ( ) ; if ( ! newType . equals ( result ) ) { return null ; } } } return result == null || result . equals ( OOrderByItem . ASC ) ; }", "nl": "returns TRUE if all the order clauses are ASC FALSE if all are DESC null otherwise"}}
{"translation": {"code": "private boolean handleClassWithIndexForSortOnly ( OSelectExecutionPlan plan , OIdentifier queryTarget , Set < String > filterClusters , QueryPlanningInfo info , OCommandContext ctx , boolean profilingEnabled ) { OSchema schema = getSchemaFromContext ( ctx ) ; OClass clazz = schema . getClass ( queryTarget . getStringValue ( ) ) ; if ( clazz == null ) { clazz = schema . getView ( queryTarget . getStringValue ( ) ) ; if ( clazz == null ) { throw new OCommandExecutionException ( \"Class not found: \" + queryTarget ) ; } } for ( OIndex idx : clazz . getIndexes ( ) . stream ( ) . filter ( i -> i . supportsOrderedIterations ( ) ) . filter ( i -> i . getDefinition ( ) != null ) . collect ( Collectors . toList ( ) ) ) { List < String > indexFields = idx . getDefinition ( ) . getFields ( ) ; if ( indexFields . size ( ) < info . orderBy . getItems ( ) . size ( ) ) { continue ; } boolean indexFound = true ; String orderType = null ; for ( int i = 0 ; i < info . orderBy . getItems ( ) . size ( ) ; i ++ ) { OOrderByItem orderItem = info . orderBy . getItems ( ) . get ( i ) ; if ( orderItem . getCollate ( ) != null ) { return false ; } String indexField = indexFields . get ( i ) ; if ( i == 0 ) { orderType = orderItem . getType ( ) ; } else { if ( orderType == null || ! orderType . equals ( orderItem . getType ( ) ) ) { indexFound = false ; break ; //ASC/DESC interleaved, cannot be used with index. } } if ( ! ( indexField . equals ( orderItem . getAlias ( ) ) || isInOriginalProjection ( indexField , orderItem . getAlias ( ) ) ) ) { indexFound = false ; break ; } } if ( indexFound && orderType != null ) { plan . chain ( new FetchFromIndexValuesStep ( idx , orderType . equals ( OOrderByItem . ASC ) , ctx , profilingEnabled ) ) ; int [ ] filterClusterIds = null ; if ( filterClusters != null ) { filterClusterIds = filterClusters . stream ( ) . map ( name -> ctx . getDatabase ( ) . getClusterIdByName ( name ) ) . mapToInt ( i -> i ) . toArray ( ) ; } plan . chain ( new GetValueFromIndexEntryStep ( ctx , filterClusterIds , profilingEnabled ) ) ; if ( info . serverToClusters . size ( ) == 1 ) { info . orderApplied = true ; } return true ; } } return false ; }", "nl": "tries to use an index for sorting only . Also adds the fetch step to the execution plan"}}
{"translation": {"code": "public boolean allowsIndexedFunctionExecutionOnTarget ( OFromClause target , OCommandContext context , OBinaryCompareOperator operator , Object right ) { if ( this . childExpressions . size ( ) != 1 ) { return false ; } return this . childExpressions . get ( 0 ) . allowsIndexedFunctionExecutionOnTarget ( target , context , operator , right ) ; }", "nl": "tests if current expression is an indexed function AND that function can be used on this target"}}
{"translation": {"code": "public boolean canExecuteIndexedFunctionWithoutIndex ( OFromClause target , OCommandContext context , OBinaryCompareOperator operator , Object right ) { if ( this . identifier == null ) { return false ; } return identifier . canExecuteIndexedFunctionWithoutIndex ( target , context , operator , right ) ; }", "nl": "tests if current expression is an indexed funciton AND that function can also be executed without using the index"}}
{"translation": {"code": "public boolean allowsIndexedFunctionExecutionOnTarget ( OFromClause target , OCommandContext context ) { return left . allowsIndexedFunctionExecutionOnTarget ( target , context , operator , right . execute ( ( OResult ) null , context ) ) ; }", "nl": "tests if current expression involves an indexed function AND that function can be used on this target"}}
{"translation": {"code": "public boolean canExecuteIndexedFunctionWithoutIndex ( OFromClause target , OCommandContext context , OBinaryCompareOperator operator , Object right ) { OSQLFunction function = OSQLEngine . getInstance ( ) . getFunction ( name . getStringValue ( ) ) ; if ( function instanceof OIndexableSQLFunction ) { return ( ( OIndexableSQLFunction ) function ) . canExecuteInline ( target , operator , right , context , this . getParams ( ) . toArray ( new OExpression [ ] { } ) ) ; } return false ; }", "nl": "tests if current function is an indexed function AND that function can also be executed without using the index"}}
{"translation": {"code": "@ Override public int [ ] getPartitionKey ( ) { if ( tasks . size ( ) == 1 ) // ONE TASK, USE THE INNER TASK'S PARTITION KEY return tasks . get ( 0 ) . getPartitionKey ( ) ; // MULTIPLE PARTITIONS final int [ ] partitions = new int [ tasks . size ( ) ] ; for ( int i = 0 ; i < tasks . size ( ) ; ++ i ) { final OAbstractRecordReplicatedTask task = tasks . get ( i ) ; partitions [ i ] = task . getPartitionKey ( ) [ 0 ] ; } return partitions ; }", "nl": "Return the partition keys of all the sub - tasks ."}}
{"translation": {"code": "@ Override public long getDistributedTimeout ( ) { final long to = OGlobalConfiguration . DISTRIBUTED_CRUD_TASK_SYNCH_TIMEOUT . getValueAsLong ( ) ; return to + ( ( to / 2 ) * tasks . size ( ) ) ; }", "nl": "Computes the timeout according to the transaction size ."}}
{"translation": {"code": "long getNextPosition ( final OAtomicOperation atomicOperation ) throws IOException { final long filledUpTo = getFilledUpTo ( atomicOperation , fileId ) ; final long pageIndex = filledUpTo - 1 ; final OCacheEntry cacheEntry = loadPageForRead ( atomicOperation , fileId , pageIndex , false , 1 ) ; try { final OClusterPositionMapBucket bucket = new OClusterPositionMapBucket ( cacheEntry , false ) ; final int bucketSize = bucket . getSize ( ) ; return pageIndex * OClusterPositionMapBucket . MAX_ENTRIES + bucketSize ; } finally { releasePageFromRead ( atomicOperation , cacheEntry ) ; } }", "nl": "Returns the next position available ."}}
{"translation": {"code": "public void checkMemoryLeaks ( ) { boolean detected = false ; if ( TRACK ) { for ( Map . Entry < OPointer , PointerTracker > entry : pointerMapping . entrySet ( ) ) { OLogManager . instance ( ) . errorNoDb ( this , \"DIRECT-TRACK: unreleased direct memory pointer `%X` detected.\" , entry . getValue ( ) . allocation , System . identityHashCode ( entry . getKey ( ) ) ) ; detected = true ; } } assert ! detected ; }", "nl": "Checks whether there are not released buffers in the pool"}}
{"translation": {"code": "public void clear ( ) { for ( OPointer pointer : pointersPool ) { allocator . deallocate ( pointer ) ; } pointersPool . clear ( ) ; pointersPoolSize . set ( 0 ) ; for ( OPointer pointer : pointerMapping . keySet ( ) ) { allocator . deallocate ( pointer ) ; } pointerMapping . clear ( ) ; }", "nl": "Clears pool and dealocates memory ."}}
{"translation": {"code": "public void shutdown ( ) { if ( shutdownFlag . compareAndSet ( false , true ) ) { try { if ( LogManager . getLogManager ( ) instanceof ShutdownLogManager ) ( ( ShutdownLogManager ) LogManager . getLogManager ( ) ) . shutdown ( ) ; } catch ( NoClassDefFoundError ignore ) { // Om nom nom. Some custom class loaders, like Tomcat's one, cannot load classes while in shutdown hooks, since their // runtime is already shutdown. Ignoring the exception, if ShutdownLogManager is not loaded at this point there are no instances // of it anyway and we have nothing to shutdown. } } }", "nl": "Shutdowns this log manager ."}}
{"translation": {"code": "@ Override public void run ( ) { if ( server != null ) if ( ! server . shutdown ( ) ) { // ALREADY IN SHUTDOWN, WAIT FOR 5 SEC MORE\r try { Thread . sleep ( 5000 ) ; } catch ( InterruptedException e ) { } } }", "nl": "Catch the JVM exit and assure to shutdown the Orient Server ."}}
{"translation": {"code": "private OClass getIndexClass ( OCommandContext ctx ) { if ( className == null ) { return null ; } OClass result = ctx . getDatabase ( ) . getMetadata ( ) . getSchema ( ) . getClass ( className . getStringValue ( ) ) ; if ( result == null ) { throw new OCommandExecutionException ( \"Cannot find class \" + className ) ; } return result ; }", "nl": "calculates the indexed class based on the class name"}}
{"translation": {"code": "public static ObjectNode objectNodeFromElement ( final Element element , final Set < String > propertyKeys , final GraphSONMode mode ) { final OGraphSONUtility graphson = element instanceof Edge ? new OGraphSONUtility ( mode , null , null , propertyKeys ) : new OGraphSONUtility ( mode , null , propertyKeys , null ) ; return graphson . objectNodeFromElement ( element ) ; }", "nl": "Creates a Jackson ObjectNode from a graph element ."}}
{"translation": {"code": "public static JSONObject jsonFromElement ( final Element element , final Set < String > propertyKeys , final GraphSONMode mode ) throws JSONException { final OGraphSONUtility graphson = element instanceof Edge ? new OGraphSONUtility ( mode , null , null , propertyKeys ) : new OGraphSONUtility ( mode , null , propertyKeys , null ) ; return graphson . jsonFromElement ( element ) ; }", "nl": "Creates a Jettison JSONObject from a graph element ."}}
{"translation": {"code": "public static Vertex vertexFromJson ( final JSONObject json , final ElementFactory factory , final GraphSONMode mode , final Set < String > propertyKeys ) throws IOException { final OGraphSONUtility graphson = new OGraphSONUtility ( mode , factory , propertyKeys , null ) ; return graphson . vertexFromJson ( json ) ; }", "nl": "Reads an individual Vertex from JSON . The vertex must match the accepted GraphSON format ."}}
{"translation": {"code": "public static Edge edgeFromJson ( final JSONObject json , final Vertex out , final Vertex in , final ElementFactory factory , final GraphSONMode mode , final Set < String > propertyKeys ) throws IOException { final OGraphSONUtility graphson = new OGraphSONUtility ( mode , factory , null , propertyKeys ) ; return graphson . edgeFromJson ( json , out , in ) ; }", "nl": "Reads an individual Edge from JSON . The edge must match the accepted GraphSON format ."}}
{"translation": {"code": "protected OType deriveFieldType ( ODocument iRecord , String fieldName , OType requestedFieldType ) { // Schema defined types can not be ignored if ( iRecord . getSchemaClass ( ) . existsProperty ( fieldName ) ) { return iRecord . getSchemaClass ( ) . getProperty ( fieldName ) . getType ( ) ; } // New type if ( requestedFieldType != null ) { return requestedFieldType ; } // Existing type (not fixed by the schema) return iRecord . fieldType ( fieldName ) ; }", "nl": "Derives the type of a field in a document ."}}
{"translation": {"code": "public OExecutionStepInternal executeUntilReturn ( ) { if ( steps . size ( ) > 0 ) { lastStep = steps . get ( steps . size ( ) - 1 ) ; } for ( int i = 0 ; i < steps . size ( ) - 1 ; i ++ ) { ScriptLineStep step = steps . get ( i ) ; if ( step . containsReturn ( ) ) { OExecutionStepInternal returnStep = step . executeUntilReturn ( ctx ) ; if ( returnStep != null ) { lastStep = returnStep ; return lastStep ; } } OResultSet lastResult = step . syncPull ( ctx , 100 ) ; while ( lastResult . hasNext ( ) ) { while ( lastResult . hasNext ( ) ) { lastResult . next ( ) ; } lastResult = step . syncPull ( ctx , 100 ) ; } } this . lastStep = steps . get ( steps . size ( ) - 1 ) ; return lastStep ; }", "nl": "executes all the script and returns last statement execution step so that it can be executed from outside"}}
{"translation": {"code": "public ODocumentFieldHandlingStrategy create ( int strategy ) { Optional < ODocumentFieldHandlingStrategy > registered = ODocumentFieldHandlingStrategyRegistry . getInstance ( ) . getStrategy ( strategy ) ; if ( registered . isPresent ( ) ) { return registered . get ( ) ; } Map < OType , ODocumentFieldOTypeHandlingStrategy > typeHandlingStrategies = new HashMap < OType , ODocumentFieldOTypeHandlingStrategy > ( ) ; switch ( strategy ) { case SINGLE_ORECORD_BYTES : typeHandlingStrategies . put ( OType . BINARY , new ODocumentSingleRecordBytesOTypeHandlingStrategy ( ) ) ; break ; case SPLIT_ORECORD_BYTES : typeHandlingStrategies . put ( OType . BINARY , new ODocumentSplitRecordBytesOTypeHandlingStrategy ( ) ) ; break ; case SIMPLE : default : break ; } ODocumentSmartFieldHandlingStrategy strategyInstance = new ODocumentSmartFieldHandlingStrategy ( typeHandlingStrategies ) ; ODocumentFieldHandlingStrategyRegistry . getInstance ( ) . registerStrategy ( strategy , strategyInstance ) ; return strategyInstance ; }", "nl": "Creates a new instance of the requested strategy . Since strategies are stateless if an existing instance already exists then it s returned ."}}
{"translation": {"code": "public List < Pattern > getDisjointPatterns ( ) { Map < PatternNode , String > reverseMap = new IdentityHashMap <> ( ) ; reverseMap . putAll ( this . aliasToNode . entrySet ( ) . stream ( ) . collect ( Collectors . toMap ( x -> x . getValue ( ) , x -> x . getKey ( ) ) ) ) ; List < Pattern > result = new ArrayList <> ( ) ; while ( ! reverseMap . isEmpty ( ) ) { Pattern pattern = new Pattern ( ) ; result . add ( pattern ) ; Map . Entry < PatternNode , String > nextNode = reverseMap . entrySet ( ) . iterator ( ) . next ( ) ; Set < PatternNode > toVisit = new HashSet <> ( ) ; toVisit . add ( nextNode . getKey ( ) ) ; while ( toVisit . size ( ) > 0 ) { PatternNode currentNode = toVisit . iterator ( ) . next ( ) ; toVisit . remove ( currentNode ) ; if ( reverseMap . containsKey ( currentNode ) ) { pattern . aliasToNode . put ( reverseMap . get ( currentNode ) , currentNode ) ; reverseMap . remove ( currentNode ) ; for ( PatternEdge x : currentNode . out ) { toVisit . add ( x . in ) ; } for ( PatternEdge x : currentNode . in ) { toVisit . add ( x . out ) ; } } } pattern . recalculateNumOfEdges ( ) ; } return result ; }", "nl": "splits this pattern into multiple"}}
{"translation": {"code": "@ Override public OResultSet executeSimple ( OCommandContext ctx ) { OResultInternal result = new OResultInternal ( ) ; result . setProperty ( \"operation\" , \"optimize database\" ) ; OStorage storage = ( ( ODatabaseInternal ) ctx . getDatabase ( ) ) . getStorage ( ) ; if ( on ) { // activate the profiler ( ( OAbstractPaginatedStorage ) storage ) . startGatheringPerformanceStatisticForCurrentThread ( ) ; result . setProperty ( \"value\" , \"on\" ) ; } else { // stop the profiler and return the stats final OSessionStoragePerformanceStatistic performanceStatistic = ( ( OAbstractPaginatedStorage ) storage ) . completeGatheringPerformanceStatisticForCurrentThread ( ) ; result . setProperty ( \"value\" , \"off\" ) ; if ( performanceStatistic != null ) { result . setProperty ( \"result\" , performanceStatistic . toDocument ( ) ) ; } else { result . setProperty ( \"result\" , \"error\" ) ; result . setProperty ( \"errorMessage\" , \"profiling of storage was not started\" ) ; } } OInternalResultSet rs = new OInternalResultSet ( ) ; rs . add ( result ) ; return rs ; }", "nl": "new execution logic"}}
{"translation": {"code": "public V getValue ( int index ) { int entryPosition = getIntValue ( POSITIONS_ARRAY_OFFSET + index * OIntegerSerializer . INT_SIZE ) ; // skip hash code entryPosition += OLongSerializer . LONG_SIZE ; if ( encryption == null ) { // skip key entryPosition += getObjectSizeInDirectMemory ( keySerializer , entryPosition ) ; } else { final int encryptedLength = getIntValue ( entryPosition ) ; entryPosition += encryptedLength + OIntegerSerializer . INT_SIZE ; } return deserializeFromDirectMemory ( valueSerializer , entryPosition ) ; }", "nl": "Obtains the value stored under the given index in this bucket ."}}
{"translation": {"code": "@ SuppressWarnings ( \"UnusedReturnValue\" ) public boolean validatedPutIndexValue ( int indexId , final Object key , final ORID value , final OBaseIndexEngine . Validator < Object , ORID > validator ) throws OInvalidIndexEngineIdException { indexId = extractInternalId ( indexId ) ; try { if ( transaction . get ( ) != null ) { return doValidatedPutIndexValue ( indexId , key , value , validator ) ; } checkOpenness ( ) ; stateLock . acquireReadLock ( ) ; try { checkOpenness ( ) ; checkLowDiskSpaceRequestsAndReadOnlyConditions ( ) ; return doValidatedPutIndexValue ( indexId , key , value , validator ) ; } finally { stateLock . releaseReadLock ( ) ; } } catch ( final OInvalidIndexEngineIdException ie ) { throw logAndPrepareForRethrow ( ie ) ; } catch ( final RuntimeException ee ) { throw logAndPrepareForRethrow ( ee ) ; } catch ( final Error ee ) { throw logAndPrepareForRethrow ( ee ) ; } catch ( final Throwable t ) { throw logAndPrepareForRethrow ( t ) ; } }", "nl": "Puts the given value under the given key into this storage for the index with the given index id . Validates the operation using the provided validator ."}}
{"translation": {"code": "public void register ( final Class < ? extends OCompression > compression ) { try { final OCompression tempInstance = compression . newInstance ( ) ; final String name = tempInstance . name ( ) ; if ( compressions . containsKey ( name ) ) throw new IllegalArgumentException ( \"Compression with name '\" + name + \"' was already registered\" ) ; if ( compressionClasses . containsKey ( tempInstance . name ( ) ) ) throw new IllegalArgumentException ( \"Compression with name '\" + name + \"' was already registered\" ) ; compressionClasses . put ( name , compression ) ; } catch ( Exception e ) { OLogManager . instance ( ) . error ( this , \"Cannot register storage compression algorithm '%s'\" , e , compression ) ; } }", "nl": "Registers a stateless implementations the same instance will be shared on all the storages ."}}
{"translation": {"code": "public Set < String > getRegisteredServers ( ) { final ODocument servers = configuration . field ( SERVERS ) ; final Set < String > result = new HashSet < String > ( ) ; if ( servers != null ) for ( String s : servers . fieldNames ( ) ) result . ( s ) ; return result ; }", "nl": "Returns the registered servers ."}}
{"translation": {"code": "public NEW_NODE_STRATEGIES getNewNodeStrategy ( ) { final String value = configuration . field ( NEW_NODE_STRATEGY ) ; if ( value != null ) return NEW_NODE_STRATEGIES . valueOf ( value . toUpperCase ( Locale . ENGLISH ) ) ; return NEW_NODE_STRATEGIES . STATIC ; }", "nl": "Returns the new node strategy between dynamic and static . If static the node is registered under the server tag ."}}
{"translation": {"code": "public static OSymmetricKey fromConfig ( final OSymmetricKeyConfig keyConfig ) { if ( keyConfig . usesKeyString ( ) ) { return fromString ( keyConfig . getKeyAlgorithm ( ) , keyConfig . getKeyString ( ) ) ; } else if ( keyConfig . usesKeyFile ( ) ) { return fromFile ( keyConfig . getKeyAlgorithm ( ) , keyConfig . getKeyFile ( ) ) ; } else if ( keyConfig . usesKeystore ( ) ) { return fromKeystore ( keyConfig . getKeystoreFile ( ) , keyConfig . getKeystorePassword ( ) , keyConfig . getKeystoreKeyAlias ( ) , keyConfig . getKeystoreKeyPassword ( ) ) ; } else { throw new OSecurityException ( \"OSymmetricKey(OSymmetricKeyConfig) Invalid configuration\" ) ; } }", "nl": "Creates an OSymmetricKey from an OSymmetricKeyConfig interface ."}}
{"translation": {"code": "public static OSymmetricKey fromFile ( final String algorithm , final String path ) { String base64Key = null ; try { java . io . FileInputStream fis = null ; try { fis = new java . io . FileInputStream ( OSystemVariableResolver . resolveSystemVariables ( path ) ) ; return fromStream ( algorithm , fis ) ; } finally { if ( fis != null ) fis . close ( ) ; } } catch ( Exception ex ) { throw OException . wrapException ( new OSecurityException ( \"OSymmetricKey.fromFile() Exception: \" + ex . getMessage ( ) ) , ex ) ; } }", "nl": "Creates an OSymmetricKey from a file containing a Base64 key ."}}
{"translation": {"code": "public static OSymmetricKey fromStream ( final String algorithm , final InputStream is ) { String base64Key = null ; try { base64Key = OIOUtils . readStreamAsString ( is ) ; } catch ( Exception ex ) { throw OException . wrapException ( new OSecurityException ( \"OSymmetricKey.fromStream() Exception: \" + ex . getMessage ( ) ) , ex ) ; } return new OSymmetricKey ( algorithm , base64Key ) ; }", "nl": "Creates an OSymmetricKey from an InputStream containing a Base64 key ."}}
{"translation": {"code": "public String encrypt ( final String transform , final byte [ ] bytes ) { String encodedJSON = null ; if ( secretKey == null ) throw new OSecurityException ( \"OSymmetricKey.encrypt() SecretKey is null\" ) ; if ( transform == null ) throw new OSecurityException ( \"OSymmetricKey.encrypt() Cannot determine cipher transformation\" ) ; try { // Throws NoSuchAlgorithmException and NoSuchPaddingException. Cipher cipher = Cipher . getInstance ( transform ) ; // If the cipher transformation requires an initialization vector then init() will create a random one. // (Use cipher.getIV() to retrieve the IV, if it exists.) cipher . init ( Cipher . ENCRYPT_MODE , secretKey ) ; // If the cipher does not use an IV, this will be null. byte [ ] initVector = cipher . getIV ( ) ; //      byte[] initVector = encCipher.getParameters().getParameterSpec(IvParameterSpec.class).getIV(); byte [ ] encrypted = cipher . doFinal ( bytes ) ; encodedJSON = encodeJSON ( encrypted , initVector ) ; } catch ( Exception ex ) { throw OException . wrapException ( new OSecurityException ( \"OSymmetricKey.encrypt() Exception: \" + ex . getMessage ( ) ) , ex ) ; } return encodedJSON ; }", "nl": "This method encrypts an array of bytes ."}}
{"translation": {"code": "public void saveToStream ( final OutputStream os ) { if ( os == null ) throw new OSecurityException ( \"OSymmetricKey.saveToStream() OutputStream is null\" ) ; try { final OutputStreamWriter osw = new OutputStreamWriter ( os ) ; try { final BufferedWriter writer = new BufferedWriter ( osw ) ; try { writer . write ( getBase64Key ( ) ) ; } finally { writer . close ( ) ; } } finally { os . close ( ) ; } } catch ( Exception ex ) { throw OException . wrapException ( new OSecurityException ( \"OSymmetricKey.saveToStream() Exception: \" + ex . getMessage ( ) ) , ex ) ; } }", "nl": "Saves the internal SecretKey to the specified OutputStream as a Base64 String ."}}
{"translation": {"code": "public void saveToKeystore ( final OutputStream os , final String ksPasswd , final String keyAlias , final String keyPasswd ) { if ( os == null ) throw new OSecurityException ( \"OSymmetricKey.saveToKeystore() OutputStream is null\" ) ; if ( ksPasswd == null ) throw new OSecurityException ( \"OSymmetricKey.saveToKeystore() Keystore Password is required\" ) ; if ( keyAlias == null ) throw new OSecurityException ( \"OSymmetricKey.saveToKeystore() Key Alias is required\" ) ; if ( keyPasswd == null ) throw new OSecurityException ( \"OSymmetricKey.saveToKeystore() Key Password is required\" ) ; try { KeyStore ks = KeyStore . getInstance ( \"JCEKS\" ) ; char [ ] ksPasswdCA = ksPasswd . toCharArray ( ) ; char [ ] keyPasswdCA = keyPasswd . toCharArray ( ) ; // Create a new KeyStore by passing null. ks . load ( null , ksPasswdCA ) ; KeyStore . ProtectionParameter protParam = new KeyStore . PasswordProtection ( keyPasswdCA ) ; KeyStore . SecretKeyEntry skEntry = new KeyStore . SecretKeyEntry ( secretKey ) ; ks . setEntry ( keyAlias , skEntry , protParam ) ; // Save the KeyStore ks . store ( os , ksPasswdCA ) ; } catch ( Exception ex ) { throw OException . wrapException ( new OSecurityException ( \"OSymmetricKey.saveToKeystore() Exception: \" + ex . getMessage ( ) ) , ex ) ; } }", "nl": "Saves the internal SecretKey as a KeyStore ."}}
{"translation": {"code": "protected static String separateAlgorithm ( final String cipherTransform ) { String [ ] array = cipherTransform . split ( \"/\" ) ; if ( array . length > 1 ) return array [ 0 ] ; return null ; }", "nl": "Returns the secret key algorithm portion of the cipher transformation ."}}
{"translation": {"code": "public < RET extends OCommandRequest > RET command ( final OCommandRequest iCommand ) { return ( RET ) new OCommandSQLPojoWrapper ( this , underlying . command ( iCommand ) ) ; }", "nl": "Returns a wrapped OCommandRequest instance to catch the result - set by converting it before to return to the user application ."}}
{"translation": {"code": "public void setDirty ( final Object iPojo ) { if ( iPojo == null ) return ; final ODocument record = getRecordByUserObject ( iPojo , false ) ; if ( record == null ) throw new OObjectNotManagedException ( \"The object \" + iPojo + \" is not managed by current database\" ) ; record . setDirty ( ) ; }", "nl": "Sets as dirty a POJO . This is useful when you change the object and need to tell to the engine to treat as dirty ."}}
{"translation": {"code": "public void unsetDirty ( final Object iPojo ) { if ( iPojo == null ) return ; final ODocument record = getRecordByUserObject ( iPojo , false ) ; if ( record == null ) return ; ORecordInternal . unsetDirty ( record ) ; }", "nl": "Sets as not dirty a POJO . This is useful when you change some other object and need to tell to the engine to treat this one as not dirty ."}}
{"translation": {"code": "void writePage ( ByteBuffer page , long pageIndex ) throws IOException { synchronized ( lockObject ) { lastAccessTime = System . nanoTime ( ) ; if ( pageIndex >= firstCachedPage && pageIndex <= firstCachedPage + pageCache . size ( ) ) { if ( pageIndex < firstCachedPage + pageCache . size ( ) ) { pageCache . set ( ( int ) ( pageIndex - firstCachedPage ) , page ) ; } else { pageCache . add ( page ) ; } } else if ( pageCache . isEmpty ( ) ) { pageCache . add ( page ) ; firstCachedPage = pageIndex ; } lastWrittenPage = page ; lastWrittenPageIndex = pageIndex ; if ( pageCache . size ( ) * OWALPage . PAGE_SIZE >= bufferSize + OWALPage . PAGE_SIZE ) { flushAllBufferPagesExceptLastOne ( ) ; } } }", "nl": "Writes page with given page index to the cache and eventually writes it to the file ."}}
{"translation": {"code": "public void open ( ) throws IOException { synchronized ( lockObject ) { lastAccessTime = System . nanoTime ( ) ; initFile ( ) ; long pagesCount = segChannel . size ( ) / OWALPage . PAGE_SIZE ; if ( segChannel . size ( ) % OWALPage . PAGE_SIZE > 0 ) { OLogManager . instance ( ) . error ( this , \"Last WAL page was written partially, auto fix\" , null ) ; segChannel . truncate ( OWALPage . PAGE_SIZE * pagesCount ) ; } firstCachedPage = - 1 ; pageCache . clear ( ) ; lastWrittenPage = null ; lastWrittenPageIndex = - 1 ; } }", "nl": "Initializes cache and opens underlying file ."}}
{"translation": {"code": "byte [ ] readPage ( long pageIndex ) throws IOException { synchronized ( lockObject ) { lastAccessTime = System . nanoTime ( ) ; if ( pageIndex == lastWrittenPageIndex ) { return lastWrittenPage . array ( ) ; } if ( pageIndex >= firstCachedPage && pageIndex < firstCachedPage + pageCache . size ( ) ) { final ByteBuffer buffer = pageCache . get ( ( int ) ( pageIndex - firstCachedPage ) ) ; return buffer . array ( ) ; } final ByteBuffer buffer = ByteBuffer . allocate ( OWALPage . PAGE_SIZE ) . order ( ByteOrder . nativeOrder ( ) ) ; initFile ( ) ; segChannel . position ( pageIndex * OWALPage . PAGE_SIZE ) ; readByteBuffer ( buffer , segChannel ) ; return buffer . array ( ) ; } }", "nl": "Read page content with given index from cache or file ."}}
{"translation": {"code": "public ODatabaseObject open ( String name , String user , String password ) { return new OObjectDatabaseTx ( ( ODatabaseDocumentInternal ) orientDB . open ( name , user , password ) ) ; }", "nl": "Open a database specified by name using the username and password if needed"}}
{"translation": {"code": "public Object execute ( final Map < Object , Object > iArgs ) { ODatabaseDocumentInternal db = getDatabase ( ) ; db . begin ( ) ; if ( className == null && clusterName == null ) throw new OCommandExecutionException ( \"Cannot execute the command because it has not been parsed yet\" ) ; OModifiableBoolean shutdownGraph = new OModifiableBoolean ( ) ; final boolean txAlreadyBegun = getDatabase ( ) . getTransaction ( ) . isActive ( ) ; try { final Set < OIdentifiable > sourceRIDs = OSQLEngine . getInstance ( ) . parseRIDTarget ( db , source , context , iArgs ) ; // CREATE EDGES final List < ODocument > result = new ArrayList < ODocument > ( sourceRIDs . size ( ) ) ; for ( OIdentifiable from : sourceRIDs ) { final OVertex fromVertex = toVertex ( from ) ; if ( fromVertex == null ) continue ; final ORID oldVertex = fromVertex . getIdentity ( ) . copy ( ) ; final ORID newVertex = fromVertex . moveTo ( className , clusterName ) ; final ODocument newVertexDoc = newVertex . getRecord ( ) ; if ( fields != null ) { // EVALUATE FIELDS for ( final OPair < String , Object > f : fields ) { if ( f . getValue ( ) instanceof OSQLFunctionRuntime ) f . setValue ( ( ( OSQLFunctionRuntime ) f . getValue ( ) ) . getValue ( newVertex . getRecord ( ) , null , context ) ) ; } OSQLHelper . bindParameters ( newVertexDoc , fields , new OCommandParameters ( iArgs ) , context ) ; } if ( merge != null ) newVertexDoc . merge ( merge , true , false ) ; // SAVE CHANGES newVertexDoc . save ( ) ; // PUT THE MOVE INTO THE RESULT result . add ( new ODocument ( ) . setTrackingChanges ( false ) . field ( \"old\" , oldVertex , OType . LINK ) . field ( \"new\" , newVertex , OType . LINK ) ) ; if ( batch > 0 && result . size ( ) % batch == 0 ) { db . commit ( ) ; db . begin ( ) ; } } db . commit ( ) ; return result ; } finally { //      if (!txAlreadyBegun) //        db.commit(); } }", "nl": "Executes the command and return the ODocument object created ."}}
{"translation": {"code": "public static OScriptResultSet singleton ( Object entity , OScriptTransformer transformer ) { return new OScriptResultSet ( Collections . singletonList ( entity ) . iterator ( ) , transformer ) ; }", "nl": "Result set with a single result ;"}}
{"translation": {"code": "public static int indexOf ( final Object [ ] array , final Comparable object ) { for ( int i = 0 ; i < array . length ; ++ i ) { if ( object . compareTo ( array [ i ] ) == 0 ) // FOUND return i ; } return - 1 ; }", "nl": "This method is used to find an item in an array ."}}
{"translation": {"code": "@ Override public String electNewLockManager ( ) { if ( hazelcastInstance == null ) throw new HazelcastInstanceNotActiveException ( ) ; final ILock lock = hazelcastInstance . getLock ( \"orientdb.lockManagerElection\" ) ; lock . lock ( ) ; try { // TRY ALL THE SERVERS IN ORDER (ALL THE SERVERS HAVE THE SAME LIST) String lockManagerServer = getLockManagerRequester ( ) . getServer ( ) ; // PROTECT FROM DOUBLE LOCK MANAGER ELECTION IN CASE OF REMOVE OF LOCK MANAGER if ( lockManagerServer != null && getActiveServers ( ) . contains ( lockManagerServer ) ) return lockManagerServer ; final String originalLockManager = lockManagerServer ; ODistributedServerLog . debug ( this , nodeName , originalLockManager , DIRECTION . OUT , \"lock '%s' is unreachable, electing a new lock...\" , originalLockManager ) ; int lockManagerServerId = - 1 ; if ( lockManagerServer != null && registeredNodeByName . containsKey ( lockManagerServer ) ) lockManagerServerId = registeredNodeByName . get ( lockManagerServer ) ; String newServer = null ; int currIndex = lockManagerServerId ; for ( int i = 0 ; i < registeredNodeById . size ( ) ; ++ i ) { currIndex ++ ; if ( currIndex >= registeredNodeById . size ( ) ) // RESTART FROM THE FIRST currIndex = 0 ; newServer = registeredNodeById . get ( currIndex ) ; if ( newServer == null ) throw new OConfigurationException ( \"Found null server at index \" + currIndex + \" of server list \" + registeredNodeById ) ; if ( newServer . equalsIgnoreCase ( getLocalNodeName ( ) ) || activeNodes . containsKey ( newServer ) ) { // TODO: IMPROVE ELECTION BY CHECKING AL THE NODES AGREE ON IT ODistributedServerLog . debug ( this , nodeName , newServer , DIRECTION . OUT , \"Trying to elected server '%s' as new lock (old=%s)...\" , newServer , originalLockManager ) ; try { getLockManagerRequester ( ) . setServer ( newServer ) ; configurationMap . put ( CONFIG_LOCKMANAGER , getLockManagerRequester ( ) . getServer ( ) ) ; ODistributedServerLog . info ( this , nodeName , newServer , DIRECTION . OUT , \"Elected server '%s' as new lock (old=%s)\" , newServer , originalLockManager ) ; break ; } catch ( Exception e ) { // NO SERVER RESPONDED, THE SERVER COULD BE ISOLATED, GO AHEAD WITH THE NEXT IN THE LIST ODistributedServerLog . info ( this , nodeName , newServer , DIRECTION . OUT , \"Error on electing server '%s' as new lock (error: %s)\" , newServer , e ) ; } } } return newServer ; } finally { lock . unlock ( ) ; } }", "nl": "Elects a new server as coordinator . The election browse the ordered server list ."}}
{"translation": {"code": "private void assignLockManagerFromCluster ( ) { String lockManagerServer = null ; while ( lockManagerServer == null ) { if ( activeNodes . size ( ) == 1 ) { // ONLY CURRENT NODE ONLINE, SET IT AS INITIAL LOCK MANAGER lockManagerServer = nodeName ; if ( configurationMap . putIfAbsent ( CONFIG_LOCKMANAGER , lockManagerServer ) == null ) break ; } else { lockManagerServer = ( String ) configurationMap . get ( CONFIG_LOCKMANAGER ) ; if ( lockManagerServer != null && lockManagerServer . equals ( nodeName ) ) { // LAST LOCK MANAGER WAS CURRENT NODE? TRY TO FORCE A NEW ELECTION OLogManager . instance ( ) . info ( this , \"Found lock as current node, even if it was offline. Forcing a new election...\" ) ; getLockManagerRequester ( ) . setServer ( lockManagerServer ) ; lockManagerServer = electNewLockManager ( ) ; break ; } if ( lockManagerServer != null ) break ; } try { Thread . sleep ( 100 ) ; } catch ( InterruptedException e ) { break ; } } getLockManagerRequester ( ) . setServer ( lockManagerServer ) ; OLogManager . instance ( ) . info ( this , \"Distributed Lock Manager server is '%s'\" , lockManagerServer ) ; }", "nl": "ASSIGN THE LOCK MANAGER AT STARTUP"}}
{"translation": {"code": "public List < String > getMasterServers ( ) { final List < String > serverList = getClusterConfiguration ( null ) . field ( SERVERS ) ; if ( serverList != null ) { // COPY AND REMOVE ANY NEW_NODE_TAG List < String > masters = new ArrayList < String > ( serverList . size ( ) ) ; for ( String s : serverList ) { if ( ! s . equals ( NEW_NODE_TAG ) ) masters . add ( s ) ; } final ROLES defRole = getDefaultServerRole ( ) ; final ODocument servers = configuration . field ( SERVERS ) ; if ( servers != null ) { for ( Iterator < String > it = masters . iterator ( ) ; it . hasNext ( ) ; ) { final String server = it . next ( ) ; final String roleAsString = servers . field ( server ) ; final ROLES role = roleAsString != null ? ROLES . valueOf ( roleAsString . toUpperCase ( Locale . ENGLISH ) ) : defRole ; if ( role != ROLES . MASTER ) it . remove ( ) ; } } return masters ; } return Collections . EMPTY_LIST ; }", "nl": "Returns an ordered list of master server . The first in the list is the first found in configuration . This is used to determine the cluster leader ."}}
{"translation": {"code": "public static int indexOf ( final int [ ] array , final int object ) { for ( int i = 0 ; i < array . length ; ++ i ) { if ( array [ i ] == object ) // FOUND return i ; } return - 1 ; }", "nl": "This method is used to find a number in an array ."}}
{"translation": {"code": "private IndexSearchDescriptor findBestIndexFor ( OCommandContext ctx , Set < OIndex < ? > > indexes , OAndBlock block , OClass clazz ) { //get all valid index descriptors List < IndexSearchDescriptor > descriptors = indexes . stream ( ) . filter ( x -> x . getInternal ( ) . canBeUsedInEqualityOperators ( ) ) . map ( index -> buildIndexSearchDescriptor ( ctx , index , block , clazz ) ) . filter ( Objects :: nonNull ) . filter ( x -> x . keyCondition != null ) . filter ( x -> x . keyCondition . getSubBlocks ( ) . size ( ) > 0 ) . collect ( Collectors . toList ( ) ) ; List < IndexSearchDescriptor > fullTextIndexDescriptors = indexes . stream ( ) . filter ( idx -> idx . getType ( ) . equalsIgnoreCase ( \"FULLTEXT\" ) ) . filter ( idx -> ! idx . getAlgorithm ( ) . equalsIgnoreCase ( \"LUCENE\" ) ) . map ( idx -> buildIndexSearchDescriptorForFulltext ( ctx , idx , block , clazz ) ) . filter ( Objects :: nonNull ) . filter ( x -> x . keyCondition != null ) . filter ( x -> x . keyCondition . getSubBlocks ( ) . size ( ) > 0 ) . collect ( Collectors . toList ( ) ) ; descriptors . addAll ( fullTextIndexDescriptors ) ; //remove the redundant descriptors (eg. if I have one on [a] and one on [a, b], the first one is redundant, just discard it) descriptors = removePrefixIndexes ( descriptors ) ; //sort by cost List < OPair < Integer , IndexSearchDescriptor > > sortedDescriptors = descriptors . stream ( ) . map ( x -> ( OPair < Integer , IndexSearchDescriptor > ) new OPair ( x . cost ( ctx ) , x ) ) . sorted ( ) . collect ( Collectors . toList ( ) ) ; //get only the descriptors with the lowest cost descriptors = sortedDescriptors . isEmpty ( ) ? Collections . emptyList ( ) : sortedDescriptors . stream ( ) . filter ( x -> x . key . equals ( sortedDescriptors . get ( 0 ) . key ) ) . map ( x -> x . value ) . collect ( Collectors . toList ( ) ) ; //sort remaining by the number of indexed fields descriptors = descriptors . stream ( ) . sorted ( Comparator . comparingInt ( x -> x . keyCondition . getSubBlocks ( ) . size ( ) ) ) . collect ( Collectors . toList ( ) ) ; //get the one that has more indexed fields return descriptors . isEmpty ( ) ? null : descriptors . get ( descriptors . size ( ) - 1 ) ; }", "nl": "given a flat AND block and a set of indexes returns the best index to be used to process it with the complete description on how to use it"}}
{"translation": {"code": "private Map < String , Set < String > > getDependencies ( Pattern pattern ) { Map < String , Set < String > > result = new HashMap < String , Set < String > > ( ) ; for ( PatternNode node : pattern . aliasToNode . values ( ) ) { Set < String > currentDependencies = new HashSet < String > ( ) ; OWhereClause filter = aliasFilters . get ( node . alias ) ; if ( filter != null && filter . getBaseExpression ( ) != null ) { List < String > involvedAliases = filter . getBaseExpression ( ) . getMatchPatternInvolvedAliases ( ) ; if ( involvedAliases != null ) { currentDependencies . addAll ( involvedAliases ) ; } } result . put ( node . alias , currentDependencies ) ; } return result ; }", "nl": "Calculate the set of dependency aliases for each alias in the pattern ."}}