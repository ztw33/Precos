{"translation": {"code": "private void doUniqueTemplates ( Formatter f , MCollection dcm , boolean useIndex ) throws IOException { f . format ( \"Show Unique GDS and PDS templates%n\" ) ; Map < Integer , FileList > gdsSet = new HashMap <> ( ) ; Map < Integer , FileList > pdsSet = new HashMap <> ( ) ; Map < Integer , FileList > drsSet = new HashMap <> ( ) ; for ( MFile mfile : dcm . getFilesSorted ( ) ) { f . format ( \" %s%n\" , mfile . getPath ( ) ) ; doUniqueTemplates ( mfile , gdsSet , pdsSet , drsSet , f ) ; } List < FileList > sorted = new ArrayList <> ( gdsSet . values ( ) ) ; Collections . sort ( sorted ) ; for ( FileList gdsl : sorted ) { f . format ( \"%nGDS %s template= %d %n\" , gdsl . name , gdsl . template ) ; for ( FileCount fc : gdsl . fileList ) { f . format ( \"  %5d %s %n\" , fc . countRecords , fc . f . getPath ( ) ) ; } } List < FileList > sortedPds = new ArrayList <> ( pdsSet . values ( ) ) ; Collections . sort ( sortedPds ) ; for ( FileList pdsl : sortedPds ) { f . format ( \"%n===================================================%n\" ) ; f . format ( \"%nPDS %s template= %d %n\" , pdsl . name , pdsl . template ) ; for ( FileCount fc : pdsl . fileList ) { f . format ( \"  %5d %s %n\" , fc . countRecords , fc . f . getPath ( ) ) ; } } List < FileList > sortedDrs = new ArrayList <> ( drsSet . values ( ) ) ; Collections . sort ( sortedDrs ) ; for ( FileList pdsl : sortedDrs ) { f . format ( \"%n===================================================%n\" ) ; f . format ( \"%nDRS %s template= %d %n\" , pdsl . name , pdsl . template ) ; for ( FileCount fc : pdsl . fileList ) { f . format ( \"  %5d %s %n\" , fc . countRecords , fc . f . getPath ( ) ) ; } } }", "nl": "Look through the collection and find what GDS and PDS templates are used ."}}
{"translation": {"code": "private CacheElement updateInCache ( CacheElement elem ) { if ( shadowCache . firstKey ( ) == elem ) return elem ; elem . updateAccessed ( ) ; CacheElement prev = shadowCache . put ( elem , elem ) ; // faster if we could just insert at the top of the list. maybe we need to use LinkedList ? if ( prev != null && ( elem != prev ) ) { CacheElementComparator cc = new CacheElementComparator ( ) ; System . out . printf ( \"elem != prev compare=%d%n\" , cc . compare ( elem , prev ) ) ; System . out . printf ( \"hash elem =%d prev=%d%n\" , elem . hashCode ( ) , prev . hashCode ( ) ) ; } return elem ; }", "nl": "get CacheElement specified by hashKey . If found update lastUsed in shadowCache ."}}
{"translation": {"code": "public int findIdx ( int want ) { if ( isConstant ) return ( want == start ) ? 0 : - 1 ; if ( isSequential ) return want - start ; if ( isSorted ) { return Arrays . binarySearch ( raw , want ) ; } // linear search for ( int i = 0 ; i < raw . length ; i ++ ) if ( raw [ i ] == want ) return i ; return - 1 ; }", "nl": "Find which index holds the value want"}}
{"translation": {"code": "public ucar . nc2 . time . Calendar getCalendarFromAttribute ( ) { Attribute cal = findAttribute ( CF . CALENDAR ) ; String s = ( cal == null ) ? null : cal . getStringValue ( ) ; if ( s == null ) { // default for CF and COARDS Attribute convention = ( ncd == null ) ? null : ncd . getRootGroup ( ) . findAttribute ( CDM . CONVENTIONS ) ; if ( convention != null ) { String hasName = convention . getStringValue ( ) ; int version = CF1Convention . getVersion ( hasName ) ; if ( version >= 0 ) { return Calendar . gregorian ; //if (version < 7 ) return Calendar.gregorian; //if (version >= 7 ) return Calendar.proleptic_gregorian; // } if ( COARDSConvention . isMine ( hasName ) ) return Calendar . gregorian ; } } return ucar . nc2 . time . Calendar . get ( s ) ; }", "nl": "needed by time coordinates"}}
{"translation": {"code": "@ Nullable public static Grib2Record findRecordByDrspos ( RandomAccessFile raf , long drsPos ) throws IOException { long pos = Math . max ( 0 , drsPos - ( 20 * 1000 ) ) ; // go back 20K\r Grib2RecordScanner scan = new Grib2RecordScanner ( raf , pos ) ; while ( scan . hasNext ( ) ) { ucar . nc2 . grib . grib2 . Grib2Record gr = scan . next ( ) ; Grib2SectionDataRepresentation drs = gr . getDataRepresentationSection ( ) ; if ( drsPos == drs . getStartingPosition ( ) ) return gr ; if ( raf . getFilePointer ( ) > drsPos ) break ; // missed it.\r } return null ; }", "nl": "tricky bit of business . recapture the entire record based on drs position . for validation ."}}
{"translation": {"code": "private static File makeTopIndexFileFromConfig ( FeatureCollectionConfig config ) { Formatter errlog = new Formatter ( ) ; CollectionSpecParser specp = config . getCollectionSpecParser ( errlog ) ; String name = StringUtil2 . replace ( config . collectionName , ' ' , \"/\" ) ; // String cname = DirectoryCollection.makeCollectionName(name, Paths.get(specp.getRootDir())); return makeIndexFile ( name , new File ( specp . getRootDir ( ) ) ) ; }", "nl": "This is only used for the top level GribCollection ."}}
{"translation": {"code": "void setRuntimeCoords ( CoordinateRuntime runtimes ) { for ( int idx = 0 ; idx < runtimes . getSize ( ) ; idx ++ ) { CalendarDate cd = runtimes . getRuntimeDate ( idx ) ; long runtime = runtimes . getRuntime ( idx ) ; CoordinateTimeAbstract time = timeMap . get ( runtime ) ; if ( time == null ) { time = isTimeInterval ? new CoordinateTimeIntv ( this . code , this . timeUnit , cd , new ArrayList <> ( 0 ) , null ) : new CoordinateTime ( this . code , this . timeUnit , cd , new ArrayList <> ( 0 ) , null ) ; timeMap . put ( runtime , time ) ; } } }", "nl": "set the list of runtime coordinates ; add any that are not already present and make an empty CoordinateTimeAbstract for it"}}
{"translation": {"code": "public static File getFileOrCache ( String fileLocation ) { File result = getExistingFileOrCache ( fileLocation ) ; if ( result != null ) return result ; return getDiskCache2 ( ) . getFile ( fileLocation ) ; }", "nl": "Get index file may be in cache directory may not exist"}}
{"translation": {"code": "protected State checkState ( ) throws IOException { State localState ; synchronized ( lock ) { if ( first ) { firstInit ( ) ; updateCollection ( state , config . updateConfig . updateType ) ; // makeDatasetTop(state); first = false ; } localState = state . copy ( ) ; } return localState ; }", "nl": "A request has come in check that the state has been initialized . this is called from the request thread ."}}
{"translation": {"code": "public DataFactory . Result openFeatureDataset ( Access access , ucar . nc2 . util . CancelTask task ) throws IOException { Dataset ds = access . getDataset ( ) ; DataFactory . Result result = new Result ( ) ; if ( ds . getFeatureType ( ) == null ) { result . errLog . format ( \"InvDatasert must specify a FeatureType%n\" ) ; result . fatalError = true ; return result ; } return openFeatureDataset ( ds . getFeatureType ( ) , access , task , result ) ; }", "nl": "Open a FeatureDataset from an Access object ."}}
{"translation": {"code": "@ Override public CatalogBuilder makeCatalog ( String match , String reqPath , URI catURI ) throws IOException { StateGrib localState = ( StateGrib ) checkState ( ) ; if ( localState == null ) return null ; // not ready yet maybe if ( localState . gribCollection == null ) return null ; // not ready yet maybe try { // case 0 if ( ( match == null ) || ( match . length ( ) == 0 ) ) { return makeCatalogTop ( catURI , localState ) ; // top catalog : uses state.top previously made in checkState() } // case 1 if ( localState . gribCollection instanceof PartitionCollectionImmutable ) { String [ ] paths = match . split ( \"/\" ) ; PartitionCollectionImmutable pc = ( PartitionCollectionImmutable ) localState . gribCollection ; return makeCatalogFromPartition ( pc , paths , 0 , catURI ) ; } } catch ( Exception e ) { e . printStackTrace ( ) ; logger . error ( \"Error making catalog for \" + configPath , e ) ; } return null ; }", "nl": "see top javadoc for possible URLs"}}
{"translation": {"code": "public static void annotate ( Dataset ds , NetcdfDataset ncDataset ) { ncDataset . setTitle ( ds . getName ( ) ) ; ncDataset . setId ( ds . getId ( ) ) ; // add properties as global attributes for ( Property p : ds . getProperties ( ) ) { String name = p . getName ( ) ; if ( null == ncDataset . findGlobalAttribute ( name ) ) { ncDataset . addAttribute ( null , new Attribute ( name , p . getValue ( ) ) ) ; } } /* ThreddsMetadata.GeospatialCoverage geoCoverage = ds.getGeospatialCoverage();\n   if (geoCoverage != null) {\n     if ( null != geoCoverage.getNorthSouthRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lat_min\", new Double(geoCoverage.getLatSouth())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lat_max\", new Double(geoCoverage.getLatNorth())));\n     }\n     if ( null != geoCoverage.getEastWestRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lon_min\", new Double(geoCoverage.getLonWest())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lon_max\", new Double(geoCoverage.getLonEast())));\n     }\n     if ( null != geoCoverage.getUpDownRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_vertical_min\", new Double(geoCoverage.getHeightStart())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_vertical_max\", new Double(geoCoverage.getHeightStart() + geoCoverage.getHeightExtent())));\n     }\n   }\n\n   DateRange timeCoverage = ds.getTimeCoverage();\n   if (timeCoverage != null) {\n     ncDataset.addAttribute(null, new Attribute(\"time_coverage_start\", timeCoverage.getStart().toDateTimeStringISO()));\n     ncDataset.addAttribute(null, new Attribute(\"time_coverage_end\", timeCoverage.getEnd().toDateTimeStringISO()));\n   } */ ncDataset . finish ( ) ; }", "nl": "Add information from the Dataset to the NetcdfDataset ."}}
{"translation": {"code": "public URI getStandardUri ( ) { try { Catalog cat = dataset . getParentCatalog ( ) ; if ( cat == null ) return new URI ( getUnresolvedUrlName ( ) ) ; return cat . resolveUri ( getUnresolvedUrlName ( ) ) ; } catch ( java . net . URISyntaxException e ) { throw new RuntimeException ( \"Error parsing URL= \" + getUnresolvedUrlName ( ) ) ; } }", "nl": "Construct the standard THREDDS access URI for this dataset access method resolved agaisnt the parent catalog if the URI is relative ."}}
{"translation": {"code": "@ Subscribe public void processEvent ( CollectionUpdateEvent event ) { if ( ! config . collectionName . equals ( event . getCollectionName ( ) ) ) return ; // not for me try { update ( event . getType ( ) ) ; } catch ( IOException e ) { logger . error ( \"Error processing event\" , e ) ; } }", "nl": "called by eventBus this is where the trigger comes in"}}
{"translation": {"code": "public Dataset copyDataset ( DatasetNode parent ) { return new Dataset ( parent , name , flds , accessBuilders , datasetBuilders ) ; }", "nl": "make an immutable copy without changin DatasetBuilder"}}
{"translation": {"code": "public Dataset findDatasetByName ( String name ) { for ( Dataset ds : getDatasets ( ) ) { if ( ds . getName ( ) . equals ( name ) ) return ds ; Dataset result = ds . findDatasetByName ( name ) ; if ( result != null ) return result ; } return null ; }", "nl": "Look though all datasets here or under here . do not go into catrefs"}}
{"translation": {"code": "public String readXlinkContent ( ) throws java . io . IOException { if ( uri == null ) return \"\" ; URL url = uri . toURL ( ) ; InputStream is = url . openStream ( ) ; ByteArrayOutputStream os = new ByteArrayOutputStream ( is . available ( ) ) ; // copy to string byte [ ] buffer = new byte [ 1024 ] ; while ( true ) { int bytesRead = is . read ( buffer ) ; if ( bytesRead == - 1 ) break ; os . write ( buffer , 0 , bytesRead ) ; } is . close ( ) ; return new String ( os . toByteArray ( ) , CDM . utf8Charset ) ; }", "nl": "Get inline content as a string else null if there is none"}}
{"translation": {"code": "public FeatureCollectionConfig readConfigFromCatalog ( String catalogAndPath ) { String catFilename ; String fcName = null ; int pos = catalogAndPath . indexOf ( \"#\" ) ; if ( pos > 0 ) { catFilename = catalogAndPath . substring ( 0 , pos ) ; fcName = catalogAndPath . substring ( pos + 1 ) ; } else { catFilename = catalogAndPath ; } File cat = new File ( catFilename ) ; org . jdom2 . Document doc ; try { SAXBuilder builder = new SAXBuilder ( ) ; doc = builder . build ( cat ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; return null ; } try { List < Element > fcElems = new ArrayList <> ( ) ; findFeatureCollection ( doc . getRootElement ( ) , fcName , fcElems ) ; if ( fcElems . size ( ) > 0 ) return readConfig ( fcElems . get ( 0 ) ) ; } catch ( IllegalStateException e ) { e . printStackTrace ( ) ; } return null ; }", "nl": "Read a catalog and extract a FeatureCollectionConfig from it"}}
{"translation": {"code": "String convertCatalogToHtml ( Catalog cat , boolean isLocalCatalog ) { StringBuilder sb = new StringBuilder ( 10000 ) ; String uri = cat . getUriString ( ) ; if ( uri == null ) uri = cat . getName ( ) ; if ( uri == null ) uri = \"unknown\" ; String catname = Escape . html ( uri ) ; // Render the page header sb . append ( getHtmlDoctypeAndOpenTag ( ) ) ; // \"<html>\\n\" ); sb . append ( \"<head>\\r\\n\" ) ; sb . append ( \"<meta http-equiv='Content-Type' content='text/html; charset=UTF-8'>\" ) ; sb . append ( \"<title>\" ) ; //if (cat.isStatic()) //  sb.append(\"TdsStaticCatalog \").append(catname); // for searching //else sb . append ( \"Catalog \" ) . append ( catname ) ; sb . append ( \"</title>\\r\\n\" ) ; sb . append ( getTdsCatalogCssLink ( ) ) . append ( \"\\n\" ) ; sb . append ( this . getGoogleTrackingContent ( ) ) ; sb . append ( \"</head>\\r\\n\" ) ; sb . append ( \"<body>\" ) ; sb . append ( \"<h1>\" ) ; // Logo //String logoUrl = this.htmlConfig.getInstallLogoUrl(); String logoUrl = htmlConfig . prepareUrlStringForHtml ( htmlConfig . getInstallLogoUrl ( ) ) ; if ( logoUrl != null ) { sb . append ( \"<img src='\" ) . append ( logoUrl ) ; String logoAlt = htmlConfig . getInstallLogoAlt ( ) ; if ( logoAlt != null ) sb . append ( \"' alt='\" ) . append ( logoAlt ) ; sb . append ( \"' align='left' valign='top'\" ) . append ( \">\\n\" ) ; } sb . append ( \" Catalog \" ) . append ( catname ) ; sb . append ( \"</h1>\" ) ; sb . append ( \"<HR size='1' noshade='noshade'>\" ) ; sb . append ( \"<table width='100%' cellspacing='0' cellpadding='5' align='center'>\\r\\n\" ) ; // Render the column headings sb . append ( \"<tr>\\r\\n\" ) ; sb . append ( \"<th align='left'><font size='+1'>\" ) ; sb . append ( \"Dataset\" ) ; sb . append ( \"</font></th>\\r\\n\" ) ; sb . append ( \"<th align='center'><font size='+1'>\" ) ; sb . append ( \"Size\" ) ; sb . append ( \"</font></th>\\r\\n\" ) ; sb . append ( \"<th align='right'><font size='+1'>\" ) ; sb . append ( \"Last Modified\" ) ; sb . append ( \"</font></th>\\r\\n\" ) ; sb . append ( \"</tr>\" ) ; // Recursively render the datasets doDatasets ( cat , cat . getDatasetsLocal ( ) , sb , false , 0 , isLocalCatalog ) ; // Render the page footer sb . append ( \"</table>\\r\\n\" ) ; sb . append ( \"<HR size='1' noshade='noshade'>\" ) ; appendSimpleFooter ( sb ) ; sb . append ( \"</body>\\r\\n\" ) ; sb . append ( \"</html>\\r\\n\" ) ; return ( sb . toString ( ) ) ; }", "nl": "Write a catalog in HTML make it look like a file directory ."}}
{"translation": {"code": "private static void createToolsFrame ( ) { // put UI in a JFrame\r frame = new JFrame ( \"NetCDF (\" + DIALOG_VERSION + \") Tools\" ) ; ui = new ToolsUI ( prefs , frame ) ; frame . setIconImage ( BAMutil . getImage ( \"netcdfUI\" ) ) ; frame . addWindowListener ( new WindowAdapter ( ) { @ Override public void windowActivated ( final WindowEvent e ) { ToolsSplashScreen . getSharedInstance ( ) . setVisible ( false ) ; } @ Override public void windowClosing ( final WindowEvent e ) { if ( ! done ) { exit ( ) ; } } } ) ; frame . getContentPane ( ) . add ( ui ) ; final Rectangle have = frame . getGraphicsConfiguration ( ) . getBounds ( ) ; final Rectangle def = new Rectangle ( 50 , 50 , 800 , 800 ) ; Rectangle want = ( Rectangle ) prefs . getBean ( FRAME_SIZE , def ) ; if ( want . getX ( ) > have . getWidth ( ) - 25 ) { // may be off screen when switcing between 2 monitor system\r want = def ; } frame . setBounds ( want ) ; frame . pack ( ) ; frame . setBounds ( want ) ; // in case a dataset was on the command line\r if ( wantDataset != null ) { setDataset ( ) ; } }", "nl": "Must call this method on the event thread ."}}
{"translation": {"code": "private static void prepareGui ( ) { final String osName = System . getProperty ( \"os.name\" ) . toLowerCase ( ) ; final boolean isMacOs = osName . startsWith ( \"mac os x\" ) ; if ( isMacOs ) { System . setProperty ( \"apple.laf.useScreenMenuBar\" , \"true\" ) ; // fixes the case on macOS where users use the system menu option to quit rather than\r // closing a window using the 'x' button.\r Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ) { @ Override public void run ( ) { doSavePrefsAndUI ( ) ; } } ) ; } else { // Not macOS, so try applying Nimbus L&F, if available.\r try { for ( UIManager . LookAndFeelInfo info : UIManager . getInstalledLookAndFeels ( ) ) { if ( \"Nimbus\" . equals ( info . getName ( ) ) ) { UIManager . setLookAndFeel ( info . getClassName ( ) ) ; break ; } } } catch ( Exception exc ) { log . warn ( \"Unable to apply Nimbus look-and-feel due to {}\" , exc . toString ( ) ) ; if ( log . isTraceEnabled ( ) ) { exc . printStackTrace ( ) ; } } } // misc Gui initialization(s)\r BAMutil . setResourcePath ( \"/resources/nj22/ui/icons/\" ) ; // Setting up a font metrics object triggers one of the most time-wasting steps of GUI set up.\r // We do it now before trying to create the splash or tools interface.\r SwingUtilities . invokeLater ( ( ) -> { final Toolkit tk = Toolkit . getDefaultToolkit ( ) ; final Font f = new Font ( \"SansSerif\" , Font . PLAIN , 12 ) ; @ SuppressWarnings ( \"deprecation\" ) final FontMetrics fm = tk . getFontMetrics ( f ) ; } ) ; }", "nl": "Set look - and - feel ."}}
{"translation": {"code": "private boolean exclude ( MFile mfile ) { if ( excludeFilters == null ) return false ; for ( MFileFilter filter : excludeFilters ) { if ( filter . accept ( mfile ) ) return true ; } return false ; }", "nl": "exclusion is an AND"}}
{"translation": {"code": "private void processDatasets ( long catId , ReadMode readMode , String dirPath , List < Dataset > datasets , Set < String > idMap ) throws IOException { if ( exceedLimit ) return ; for ( Dataset ds : datasets ) { if ( datasetTracker . trackDataset ( catId , ds , callback ) ) countDatasets ++ ; if ( maxDatasetsProcess > 0 && countDatasets > maxDatasetsProcess ) exceedLimit = true ; // look for duplicate ids String id = ds . getID ( ) ; if ( id != null ) { if ( idMap . contains ( id ) ) { logCatalogInit . error ( ERROR + \"Duplicate id on  '\" + ds . getName ( ) + \"' id= '\" + id + \"'\" ) ; } else { idMap . add ( id ) ; } } if ( ( ds instanceof DatasetScan ) || ( ds instanceof FeatureCollectionRef ) ) continue ; if ( ds instanceof CatalogScan ) continue ; if ( ds instanceof CatalogRef ) { // follow catalog refs CatalogRef catref = ( CatalogRef ) ds ; String href = catref . getXlinkHref ( ) ; // if (logCatalogInit.isDebugEnabled()) logCatalogInit.debug(\"  catref.getXlinkHref=\" + href); // Check that catRef is relative if ( ! href . startsWith ( \"http:\" ) ) { // Clean up relative URLs that start with \"./\" if ( href . startsWith ( \"./\" ) ) { href = href . substring ( 2 ) ; } String path ; String contextPathPlus = this . contextPath + \"/\" ; if ( href . startsWith ( contextPathPlus ) ) { path = href . substring ( contextPathPlus . length ( ) ) ; // absolute starting from content root } else if ( href . startsWith ( \"/\" ) ) { // Drop the catRef because it points to a non-TDS served catalog. logCatalogInit . error ( ERROR + \"Skipping catalogRef <xlink:href=\" + href + \">. Reference is relative to the server outside the context path [\" + contextPathPlus + \"]. \" + \"Parent catalog info: Name=\\\"\" + catref . getParentCatalog ( ) . getName ( ) + \"\\\"; Base URI=\\\"\" + catref . getParentCatalog ( ) . getUriString ( ) + \"\\\"; dirPath=\\\"\" + dirPath + \"\\\".\" ) ; continue ; } else { path = dirPath + href ; // reletive starting from current directory } CatalogExt ext = catalogTracker . get ( path ) ; long lastRead = ( ext == null ) ? 0 : ext . getLastRead ( ) ; checkCatalogToRead ( readMode , path , false , lastRead ) ; } } else { // recurse through nested datasets processDatasets ( catId , readMode , dirPath , ds . getDatasetsLocal ( ) , idMap ) ; } } }", "nl": "dirPath = the directory path reletive to the rootDir"}}
{"translation": {"code": "public boolean resourceControlOk ( HttpServletRequest req , HttpServletResponse res , String reqPath ) { if ( null == reqPath ) reqPath = TdsPathUtils . extractPath ( req , null ) ; // see if its under resource control String rc = null ; DataRootManager . DataRootMatch match = dataRootManager . findDataRootMatch ( reqPath ) ; if ( match != null ) { rc = match . dataRoot . getRestrict ( ) ; // datasetScan, featCollection are restricted at the dataRoot } if ( rc == null ) { rc = datasetTracker . findResourceControl ( reqPath ) ; // regular datasets tracked here } return resourceAuthorized ( req , res , rc ) ; }", "nl": "Check if this is making a request for a restricted dataset and if so if its allowed ."}}
{"translation": {"code": "public CoordinateTimeAbstract makeBestFromComplete ( ) { int [ ] best = new int [ time2runtime . length ] ; int last = - 1 ; int count = 0 ; for ( int i = 0 ; i < time2runtime . length ; i ++ ) { int time = time2runtime [ i ] ; if ( time >= last ) { last = time ; best [ i ] = time ; count ++ ; } else { best [ i ] = - 1 ; } } return makeBestFromComplete ( best , count ) ; }", "nl": "Implements coverting a complete best to a monotonic best . The reftime is not allowed to decrease"}}
{"translation": {"code": "public boolean finish ( ) { boolean ok = true ; java . util . Iterator iter ; logger . debug ( \"Now finish \" + getName ( ) + \" id= \" + getID ( ) ) ; authorityName = null ; dataType = null ; dataFormatType = null ; defaultService = null ; gc = null ; tc = null ; docs = new ArrayList <> ( ) ; metadata = new ArrayList <> ( ) ; properties = new ArrayList <> ( ) ; creators = new ArrayList <> ( ) ; contributors = new ArrayList <> ( ) ; dates = new ArrayList <> ( ) ; keywords = new ArrayList <> ( ) ; projects = new ArrayList <> ( ) ; publishers = new ArrayList <> ( ) ; variables = new ArrayList <> ( ) ; canonicalize ( ) ; // canonicalize thredds metadata transfer2PublicMetadata ( tm , true ) ; // add local metadata transfer2PublicMetadata ( tmi , true ) ; // add local inherited metadata transferInheritable2PublicMetadata ( ( InvDatasetImpl ) getParent ( ) ) ; // add inheritable metadata from parents // build the expanded access list access = new ArrayList <> ( ) ; // add access element if urlPath is specified if ( ( urlPath != null ) && ( getServiceDefault ( ) != null ) ) { InvAccessImpl a = new InvAccessImpl ( this , urlPath , getServiceDefault ( ) ) ; a . setSize ( size ) ; a . finish ( ) ; addExpandedAccess ( a ) ; } // add local access elements iter = accessLocal . iterator ( ) ; while ( iter . hasNext ( ) ) { InvAccessImpl a = ( InvAccessImpl ) iter . next ( ) ; a . finish ( ) ; addExpandedAccess ( a ) ; } // recurse into child datasets. if ( ! ( this instanceof InvCatalogRef ) ) { for ( InvDataset invDataset : this . getDatasets ( ) ) { InvDatasetImpl curDs = ( InvDatasetImpl ) invDataset ; ok &= curDs . finish ( ) ; } } return ok ; }", "nl": "Finish constructing after all elements have been added . This does the inheritence thing This can be called again if new elements are added ."}}
{"translation": {"code": "public static void writePointObsDataset ( PointObsDataset pobsDataset , String fileOut ) throws IOException { // see if we have an altitude String altUnits = null ; DataIterator iterOne = pobsDataset . getDataIterator ( - 1 ) ; while ( iterOne . hasNext ( ) ) { PointObsDatatype pobsData = ( PointObsDatatype ) iterOne . nextData ( ) ; ucar . unidata . geoloc . EarthLocation loc = pobsData . getLocation ( ) ; altUnits = Double . isNaN ( loc . getAltitude ( ) ) ? null : \"meters\" ; break ; } List < VariableSimpleIF > vars = pobsDataset . getDataVariables ( ) ; List < PointObVar > nvars = new ArrayList < PointObVar > ( vars . size ( ) ) ; // put vars in order for ( VariableSimpleIF v : vars ) { if ( v . getDataType ( ) . isNumeric ( ) ) nvars . add ( new PointObVar ( v ) ) ; } int ndoubles = vars . size ( ) ; double [ ] dvals = new double [ ndoubles ] ; for ( VariableSimpleIF v : vars ) { if ( v . getDataType ( ) . isString ( ) ) nvars . add ( new PointObVar ( v ) ) ; } String [ ] svals = new String [ vars . size ( ) - ndoubles ] ; FileOutputStream fos = new FileOutputStream ( fileOut ) ; DataOutputStream out = new DataOutputStream ( fos ) ; CFPointObWriter writer = new CFPointObWriter ( out , pobsDataset . getGlobalAttributes ( ) , altUnits , nvars , - 1 ) ; DataIterator iter = pobsDataset . getDataIterator ( 1000 * 1000 ) ; while ( iter . hasNext ( ) ) { PointObsDatatype pobsData = ( PointObsDatatype ) iter . nextData ( ) ; StructureData sdata = pobsData . getData ( ) ; int dcount = 0 ; int scount = 0 ; for ( PointObVar v : nvars ) { if ( v . getDataType ( ) . isNumeric ( ) ) { Array data = sdata . getArray ( v . getName ( ) ) ; data . resetLocalIterator ( ) ; if ( data . hasNext ( ) ) dvals [ dcount ++ ] = data . nextDouble ( ) ; } else if ( v . getDataType ( ) . isString ( ) ) { ArrayChar data = ( ArrayChar ) sdata . getArray ( v . getName ( ) ) ; svals [ scount ++ ] = data . getString ( ) ; } } ucar . unidata . geoloc . EarthLocation loc = pobsData . getLocation ( ) ; writer . addPoint ( loc . getLatitude ( ) , loc . getLongitude ( ) , loc . getAltitude ( ) , pobsData . getObservationTimeAsDate ( ) , dvals , svals ) ; } writer . finish ( ) ; }", "nl": "write data from a ucar . nc2 . dt . PointObsDataset into CF point format ."}}
{"translation": {"code": "public String getFullName ( ) { return ( parent == null ) ? name : ( parent . getFullName ( ) == null || parent . getFullName ( ) . length ( ) == 0 ) ? name : parent . getFullName ( ) + \"/\" + name ; }", "nl": "Get the full heirarchical name of the dataset which has all parent collection names ."}}
{"translation": {"code": "public InvAccess getAccess ( thredds . catalog . ServiceType type ) { for ( InvAccess a : getAccess ( ) ) { InvService s = a . getService ( ) ; if ( s . getServiceType ( ) == type ) return a ; } return null ; }", "nl": "Get access element of the specified service type for this dataset . If more than one get the first one ."}}
{"translation": {"code": "public InvService findService ( String name ) { if ( name == null ) return null ; // search local (but expanded) services for ( InvService p : services ) { if ( p . getName ( ) . equals ( name ) ) return p ; } // not found, look in parent if ( parent != null ) return parent . findService ( name ) ; return ( catalog == null ) ? null : catalog . findService ( name ) ; }", "nl": "Find the named service declared in this dataset or one of its parents ."}}
{"translation": {"code": "public String getUserCSS ( ) { return new StringBuilder ( ) . append ( \"<link rel='stylesheet' href='\" ) . append ( this . htmlConfig . prepareUrlStringForHtml ( this . htmlConfig . getPageCssUrl ( ) ) ) . append ( \"' type='text/css' >\" ) . toString ( ) ; }", "nl": "public static final String UNIDATA_CSS"}}
{"translation": {"code": "public java . util . List < InvMetadata > getMetadata ( thredds . catalog . MetadataType want ) { List < InvMetadata > result = new ArrayList < InvMetadata > ( ) ; for ( InvMetadata m : getMetadata ( ) ) { MetadataType mtype = MetadataType . getType ( m . getMetadataType ( ) ) ; if ( mtype == want ) result . add ( m ) ; } return result ; }", "nl": "Get the metadata elements of the specified type ."}}
{"translation": {"code": "protected InvDatasetImpl readDataset ( InvCatalogImpl catalog , InvDatasetImpl parent , Element dsElem , URI base ) { // deal with aliases String name = dsElem . getAttributeValue ( \"name\" ) ; String alias = dsElem . getAttributeValue ( \"alias\" ) ; if ( alias != null ) { InvDatasetImpl ds = ( InvDatasetImpl ) catalog . findDatasetByID ( alias ) ; if ( ds == null ) { factory . appendErr ( \" ** Parse error: dataset named \" + name + \" has illegal alias = \" + alias + \"\\n\" ) ; return null ; } return new InvDatasetImplProxy ( name , ds ) ; } InvDatasetImpl dataset = new InvDatasetImpl ( parent , name ) ; readDatasetInfo ( catalog , dataset , dsElem , base ) ; if ( InvCatalogFactory . debugXML ) System . out . println ( \" Dataset added: \" + dataset . dump ( ) ) ; return dataset ; }", "nl": "read a dataset element"}}
{"translation": {"code": "protected InvDatasetScan readDatasetScan ( InvCatalogImpl catalog , InvDatasetImpl parent , Element dsElem , URI base ) { InvDatasetScan datasetScan ; if ( dsElem . getAttributeValue ( \"dirLocation\" ) == null ) { if ( dsElem . getAttributeValue ( \"location\" ) == null ) { logger . error ( \"readDatasetScan(): datasetScan has neither a \\\"location\\\" nor a \\\"dirLocation\\\" attribute.\" ) ; datasetScan = null ; } else { return readDatasetScanNew ( catalog , parent , dsElem , base ) ; } } else { String name = dsElem . getAttributeValue ( \"name\" ) ; factory . appendWarning ( \"**Warning: Dataset \" + name + \" using old form of DatasetScan (dirLocation instead of location)\\n\" ) ; String path = dsElem . getAttributeValue ( \"path\" ) ; String scanDir = expandAliasForPath ( dsElem . getAttributeValue ( \"dirLocation\" ) ) ; String filter = dsElem . getAttributeValue ( \"filter\" ) ; String addDatasetSizeString = dsElem . getAttributeValue ( \"addDatasetSize\" ) ; String addLatest = dsElem . getAttributeValue ( \"addLatest\" ) ; String sortOrderIncreasingString = dsElem . getAttributeValue ( \"sortOrderIncreasing\" ) ; boolean sortOrderIncreasing = false ; if ( sortOrderIncreasingString != null ) if ( sortOrderIncreasingString . equalsIgnoreCase ( \"true\" ) ) sortOrderIncreasing = true ; boolean addDatasetSize = true ; if ( addDatasetSizeString != null ) if ( addDatasetSizeString . equalsIgnoreCase ( \"false\" ) ) addDatasetSize = false ; if ( path != null ) { if ( path . charAt ( 0 ) == ' ' ) path = path . substring ( 1 ) ; int last = path . length ( ) - 1 ; if ( path . charAt ( last ) == ' ' ) path = path . substring ( 0 , last ) ; } if ( scanDir != null ) { int last = scanDir . length ( ) - 1 ; if ( scanDir . charAt ( last ) != ' ' ) scanDir = scanDir + ' ' ; } Element atcElem = dsElem . getChild ( \"addTimeCoverage\" , defNS ) ; String dsNameMatchPattern = null ; String startTimeSubstitutionPattern = null ; String duration = null ; if ( atcElem != null ) { dsNameMatchPattern = atcElem . getAttributeValue ( \"datasetNameMatchPattern\" ) ; startTimeSubstitutionPattern = atcElem . getAttributeValue ( \"startTimeSubstitutionPattern\" ) ; duration = atcElem . getAttributeValue ( \"duration\" ) ; } try { datasetScan = new InvDatasetScan ( catalog , parent , name , path , scanDir , filter , addDatasetSize , addLatest , sortOrderIncreasing , dsNameMatchPattern , startTimeSubstitutionPattern , duration ) ; readDatasetInfo ( catalog , datasetScan , dsElem , base ) ; if ( InvCatalogFactory . debugXML ) System . out . println ( \" Dataset added: \" + datasetScan . dump ( ) ) ; } catch ( Exception e ) { logger . error ( \"Reading DatasetScan\" , e ) ; datasetScan = null ; } } return datasetScan ; }", "nl": "read a dataset scan element"}}
{"translation": {"code": "public InvCatalog getParentCatalog ( ) { if ( catalog != null ) return catalog ; return ( parent != null ) ? parent . getParentCatalog ( ) : null ; }", "nl": "Get containing catalog ."}}
{"translation": {"code": "public String getUniqueID ( ) { String authority = getAuthority ( ) ; if ( ( authority != null ) && ( getID ( ) != null ) ) return authority + \":\" + getID ( ) ; else if ( getID ( ) != null ) return getID ( ) ; else return null ; }", "nl": "If this dataset has an authority and an ID then the concatenation of them is the globally unique ID ."}}
{"translation": {"code": "private void transferInheritableMetadata ( InvDatasetImpl fromDs , ThreddsMetadata target , boolean copyInheritedMetadataFromParents ) { if ( fromDs == null ) return ; logger . debug ( \" transferInheritedMetadata= \" + fromDs . getName ( ) ) ; target . add ( fromDs . getLocalMetadataInheritable ( ) , true ) ; /* look through local metadata, find inherited InvMetadata elements\n    ThreddsMetadata tmd = fromDs.getLocalMetadata();\n    Iterator iter = tmd.getMetadata().iterator();\n    while (iter.hasNext()) {\n      InvMetadata meta = (InvMetadata) iter.next();\n      if (meta.isInherited()) {\n        if (!meta.isThreddsMetadata()) {\n          tmc.addMetadata( meta);\n        } else {\n          logger.debug(\"  transferInheritedMetadata \"+meta.hashCode()+\" = \"+meta);\n          meta.finish(); // LOOK ?? make sure XLink is read in.\n          tmc.add( meta.getThreddsMetadata(), true);\n        }\n      }\n    }   */ // now do the same for the parents if ( copyInheritedMetadataFromParents ) transferInheritableMetadata ( ( InvDatasetImpl ) fromDs . getParent ( ) , target , true ) ; }", "nl": "transfer inherited metadata consolidating it into target"}}
{"translation": {"code": "protected boolean emailOK ( ThreddsMetadata . Source p ) { String email = p . getEmail ( ) ; return email . indexOf ( ' ' ) >= 0 ; // should really do a regexp }", "nl": "check its an acceptable form of email"}}
{"translation": {"code": "public void writeXML ( InvCatalogImpl catalog , OutputStream os , boolean raw ) throws IOException { InvCatalogConvertIF converter = this . getCatalogConverter ( XMLEntityResolver . CATALOG_NAMESPACE_10 ) ; converter . writeXML ( catalog , os , raw ) ; }", "nl": "Write the InvCatalogImpl to the OutputStream as a InvCatalog 1 . 0 document ."}}
{"translation": {"code": "public int crawl ( InvCatalogImpl cat , CancelTask task , PrintWriter out , Object context ) { if ( out != null ) out . println ( \"***CATALOG \" + cat . getCreateFrom ( ) ) ; countCatrefs = 0 ; for ( InvDataset ds : cat . getDatasets ( ) ) { if ( type == Type . all ) crawlDataset ( ds , task , out , context , true ) ; else crawlDirectDatasets ( ds , task , out , context , true ) ; if ( ( task != null ) && task . isCancel ( ) ) break ; } return 1 + countCatrefs ; }", "nl": "Crawl a catalog thats already been opened . When you get to a dataset containing leaf datasets do all only the first or a randomly chosen one ."}}
{"translation": {"code": "public void addDataset ( int index , InvDatasetImpl ds ) { if ( ds == null ) return ; ds . setParent ( this ) ; datasets . add ( index , ds ) ; hashCode = 0 ; }", "nl": "Add a nested dataset at the location indicated by index ."}}
{"translation": {"code": "public void crawlDataset ( InvDataset ds , CancelTask task , PrintWriter out , Object context , boolean release ) { boolean isCatRef = ( ds instanceof InvCatalogRef ) ; if ( filter != null && filter . skipAll ( ds ) ) { if ( isCatRef && release ) ( ( InvCatalogRef ) ds ) . release ( ) ; return ; } boolean isDataScan = ds . findProperty ( \"DatasetScan\" ) != null ; if ( isCatRef ) { InvCatalogRef catref = ( InvCatalogRef ) ds ; if ( out != null ) out . println ( \" **CATREF \" + catref . getURI ( ) + \" (\" + ds . getName ( ) + \") \" ) ; countCatrefs ++ ; if ( ! listen . getCatalogRef ( catref , context ) ) { if ( release ) catref . release ( ) ; return ; } } if ( ! isCatRef || isDataScan ) listen . getDataset ( ds , context ) ; // recurse - depth first List < InvDataset > dlist = ds . getDatasets ( ) ; if ( isCatRef ) { InvCatalogRef catref = ( InvCatalogRef ) ds ; if ( ! isDataScan ) { listen . getDataset ( catref . getProxyDataset ( ) , context ) ; // wait till a catref is read, so all metadata is there ! } } for ( InvDataset dds : dlist ) { crawlDataset ( dds , task , out , context , release ) ; if ( ( task != null ) && task . isCancel ( ) ) break ; } if ( isCatRef && release ) { InvCatalogRef catref = ( InvCatalogRef ) ds ; catref . release ( ) ; } }", "nl": "Crawl this dataset recursively return all datasets"}}
{"translation": {"code": "public void addDocumentation ( String type , String content ) { if ( content == null ) { removeDocumentation ( type ) ; return ; } content = content . trim ( ) ; for ( InvDocumentation doc : getDocumentation ( ) ) { String dtype = doc . getType ( ) ; if ( ( dtype != null ) && dtype . equalsIgnoreCase ( type ) ) { doc . setInlineContent ( content ) ; return ; } } if ( content . length ( ) > 0 ) addDocumentation ( new InvDocumentation ( null , null , null , type , content ) ) ; }", "nl": "set specified type of documentation"}}
{"translation": {"code": "public void removeDocumentation ( String type ) { Iterator iter = docs . iterator ( ) ; while ( iter . hasNext ( ) ) { InvDocumentation doc = ( InvDocumentation ) iter . next ( ) ; String dtype = doc . getType ( ) ; if ( ( dtype != null ) && dtype . equalsIgnoreCase ( type ) ) iter . remove ( ) ; } }", "nl": "remove all instances of specified type of documentation"}}
{"translation": {"code": "public void add ( ThreddsMetadata tmd , boolean includeInherited ) { creators . addAll ( tmd . getCreators ( ) ) ; contributors . addAll ( tmd . getContributors ( ) ) ; dates . addAll ( tmd . getDates ( ) ) ; docs . addAll ( tmd . getDocumentation ( ) ) ; keywords . addAll ( tmd . getKeywords ( ) ) ; projects . addAll ( tmd . getProjects ( ) ) ; properties . addAll ( tmd . getProperties ( ) ) ; publishers . addAll ( tmd . getPublishers ( ) ) ; variables . addAll ( tmd . getVariables ( ) ) ; if ( includeInherited ) metadata . addAll ( tmd . getMetadata ( ) ) ; else { for ( InvMetadata mdata : tmd . getMetadata ( ) ) { if ( ! mdata . isInherited ( ) ) metadata . add ( mdata ) ; } } // LOOK! should be copies ??!! if ( gc == null ) gc = tmd . getGeospatialCoverage ( ) ; if ( timeCoverage == null ) timeCoverage = tmd . getTimeCoverage ( ) ; if ( serviceName == null ) serviceName = tmd . getServiceName ( ) ; if ( dataType == null ) dataType = tmd . getDataType ( ) ; if ( dataSize == 0.0 ) dataSize = tmd . getDataSize ( ) ; if ( dataFormat == null ) dataFormat = tmd . getDataFormatType ( ) ; if ( authorityName == null ) authorityName = tmd . getAuthority ( ) ; if ( variableMapLink == null ) variableMapLink = tmd . getVariableMap ( ) ; }", "nl": "Add all the content from another ThreddsMetadata"}}
{"translation": {"code": "public void removeService ( InvService service ) { servicesLocal . remove ( service ) ; services . remove ( service ) ; // remove nested servers for ( InvService nested : service . getServices ( ) ) { services . remove ( nested ) ; } }", "nl": "Remove a service from this dataset ."}}
{"translation": {"code": "public void setServicesLocal ( java . util . List < InvService > s ) { this . services = new ArrayList <> ( ) ; this . servicesLocal = new ArrayList <> ( ) ; for ( InvService elem : s ) { addService ( elem ) ; } hashCode = 0 ; }", "nl": "Set the list of services attached specifically to this dataset . Discard any previous servies ."}}
{"translation": {"code": "public ThreddsDataFactory . Result openFeatureDataset ( InvAccess access , ucar . nc2 . util . CancelTask task ) throws IOException { InvDataset invDataset = access . getDataset ( ) ; ThreddsDataFactory . Result result = new Result ( ) ; if ( invDataset . getDataType ( ) == null ) { result . errLog . format ( \"InvDatasert must specify a FeatureType%n\" ) ; result . fatalError = true ; return result ; } return openFeatureDataset ( invDataset . getDataType ( ) , access , task , result ) ; }", "nl": "Open a FeatureDataset from an InvAccess object ."}}
{"translation": {"code": "private String idvDatasetCatalog ( String xml ) { String ret = xml . replace ( \"variables\" , \"Variables\" ) ; ret = ret . replace ( \"timeCoverage\" , \"TimeSpan\" ) ; StringBuilder sub = new StringBuilder ( ret . substring ( 0 , ret . indexOf ( \"<geospatialCoverage>\" ) ) ) ; sub . append ( \"<LatLonBox>\\n\\t<north>90.0</north>\\n\\t<south>-90.0</south>\" ) ; sub . append ( \"\\n\\t<east>180.0</east>\\n\\t<west>-180.0</west></LatLonBox>\" ) ; String endCoverage = \"</geospatialCoverage>\" ; sub . append ( ret . substring ( ret . indexOf ( endCoverage ) + endCoverage . length ( ) ) ) ; return sub . toString ( ) ; }", "nl": "This code tweaks our catalog output to match ."}}
{"translation": {"code": "private boolean put ( DataRootExt dateRootExt ) { map . put ( dateRootExt . getPath ( ) , dateRootExt ) ; return treeSet . add ( dateRootExt . getPath ( ) ) ; }", "nl": "Add a dataRootExt to in - memory tree ."}}
{"translation": {"code": "public String findLongestPathMatch ( String reqPath ) { SortedSet < String > tail = treeSet . tailSet ( reqPath ) ; if ( tail . isEmpty ( ) ) return null ; String after = tail . first ( ) ; if ( reqPath . startsWith ( after ) ) // common case return tail . first ( ) ; // have to check more, until no common starting chars for ( String key : tail ) { if ( reqPath . startsWith ( key ) ) return key ; // terminate when there's no match at all. if ( StringUtil2 . match ( reqPath , key ) == 0 ) break ; } return null ; }", "nl": "Find the longest path match ."}}
{"translation": {"code": "public String toNcML ( String url ) throws IOException { NcMLWriter ncmlWriter = new NcMLWriter ( ) ; ncmlWriter . setWriteVariablesPredicate ( NcMLWriter . writeNoVariablesPredicate ) ; Element netcdfElement = ncmlWriter . makeNetcdfElement ( this , url ) ; return ncmlWriter . writeToString ( netcdfElement ) ; }", "nl": "CDL representation of Netcdf header info non strict"}}
{"translation": {"code": "public void renderPlanView ( java . awt . Graphics2D g , AffineTransform dFromN ) { if ( ( dataState . grid == null ) || ( colorScale == null ) || ( drawProjection == null ) ) return ; if ( ! drawGrid && ! drawContours ) return ; // no anitaliasing g . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , RenderingHints . VALUE_ANTIALIAS_OFF ) ; dataH = readHSlice ( wantLevel , wantTime , wantEnsemble , wantRunTime ) ; if ( dataH == null ) return ; setColorScaleParams ( ) ; if ( drawGrid ) drawGridHoriz ( g , dataH ) ; //if (drawContours) //  drawContours(g, dataH.transpose(0, 1), dFromN); if ( drawGridLines ) drawGridLines ( g , dataH ) ; if ( drawBB ) drawGridBB ( g , this . dataState . coverageDataset . getLatlonBoundingBox ( ) ) ; }", "nl": "Do the rendering to the given Graphics2D object ."}}
{"translation": {"code": "protected boolean addParameter ( CoordinateTransform rs , String paramName , NetcdfFile ds , String varNameEscaped ) { if ( null == ( ds . findVariable ( varNameEscaped ) ) ) { if ( null != errBuffer ) errBuffer . format ( \"CoordTransBuilder %s: no Variable named %s%n\" , getTransformName ( ) , varNameEscaped ) ; return false ; } rs . addParameter ( new Parameter ( paramName , varNameEscaped ) ) ; return true ; }", "nl": "Add a Parameter to a CoordinateTransform . Make sure that the variable exists . If readData is true read the data and use it as the value of the parameter otherwise use the variable name as the value of the parameter ."}}
{"translation": {"code": "public CalendarDateRange getCalendarDateRange ( Calendar cal ) { if ( dateRange == null ) return null ; if ( cal . equals ( Calendar . getDefault ( ) ) ) return dateRange ; // otherwise must reparse return makeCalendarDateRange ( cal ) ; }", "nl": "return requested CalendarDateRange ."}}
{"translation": {"code": "@ Override public String getResourcePath ( DapRequest drq , String location ) throws DapException { String realpath ; if ( TdsRequestedDataset . getDatasetManager ( ) != null ) { realpath = TdsRequestedDataset . getLocationFromRequestPath ( location ) ; } else { assert TdsRequestedDataset . getDatasetManager ( ) == null ; String prefix = drq . getResourceRoot ( ) ; assert ( prefix != null ) ; realpath = DapUtil . canonjoin ( prefix , location ) ; } if ( ! TESTING ) { if ( ! TdsRequestedDataset . resourceControlOk ( drq . getRequest ( ) , drq . getResponse ( ) , realpath ) ) throw new DapException ( \"Not authorized: \" + location ) . setCode ( DapCodes . SC_FORBIDDEN ) ; } File f = new File ( realpath ) ; if ( ! f . exists ( ) || ! f . canRead ( ) ) throw new DapException ( \"Not found: \" + location ) . setCode ( DapCodes . SC_NOT_FOUND ) ; //ncfile = TdsRequestedDataset.getNetcdfFile(this.request, this.response, path); return realpath ; }", "nl": "to work under Intellij ."}}
{"translation": {"code": "static public boolean isUnsigned ( opendap . dap . BaseType dtype ) { return ( dtype instanceof DByte ) || ( dtype instanceof DUInt16 ) || ( dtype instanceof DUInt32 ) ; }", "nl": "Get whether this is an unsigned type ."}}
{"translation": {"code": "private boolean isGroup ( DStructure dstruct ) { BaseType parent = ( BaseType ) dstruct . getParent ( ) ; if ( parent == null ) return true ; if ( parent instanceof DStructure ) return isGroup ( ( DStructure ) parent ) ; return true ; }", "nl": "make a structure into a group if its scalar and all parents are groups"}}
{"translation": {"code": "private boolean box9 ( double wantLat , double wantLon , int [ ] rectIndex ) { int row = rectIndex [ 0 ] ; int minrow = Math . max ( row - 1 , 0 ) ; int maxrow = Math . min ( row + 1 , nrows ) ; int col = rectIndex [ 1 ] ; int mincol = Math . max ( col - 1 , 0 ) ; int maxcol = Math . min ( col + 1 , ncols ) ; if ( debug ) System . out . printf ( \"%n   box9:\" ) ; for ( int i = minrow ; i <= maxrow ; i ++ ) for ( int j = mincol ; j <= maxcol ; j ++ ) { rectIndex [ 0 ] = i ; rectIndex [ 1 ] = j ; if ( contains ( wantLat , wantLon , rectIndex ) ) return true ; } return false ; }", "nl": "we think its got to be in one of the 9 boxes around rectIndex"}}
{"translation": {"code": "void putResourceControl ( Dataset ds ) { if ( logger . isDebugEnabled ( ) ) logger . debug ( \"putResourceControl \" + ds . getRestrictAccess ( ) + \" for \" + ds . getName ( ) ) ; resourceControlHash . put ( ds . getUrlPath ( ) , ds . getRestrictAccess ( ) ) ; // resourceControl is inherited, but no guarentee that children paths are related, unless its a //   DatasetScan or InvDatasetFmrc. So we keep track of all datasets that have a ResourceControl, including children // DatasetScan and InvDatasetFmrc must use a PathMatcher, others can use exact match (hash) /* if (ds instanceof DatasetScan) {\n      DatasetScan scan = (DatasetScan) ds;\n      if (debugResourceControl)\n        System.out.println(\"putResourceControl \" + ds.getRestrictAccess() + \" for datasetScan \" + scan.getPath());\n      resourceControlMatcher.put(scan.getPath(), ds.getRestrictAccess());\n\n    } else { // dataset\n      if (debugResourceControl)\n        System.out.println(\"putResourceControl \" + ds.getRestrictAccess() + \" for dataset \" + ds.getUrlPath());\n\n      // LOOK: seems like you only need to add if InvAccess.InvService.isReletive\n      // LOOK: seems like we should use resourceControlMatcher to make sure we match .dods, etc\n      for (Access access : ds.getAccess()) {\n        if (access.getService().isRelativeBase())\n          resourceControlHash.put(access.getUrlPath(), ds.getRestrictAccess());\n      }\n    }  */ hasResourceControl = true ; }", "nl": "This tracks Dataset elements that have resource control attributes"}}
{"translation": {"code": "private Object makeDynamicCatalog ( String path , URI baseURI ) throws IOException { boolean isLatest = path . endsWith ( \"/latest.xml\" ) ; // strip off the filename int pos = path . lastIndexOf ( \"/\" ) ; String workPath = ( pos >= 0 ) ? path . substring ( 0 , pos ) : path ; String filename = ( pos > 0 ) ? path . substring ( pos + 1 ) : path ; // now look through the data roots for a maximal match DataRootManager . DataRootMatch match = dataRootManager . findDataRootMatch ( workPath ) ; if ( match == null ) return null ; // Feature Collection if ( match . dataRoot . getFeatureCollection ( ) != null ) { InvDatasetFeatureCollection fc = featureCollectionCache . get ( match . dataRoot . getFeatureCollection ( ) ) ; if ( isLatest ) return fc . makeLatest ( match . remaining , path , baseURI ) ; else return fc . makeCatalog ( match . remaining , path , baseURI ) ; } // DatasetScan DatasetScan dscan = match . dataRoot . getDatasetScan ( ) ; if ( dscan != null ) { if ( log . isDebugEnabled ( ) ) log . debug ( \"makeDynamicCatalog(): Calling DatasetScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\" ) ; CatalogBuilder cat ; if ( isLatest ) cat = dscan . makeCatalogForLatest ( workPath , baseURI ) ; else cat = dscan . makeCatalogForDirectory ( workPath , baseURI ) ; if ( null == cat ) log . error ( \"makeDynamicCatalog(): DatasetScan.makeCatalogForDirectory failed = \" + workPath ) ; return cat ; } // CatalogScan CatalogScan catScan = match . dataRoot . getCatalogScan ( ) ; if ( catScan != null ) { if ( ! filename . equalsIgnoreCase ( CatalogScan . CATSCAN ) ) { // its an actual catalog return catScan . getCatalog ( tdsContext . getThreddsDirectory ( ) , match . remaining , filename , ccc ) ; } if ( log . isDebugEnabled ( ) ) log . debug ( \"makeDynamicCatalog(): Calling CatalogScan.makeCatalogForDirectory( \" + baseURI + \", \" + path + \").\" ) ; CatalogBuilder cat = catScan . makeCatalogFromDirectory ( tdsContext . getThreddsDirectory ( ) , match . remaining , baseURI ) ; if ( null == cat ) log . error ( \"makeDynamicCatalog(): CatalogScan.makeCatalogForDirectory failed = \" + workPath ) ; return cat ; } log . warn ( \"makeDynamicCatalog() failed for =\" + workPath + \" request path= \" + path ) ; return null ; }", "nl": "barfola on the return type"}}
{"translation": {"code": "public void processEvents ( ) { if ( ! enable ) return ; for ( ; ; ) { // wait for key to be signalled WatchKey key ; try { key = watcher . take ( ) ; } catch ( InterruptedException x ) { return ; } Path dir = keys . get ( key ) ; if ( dir == null ) { System . err . println ( \"WatchKey not recognized!!\" ) ; continue ; } for ( WatchEvent < ? > event : key . pollEvents ( ) ) { WatchEvent . Kind kind = event . kind ( ) ; // TBD - provide example of how OVERFLOW event is handled if ( kind == OVERFLOW ) { continue ; } // Context for directory entry event is the file name of entry WatchEvent < Path > ev = cast ( event ) ; Path name = ev . context ( ) ; Path child = dir . resolve ( name ) ; // print out event System . out . format ( \"%s: %s%n\" , event . kind ( ) . name ( ) , child ) ; // if directory is created, and watching recursively, then // register it and its sub-directories if ( recursive && ( kind == ENTRY_CREATE ) ) { try { if ( Files . isDirectory ( child , NOFOLLOW_LINKS ) ) { registerAll ( child ) ; } } catch ( IOException x ) { // ignore to keep sample readbale } } } // reset key and remove from set if directory no longer accessible boolean valid = key . reset ( ) ; if ( ! valid ) { keys . remove ( key ) ; // all directories are inaccessible if ( keys . isEmpty ( ) ) { break ; } } } }", "nl": "Process all events for keys queued to the watcher"}}
{"translation": {"code": "public void register ( Path dir ) throws IOException { if ( ! enable ) return ; WatchKey key = dir . register ( watcher , ENTRY_CREATE , ENTRY_DELETE , ENTRY_MODIFY ) ; if ( trace ) { Path prev = keys . get ( key ) ; if ( prev == null ) { System . out . format ( \"CatalogWatcher register: %s%n\" , dir ) ; } else { if ( ! dir . equals ( prev ) ) { System . out . format ( \"update: %s -> %s%n\" , prev , dir ) ; } } } keys . put ( key , dir ) ; }", "nl": "Register the given directory with the WatchService"}}
{"translation": {"code": "public Iterable < ? extends CatalogExt > getCatalogs ( ) { if ( catalogs == null ) readCatalogs ( ) ; List < CatalogExt > result = new ArrayList <> ( ) ; for ( CatalogExt ext : catalogs . values ( ) ) result . ( ext ) ; Collections . sort ( result , ( o1 , o2 ) -> o1 . getCatRelLocation ( ) . compareTo ( o2 . getCatRelLocation ( ) ) ) ; // java 8 lambda, baby return result ; }", "nl": "return sorted catalogs"}}
{"translation": {"code": "static public void exit ( ) { if ( timer != null ) { timer . cancel ( ) ; System . out . printf ( \"DiskCache2.exit()%n\" ) ; } timer = null ; }", "nl": "Be sure to call this when your application exits otherwise your process may not exit without being killed ."}}
{"translation": {"code": "public static void cleanupBefore ( String pathname , long trackerNumber ) { for ( long tnum = trackerNumber - 1 ; tnum > 0 ; tnum -- ) { File oldDatabaseFile = new File ( pathname + datasetName + \".\" + tnum ) ; if ( ! oldDatabaseFile . exists ( ) ) break ; if ( oldDatabaseFile . delete ( ) ) { catalogInitLog . info ( \"DatasetTrackerChronicle deleted {} \" , oldDatabaseFile . getAbsolutePath ( ) ) ; } else { catalogInitLog . error ( \"DatasetTrackerChronicle not able to delete {} \" , oldDatabaseFile . getAbsolutePath ( ) ) ; } } }", "nl": "delete old databases"}}
{"translation": {"code": "public CatalogBuilder makeCatalogBuilder ( ) { CatalogBuilder builder = new CatalogBuilder ( this ) ; for ( Dataset ds : getDatasetsLocal ( ) ) { builder . addDataset ( makeDatasetBuilder ( null , ds ) ) ; } return builder ; }", "nl": "turn ConfigCatalog into a mutable CatalogBuilder so we can mutate"}}
{"translation": {"code": "public void addVariableAttribute ( String varName , String attName , Array value ) { Attribute att = new Attribute ( attName , value ) ; addVariableAttribute ( varName , att ) ; }", "nl": "Add an attribute of type Array to the named Variable . Must be in define mode ."}}
{"translation": {"code": "public Attribute renameGlobalAttribute ( String oldName , String newName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; Attribute att = findGlobalAttribute ( oldName ) ; if ( null == att ) return null ; rootGroup . remove ( att ) ; att = new Attribute ( newName , att . getValues ( ) ) ; rootGroup . addAttribute ( att ) ; return att ; }", "nl": "Rename a global Attribute . Must be in define mode ."}}
{"translation": {"code": "public Attribute renameVariableAttribute ( String varName , String attName , String newName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; Variable v = findVariable ( varName ) ; if ( v == null ) return null ; Attribute att = v . findAttribute ( attName ) ; if ( null == att ) return null ; v . remove ( att ) ; att = new Attribute ( newName , att . getValues ( ) ) ; v . addAttribute ( att ) ; return att ; }", "nl": "Rename a variable Attribute . Must be in define mode ."}}
{"translation": {"code": "public Attribute deleteGlobalAttribute ( String attName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; Attribute att = findGlobalAttribute ( attName ) ; if ( null == att ) return null ; rootGroup . remove ( att ) ; return att ; }", "nl": "Delete a global Attribute . Must be in define mode ."}}
{"translation": {"code": "private Optional < CoverageCoordAxisBuilder > subsetValues ( double minValue , double maxValue , int stride ) { if ( axis . getSpacing ( ) == CoverageCoordAxis . Spacing . discontiguousInterval ) return subsetValuesDiscontinuous ( minValue , maxValue , stride ) ; double lower = axis . isAscending ( ) ? Math . min ( minValue , maxValue ) : Math . max ( minValue , maxValue ) ; double upper = axis . isAscending ( ) ? Math . max ( minValue , maxValue ) : Math . min ( minValue , maxValue ) ; int minIndex = findCoordElement ( lower , false ) ; int maxIndex = findCoordElement ( upper , false ) ; if ( minIndex >= axis . getNcoords ( ) ) return Optional . empty ( String . format ( \"no points in subset: lower %f > end %f\" , lower , axis . getEndValue ( ) ) ) ; if ( maxIndex < 0 ) return Optional . empty ( String . format ( \"no points in subset: upper %f < start %f\" , upper , axis . getStartValue ( ) ) ) ; if ( minIndex < 0 ) minIndex = 0 ; if ( maxIndex >= axis . getNcoords ( ) ) maxIndex = axis . getNcoords ( ) - 1 ; int count = maxIndex - minIndex + 1 ; if ( count <= 0 ) throw new IllegalArgumentException ( \"no points in subset\" ) ; try { return Optional . of ( subsetByIndex ( new Range ( minIndex , maxIndex , stride ) ) ) ; } catch ( InvalidRangeException e ) { return Optional . empty ( e . getMessage ( ) ) ; } }", "nl": "look must handle discon interval different"}}
{"translation": {"code": "public void doPost ( HttpServletRequest req , HttpServletResponse res ) throws ServletException , IOException { log . info ( \"doPost(): \" + UsageLog . setupRequestContext ( req ) ) ; // Check that we have a file upload request boolean isMultipart = ServletFileUpload . isMultipartContent ( req ) ; if ( ! isMultipart ) { log . info ( \"doPost(): \" + UsageLog . closingMessageForRequestContext ( HttpServletResponse . SC_BAD_REQUEST , 0 ) ) ; res . sendError ( HttpServletResponse . SC_BAD_REQUEST ) ; return ; } //Create a new file upload handler ServletFileUpload upload = new ServletFileUpload ( this . cdmValidatorContext . getFileuploadFileItemFactory ( ) ) ; upload . setSizeMax ( this . cdmValidatorContext . getMaxFileUploadSize ( ) ) ; // maximum bytes before a FileUploadException will be thrown List < FileItem > fileItems ; try { fileItems = ( List < FileItem > ) upload . parseRequest ( req ) ; } catch ( FileUploadException e ) { log . info ( \"doPost(): Validator FileUploadException\" , e ) ; log . info ( \"doPost(): \" + UsageLog . closingMessageForRequestContext ( HttpServletResponse . SC_BAD_REQUEST , 0 ) ) ; if ( ! res . isCommitted ( ) ) res . sendError ( HttpServletResponse . SC_BAD_REQUEST ) ; return ; } //Process the uploaded items String username = null ; boolean wantXml = false ; for ( FileItem item : fileItems ) { if ( item . isFormField ( ) ) { if ( \"username\" . equals ( item . getFieldName ( ) ) ) username = item . getString ( ) ; if ( \"xml\" . equals ( item . getFieldName ( ) ) ) wantXml = item . getString ( ) . equals ( \"true\" ) ; } } for ( FileItem item : fileItems ) { if ( ! item . isFormField ( ) ) { try { processUploadedFile ( req , res , ( DiskFileItem ) item , username , wantXml ) ; return ; } catch ( Exception e ) { log . info ( \"doPost(): Validator processUploadedFile\" , e ) ; log . info ( \"doPost(): \" + UsageLog . closingMessageForRequestContext ( HttpServletResponse . SC_BAD_REQUEST , 0 ) ) ; res . sendError ( HttpServletResponse . SC_BAD_REQUEST , e . getMessage ( ) ) ; } } } }", "nl": "POST handles uploaded files"}}
{"translation": {"code": "synchronized protected void setAuthenticationAndProxy ( HttpClientBuilder cb ) throws HTTPException { // First, setup the ssl factory cb . setSSLSocketFactory ( ( SSLConnectionSocketFactory ) authcontrols . get ( AuthProp . SSLFACTORY ) ) ; // Second, Construct a CredentialsProvider that is // the union of the Proxy credentials plus // either the global or local credentials; local overrides global // Unfortunately, we cannot either clone or extract the contents // of the client supplied provider, so we are forced (for now) // to modify the client supplied provider. // Look in the local credentials first for for best scope match AuthScope bestMatch = HTTPAuthUtil . bestmatch ( scope , localcreds . keySet ( ) ) ; CredentialsProvider cp = null ; if ( bestMatch != null ) { cp = localcreds . get ( bestMatch ) ; } else { bestMatch = HTTPAuthUtil . bestmatch ( scope , globalcredfactories . keySet ( ) ) ; if ( bestMatch != null ) { HTTPProviderFactory factory = globalcredfactories . get ( bestMatch ) ; cp = factory . getProvider ( bestMatch ) ; } } // Build the proxy credentials and AuthScope Credentials proxycreds = null ; AuthScope proxyscope = null ; String user = ( String ) authcontrols . get ( AuthProp . PROXYUSER ) ; String pwd = ( String ) authcontrols . get ( AuthProp . PROXYPWD ) ; HttpHost httpproxy = ( HttpHost ) authcontrols . get ( AuthProp . HTTPPROXY ) ; HttpHost httpsproxy = ( HttpHost ) authcontrols . get ( AuthProp . HTTPSPROXY ) ; if ( user != null && ( httpproxy != null || httpsproxy != null ) ) { if ( httpproxy != null ) proxyscope = HTTPAuthUtil . hostToAuthScope ( httpproxy ) ; else //httpsproxy != null proxyscope = HTTPAuthUtil . hostToAuthScope ( httpsproxy ) ; proxycreds = new UsernamePasswordCredentials ( user , pwd ) ; } if ( cp == null && proxycreds != null && proxyscope != null ) { // If client provider is null and proxycreds are not, // then use proxycreds alone cp = new BasicCredentialsProvider ( ) ; cp . setCredentials ( proxyscope , proxycreds ) ; } else if ( cp != null && proxycreds != null && proxyscope != null ) { // If client provider is not null and proxycreds are not, // then add proxycreds to the client provider cp . setCredentials ( proxyscope , proxycreds ) ; } if ( cp != null ) this . sessioncontext . setCredentialsProvider ( cp ) ; }", "nl": "Handle authentication and Proxy ing"}}
{"translation": {"code": "@ Override public long length ( ) { // If the summary is already in the cache, return it. // It'll have been added by a listDatasets() call on the parent directory. S3ObjectSummary objectSummary = objectSummaryCache . getIfPresent ( s3uri ) ; if ( objectSummary != null ) { return objectSummary . getSize ( ) ; } /* Get the metadata directly from S3. This will be expensive.\n         * We get punished hard if length() and/or lastModified() is called on a bunch of datasets without\n         * listDatasets() first being called on their parent directory.\n         *\n         * So, is the right thing to do here \"getParentDataset().listDatasets()\" and then query the cache again?\n         * Perhaps, but listDatasets() throws an IOException, and length() and lastModified() do not.\n         * We would have to change their signatures and the upstream client code to make it work.\n         */ ObjectMetadata metadata = threddsS3Client . getObjectMetadata ( s3uri ) ; if ( metadata != null ) { return metadata . getContentLength ( ) ; } else { // \"this\" may be a collection or non-existent. In both cases, we return 0. return 0 ; } }", "nl": "Returns the size of the dataset in bytes . Will be zero if this dataset is a collection or non - existent ."}}
{"translation": {"code": "@ Override public Date lastModified ( ) { S3ObjectSummary objectSummary = objectSummaryCache . getIfPresent ( s3uri ) ; if ( objectSummary != null ) { return objectSummary . getLastModified ( ) ; } ObjectMetadata metadata = threddsS3Client . getObjectMetadata ( s3uri ) ; if ( metadata != null ) { return metadata . getLastModified ( ) ; } else { // \"this\" may be a collection or non-existent. In both cases, we return null. return null ; } }", "nl": "Returns the date that the dataset was last modified . Will be null if the dataset is a collection or non - existent ."}}
{"translation": {"code": "public String writeToString ( Element elem ) { try ( StringWriter writer = new StringWriter ( ) ) { writeToWriter ( elem , writer ) ; return writer . toString ( ) ; } catch ( IOException e ) { throw new AssertionError ( \"CAN'T HAPPEN: StringWriter.close() is a no-op.\" , e ) ; } }", "nl": "Writes an NcML element to a string ."}}
{"translation": {"code": "public void writeToFile ( Element elem , File outFile ) throws IOException { try ( OutputStream outStream = new BufferedOutputStream ( new FileOutputStream ( outFile , false ) ) ) { writeToStream ( elem , outStream ) ; } }", "nl": "Writes an NcML element to an output file ."}}
{"translation": {"code": "public static String unescapeURL ( String url ) { String newurl ; newurl = urlDecode ( url ) ; return newurl ; }", "nl": "Decode all of the parts of the url including query and fragment"}}
{"translation": {"code": "private int findClosest ( ArrayDouble . D2 boundsForRun , double target ) { double minDiff = Double . MAX_VALUE ; int idxFound = - 1 ; int n = boundsForRun . getShape ( ) [ 0 ] ; for ( int i = 0 ; i < n ; i ++ ) { double midpoint = ( boundsForRun . get ( i , 0 ) + boundsForRun . get ( i , 1 ) ) / 2.0 ; double diff = Math . abs ( midpoint - target ) ; if ( diff < minDiff ) { minDiff = diff ; idxFound = i ; } } return idxFound ; }", "nl": "return index of closest value to target"}}
{"translation": {"code": "public Array readData2 ( CoordsSet want , RangeIterator yRange , RangeIterator xRange ) throws IOException { if ( vindex instanceof PartitionCollectionImmutable . VariableIndexPartitioned ) return readDataFromPartition2 ( ( PartitionCollectionImmutable . VariableIndexPartitioned ) vindex , want , yRange , xRange ) ; else return readDataFromCollection2 ( vindex , want , yRange , xRange ) ; }", "nl": "Coordinate based subsetting for Coverage"}}
{"translation": {"code": "@ Nullable synchronized Record getRecordAt ( SubsetParams coords ) { int [ ] want = new int [ getRank ( ) ] ; int count = 0 ; int runIdx = - 1 ; for ( Coordinate coord : getCoordinates ( ) ) { int idx = - 1 ; switch ( coord . getType ( ) ) { case runtime : CalendarDate runtimeCooord = coords . getRunTime ( ) ; idx = coord . getIndex ( runtimeCooord ) ; runIdx = idx ; break ; case timeIntv : double [ ] timeIntv = coords . getTimeOffsetIntv ( ) ; idx = coord . getIndex ( new TimeCoordIntvValue ( ( int ) timeIntv [ 0 ] , ( int ) timeIntv [ 1 ] ) ) ; break ; case time : Double timeOffset = coords . getTimeOffset ( ) ; // Double int coordInt = timeOffset . intValue ( ) ; idx = coord . getIndex ( coordInt ) ; break ; case time2D : timeIntv = coords . getTimeOffsetIntv ( ) ; if ( timeIntv != null ) { TimeCoordIntvValue coordTinv = new TimeCoordIntvValue ( ( int ) timeIntv [ 0 ] , ( int ) timeIntv [ 1 ] ) ; idx = ( ( CoordinateTime2D ) coord ) . findTimeIndexFromVal ( runIdx , coordTinv ) ; // LOOK can only use if orthogonal break ; } Double timeCoord = coords . getTimeOffset ( ) ; if ( timeCoord != null ) { coordInt = timeCoord . intValue ( ) ; idx = ( ( CoordinateTime2D ) coord ) . findTimeIndexFromVal ( runIdx , coordInt ) ; break ; } // the OneTime case CoordinateTime2D coord2D = ( CoordinateTime2D ) coord ; if ( coord2D . getNtimes ( ) == 1 ) { idx = 0 ; break ; } throw new IllegalStateException ( \"time2D must have timeOffset ot timeOffsetIntv coordinare\" ) ; case vert : double [ ] vertIntv = coords . getVertCoordIntv ( ) ; if ( vertIntv != null ) { VertCoordValue coordVert = new VertCoordValue ( vertIntv [ 0 ] , vertIntv [ 1 ] ) ; idx = coord . getIndex ( coordVert ) ; break ; } Double vertCoord = coords . getVertCoord ( ) ; if ( vertCoord != null ) { VertCoordValue coordVert = new VertCoordValue ( vertCoord ) ; idx = coord . getIndex ( coordVert ) ; } break ; case ens : Double ensVal = coords . getEnsCoord ( ) ; idx = ( ( CoordinateEns ) coord ) . getIndexByMember ( ensVal ) ; break ; default : logger . warn ( \"GribCollectionImmutable: missing CoordVal for {}%n\" , coord . getName ( ) ) ; } if ( idx < 0 ) { logger . debug ( \"Cant find index for value in axis {} in variable {}\" , coord . getName ( ) , name ) ; return null ; } want [ count ++ ] = idx ; } return sa . getContent ( want ) ; }", "nl": "coord based record finding . note only one record at a time"}}
{"translation": {"code": "public TimeHelper setReferenceDate ( CalendarDate refDate ) { CalendarDateUnit cdUnit = CalendarDateUnit . of ( dateUnit . getCalendar ( ) , dateUnit . getCalendarField ( ) , refDate ) ; return new TimeHelper ( cdUnit ) ; }", "nl": "copy on modify"}}
{"translation": {"code": "private CoverageCoordAxis1D findDependent ( CoverageCoordAxis independentAxis , AxisType axisType ) { for ( CoverageCoordAxis axis : axes ) { if ( axis . getDependenceType ( ) == CoverageCoordAxis . DependenceType . dependent ) { for ( String axisName : axis . dependsOn ) { if ( axisName . equalsIgnoreCase ( independentAxis . getName ( ) ) && axis . getAxisType ( ) == axisType ) return ( CoverageCoordAxis1D ) axis ; } } } return null ; }", "nl": "find the dependent axis that depend on independentAxis"}}
{"translation": {"code": "static public void printArray ( Array array , PrintWriter pw ) { printArray ( array , null , null , pw , new Indent ( 2 ) , null , true ) ; }", "nl": "Print array to PrintWriter"}}
{"translation": {"code": "private Optional < List < RangeIterator > > computeBounds ( LatLonRect llbb , int horizStride ) { synchronized ( this ) { if ( edges == null ) edges = new Edges ( ) ; } return edges . computeBoundsExhaustive ( llbb , horizStride ) ; }", "nl": "return y x ranges"}}
{"translation": {"code": "private Optional < CoverageCoordAxis > subsetLon ( LatLonRect llbb , int stride ) throws InvalidRangeException { double wantMin = LatLonPointImpl . lonNormalFrom ( llbb . getLonMin ( ) , lonAxis . getStartValue ( ) ) ; double wantMax = LatLonPointImpl . lonNormalFrom ( llbb . getLonMax ( ) , lonAxis . getStartValue ( ) ) ; double start = lonAxis . getStartValue ( ) ; double end = lonAxis . getEndValue ( ) ; // use MAMath.MinMax as a container for two values, min and max List < MAMath . MinMax > lonIntvs = subsetLonIntervals ( wantMin , wantMax , start , end ) ; if ( lonIntvs . size ( ) == 0 ) return Optional . empty ( String . format ( \"longitude want [%f,%f] does not intersect lon axis [%f,%f]\" , wantMin , wantMax , start , end ) ) ; if ( lonIntvs . size ( ) == 1 ) { MAMath . MinMax lonIntv = lonIntvs . get ( 0 ) ; return lonAxis . subset ( lonIntv . min , lonIntv . max , stride ) ; } // this is the seam crossing case return lonAxis . subsetByIntervals ( lonIntvs , stride ) ; }", "nl": "here s where to deal with crossing seam"}}
{"translation": {"code": "private ucar . ma2 . Array readRecordDataSubset ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException { Range recordRange = section . getRange ( 0 ) ; int nrecords = recordRange . length ( ) ; // create the ArrayStructureMA StructureMembers members = s . makeStructureMembers ( ) ; for ( StructureMembers . Member m : members . getMembers ( ) ) { Variable v2 = s . findVariable ( m . getName ( ) ) ; N3header . Vinfo vinfo = ( N3header . Vinfo ) v2 . getSPobject ( ) ; m . setDataParam ( ( int ) ( vinfo . begin - header . recStart ) ) ; // offset from start of record // construct the full shape int rank = m . getShape ( ) . length ; int [ ] fullShape = new int [ rank + 1 ] ; fullShape [ 0 ] = nrecords ; // the first dimension System . arraycopy ( m . getShape ( ) , 0 , fullShape , 1 , rank ) ; // the remaining dimensions Array data = Array . factory ( m . getDataType ( ) , fullShape ) ; m . setDataArray ( data ) ; m . setDataObject ( data . getIndexIterator ( ) ) ; } //LOOK this is all wrong - why using recsize ??? return null ; /* members.setStructureSize(recsize);\n    ArrayStructureMA structureArray = new ArrayStructureMA(members, new int[]{nrecords});\n\n    // note dependency on raf; should probably defer to subclass\n    // loop over records\n    byte[] record = new byte[ recsize];\n    ByteBuffer bb = ByteBuffer.wrap(record);\n    for (int recnum = recordRange.first(); recnum <= recordRange.last(); recnum += recordRange.stride()) {\n      if (debugRecord) System.out.println(\" readRecordDataSubset recno= \" + recnum);\n\n      // read one record\n      raf.seek(recStart + recnum * recsize); // where the record starts\n      if (recnum != numrecs - 1)\n        raf.readFully(record, 0, recsize);\n      else\n        raf.read(record, 0, recsize); // \"wart\" allows file to be one byte short. since its always padding, we allow\n\n      // transfer desired variable(s) to result array(s)\n      for (StructureMembers.Member m : members.getMembers()) {\n        IndexIterator dataIter = (IndexIterator) m.getDataObject();\n        IospHelper.copyFromByteBuffer(bb, m, dataIter);\n      }\n    }\n\n    return structureArray;  */ }", "nl": "Read data from record structure that has been subsetted . Read one record at at time put requested variable into ArrayStructureMA ."}}
{"translation": {"code": "protected void fillNonRecordVariables ( ) throws IOException { // run through each variable for ( Variable v : ncfile . getVariables ( ) ) { if ( v . isUnlimited ( ) ) continue ; try { writeData ( v , v . getShapeAsSection ( ) , makeConstantArray ( v ) ) ; } catch ( InvalidRangeException e ) { e . printStackTrace ( ) ; // shouldnt happen } } }", "nl": "fill buffer with fill value"}}
{"translation": {"code": "static public boolean isValidNetcdf3ObjectName ( String name ) { Matcher m = objectNamePatternOld . matcher ( name ) ; return m . matches ( ) ; }", "nl": "Determine if the given name can be used for a Dimension Attribute or Variable name . Should match makeValidNetcdf3ObjectName ."}}
{"translation": {"code": "public static String makeValidNetcdfObjectName ( String name ) { StringBuilder sb = new StringBuilder ( name ) ; while ( sb . length ( ) > 0 ) { int cp = sb . codePointAt ( 0 ) ; // First char must be [a-z][A-Z][0-9]_ | UTF8 if ( cp <= 0x7f ) { if ( ! ( ' ' <= cp && cp <= ' ' ) && ! ( ' ' <= cp && cp <= ' ' ) && ! ( ' ' <= cp && cp <= ' ' ) && cp != ' ' ) { sb . deleteCharAt ( 0 ) ; continue ; } } break ; } for ( int pos = 1 ; pos < sb . length ( ) ; ++ pos ) { int cp = sb . codePointAt ( pos ) ; // handle simple 0x00-0x7F characters here if ( cp <= 0x7F ) { if ( cp < ' ' || cp > 0x7E || cp == ' ' ) { // control char, DEL, or forward-slash sb . deleteCharAt ( pos ) ; -- pos ; } } } while ( sb . length ( ) > 0 ) { int cp = sb . codePointAt ( sb . length ( ) - 1 ) ; if ( cp <= 0x7f && Character . isWhitespace ( cp ) ) { sb . deleteCharAt ( sb . length ( ) - 1 ) ; } else { break ; } } if ( sb . length ( ) == 0 ) { throw new IllegalArgumentException ( String . format ( \"Illegal NetCDF object name: '%s'\" , name ) ) ; } return sb . toString ( ) ; }", "nl": "Convert a name to a legal netcdf - 3 name ."}}
{"translation": {"code": "public double makeOffsetFromRefDate ( CalendarDate date ) { if ( isCalendarField ) { if ( date . equals ( baseDate ) ) return 0.0 ; return date . getDifference ( baseDate , periodField ) ; } else { long msecs = date . getDifferenceInMsecs ( baseDate ) ; return msecs / period . getValueInMillisecs ( ) ; } }", "nl": "inverse of makeCalendarDate"}}
{"translation": {"code": "private static FileSystemProvider getProvider ( URI uri ) throws IOException { if ( fsproviders . containsKey ( uri . getScheme ( ) ) ) { return fsproviders . get ( uri . getScheme ( ) ) ; } else { FileSystem fs ; try { fs = FileSystems . newFileSystem ( uri , new HashMap < String , Object > ( ) , Thread . currentThread ( ) . getContextClassLoader ( ) ) ; } catch ( FileSystemAlreadyExistsException e ) { fs = FileSystems . getFileSystem ( uri ) ; } fsproviders . put ( uri . getScheme ( ) , fs . provider ( ) ) ; return fs . provider ( ) ; } }", "nl": "filesystem can t be re - created either ."}}
{"translation": {"code": "public void setStationInfo ( String stnIdVName , String stnDescVName , String stnIndexVName , StationHelper stationHelper ) { this . stnIdVName = stnIdVName ; this . stnDescVName = stnDescVName ; this . stnIndexVName = stnIndexVName ; this . stationHelper = stationHelper ; if ( stnIdVName != null ) { Variable stationVar = ncfile . findVariable ( stnIdVName ) ; stationIdType = stationVar . getDataType ( ) ; } }", "nl": "Set extra information used by station obs datasets . Use stnIdVName or stnIndexVName ."}}
{"translation": {"code": "static private ServiceType searchFragment ( String fragment ) { if ( fragment . length ( ) == 0 ) return null ; Map < String , String > map = parseFragment ( fragment ) ; if ( map == null ) return null ; String protocol = map . get ( \"protocol\" ) ; if ( protocol == null ) { for ( String p : FRAGPROTOCOLS ) { if ( map . get ( p ) != null ) { protocol = p ; break ; } } } if ( protocol != null ) { if ( protocol . equalsIgnoreCase ( \"dap\" ) || protocol . equalsIgnoreCase ( \"dods\" ) ) return ServiceType . OPENDAP ; if ( protocol . equalsIgnoreCase ( \"dap4\" ) ) return ServiceType . DAP4 ; if ( protocol . equalsIgnoreCase ( \"cdmremote\" ) ) return ServiceType . CdmRemote ; if ( protocol . equalsIgnoreCase ( \"thredds\" ) ) return ServiceType . THREDDS ; if ( protocol . equalsIgnoreCase ( \"ncml\" ) ) return ServiceType . NCML ; } return null ; }", "nl": "Given a location find markers indicated which protocol to use LOOK what use case is this handling ?"}}
{"translation": {"code": "static private ServiceType checkIfDods ( String location ) throws IOException { int len = location . length ( ) ; // Strip off any trailing .dds, .das, or .dods if ( location . endsWith ( \".dds\" ) ) location = location . substring ( 0 , len - \".dds\" . length ( ) ) ; if ( location . endsWith ( \".das\" ) ) location = location . substring ( 0 , len - \".das\" . length ( ) ) ; if ( location . endsWith ( \".dods\" ) ) location = location . substring ( 0 , len - \".dods\" . length ( ) ) ; // Opendap assumes that the caller has properly escaped the url try ( // For some reason, the head method is not using credentials // method = session.newMethodHead(location + \".dds\"); HTTPMethod method = HTTPFactory . Get ( location + \".dds\" ) ) { int status = method . execute ( ) ; if ( status == 200 ) { Header h = method . getResponseHeader ( \"Content-Description\" ) ; if ( ( h != null ) && ( h . getValue ( ) != null ) ) { String v = h . getValue ( ) ; if ( v . equalsIgnoreCase ( \"dods-dds\" ) || v . equalsIgnoreCase ( \"dods_dds\" ) ) return ServiceType . OPENDAP ; else throw new IOException ( \"OPeNDAP Server Error= \" + method . getResponseAsString ( ) ) ; } } if ( status == HttpStatus . SC_UNAUTHORIZED || status == HttpStatus . SC_FORBIDDEN ) throw new IOException ( \"Unauthorized to open dataset \" + location ) ; // not dods return null ; } }", "nl": "not sure what other opendap servers do so fall back on check for dds"}}
{"translation": {"code": "public Array decodeVlenData ( NcStreamProto . DataCol dproto ) throws IOException { DataType dataType = NcStream . convertDataType ( dproto . getDataType ( ) ) ; ByteBuffer bb = dproto . getPrimdata ( ) . asReadOnlyByteBuffer ( ) ; ByteOrder bo = dproto . getBigend ( ) ? ByteOrder . BIG_ENDIAN : ByteOrder . LITTLE_ENDIAN ; bb . order ( bo ) ; Array alldata = Array . factory ( dataType , new int [ ] { dproto . getNelems ( ) } , bb ) ; // flat array IndexIterator all = alldata . getIndexIterator ( ) ; Section section = NcStream . decodeSection ( dproto . getSection ( ) ) ; Array [ ] data = new Array [ ( int ) section . computeSize ( ) ] ; // divide the primitive data into variable length arrays int count = 0 ; for ( int len : dproto . getVlensList ( ) ) { Array primdata = Array . factory ( dataType , new int [ ] { len } ) ; IndexIterator prim = primdata . getIndexIterator ( ) ; for ( int i = 0 ; i < len ; i ++ ) { prim . setObjectNext ( all . getObjectNext ( ) ) ; // generic } data [ count ++ ] = primdata ; } // return Array.makeObjectArray(dataType, data[0].getClass(), section.getShape(), data); return Array . makeVlenArray ( section . getShape ( ) , data ) ; }", "nl": "top level vlen"}}
{"translation": {"code": "public static int setResponseContentLength ( HttpServletResponse response , String s ) throws UnsupportedEncodingException { int length = s . getBytes ( response . getCharacterEncoding ( ) ) . length ; response . setContentLength ( length ) ; return length ; }", "nl": "Set the proper content length for the string"}}
{"translation": {"code": "public static int countBits ( byte [ ] bitmap ) { int bits = 0 ; for ( byte b : bitmap ) { short s = DataType . unsignedByteToShort ( b ) ; bits += Long . bitCount ( s ) ; } return bits ; }", "nl": "count number of bits on in bitmap"}}
{"translation": {"code": "static public void init ( CredentialsProvider provider , String userAgent ) { if ( provider != null ) try { HTTPSession . setGlobalCredentialsProvider ( provider ) ; } catch ( HTTPException e ) { throw new IllegalArgumentException ( e ) ; } if ( userAgent != null ) HTTPSession . setGlobalUserAgent ( userAgent + \"/NetcdfJava/HttpClient\" ) ; else HTTPSession . setGlobalUserAgent ( \"NetcdfJava/HttpClient\" ) ; }", "nl": "initialize the HttpClient layer ."}}
{"translation": {"code": "private void aa ( final String alias , final String name ) throws UnitExistsException , NoSuchUnitException , UnitParseException , SpecificationException , UnitDBException , PrefixDBException , OperationException , NameException , UnitSystemException { aa ( alias , name , null ) ; }", "nl": "Adds an alias for a unit to the database ."}}
{"translation": {"code": "private static UnitDBImpl derivedUnitDB ( ) throws NameException , UnitExistsException , NoSuchUnitException { final UnitDBImpl db = new UnitDBImpl ( 42 , 43 ) ; db . addUnit ( HERTZ ) ; db . addUnit ( NEWTON ) ; db . addUnit ( PASCAL ) ; db . addUnit ( JOULE ) ; db . addUnit ( WATT ) ; db . addUnit ( COULOMB ) ; db . addUnit ( VOLT ) ; db . addUnit ( FARAD ) ; db . addUnit ( OHM ) ; db . addUnit ( SIEMENS ) ; db . addUnit ( WEBER ) ; db . addUnit ( TESLA ) ; db . addUnit ( HENRY ) ; db . addUnit ( DEGREE_CELSIUS ) ; db . addUnit ( LUMEN ) ; db . addUnit ( LUX ) ; db . addUnit ( BECQUEREL ) ; db . addUnit ( GRAY ) ; db . addUnit ( SIEVERT ) ; db . addUnit ( MINUTE ) ; db . addUnit ( HOUR ) ; db . addUnit ( DAY ) ; db . addUnit ( ARC_DEGREE ) ; db . addUnit ( ARC_MINUTE ) ; db . addUnit ( ARC_SECOND ) ; db . addUnit ( LITER ) ; db . addUnit ( METRIC_TON ) ; db . addUnit ( NAUTICAL_MILE ) ; db . addUnit ( KNOT ) ; db . addUnit ( ANGSTROM ) ; db . addUnit ( ARE ) ; db . addUnit ( HECTARE ) ; db . addUnit ( BARN ) ; db . addUnit ( BAR ) ; db . addUnit ( GAL ) ; db . addUnit ( CURIE ) ; db . addUnit ( ROENTGEN ) ; db . addUnit ( RAD ) ; db . addUnit ( REM ) ; db . addAlias ( \"litre\" , \"liter\" , \"l\" ) ; db . addAlias ( \"tonne\" , \"metric ton\" ) ; db . addSymbol ( \"tne\" , \"tonne\" ) ; return db ; }", "nl": "Returns the derived unit database of the SI ."}}
{"translation": {"code": "private static UnitDBImpl baseUnitDB ( ) throws NameException , UnitExistsException , NoSuchUnitException { final UnitDBImpl db = new UnitDBImpl ( 9 , 9 ) ; db . addUnit ( AMPERE ) ; db . addUnit ( CANDELA ) ; db . addUnit ( KELVIN ) ; db . addUnit ( KILOGRAM ) ; db . addUnit ( METER ) ; db . addUnit ( MOLE ) ; db . addUnit ( SECOND ) ; db . addUnit ( RADIAN ) ; db . addUnit ( STERADIAN ) ; db . addAlias ( \"metre\" , \"meter\" ) ; return db ; }", "nl": "Returns the base unit database of the SI ."}}
{"translation": {"code": "private static Unit du ( final String name , final String symbol , final Unit definition ) throws NameException { return definition . clone ( UnitName . newUnitName ( name , null , symbol ) ) ; }", "nl": "Factory method for constructing a derived unit ."}}
{"translation": {"code": "private static BaseUnit bu ( final String name , final String symbol , final BaseQuantity quantity ) throws NameException , UnitExistsException { return BaseUnit . getOrCreate ( UnitName . newUnitName ( name , null , symbol ) , quantity ) ; }", "nl": "Factory method for constructing a base unit ."}}
{"translation": {"code": "public void addToMenu ( final JMenu menu ) { final UIManager . LookAndFeelInfo [ ] plafInfo = UIManager . getInstalledLookAndFeels ( ) ; for ( UIManager . LookAndFeelInfo aPlafInfo : plafInfo ) { addToMenu ( aPlafInfo . getName ( ) , aPlafInfo . getClassName ( ) , menu ) ; } final LookAndFeel current = UIManager . getLookAndFeel ( ) ; System . out . printf ( \"current L&F=%s%n\" , current . getName ( ) ) ; }", "nl": "Add a set of MenuItems to the given JMenu one for each possible L&F . if this platform doesnt support the L&F disable the MenuItem ."}}
{"translation": {"code": "@ Override public int [ ] getForecastTimeIntervalOffset ( Grib2Record gr ) { Grib2Pds pds = gr . getPDS ( ) ; if ( ! pds . isTimeInterval ( ) ) { return null ; } // LOOK this is hack for CFSR monthly combobulation // see http://rda.ucar.edu/datasets/ds093.2/#docs/time_ranges.html int statType = pds . getOctet ( 47 ) ; int n = pds . getInt4StartingAtOctet ( 50 ) ; int p2 = pds . getInt4StartingAtOctet ( 55 ) ; int p2mp1 = pds . getInt4StartingAtOctet ( 62 ) ; int p1 = p2 - p2mp1 ; int start , end ; switch ( statType ) { case 193 : start = p1 ; end = p1 + n * p2 ; break ; case 194 : start = 0 ; end = n * p2 ; break ; case 195 : case 204 : case 205 : start = p1 ; end = p2 ; break ; default : throw new IllegalArgumentException ( \"unknown statType \" + statType ) ; } return new int [ ] { start , end } ; }", "nl": "Reference time is the start time of the first forecast other forecasts at 6 - hour intervals . Number in Ave = number of forecast used"}}
{"translation": {"code": "public static String backslashEncode ( String s ) { StringBuilder buf = new StringBuilder ( ) ; for ( int i = 0 ; i < s . length ( ) ; i ++ ) { int c = buf . charAt ( i ) ; if ( _MustBackslashEscape . indexOf ( c ) >= 0 ) buf . append ( _BACKSLASHEscape ) ; buf . append ( ( char ) c ) ; } return buf . toString ( ) ; }", "nl": "Define the DEFINITIVE URL BACKSLASH escape function ."}}
{"translation": {"code": "public String getSessionID ( ) { String sid = null ; String jsid = null ; List < Cookie > cookies = this . sessioncontext . getCookieStore ( ) . getCookies ( ) ; for ( Cookie cookie : cookies ) { if ( cookie . getName ( ) . equalsIgnoreCase ( \"sessionid\" ) ) sid = cookie . getValue ( ) ; if ( cookie . getName ( ) . equalsIgnoreCase ( \"jsessionid\" ) ) jsid = cookie . getValue ( ) ; } return ( sid == null ? jsid : sid ) ; }", "nl": "Extract the sessionid cookie value"}}
{"translation": {"code": "static URI uriExclude ( final URI uri , URIPart ... excludes ) { URIBuilder urib = new URIBuilder ( ) ; EnumSet < URIPart > set = EnumSet . of ( excludes [ 0 ] , excludes ) ; for ( URIPart part : URIPart . values ( ) ) { if ( set . contains ( part ) ) continue ; switch ( part ) { case SCHEME : urib . setScheme ( uri . getScheme ( ) ) ; break ; case USERINFO : urib . setUserInfo ( uri . getUserInfo ( ) ) ; break ; case HOST : urib . setHost ( uri . getHost ( ) ) ; break ; case PORT : urib . setPort ( uri . getPort ( ) ) ; break ; case PATH : urib . setPath ( uri . getPath ( ) ) ; break ; case QUERY : urib . setCustomQuery ( uri . getQuery ( ) ) ; break ; case FRAGMENT : urib . setFragment ( uri . getFragment ( ) ) ; break ; } } try { return urib . build ( ) ; } catch ( URISyntaxException e ) { throw new IllegalArgumentException ( e . getMessage ( ) ) ; } }", "nl": "Remove selected fields from a URI producing a new URI"}}
{"translation": {"code": "private static final boolean checkDouble ( String s ) { try { //Coverity[FB.DLS_DEAD_LOCAL_STORE] double val = Double . parseDouble ( s ) ; if ( DebugValueChecking ) { DAPNode . log . debug ( \"Attribute.checkDouble() - string: '\" + s + \"'   value: \" + val ) ; } return true ; } catch ( NumberFormatException e ) { if ( s . equalsIgnoreCase ( \"nan\" ) || s . equalsIgnoreCase ( \"inf\" ) ) return true ; return false ; } }", "nl": "Check if string is a valid Float64 ."}}
{"translation": {"code": "private static final boolean checkUInt ( String s ) { // Note: Because there is no Unsigned class in Java, use Long instead. try { long val = Long . parseLong ( s ) ; if ( DebugValueChecking ) { DAPNode . log . debug ( \"Attribute.checkUInt() - string: '\" + s + \"'   value: \" + val ) ; } if ( val > 0xFFFFFFFF L ) return false ; else return true ; } catch ( NumberFormatException e ) { return false ; } }", "nl": "Check if string is a valid UInt32 ."}}
{"translation": {"code": "private static final boolean checkShort ( String s ) { try { short val = Short . parseShort ( s ) ; if ( DebugValueChecking ) { DAPNode . log . debug ( \"Attribute.checkShort() - string: '\" + s + \"'   value: \" + val ) ; } return true ; } catch ( NumberFormatException e ) { return false ; } }", "nl": "Check if string is a valid Int16 ."}}
{"translation": {"code": "private static final boolean checkByte ( String s ) throws AttributeBadValueException { try { // Byte.parseByte() can't be used because values > 127 are allowed short val = Short . parseShort ( s ) ; if ( DebugValueChecking ) { log . debug ( \"Attribute.checkByte() - string: '\" + s + \"'   value: \" + val ) ; } if ( val > 0xFF || val < 0 ) return false ; else return true ; } catch ( NumberFormatException e ) { throw new AttributeBadValueException ( \"`\" + s + \"' is not a Byte value.\" ) ; } }", "nl": "Check if string is a valid Byte ."}}
{"translation": {"code": "private static void dispatchCheckValue ( int type , String value ) throws AttributeBadValueException { switch ( type ) { case BYTE : if ( ! checkByte ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not a Byte value.\" ) ; break ; case INT16 : if ( ! checkShort ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not an Int16 value.\" ) ; break ; case UINT16 : if ( ! checkUShort ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not an UInt16 value.\" ) ; break ; case INT32 : if ( ! checkInt ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not an Int32 value.\" ) ; break ; case UINT32 : if ( ! checkUInt ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not an UInt32 value.\" ) ; break ; case FLOAT32 : if ( ! checkFloat ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not a Float32 value.\" ) ; break ; case FLOAT64 : if ( ! checkDouble ( value ) ) throw new AttributeBadValueException ( \"`\" + value + \"' is not a Float64 value.\" ) ; break ; //    case BOOLEAN: //      if(!checkBoolean(value)) //\tthrow new AttributeBadValueException(\"`\" + value + \"' is not a Boolean value.\"); //      break; default : // Assume UNKNOWN, CONTAINER, STRING, and URL are okay. } }", "nl": "Check if the value is legal for a given type ."}}
{"translation": {"code": "private static String forceValue ( int type , String value ) throws AttributeBadValueException { try { dispatchCheckValue ( type , value ) ; } catch ( AttributeBadValueException abe ) { if ( type == BYTE ) { // Try again: allow e.g. negative byte values short val = Short . parseShort ( value ) ; if ( val > 255 && val < - 128 ) throw new AttributeBadValueException ( \"Cannot convert to byte: \" + value ) ; value = Integer . toString ( ( val & 0xFF ) ) ; } } return value ; }", "nl": "Check if the value is legal for a given type and try to convert to specified type ."}}
{"translation": {"code": "int findCoordElement ( double [ ] target , boolean bounded ) { switch ( axis . getSpacing ( ) ) { case regularInterval : // can use midpoint return findCoordElementRegular ( ( target [ 0 ] + target [ 1 ] ) / 2 , bounded ) ; case contiguousInterval : // can use midpoint return findCoordElementContiguous ( ( target [ 0 ] + target [ 1 ] ) / 2 , bounded ) ; case discontiguousInterval : // cant use midpoint return findCoordElementDiscontiguousInterval ( target , bounded ) ; } throw new IllegalStateException ( \"unknown spacing\" + axis . getSpacing ( ) ) ; }", "nl": "Given a coordinate interval find what grid element matches it ."}}
{"translation": {"code": "public void setup ( HttpServletRequest req , HttpServletResponse resp ) throws SendError { this . req = req ; this . res = resp ; if ( ! once ) doonce ( req ) ; // Parse any query parameters try { this . params = new DownloadParameters ( req ) ; } catch ( IOException ioe ) { throw new SendError ( res . SC_BAD_REQUEST , ioe ) ; } }", "nl": "Setup for each request"}}
{"translation": {"code": "static public String canonjoin ( String prefix , String suffix ) { if ( prefix == null ) prefix = \"\" ; if ( suffix == null ) suffix = \"\" ; prefix = HTTPUtil . canonicalpath ( prefix ) ; suffix = HTTPUtil . canonicalpath ( suffix ) ; StringBuilder result = new StringBuilder ( ) ; result . append ( prefix ) ; int prelen = prefix . length ( ) ; if ( prelen > 0 && result . charAt ( prelen - 1 ) != ' ' ) { result . append ( ' ' ) ; prelen ++ ; } if ( suffix . length ( ) > 0 && suffix . charAt ( 0 ) == ' ' ) result . append ( suffix . substring ( 1 ) ) ; else result . append ( suffix ) ; int len = result . length ( ) ; if ( len > 0 && result . charAt ( len - 1 ) == ' ' ) { result . deleteCharAt ( len - 1 ) ; len -- ; } return result . toString ( ) ; }", "nl": "Join two string together to form proper path WITHOUT trailing slash"}}
{"translation": {"code": "protected Object readAs ( DapVariable atomvar , DapType basetype , List < Slice > slices ) throws DapException { if ( basetype . getTypeSort ( ) == TypeSort . Enum ) { // short circuit this case basetype = ( ( DapEnumeration ) basetype ) . getBaseType ( ) ; return readAs ( atomvar , basetype , slices ) ; } long count = DapUtil . sliceProduct ( slices ) ; Object result = LibTypeFcns . newVector ( basetype , count ) ; Odometer odom = Odometer . factory ( slices ) ; if ( DapUtil . isContiguous ( slices ) && basetype . isFixedSize ( ) ) readContig ( slices , basetype , count , odom , result ) ; else readOdom ( slices , basetype , odom , result ) ; return result ; }", "nl": "Allow specification of basetype to use ; used for enumerations"}}
{"translation": {"code": "public Slice slice ( int i ) { if ( i < 0 || i >= this . rank ) throw new IllegalArgumentException ( ) ; return this . slices . get ( i ) ; }", "nl": "Return ith slice"}}
{"translation": {"code": "public double getDouble ( int offset ) { DapVariable d4var = ( DapVariable ) getTemplate ( ) ; long [ ] dimsizes = DapUtil . getDimSizes ( d4var . getDimensions ( ) ) ; return getDouble ( DapUtil . offsetToIndex ( offset , dimsizes ) ) ; }", "nl": "Convert int base to Index based"}}
{"translation": {"code": "static public List < Slice > offsetToSlices ( long offset , DapVariable template ) throws DapException { List < DapDimension > dims = template . getDimensions ( ) ; long [ ] dimsizes = DapUtil . getDimSizes ( dims ) ; return indexToSlices ( offsetToIndex ( offset , dimsizes ) , template ) ; }", "nl": "Provide a helper function to convert an offset to a slice list ."}}
{"translation": {"code": "static public CEConstraint compile ( String sce , DapDataset dmr ) throws DapException { // Process any constraint if ( sce == null || sce . length ( ) == 0 ) return CEConstraint . getUniversal ( dmr ) ; CEParserImpl ceparser = new CEParserImpl ( dmr ) ; if ( PARSEDEBUG ) ceparser . setDebugLevel ( 1 ) ; if ( DEBUG ) { System . err . println ( \"Dap4Servlet: parsing constraint: |\" + sce + \"|\" ) ; } boolean ok ; try { ok = ceparser . parse ( sce ) ; } catch ( ParseException pe ) { ok = false ; } if ( ! ok ) throw new DapException ( \"Constraint parse failed: \" + sce ) ; CEAST root = ceparser . getCEAST ( ) ; CECompiler compiler = new CECompiler ( ) ; CEConstraint ce = compiler . compile ( dmr , root ) ; ce . expand ( ) ; ce . finish ( ) ; return ce ; }", "nl": "Static Utility for compiling a constraint string"}}
{"translation": {"code": "protected CDMArrayAtomic createAtomicVar ( DataCursor data ) throws DapException { CDMArrayAtomic array = new CDMArrayAtomic ( data ) ; return array ; }", "nl": "Create an Atomic Valued variable ."}}
{"translation": {"code": "public long index ( ) { long offset = 0 ; for ( int i = 0 ; i < this . indices . length ; i ++ ) { offset *= this . dimsizes [ i ] ; offset += this . indices [ i ] ; } return offset ; }", "nl": "Compute the linear index from the current odometer indices ."}}
{"translation": {"code": "@ Override public ucar . ma2 . Array getArray ( int recno , StructureMembers . Member m ) { return ( ucar . ma2 . Array ) memberArray ( recno , memberIndex ( m ) ) ; }", "nl": "Key interface method coming in from StructureDataA ."}}
{"translation": {"code": "protected void writeStructure ( DataCursor data , SerialWriter dst ) throws IOException { DapVariable template = ( DapVariable ) data . getTemplate ( ) ; DapStructure ds = ( DapStructure ) template . getBaseType ( ) ; assert ( this . ce . references ( template ) ) ; List < Slice > slices = ce . getConstrainedSlices ( template ) ; Odometer odom = Odometer . factory ( slices ) ; while ( odom . hasNext ( ) ) { Index index = odom . next ( ) ; DataCursor [ ] instance = ( DataCursor [ ] ) data . read ( index ) ; writeStructure1 ( instance [ 0 ] , dst ) ; } }", "nl": "Write out a scalar or array structure instance"}}
{"translation": {"code": "protected void printCompoundInstance ( DataCursor datav ) throws DapException { //Index index = datav.getIndex(); DapStructure dstruct = ( DapStructure ) ( ( DapVariable ) datav . getTemplate ( ) ) . getBaseType ( ) ; switch ( datav . getScheme ( ) ) { case STRUCTURE : case RECORD : List < DapVariable > dfields = dstruct . getFields ( ) ; for ( int f = 0 ; f < dfields . size ( ) ; f ++ ) { DapVariable field = dfields . get ( f ) ; List < Slice > fieldslices = this . ce . getConstrainedSlices ( field ) ; DataCursor fdata = datav . readField ( f ) ; printVariable ( fdata , fieldslices ) ; } break ; case SEQUENCE : DapSequence dseq = ( DapSequence ) dstruct ; long count = datav . getRecordCount ( ) ; for ( long r = 0 ; r < count ; r ++ ) { DataCursor dr = datav . readRecord ( r ) ; printer . marginPrint ( \"[\" ) ; printer . eol ( ) ; printer . indent ( ) ; printCompoundInstance ( dr ) ; printer . outdent ( ) ; printer . marginPrint ( \"]\" ) ; } break ; default : throw new DapException ( \"Unexpected data cursor scheme:\" + datav . getScheme ( ) ) ; } }", "nl": "Print a single structure or sequence or record instance"}}
{"translation": {"code": "protected void writeAtomicVariable ( DataCursor data , SerialWriter dst ) throws IOException { DapVariable template = ( DapVariable ) data . getTemplate ( ) ; assert ( this . ce . references ( template ) ) ; DapType basetype = template . getBaseType ( ) ; // get the slices from constraint List < Slice > slices = ce . getConstrainedSlices ( template ) ; if ( slices == null ) throw new DapException ( \"Unknown variable: \" + template . getFQN ( ) ) ; Object values = data . read ( slices ) ; dst . writeAtomicArray ( basetype , values ) ; }", "nl": "Write out an atomic variable ."}}
{"translation": {"code": "static public boolean isContiguous ( List < Slice > slices ) { for ( Slice sl : slices ) { if ( sl . getStride ( ) != 1 ) return false ; } return true ; }", "nl": "Test if a set of slices represent a contiguous region This is equivalent to saying all strides are one"}}
{"translation": {"code": "synchronized public boolean registered ( Class < ? extends DSP > klass ) { for ( Registration r : registry ) { if ( r . dspclass == klass ) return true ; } return false ; }", "nl": "See if a specific DSP is registered"}}
{"translation": {"code": "static public String canonical ( String s ) { if ( s != null ) { s = s . trim ( ) ; if ( s . length ( ) == 0 ) s = null ; } return s ; }", "nl": "Canonicalize a part of a URL"}}
{"translation": {"code": "static protected long minmax ( long value , long min , long max ) { if ( value < min ) return min ; if ( value > max ) return max ; return value ; }", "nl": "Peg a value to either the min or max depending on sign ."}}
{"translation": {"code": "public FileDSP open ( byte [ ] rawdata ) throws DapException { try { this . raw = rawdata ; ByteArrayInputStream stream = new ByteArrayInputStream ( this . raw ) ; ChunkInputStream rdr = new ChunkInputStream ( stream , RequestMode . DAP ) ; String document = rdr . readDMR ( ) ; byte [ ] serialdata = DapUtil . readbinaryfile ( rdr ) ; super . build ( document , serialdata , rdr . getRemoteByteOrder ( ) ) ; return this ; } catch ( IOException ioe ) { throw new DapException ( ioe ) . setCode ( DapCodes . SC_INTERNAL_SERVER_ERROR ) ; } }", "nl": "Extension to access a raw byte stream"}}
{"translation": {"code": "static boolean isSpecial ( DapAttribute attr ) { if ( attr . getParent ( ) . getSort ( ) == DapSort . DATASET ) { for ( String s : GROUPSPECIAL ) { if ( s . equals ( attr . getShortName ( ) ) ) return true ; } } else if ( attr . getParent ( ) . getSort ( ) == DapSort . VARIABLE ) { for ( String s : VARSPECIAL ) { if ( s . equals ( attr . getShortName ( ) ) ) return true ; } } return false ; }", "nl": "Special here is not the same as reserved"}}
{"translation": {"code": "static List < Nc4Cursor > getCursorPath ( Nc4Cursor cursor ) { List < Nc4Cursor > path = new ArrayList <> ( ) ; for ( ; ; ) { if ( ! cursor . getScheme ( ) . isCompoundArray ( ) ) // suppress path . add ( 0 , cursor ) ; if ( cursor . getScheme ( ) == Scheme . SEQUENCE ) { // Stop here because the sequence has the vlen mem as its mem break ; } Nc4Cursor next = ( Nc4Cursor ) cursor . getContainer ( ) ; if ( next == null ) { assert cursor . getTemplate ( ) . isTopLevel ( ) ; break ; } assert next . getTemplate ( ) . getSort ( ) == DapSort . VARIABLE ; cursor = next ; } return path ; }", "nl": "Given a cursor get a list of containing cursors with the following constraints . 1 . the first element in the path is a top - level variable . 2 . the remaining elements are the enclosing compound variables 3 . the last element is the incoming cursor ."}}
{"translation": {"code": "static public boolean isSinglePoint ( List < Slice > slices ) { for ( Slice sl : slices ) { if ( sl . getCount ( ) != 1 ) return false ; } return true ; }", "nl": "Test if a set of slices represent a single position"}}
{"translation": {"code": "static public Index slicesToIndex ( List < Slice > slices ) throws DapException { long [ ] positions = new long [ slices . size ( ) ] ; long [ ] dimsizes = new long [ slices . size ( ) ] ; for ( int i = 0 ; i < positions . length ; i ++ ) { Slice s = slices . get ( i ) ; if ( s . getCount ( ) != 1 ) throw new DapException ( \"Attempt to convert non-singleton sliceset to index\" ) ; positions [ i ] = s . getFirst ( ) ; dimsizes [ i ] = s . getMax ( ) ; } return new Index ( positions , dimsizes ) ; }", "nl": "If a set of slices refers to a single position then return the corresponding Index . Otherwise throw Exception ."}}
{"translation": {"code": "static List < Dimension > getCoreDimset ( List < Dimension > dimset ) throws DapException { if ( dimset == null ) return null ; List < Dimension > core = new ArrayList <> ( ) ; int pos = - 1 ; int count = 0 ; for ( int i = 0 ; i < dimset . size ( ) ; i ++ ) { if ( dimset . get ( i ) . isVariableLength ( ) ) { pos = i ; count ++ ; } else core . add ( dimset . get ( i ) ) ; } if ( ( pos != dimset . size ( ) - 1 ) || count > 1 ) throw new DapException ( \"Unsupported use of (*) Dimension\" ) ; return core ; }", "nl": "Strip vlen dimensions from a set of dimensions"}}
{"translation": {"code": "static boolean memequal ( byte [ ] b1 , byte [ ] b2 , int len ) { if ( b1 == b2 ) return true ; if ( b1 == null || b2 == null ) return false ; if ( b1 . length < len || b2 . length < len ) return false ; for ( int i = 0 ; i < len ; i ++ ) { if ( b1 [ i ] != b2 [ i ] ) return false ; } return true ; }", "nl": "Not quite memcmp"}}
{"translation": {"code": "protected void parseresponse ( Node root ) throws ParseException { String elemname = root . getNodeName ( ) ; if ( elemname . equalsIgnoreCase ( \"Error\" ) ) { parseerror ( root ) ; } else if ( elemname . equalsIgnoreCase ( \"Dataset\" ) ) { parsedataset ( root ) ; } else throw new ParseException ( \"Unexpected response root: \" + elemname ) ; }", "nl": "Recursive descent parser"}}
{"translation": {"code": "List < Node > getSubnodes ( Node parent ) { List < Node > subs = new ArrayList <> ( ) ; NodeList nodes = parent . getChildNodes ( ) ; for ( int i = 0 ; i < nodes . getLength ( ) ; i ++ ) { Node n = nodes . item ( i ) ; if ( n . getNodeType ( ) == Node . ELEMENT_NODE ) subs . add ( n ) ; } return subs ; }", "nl": "Return the subnodes of a node with non - element nodes suppressed"}}
{"translation": {"code": "static public NcmlCollectionReader readNcML ( String ncmlString , Formatter errlog ) throws IOException { StringReader reader = new StringReader ( ncmlString ) ; org . jdom2 . Document doc ; try { SAXBuilder builder = new SAXBuilder ( ) ; if ( debugURL ) System . out . println ( \" NetcdfDataset NcML String = <\" + ncmlString + \">\" ) ; doc = builder . build ( new StringReader ( ncmlString ) ) ; } catch ( JDOMException e ) { throw new IOException ( e . getMessage ( ) ) ; } if ( debugXML ) System . out . println ( \" SAXBuilder done\" ) ; return readXML ( doc , errlog , null ) ; }", "nl": "Read an NcML file from a String and construct a NcmlCollectionReader from its scan or scanFmrc element ."}}
{"translation": {"code": "@ RequestMapping ( \"**/datasetBoundaries.xml\" ) public void getDatasetBoundaries ( NcssParamsBean params , HttpServletRequest req , HttpServletResponse res ) throws IOException , UnsupportedResponseFormatException { SupportedFormat format = SupportedOperation . DATASET_BOUNDARIES_REQUEST . getSupportedFormat ( params . getAccept ( ) ) ; switch ( format ) { case WKT : getDatasetBoundariesWKT ( req , res ) ; break ; case JSON : getDatasetBoundariesGeoJSON ( req , res ) ; break ; default : throw new IllegalArgumentException ( String . format ( \"Expected %s or %s, but got %s\" , SupportedFormat . WKT , SupportedFormat . JSON , format ) ) ; } }", "nl": "Supported for backwards compatibility . We prefer that datasetBoundaries . wkt or datasetBoundaries . json are used ."}}
{"translation": {"code": "@ Override public boolean isViewable ( Dataset ds ) { Access access = ds . getAccess ( ServiceType . WMS ) ; return access != null && ( ThreddsConfig . getBoolean ( \"WMS.allow\" , false ) ) ; }", "nl": "Returns true if this is a gridded dataset that is accessible via WMS ."}}
{"translation": {"code": "@ Override public synchronized String nc_inq_libvers ( ) { String ret ; try { ce ( ) ; ret = nc4 . nc_inq_libvers ( ) ; if ( TRACE ) trace ( ret , \"nc_inq_libvers\" , \"-\" ) ; } finally { cx ( ) ; } return ret ; }", "nl": "Begin API Override"}}
{"translation": {"code": "static private ServiceType searchPath ( String url ) { if ( false ) { // Disable for now if ( url == null || url . length ( ) == 0 ) return null ; url = url . toLowerCase ( ) ; // for matching purposes for ( int i = 0 ; i < FRAGPROTOCOLS . length ; i ++ ) { String p = FRAGPROTOCOLS [ i ] ; if ( url . indexOf ( \"/thredds/\" + p . toLowerCase ( ) + \"/\" ) >= 0 ) { return FRAGPROTOSVCTYPE [ i ] ; } } } return null ; }", "nl": "Given a url search the path to look for protocol indicators"}}
{"translation": {"code": "public static String sweepAngleAxisToScanGeom ( String sweepAngleAxis ) { String scanGeom = GOES ; if ( sweepAngleAxis . equals ( \"y\" ) ) { scanGeom = GEOS ; } return scanGeom ; }", "nl": "Find scan geometry associated with sweep_angle_axis"}}
{"translation": {"code": "private void writeHeadersAndBB ( ) { fileOutput += \"<wfs:FeatureCollection xsi:schemaLocation=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/wfs/2.0 http://schemas.opengis.net/wfs/2.0/wfs.xsd \" + namespace + \" \" + server + \"?request=DescribeFeatureType\" + WFSXMLHelper . AMPERSAND + \"service=wfs\" + WFSXMLHelper . AMPERSAND + \"version=2.0.0\" + WFSXMLHelper . AMPERSAND + \"typename=\" + WFSController . TDSNAMESPACE + \"%3A\" + ftName ) + \" xmlns:xsi=\" + WFSXMLHelper . encQuotes ( \"http://www.w3.org/2001/XMLSchema-instance\" ) + \" xmlns:xlink=\" + WFSXMLHelper . encQuotes ( \"http://www.w3.org/1999/xlink\" ) + \" xmlns:gml=\" + WFSXMLHelper . encQuotes ( \"http://opengis.net/gml/3.2\" ) + \" xmlns:fes=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/fes/2.0\" ) + \" xmlns:ogc=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/ogc\" ) + \" xmlns:wfs=\" + WFSXMLHelper . encQuotes ( \"http://opengis.net/wfs/2.0\" ) + \" xmlns:\" + WFSController . TDSNAMESPACE + \"=\" + WFSXMLHelper . encQuotes ( namespace ) + \" xmlns=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/wfs/2.0\" ) + \" version=\\\"2.0.0\\\" numberMatched=\" + WFSXMLHelper . encQuotes ( String . valueOf ( geometries . size ( ) ) ) + \" numberReturned=\" + WFSXMLHelper . encQuotes ( String . valueOf ( geometries . size ( ) ) ) + \">\" ; double [ ] boundLower ; double [ ] boundUpper ; if ( geometries . isEmpty ( ) ) { boundLower = new double [ 2 ] ; boundUpper = new double [ 2 ] ; boundLower [ 0 ] = - 180 ; boundLower [ 1 ] = - 90 ; boundUpper [ 0 ] = 180 ; boundUpper [ 1 ] = 90 ; } else { boundLower = geometries . get ( 0 ) . getBBLower ( ) ; boundUpper = geometries . get ( 0 ) . getBBUpper ( ) ; } // WFS Bounding Box\r for ( SimpleGeometry item : geometries ) { // Find the overall BB\r // Test Lower\r double [ ] low = item . getBBLower ( ) ; if ( boundLower [ 0 ] > low [ 0 ] ) boundLower [ 0 ] = low [ 0 ] ; if ( boundLower [ 1 ] > low [ 1 ] ) boundLower [ 1 ] = low [ 1 ] ; // Test Upper\r double [ ] upper = item . getBBUpper ( ) ; if ( boundUpper [ 0 ] < upper [ 0 ] ) boundUpper [ 0 ] = upper [ 0 ] ; if ( boundUpper [ 1 ] < upper [ 1 ] ) boundUpper [ 1 ] = upper [ 1 ] ; // Add some padding\r boundLower [ 0 ] -= 10 ; boundLower [ 1 ] -= 10 ; boundUpper [ 0 ] += 10 ; boundUpper [ 1 ] += 10 ; } fileOutput += \"<wfs:boundedBy>\" + \"<wfs:Envelope srsName=\" + \"\\\"urn:ogc:def:crs:EPSG::4326\\\"\" + \">\" + \"<wfs:lowerCorner>\" + boundLower [ 0 ] + \" \" + boundLower [ 1 ] + \"</wfs:lowerCorner>\" + \"<wfs:upperCorner>\" + boundUpper [ 0 ] + \" \" + boundUpper [ 1 ] + \"</wfs:upperCorner>\" + \"</wfs:Envelope>\" + \"</wfs:boundedBy>\" ; }", "nl": "Writes headers and bounding box"}}
{"translation": {"code": "private void getCapabilities ( PrintWriter out , HttpServletRequest hsreq , SimpleGeometryCSBuilder sgcs ) { WFSGetCapabilitiesWriter gcdw = new WFSGetCapabilitiesWriter ( out , WFSController . constructServerPath ( hsreq ) ) ; gcdw . startXML ( ) ; gcdw . addOperation ( WFSRequestType . GetCapabilities ) ; gcdw . addOperation ( WFSRequestType . DescribeFeatureType ) ; gcdw . addOperation ( WFSRequestType . GetFeature ) ; gcdw . writeOperations ( ) ; List < String > seriesNames = sgcs . getGeometrySeriesNames ( ) ; for ( String name : seriesNames ) { gcdw . addFeature ( new WFSFeature ( TDSNAMESPACE + \":\" + name , name ) ) ; } gcdw . writeFeatureTypes ( ) ; gcdw . finishXML ( ) ; }", "nl": "Processes GetCapabilities requests ."}}
{"translation": {"code": "private WFSExceptionWriter checkParametersForError ( String request , String version , String service , String typeName ) { // The SERVICE parameter is required. If not specified, is an error (throw exception through XML).\r if ( service != null ) { // For the WFS servlet it must be WFS if not, write out an InvalidParameterValue exception.\r if ( ! service . equalsIgnoreCase ( \"WFS\" ) ) { return new WFSExceptionWriter ( \"WFS Server error. SERVICE parameter must be of value WFS.\" , \"service\" , \"InvalidParameterValue\" ) ; } } else { return new WFSExceptionWriter ( \"WFS server error. SERVICE parameter is required.\" , \"request\" , \"MissingParameterValue\" ) ; } // The REQUEST Parameter is required. If not specified, is an error (throw exception through XML).\r if ( request != null ) { // Only go through version checks if NOT a Get Capabilities request, the VERSION parameter is required for all operations EXCEPT GetCapabilities section 7.6.25 of WFS 2.0 Interface Standard\r if ( ! request . equalsIgnoreCase ( WFSRequestType . GetCapabilities . toString ( ) ) ) { if ( version != null ) { // If the version is not failed report exception VersionNegotiationFailed, from OGC Web Services Common Standard section 7.4.1\r // Get each part\r String [ ] versionParts = version . split ( \"\\\\.\" ) ; for ( int ind = 0 ; ind < versionParts . length ; ind ++ ) { // Check if number will throw NumberFormatException if not.\r try { Integer . valueOf ( versionParts [ ind ] ) ; } /* Version parameters are only allowed to consist of numbers and periods. If this is not the case then\r\n\t\t\t\t\t\t * It qualifies for InvalidParameterException\r\n\t\t\t\t\t\t */ catch ( NumberFormatException excep ) { return new WFSExceptionWriter ( \"WFS server error. VERSION parameter consists of invalid characters.\" , \"version\" , \"InvalidParameterValue\" ) ; } } /* Now the version parts are all constructed from the parameter\r\n\t\t\t\t\t * Analyze for correctness. \r\n\t\t\t\t\t */ boolean validVersion = false ; // If just number 2 is specified, assume 2.0.0, pass the check\r if ( versionParts . length == 1 ) if ( versionParts [ 0 ] . equals ( \"2\" ) ) validVersion = true ; // Two or more version parts specified, make sure it's 2.0.#.#...\r if ( versionParts . length >= 2 ) if ( versionParts [ 0 ] . equals ( \"2\" ) && versionParts [ 1 ] . equals ( \"0\" ) ) validVersion = true ; /* Another exception VersionNegotiationFailed is specified by OGC Web Services Common\r\n\t\t\t\t\t * for version mismatches. If the version check failed print this exception\r\n\t\t\t\t\t */ if ( ! validVersion ) { return new WFSExceptionWriter ( \"WFS Server error. Version requested is not supported.\" , null , \"VersionNegotiationFailed\" ) ; } } else { return new WFSExceptionWriter ( \"WFS server error. VERSION parameter is required.\" , \"request\" , \"MissingParameterValue\" ) ; } // Last check to see if typenames is specified, must be for GetFeature, DescribeFeatureType\r if ( typeName == null ) { return new WFSExceptionWriter ( \"WFS server error. For the specifed request, parameter typename or typenames must be specified.\" , request , \"MissingParameterValue\" ) ; } } WFSRequestType reqToProc = WFSRequestType . getWFSRequestType ( request ) ; if ( reqToProc == null ) return new WFSExceptionWriter ( \"WFS server error. REQUEST parameter is not valid. Possible values: GetCapabilities, \" + \"DescribeFeatureType, GetFeature\" , \"request\" , \"InvalidParameterValue\" ) ; } else { return new WFSExceptionWriter ( \"WFS server error. REQUEST parameter is required.\" , \"request\" , \"MissingParameterValue\" ) ; } return null ; }", "nl": "Checks request parameters for errors . Will send back an XML Exception if any errors are encountered ."}}
{"translation": {"code": "public static String constructServerPath ( HttpServletRequest hsreq ) { return hsreq . getScheme ( ) + \"://\" + hsreq . getServerName ( ) + \":\" + hsreq . getServerPort ( ) + \"/thredds/wfs/\" ; }", "nl": "Constructs the full server URI from a request"}}
{"translation": {"code": "public void startXML ( ) { fileOutput += \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\" ; fileOutput += \"<schema \" + \"xmlns:\" + WFSController . TDSNAMESPACE + \"=\" + WFSXMLHelper . encQuotes ( namespace ) + \" \" + \"xmlns:ogc=\\\"http://www.opengis.net/ogc\\\" xmlns:xsd=\\\"http://www.w3.org/2001/XMLSchema\\\" \" + \"xmlns=\\\"http://www.w3.org/2001/XMLSchema\\\" xmlns:gml=\\\"http://www.opengis.net/gml\\\" \" + \"targetNamespace=\\\"\" + server + \"\\\" elementFormDefault=\\\"qualified\\\" \" + \"version=\\\"0.1\\\">\" ; fileOutput += \"<xsd:import namespace=\\\"http://www.opengis.net/gml\\\" \" + \"schemaLocation=\\\"http://schemas.opengis.net/gml/2.1.2/feature.xsd\\\"/>\" ; }", "nl": "Initiate the response with an XML file with an XML header"}}
{"translation": {"code": "public void setNext ( Polygon next ) { if ( next instanceof CFPolygon ) { setNext ( ( CFPolygon ) next ) ; } else this . next = next ; }", "nl": "Sets the next polygon which make up the multipolygon which this polygon is a part of . If next is a CFPolygon automatically connects the other polygon to this polygon as well ."}}
{"translation": {"code": "private void writeHeadersAndSS ( ) { fileOutput += \"<wfs:WFS_Capabilities xsi:schemaLocation=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/wfs/2.0 http://schemas.opengis.net/wfs/2.0/wfs.xsd \" ) + \" xmlns:xsi=\" + WFSXMLHelper . encQuotes ( \"http://www.w3.org/2001/XMLSchema-instance\" ) + \" xmlns:xlink=\" + WFSXMLHelper . encQuotes ( \"http://www.w3.org/1999/xlink\" ) + \" xmlns:gml=\" + WFSXMLHelper . encQuotes ( \"http://opengis.net/gml\" ) + \" xmlns:fes=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/fes/2.0\" ) + \" xmlns:ogc=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/ogc\" ) + \" xmlns:ows=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/ows/1.1\\\" xmlns:wfs=\\\"http://opengis.net/wfs/2.0\" ) + \" xmlns=\" + WFSXMLHelper . encQuotes ( \"http://www.opengis.net/wfs/2.0\" ) + \" version=\\\"2.0.0\\\">\" ; writeServiceInfo ( ) ; }", "nl": "Writes headers and service sections"}}
{"translation": {"code": "public String writeFeature ( SimpleGeometry geom ) { if ( geom instanceof Point ) return writePoint ( ( Point ) geom ) ; else if ( geom instanceof Line ) return writeLine ( ( Line ) geom ) ; else if ( geom instanceof Polygon ) return writePolygon ( ( Polygon ) geom ) ; else return null ; }", "nl": "Checks the type of the Simple Geom and calls the appropriate method to build the xml"}}
{"translation": {"code": "private String writeLine ( Line line ) { String xml = \"\" ; xml += \"<gml:LineString><gml:posList>\" ; for ( Point point : line . getPoints ( ) ) { xml += point . getX ( ) + \" \" + point . getY ( ) + \" \" ; } xml += \"</gml:posList></gml:LineString>\" ; return xml ; }", "nl": "Takes in a line and iterates through all its points writing the posList to xml"}}
{"translation": {"code": "public double [ ] getBBUpper ( ) { double [ ] bbUpper = new double [ 2 ] ; List < Point > ptList = this . getPoints ( ) ; if ( ptList . isEmpty ( ) ) return null ; bbUpper [ 0 ] = ptList . get ( 0 ) . getY ( ) ; bbUpper [ 1 ] = ptList . get ( 0 ) . getY ( ) ; for ( Point pt : this . getPoints ( ) ) { if ( bbUpper [ 0 ] < pt . getX ( ) ) { bbUpper [ 0 ] = pt . getX ( ) ; } if ( bbUpper [ 1 ] < pt . getY ( ) ) { bbUpper [ 1 ] = pt . getY ( ) ; } } // Got maximum points, add some padding.\r bbUpper [ 0 ] += 10 ; bbUpper [ 1 ] += 10 ; return bbUpper ; }", "nl": "Gets the upper bounding box coordinate on the line ."}}
{"translation": {"code": "public void writeFeatures ( ) { for ( WFSFeature feat : featureList ) { fileOutput += \"<xsd:complexType name=\\\"\" + feat . getTitle ( ) + \"\\\">\" ; fileOutput += \"<xsd:complexContent>\" ; fileOutput += \"<xsd:extension base=\\\"gml:\" + feat . getType ( ) + \"\\\">\" ; fileOutput += \"<xsd:sequence>\" ; for ( WFSFeatureAttribute attribute : feat . getAttributes ( ) ) { fileOutput += \"<xsd:element name =\\\"\" + attribute . getName ( ) + \"\\\" type=\\\"\" + attribute . getType ( ) + \"\\\"/>\" ; } fileOutput += \"</xsd:sequence>\" ; fileOutput += \"</xsd:extension>\" ; fileOutput += \"</xsd:complexContent>\" ; fileOutput += \"</xsd:complexType>\" ; fileOutput += \"<xsd:element name =\\\"\" + feat . getName ( ) + \"\\\" type=\\\"tds:\" + feat . getTitle ( ) + \"\\\"/>\" ; } }", "nl": "Write the features from the featureList . For each feature write its attributes"}}
{"translation": {"code": "public GeometryType getGeometryType ( String name ) { Variable geometryVar = ds . findVariable ( name ) ; if ( geometryVar == null ) return null ; // CFConvention\r if ( ds . findGlobalAttribute ( CF . CONVENTIONS ) != null ) if ( ucar . nc2 . dataset . conv . CF1Convention . getVersion ( ds . findGlobalAttribute ( CF . CONVENTIONS ) . getStringValue ( ) ) >= 8 ) { Attribute geometryTypeAttr = null ; String geometry_type = null ; geometryTypeAttr = geometryVar . findAttribute ( CF . GEOMETRY_TYPE ) ; if ( geometryTypeAttr == null ) return null ; geometry_type = geometryTypeAttr . getStringValue ( ) ; switch ( geometry_type ) { case CF . POLYGON : return GeometryType . POLYGON ; case CF . LINE : return GeometryType . LINE ; case CF . POINT : return GeometryType . POINT ; default : return null ; } } return null ; }", "nl": "Given a variable name returns the geometry type which that variable is associated with . If the variable has no simple geometry information null will be returned ."}}
{"translation": {"code": "public void write ( HttpServletResponse hsr ) throws IOException { PrintWriter xmlResponse = hsr . getWriter ( ) ; xmlResponse . append ( \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\" ) ; xmlResponse . append ( \"<ows:ExceptionReport xml:lang=\\\"en-US\\\" xsi:schemaLocation=\\\"http://www.opengis.net/ows/1.1\" + \" http://schemas.opengis.net/ows/1.1.0/owsExceptionReport.xsd\\\" version=\\\"2.0.0\\\" xmlns:ows=\\\"http://www.opengis.net/ows/1.1\\\"\" + \" xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\">\" ) ; xmlResponse . append ( \"<ows:Exception \" ) ; if ( locator != null ) xmlResponse . append ( \"locator=\\\"\" + locator + \"\\\" \" ) ; xmlResponse . append ( \"exceptionCode=\\\"\" + ExceptionCode + \"\\\">\" ) ; xmlResponse . append ( \"<ows:ExceptionText>\" + text + \"</ows:ExceptionText>\" ) ; xmlResponse . append ( \"</ows:Exception>\" ) ; xmlResponse . append ( \"</ows:ExceptionReport>\" ) ; }", "nl": "Given the information on construction writes the necessary exception information ."}}
{"translation": {"code": "private String writePoint ( Point point ) { String xml = \"\" ; xml += \"<gml:Point srsName=\\\"http://www.opengis.net/gml/srs/epsg.xml@900913\\\" srsDimension=\\\"2\\\">\" + \"<gml:pos>\" + point . getX ( ) + \" \" + point . getY ( ) + \"</gml:pos>\" + \"</gml:Point>\" ; return xml ; }", "nl": "Takes in a point and writes its xml"}}
{"translation": {"code": "public long readLELong ( ) throws IOException { readFully ( w , 0 , 8 ) ; return ( long ) ( w [ 7 ] & 0xff ) << 56 | ( long ) ( w [ 6 ] & 0xff ) << 48 | ( long ) ( w [ 5 ] & 0xff ) << 40 | ( long ) ( w [ 4 ] & 0xff ) << 32 | ( long ) ( w [ 3 ] & 0xff ) << 24 | ( long ) ( w [ 2 ] & 0xff ) << 16 | ( long ) ( w [ 1 ] & 0xff ) << 8 | ( long ) ( w [ 0 ] & 0xff ) ; }", "nl": "read a long in little endian format"}}
{"translation": {"code": "public static boolean isUnitless ( String unit ) { if ( unit == null ) return true ; String munge = unit . toLowerCase ( ) . trim ( ) ; munge = StringUtil2 . remove ( munge , ' ' ) ; return munge . length ( ) == 0 || munge . startsWith ( \"numeric\" ) || munge . startsWith ( \"non-dim\" ) || munge . startsWith ( \"see\" ) || munge . startsWith ( \"proportion\" ) || munge . startsWith ( \"code\" ) || munge . startsWith ( \"0=\" ) || munge . equals ( \"1\" ) ; }", "nl": "The given unit is unitless ."}}
{"translation": {"code": "public boolean nearlyEquals ( VertCoordValue other ) { return Misc . nearlyEquals ( value1 , other . value1 ) && Misc . nearlyEquals ( value2 , other . value2 ) ; }", "nl": "cannot do approx equals and be consistent with hashCode so make seperate call"}}
{"translation": {"code": "public TimeCoordIntvValue convertReferenceDate ( CalendarDate refDate , CalendarPeriod timeUnit ) { if ( timeUnit == null ) { throw new IllegalArgumentException ( \"null time unit\" ) ; } int startOffset = timeUnit . getOffset ( refDate , start ) ; // LOOK wrong - not dealing with value ?? int endOffset = timeUnit . getOffset ( refDate , end ) ; return new TimeCoordIntvValue ( startOffset , endOffset ) ; }", "nl": "Calculate the offset in units of timeUnit from the given reference date?"}}