{"translation": {"code": "private CoordinateTransform makeUTMProjection ( NetcdfDataset ds ) { int zone = ( int ) findAttributeDouble ( ds , \"P_ALP\" ) ; double ycent = findAttributeDouble ( ds , \"YCENT\" ) ; //double lon0 = findAttributeDouble( \"X_CENT\"); //double lat0 = findAttributeDouble( \"Y_CENT\"); /**\n     * Construct a UTM Projection.\n     * @param zone - UTM zone\n     * @param if ycent < 0, then isNorth = False\n     */ boolean isNorth = true ; if ( ycent < 0 ) isNorth = false ; UtmProjection utm = new UtmProjection ( zone , isNorth ) ; return new ProjectionCT ( \"UTM\" , \"EPSG\" , utm ) ; }", "nl": "Intend to use EPSG system parameters"}}
{"translation": {"code": "private InputStream filterTag ( InputStream in ) throws IOException { BufferedReader buffIn = new BufferedReader ( new InputStreamReader ( in , CDM . UTF8 ) ) ; ByteArrayOutputStream bos = new ByteArrayOutputStream ( 10000 ) ; String line = buffIn . readLine ( ) ; while ( line != null ) { String lline = line . toLowerCase ( ) ; if ( lline . contains ( \"<meta \" ) ) // skip meta tags continue ; //System.out.println(\"--\"+line); bos . write ( line . getBytes ( CDM . utf8Charset ) ) ; line = buffIn . readLine ( ) ; } buffIn . close ( ) ; return new ByteArrayInputStream ( bos . toByteArray ( ) ) ; }", "nl": "workaround for HTMLEditorKit . Parser cant deal with content - encoding"}}
{"translation": {"code": "public BufferedImage getNextImage ( boolean forward ) { if ( grid != null ) { if ( forward ) { this . time ++ ; if ( this . time >= this . ntimes ) this . time = 0 ; } else { this . time -- ; if ( this . time < 0 ) this . time = this . ntimes - 1 ; } Array data ; try { data = grid . readDataSlice ( this . time , 0 , - 1 , - 1 ) ; return ImageArrayAdapter . makeGrayscaleImage ( data , grid ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; return null ; } } if ( currentFile == null ) return null ; if ( currentDir == null ) { currentDirFileNo = 0 ; currentDir = currentFile . getParentFile ( ) ; currentDirFileList = new ArrayList <> ( ) ; addToList ( currentDir , currentDirFileList ) ; //Arrays.asList(currentDir.listFiles()); //Collections.sort(currentDirFileList); for ( int i = 0 ; i < currentDirFileList . size ( ) ; i ++ ) { File file = currentDirFileList . get ( i ) ; if ( file . equals ( currentFile ) ) currentDirFileNo = i ; } } if ( forward ) { currentDirFileNo ++ ; if ( currentDirFileNo >= currentDirFileList . size ( ) ) currentDirFileNo = 0 ; } else { currentDirFileNo -- ; if ( currentDirFileNo < 0 ) currentDirFileNo = currentDirFileList . size ( ) - 1 ; } File nextFile = currentDirFileList . get ( currentDirFileNo ) ; try { System . out . println ( \"Open image \" + nextFile ) ; return javax . imageio . ImageIO . read ( nextFile ) ; } catch ( IOException e ) { System . out . println ( \"Failed to open image \" + nextFile ) ; return getNextImage ( forward ) ; } }", "nl": "This assumes you have opened a file . looks in the parent directory ."}}
{"translation": {"code": "public int read ( ) { if ( streamEnd ) { return - 1 ; } else { int retChar = currentChar ; switch ( currentState ) { case START_BLOCK_STATE : break ; case RAND_PART_A_STATE : break ; case RAND_PART_B_STATE : setupRandPartB ( ) ; break ; case RAND_PART_C_STATE : setupRandPartC ( ) ; break ; case NO_RAND_PART_A_STATE : break ; case NO_RAND_PART_B_STATE : setupNoRandPartB ( ) ; break ; case NO_RAND_PART_C_STATE : setupNoRandPartC ( ) ; break ; default : break ; } return retChar ; } }", "nl": "Reads the stream ."}}
{"translation": {"code": "public boolean writeXML ( QueryCapability dqc , String filename ) { try { BufferedOutputStream os = new BufferedOutputStream ( new FileOutputStream ( filename ) ) ; writeXML ( dqc , os ) ; os . close ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; return false ; } return true ; }", "nl": "Write the catalog as an XML document to the specified filename ."}}
{"translation": {"code": "public Number getNumericValue ( int index ) { if ( ( index < 0 ) || ( index >= nelems ) ) return null ; // LOOK can attributes be enum valued? for now, no switch ( dataType ) { case STRING : try { return new Double ( getStringValue ( index ) ) ; } catch ( NumberFormatException e ) { return null ; } case BYTE : case UBYTE : return values . getByte ( index ) ; case SHORT : case USHORT : return values . getShort ( index ) ; case INT : case UINT : return values . getInt ( index ) ; case FLOAT : return values . getFloat ( index ) ; case DOUBLE : return values . getDouble ( index ) ; case LONG : case ULONG : return values . getLong ( index ) ; } return null ; }", "nl": "Retrieve a numeric value by index . If it s a String it will try to parse it as a double ."}}
{"translation": {"code": "protected void writeCDL ( Formatter f , boolean strict , String parentname ) { if ( strict && ( isString ( ) || this . getEnumType ( ) != null ) ) // Force type explicitly for string. f . format ( \"string \" ) ; //note lower case and trailing blank if ( strict && parentname != null ) f . format ( NetcdfFile . makeValidCDLName ( parentname ) ) ; f . format ( \":\" ) ; f . format ( \"%s\" , strict ? NetcdfFile . makeValidCDLName ( getShortName ( ) ) : getShortName ( ) ) ; if ( isString ( ) ) { f . format ( \" = \" ) ; for ( int i = 0 ; i < getLength ( ) ; i ++ ) { if ( i != 0 ) f . format ( \", \" ) ; String val = getStringValue ( i ) ; if ( val != null ) f . format ( \"\\\"%s\\\"\" , encodeString ( val ) ) ; } } else if ( getEnumType ( ) != null ) { f . format ( \" = \" ) ; for ( int i = 0 ; i < getLength ( ) ; i ++ ) { if ( i != 0 ) f . format ( \", \" ) ; EnumTypedef en = getEnumType ( ) ; String econst = getStringValue ( i ) ; Integer ecint = en . lookupEnumInt ( econst ) ; if ( ecint == null ) throw new ForbiddenConversionException ( \"Illegal enum constant: \" + econst ) ; f . format ( \"\\\"%s\\\"\" , encodeString ( econst ) ) ; } } else { f . format ( \" = \" ) ; for ( int i = 0 ; i < getLength ( ) ; i ++ ) { if ( i != 0 ) f . format ( \", \" ) ; Number number = getNumericValue ( i ) ; if ( dataType . isUnsigned ( ) ) { // 'number' is unsigned, but will be treated as signed when we print it below, because Java only has signed // types. If it is large enough ( >= 2^(BIT_WIDTH-1) ), its most-significant bit will be interpreted as the // sign bit, which will result in an invalid (negative) value being printed. To prevent that, we're going // to widen the number before printing it. number = DataType . widenNumber ( number ) ; } f . format ( \"%s\" , number ) ; if ( dataType . isUnsigned ( ) ) { f . format ( \"U\" ) ; } if ( dataType == DataType . FLOAT ) f . format ( \"f\" ) ; else if ( dataType == DataType . SHORT || dataType == DataType . USHORT ) { f . format ( \"S\" ) ; } else if ( dataType == DataType . BYTE || dataType == DataType . UBYTE ) { f . format ( \"B\" ) ; } else if ( dataType == DataType . LONG || dataType == DataType . ULONG ) { f . format ( \"L\" ) ; } } } }", "nl": "Write CDL representation into f"}}
{"translation": {"code": "private void setStringValue ( String val ) { if ( val == null ) throw new IllegalArgumentException ( \"Attribute value cannot be null\" ) ; // get rid of trailing nul characters int len = val . length ( ) ; while ( ( len > 0 ) && ( val . charAt ( len - 1 ) == 0 ) ) len -- ; if ( len != val . length ( ) ) val = val . substring ( 0 , len ) ; this . svalue = val ; this . nelems = 1 ; this . dataType = DataType . STRING ; //values = Array.factory(String.class, new int[]{1}); //values.setObject(values.getIndex(), val); //setValues(values); }", "nl": "set the value as a String trimming trailing zeroes"}}
{"translation": {"code": "public void setValues ( Array arr ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( arr == null ) { dataType = DataType . STRING ; return ; } if ( arr . getElementType ( ) == char . class ) { // turn CHAR into STRING ArrayChar carr = ( ArrayChar ) arr ; if ( carr . getRank ( ) == 1 ) { // common case svalue = carr . getString ( ) ; this . nelems = 1 ; this . dataType = DataType . STRING ; return ; } // otherwise its an array of Strings arr = carr . make1DStringArray ( ) ; } // this should be a utility somewhere if ( arr . getElementType ( ) == ByteBuffer . class ) { // turn OPAQUE into BYTE int totalLen = 0 ; arr . resetLocalIterator ( ) ; while ( arr . hasNext ( ) ) { ByteBuffer bb = ( ByteBuffer ) arr . next ( ) ; totalLen += bb . limit ( ) ; } byte [ ] ba = new byte [ totalLen ] ; int pos = 0 ; arr . resetLocalIterator ( ) ; while ( arr . hasNext ( ) ) { ByteBuffer bb = ( ByteBuffer ) arr . next ( ) ; System . arraycopy ( bb . array ( ) , 0 , ba , pos , bb . limit ( ) ) ; pos += bb . limit ( ) ; } arr = Array . factory ( DataType . BYTE , new int [ ] { totalLen } , ba ) ; } if ( DataType . getType ( arr ) == DataType . OBJECT ) throw new IllegalArgumentException ( \"Cant set Attribute with type \" + arr . getElementType ( ) ) ; if ( arr . getRank ( ) > 1 ) arr = arr . reshape ( new int [ ] { ( int ) arr . getSize ( ) } ) ; // make sure 1D this . values = arr ; this . nelems = ( int ) arr . getSize ( ) ; this . dataType = DataType . getType ( arr ) ; }", "nl": "set the values from an Array"}}
{"translation": {"code": "public void scan ( ) throws IOException { if ( state == 1 ) throw new IllegalStateException ( \"Scan already underway.\" ) ; if ( state >= 2 ) throw new IllegalStateException ( \"Scan has already been generated.\" ) ; state = 1 ; // Make sure proxyDsHandlers Map is not null. if ( proxyDsHandlers == null ) proxyDsHandlers = Collections . EMPTY_MAP ; // Create a skeleton catalog. genCatalog = createSkeletonCatalog ( currentLevel ) ; InvDatasetImpl topInvDs = ( InvDatasetImpl ) genCatalog . getDatasets ( ) . get ( 0 ) ; // Get the datasets in this collection. List crDsList = currentLevel . listDatasets ( this . filter ) ; // Sort the datasets in this collection. // @todo Should we move sort to end of this method? As is, we can't use naming or enhancements to determine sort order. if ( sorter != null ) sorter . sort ( crDsList ) ; // Add the datasets to the catalog. for ( int i = 0 ; i < crDsList . size ( ) ; i ++ ) //for ( Iterator it = crDsList.iterator(); it.hasNext(); ) { CrawlableDataset curCrDs = ( CrawlableDataset ) crDsList . get ( i ) ; InvDatasetImpl curInvDs = ( InvDatasetImpl ) createInvDatasetFromCrawlableDataset ( curCrDs , topInvDs , null ) ; // Add dataset info to appropriate lists. InvCrawlablePair dsInfo = new InvCrawlablePair ( curCrDs , curInvDs ) ; //allDsInfo.add( dsInfo ); if ( curCrDs . isCollection ( ) ) catRefInfo . add ( dsInfo ) ; else atomicDsInfo . add ( dsInfo ) ; // Add current InvDataset to top dataset. topInvDs . addDataset ( curInvDs ) ; } // Tie up any loose ends in catalog with finish(). ( ( InvCatalogImpl ) genCatalog ) . finish ( ) ; // Add proxy datasets to list (only if some atomic datasets in this collection). if ( atomicDsInfo . size ( ) > 0 ) { boolean anyProxiesAdded = false ; for ( Iterator it = proxyDsHandlers . values ( ) . iterator ( ) ; it . hasNext ( ) ; ) { // Get current ProxyDatasetHandler curProxy = ( ProxyDatasetHandler ) it . next ( ) ; InvService proxyService = curProxy . getProxyDatasetService ( currentLevel ) ; if ( proxyService != null ) { // Create proxy CrawlableDataset and corresponding InvDataset CrawlableDataset crDsToAdd = curProxy . createProxyDataset ( currentLevel ) ; InvDatasetImpl invDsToAdd = createInvDatasetFromCrawlableDataset ( crDsToAdd , topInvDs , proxyService ) ; // Add dataset info to appropriate lists. InvCrawlablePair dsInfo = new InvCrawlablePair ( crDsToAdd , invDsToAdd ) ; proxyDsInfo . add ( dsInfo ) ; // Add dataset to catalog int index = curProxy . getProxyDatasetLocation ( currentLevel , topInvDs . getDatasets ( ) . size ( ) ) ; topInvDs . addDataset ( index , ( InvDatasetImpl ) invDsToAdd ) ; genCatalog . addService ( proxyService ) ; anyProxiesAdded = true ; } } // Tie up any proxy dataset loose ends. if ( anyProxiesAdded ) ( ( InvCatalogImpl ) genCatalog ) . finish ( ) ; } // Add any top-level metadata. this . addTopLevelMetadata ( genCatalog , true ) ; state = 2 ; return ; }", "nl": "Scan the collection and gather information on contained datasets ."}}
{"translation": {"code": "public InvCatalogImpl generateProxyDsResolverCatalog ( ProxyDatasetHandler pdh ) { if ( state != 2 ) throw new IllegalStateException ( \"Scan has not been performed.\" ) ; if ( ! proxyDsHandlers . containsValue ( pdh ) ) throw new IllegalArgumentException ( \"Unknown ProxyDatasetHandler.\" ) ; // Create a skeleton catalog. InvCatalogImpl catalog = createSkeletonCatalog ( currentLevel ) ; InvDatasetImpl topDs = ( InvDatasetImpl ) catalog . getDatasets ( ) . get ( 0 ) ; // Find actual dataset in the list of atomic dataset InvCrawlablePairs. InvCrawlablePair actualDsInfo = pdh . getActualDataset ( atomicDsInfo ) ; if ( actualDsInfo == null ) return catalog ; // TODO Test this case in TestDataRootHandler. InvDatasetImpl actualInvDs = ( InvDatasetImpl ) actualDsInfo . getInvDataset ( ) ; actualInvDs . setName ( pdh . getActualDatasetName ( actualDsInfo , topDs . getName ( ) ) ) ; // Add current InvDataset to top dataset. catalog . removeDataset ( topDs ) ; catalog . addDataset ( actualInvDs ) ; // topDs.addDataset( actualInvDs ); // Finish catalog. catalog . finish ( ) ; // Add any top-level metadata. this . addTopLevelMetadata ( catalog , false ) ; return catalog ; }", "nl": "Generate the catalog for a resolver request of the given ProxyDatasetHandler ."}}
{"translation": {"code": "public float [ ] getParamValues ( DoradeRDAT rdat , float [ ] workingArray ) throws DescriptorException { if ( ! paramName . equals ( rdat . getParamName ( ) ) ) throw new DescriptorException ( \"parameter name mismatch\" ) ; byte [ ] paramData = rdat . getRawData ( ) ; int nCells = myRADD . getNCells ( ) ; float [ ] values ; if ( workingArray != null && workingArray . length == nCells ) { values = workingArray ; } else { values = new float [ nCells ] ; } short [ ] svalues = null ; if ( myRADD . getCompressionScheme ( ) == DoradeRADD . COMPRESSION_HRD ) { if ( binaryFormat != DoradePARM . FORMAT_16BIT_INT ) { throw new DescriptorException ( \"Cannot unpack \" + \"compressed data with binary format \" + binaryFormat ) ; } svalues = uncompressHRD ( paramData , nCells ) ; } for ( int cell = 0 ; cell < nCells ; cell ++ ) { switch ( binaryFormat ) { case DoradePARM . FORMAT_8BIT_INT : byte bval = paramData [ cell ] ; values [ cell ] = ( bval == badDataFlag ) ? BAD_VALUE : ( bval - bias ) / scale ; break ; case DoradePARM . FORMAT_16BIT_INT : short sval = ( svalues != null ) ? svalues [ cell ] : grabShort ( paramData , 2 * cell ) ; values [ cell ] = ( sval == badDataFlag ) ? BAD_VALUE : ( sval - bias ) / scale ; break ; case DoradePARM . FORMAT_32BIT_INT : int ival = grabInt ( paramData , 4 * cell ) ; values [ cell ] = ( ival == badDataFlag ) ? BAD_VALUE : ( ival - bias ) / scale ; break ; case DoradePARM . FORMAT_32BIT_FLOAT : float fval = grabFloat ( paramData , 4 * cell ) ; values [ cell ] = ( fval == badDataFlag ) ? BAD_VALUE : ( fval - bias ) / scale ; break ; case DoradePARM . FORMAT_16BIT_FLOAT : throw new DescriptorException ( \"can't unpack 16-bit \" + \"float data yet\" ) ; default : throw new DescriptorException ( \"bad binary format (\" + binaryFormat + \")\" ) ; } } return values ; }", "nl": "Get the unpacked data values for a selected parameter ."}}
{"translation": {"code": "public int compareTo ( final BaseQuantity that ) { int comp ; if ( this == that ) { comp = 0 ; } else { comp = getName ( ) . compareToIgnoreCase ( that . getName ( ) ) ; if ( comp == 0 && getSymbol ( ) != null ) { comp = getSymbol ( ) . compareTo ( that . getSymbol ( ) ) ; } } return comp ; }", "nl": "Compares this base quantity to another base quantity ."}}
{"translation": {"code": "public void setStream ( InputStream zStream ) { last = 0 ; origPtr = 0 ; blockSize100k = 0 ; blockRandomised = false ; bsBuff = 0 ; bsLive = 0 ; mCrc = new CRC ( ) ; nInUse = 0 ; bsStream = null ; streamEnd = false ; currentChar = - 1 ; currentState = START_BLOCK_STATE ; storedBlockCRC = storedCombinedCRC = 0 ; computedBlockCRC = computedCombinedCRC = 0 ; i2 = count = chPrev = ch2 = 0 ; i = tPos = 0 ; rNToGo = 0 ; rTPos = 0 ; j2 = 0 ; z = 0 ; bsSetStream ( zStream ) ; initialize ( ) ; if ( ! streamEnd ) { // Handle if initialize does not detect valid bz2 stream initBlock ( ) ; setupBlock ( ) ; } }", "nl": "Added 5 - 30 - 2006 to allow for resetting of the input used by this object . This saves in memory allocation costs"}}
{"translation": {"code": "public static Cursor makeCursor ( String name ) { Image image = getImage ( name ) ; if ( null == image ) return null ; Cursor cursor ; try { Toolkit tk = Toolkit . getDefaultToolkit ( ) ; if ( debug ) { ImageObserver obs = new ImageObserver ( ) { public boolean imageUpdate ( Image image , int flags , int x , int y , int width , int height ) { return true ; } } ; System . out . println ( \" bestCursorSize = \" + tk . getBestCursorSize ( image . getWidth ( obs ) , image . getHeight ( obs ) ) ) ; System . out . println ( \" getMaximumCursorColors = \" + tk . getMaximumCursorColors ( ) ) ; } cursor = tk . createCustomCursor ( image , new Point ( 17 , 17 ) , name ) ; } catch ( IndexOutOfBoundsException e ) { System . out . println ( \"NavigatedPanel createCustomCursor failed \" + e ) ; return null ; } return cursor ; }", "nl": "Get a gif file make it into a Cursor ."}}
{"translation": {"code": "public static Image getImage ( String fullImageName ) { Image image = null ; java . net . URL url = cl . getResource ( fullImageName ) ; if ( url != null ) image = Toolkit . getDefaultToolkit ( ) . createImage ( url ) ; if ( image == null ) System . out . println ( \"  ERROR: Resource.getImageResource failed on \" + fullImageName ) ; return image ; }", "nl": "Get a gif file make it into an Image ."}}
{"translation": {"code": "public static ImageIcon getIcon ( String fullIconName , boolean errMsg ) { ImageIcon icon = null ; java . net . URL iconR = cl . getResource ( fullIconName ) ; if ( debugIcon ) { System . out . println ( \"classLoader \" + cl . getClassLoader ( ) ) ; System . out . println ( \"  Resource.getIcon on \" + fullIconName + \" = \" + iconR ) ; } if ( iconR != null ) icon = new ImageIcon ( iconR ) ; if ( ( icon == null ) && errMsg ) System . out . println ( \"  ERROR: Resource.getIcon failed on \" + fullIconName ) ; else if ( debugIcon ) System . out . println ( \"  Resource.getIcon ok on \" + fullIconName ) ; return icon ; }", "nl": "Get a gif file make it into an ImageIcon ."}}
{"translation": {"code": "public boolean isDatasetUseable ( InvDataset ds , StringBuilder sbuff ) { boolean ok = true ; sbuff . append ( \"Dataset \" + ds . getName ( ) + \" id = \" + ds . getID ( ) + \": \" ) ; if ( ! ds . isHarvest ( ) ) { ok = false ; sbuff . append ( \"Dataset \" + ds . getName ( ) + \" id = \" + ds . getID ( ) + \" has harvest = false\\n\" ) ; } if ( ds . getName ( ) == null ) { ok = false ; sbuff . append ( \" missing Name field\\n\" ) ; } if ( ds . getUniqueID ( ) == null ) { ok = false ; sbuff . append ( \" missing ID field\\n\" ) ; } ThreddsMetadata . Variables vs = ds . getVariables ( \"DIF\" ) ; if ( ( vs == null ) || ( vs . getVariableList ( ) . size ( ) == 0 ) ) vs = ds . getVariables ( \"GRIB-1\" ) ; if ( ( vs == null ) || ( vs . getVariableList ( ) . size ( ) == 0 ) ) vs = ds . getVariables ( \"GRIB-2\" ) ; if ( ( vs == null ) || ( vs . getVariableList ( ) . size ( ) == 0 ) ) { ok = false ; sbuff . append ( \" missing Variables with DIF or GRIB compatible vocabulary\\n\" ) ; } List list = ds . getPublishers ( ) ; if ( ( list == null ) || ( list . size ( ) == 0 ) ) { ok = false ; sbuff . append ( \" must have publisher element that defines the data center\\n\" ) ; } String summary = ds . getDocumentation ( \"summary\" ) ; if ( summary == null ) { ok = false ; sbuff . append ( \" must have documentation element of type summary\\n\" ) ; } sbuff . append ( \" useable= \" + ok + \"\\n\" ) ; return ok ; }", "nl": "See if a dataset is harvestable to a DIF record ."}}
{"translation": {"code": "static public String makeName ( List < CoordinateAxis > axes ) { List < CoordinateAxis > axesSorted = new ArrayList <> ( axes ) ; Collections . sort ( axesSorted , new CoordinateAxis . AxisComparator ( ) ) ; StringBuilder buff = new StringBuilder ( ) ; for ( int i = 0 ; i < axesSorted . size ( ) ; i ++ ) { CoordinateAxis axis = axesSorted . get ( i ) ; if ( i > 0 ) buff . append ( \" \" ) ; buff . append ( axis . getFullNameEscaped ( ) ) ; } return buff . toString ( ) ; }", "nl": "Create standard name from list of axes . Sort the axes first"}}
{"translation": {"code": "private CoordinateAxis lesserRank ( CoordinateAxis a1 , CoordinateAxis a2 ) { if ( a1 == null ) return a2 ; return ( a1 . getRank ( ) <= a2 . getRank ( ) ) ? a1 : a2 ; }", "nl": "prefer smaller ranks in case more than one"}}
{"translation": {"code": "public ProjectionCT getProjectionCT ( ) { for ( CoordinateTransform ct : coordTrans ) { if ( ct instanceof ProjectionCT ) return ( ProjectionCT ) ct ; } return null ; }", "nl": "Find the first ProjectionCT from the list of CoordinateTransforms ."}}
{"translation": {"code": "public boolean isGeoXY ( ) { if ( ( xAxis == null ) || ( yAxis == null ) ) return false ; return null != getProjection ( ) && ! ( projection instanceof LatLonProjection ) ; }", "nl": "true if it has X and Y CoordinateAxis and a CoordTransform Projection"}}
{"translation": {"code": "public String getTextContent ( String url ) throws IOException { if ( debug ) System . out . println ( \" URL.getTextContent=\" + url ) ; baseURL = new URL ( url ) ; InputStream in = baseURL . openStream ( ) ; InputStreamReader r = new InputStreamReader ( filterTag ( in ) , CDM . UTF8 ) ; HTMLEditorKit . ParserCallback callback = new CallerBacker ( ) ; textBuffer = new StringBuffer ( 3000 ) ; wantURLS = false ; wantText = true ; parser . parse ( r , callback , false ) ; return textBuffer . toString ( ) ; }", "nl": "Extract text content from the given URL and return in String"}}
{"translation": {"code": "public ArrayList extract ( String url ) throws IOException { if ( debug ) System . out . println ( \" URLextract=\" + url ) ; baseURL = new URL ( url ) ; InputStream in = baseURL . openStream ( ) ; InputStreamReader r = new InputStreamReader ( filterTag ( in ) , CDM . UTF8 ) ; HTMLEditorKit . ParserCallback callback = new CallerBacker ( ) ; urlList = new ArrayList ( ) ; wantURLS = true ; wantText = false ; parser . parse ( r , callback , false ) ; return urlList ; }", "nl": "Extract all A - HREF contained URLS from the given URL and return in List"}}
{"translation": {"code": "public InvCatalogImpl makeCatalogForDirectory ( String orgPath , URI catURI ) { if ( log . isDebugEnabled ( ) ) { log . debug ( \"baseURI=\" + catURI ) ; log . debug ( \"orgPath=\" + orgPath ) ; log . debug ( \"rootPath=\" + rootPath ) ; log . debug ( \"scanLocation=\" + scanLocation ) ; } // Get the dataset path. String dsDirPath = translatePathToLocation ( orgPath ) ; if ( dsDirPath == null ) { String tmpMsg = \"makeCatalogForDirectory(): Requesting path <\" + orgPath + \"> must start with \\\"\" + rootPath + \"\\\".\" ; log . error ( tmpMsg ) ; return null ; } // Setup and create catalog builder. CatalogBuilder catBuilder = buildCatalogBuilder ( ) ; if ( catBuilder == null ) return null ; // A very round about way to remove the filename (e.g., \"catalog.xml\"). // Note: Gets around \"path separator at end of path\" issues that are CrDs implementation dependant. // Note: Does not check that CrDs is allowed by filters. String dsPath = dsDirPath . substring ( scanLocationCrDs . getPath ( ) . length ( ) ) ; if ( dsPath . startsWith ( \"/\" ) ) dsPath = dsPath . substring ( 1 ) ; CrawlableDataset reqCrDs = scanLocationCrDs . getDescendant ( dsPath ) ; CrawlableDataset parent = reqCrDs . getParentDataset ( ) ; if ( parent == null ) { log . error ( \"makeCatalogForDirectory(): I/O error getting parent crDs level <\" + dsDirPath + \">: \" ) ; return null ; } dsDirPath = parent . getPath ( ) ; // Get the CrawlableDataset for the desired catalog level (checks that allowed by filters). CrawlableDataset catalogCrDs ; try { catalogCrDs = catBuilder . requestCrawlableDataset ( dsDirPath ) ; } catch ( IOException e ) { log . error ( \"makeCatalogForDirectory(): I/O error getting catalog level <\" + dsDirPath + \">: \" + e . getMessage ( ) , e ) ; return null ; } if ( catalogCrDs == null ) { log . warn ( \"makeCatalogForDirectory(): requested catalog level <\" + dsDirPath + \"> not allowed (filtered out).\" ) ; return null ; } if ( ! catalogCrDs . isCollection ( ) ) { log . warn ( \"makeCatalogForDirectory(): requested catalog level <\" + dsDirPath + \"> is not a collection.\" ) ; return null ; } // Generate the desired catalog using the builder. InvCatalogImpl catalog ; try { catalog = catBuilder . generateCatalog ( catalogCrDs ) ; } catch ( IOException e ) { log . error ( \"makeCatalogForDirectory(): catalog generation failed <\" + catalogCrDs . getPath ( ) + \">: \" + e . getMessage ( ) ) ; return null ; } // Set the catalog base URI. if ( catalog != null ) catalog . setBaseURI ( catURI ) ; //    InvDatasetImpl top = (InvDatasetImpl) catalog.getDataset(); //    // if we name it carefully, can get catalogRef to useProxy == true (disappear top dataset) //    if ( service.isRelativeBase()) { //      pos = dataDir.lastIndexOf(\"/\"); //      String lastDir = (pos > 0) ? dataDir.substring(pos+1) : dataDir; //      String topName = lastDir.length() > 0 ? lastDir : getName(); //      top.setName( topName); //    } return catalog ; }", "nl": "Try to build a catalog for the given path by scanning the location associated with this InvDatasetScan . The given path must start with the path of this InvDatasetScan ."}}
{"translation": {"code": "public InvCatalogImpl makeProxyDsResolverCatalog ( String path , URI baseURI ) { if ( path == null ) return null ; if ( path . endsWith ( \"/\" ) ) return null ; // Get the dataset path. String dsDirPath = translatePathToLocation ( path ) ; if ( dsDirPath == null ) { log . error ( \"makeProxyDsResolverCatalog(): Requesting path <\" + path + \"> must start with \\\"\" + rootPath + \"\\\".\" ) ; return null ; } // Split into parent path and dataset name. int pos = dsDirPath . lastIndexOf ( ' ' ) ; if ( pos == - 1 ) { log . error ( \"makeProxyDsResolverCatalog(): Requesting path <\" + path + \"> must contain a slash (\\\"/\\\").\" ) ; return null ; } String dsName = dsDirPath . substring ( pos + 1 ) ; dsDirPath = dsDirPath . substring ( 0 , pos ) ; // Find matching ProxyDatasetHandler. ProxyDatasetHandler pdh = this . getProxyDatasetHandlers ( ) . get ( dsName ) ; if ( pdh == null ) { log . error ( \"makeProxyDsResolverCatalog(): No matching proxy dataset handler found <\" + dsName + \">.\" ) ; return null ; } // Setup and create catalog builder. CatalogBuilder catBuilder = buildCatalogBuilder ( ) ; if ( catBuilder == null ) return null ; // Get the CrawlableDataset for the desired catalog level. CrawlableDataset catalogCrDs ; try { catalogCrDs = catBuilder . requestCrawlableDataset ( dsDirPath ) ; } catch ( IOException e ) { log . error ( \"makeProxyDsResolverCatalog(): failed to create CrawlableDataset for catalogLevel <\" + dsDirPath + \"> and class <\" + crDsClassName + \">: \" + e . getMessage ( ) , e ) ; return null ; } if ( catalogCrDs == null ) { log . warn ( \"makeProxyDsResolverCatalog(): requested catalog level <\" + dsDirPath + \"> not allowed (filtered out).\" ) ; return null ; } if ( ! catalogCrDs . isCollection ( ) ) { log . warn ( \"makeProxyDsResolverCatalog(): requested catalog level <\" + dsDirPath + \"> not a collection.\" ) ; return null ; } // Generate the desired catalog using the builder. InvCatalogImpl catalog ; try { catalog = ( InvCatalogImpl ) catBuilder . generateProxyDsResolverCatalog ( catalogCrDs , pdh ) ; } catch ( IOException e ) { log . error ( \"makeProxyDsResolverCatalog(): catalog generation failed <\" + catalogCrDs . getPath ( ) + \">: \" + e . getMessage ( ) ) ; return null ; } // Set the catalog base URI. if ( catalog != null ) catalog . setBaseURI ( baseURI ) ; return catalog ; }", "nl": "Try to build a catalog for the given resolver path by scanning the location associated with this InvDatasetScan . The given path must start with the path of this InvDatasetScan and refer to a resolver ProxyDatasetHandler that is part of this InvDatasetScan ."}}
{"translation": {"code": "public boolean isNumeric ( ) { return ( getDataType ( ) != DataType . CHAR ) && ( getDataType ( ) != DataType . STRING ) && ( getDataType ( ) != DataType . STRUCTURE ) ; }", "nl": "Does the axis have numeric values ."}}
{"translation": {"code": "public int getGateSize ( int datatype ) { switch ( datatype ) { case REFLECTIVITY : return ( ( int ) reflect_gate_size ) ; case VELOCITY_HI : case VELOCITY_LOW : case SPECTRUM_WIDTH : return ( ( int ) doppler_gate_size ) ; //high resolution case REFLECTIVITY_HIGH : return ( ( int ) reflectHR_gate_size ) ; case VELOCITY_HIGH : return ( ( int ) velocityHR_gate_size ) ; case SPECTRUM_WIDTH_HIGH : return ( ( int ) spectrumHR_gate_size ) ; case DIFF_REFLECTIVITY_HIGH : return ( ( int ) zdrHR_gate_size ) ; case DIFF_PHASE : return ( ( int ) phiHR_gate_size ) ; case CORRELATION_COEFFICIENT : return ( ( int ) rhoHR_gate_size ) ; } return - 1 ; }", "nl": "This method returns the gate size in meters"}}
{"translation": {"code": "public int getGateStart ( int datatype ) { switch ( datatype ) { case REFLECTIVITY : return ( ( int ) reflect_first_gate ) ; case VELOCITY_HI : case VELOCITY_LOW : case SPECTRUM_WIDTH : return ( ( int ) doppler_first_gate ) ; //high resolution case REFLECTIVITY_HIGH : return ( ( int ) reflectHR_first_gate ) ; case VELOCITY_HIGH : return ( ( int ) velocityHR_first_gate ) ; case SPECTRUM_WIDTH_HIGH : return ( ( int ) spectrumHR_first_gate ) ; case DIFF_REFLECTIVITY_HIGH : return ( ( int ) zdrHR_first_gate ) ; case DIFF_PHASE : return ( ( int ) phiHR_first_gate ) ; case CORRELATION_COEFFICIENT : return ( ( int ) rhoHR_first_gate ) ; } return - 1 ; }", "nl": "This method returns the starting gate in meters"}}
{"translation": {"code": "public int getGateCount ( int datatype ) { switch ( datatype ) { case REFLECTIVITY : return ( ( int ) reflect_gate_count ) ; case VELOCITY_HI : case VELOCITY_LOW : case SPECTRUM_WIDTH : return ( ( int ) doppler_gate_count ) ; // hight resolution case REFLECTIVITY_HIGH : return ( ( int ) reflectHR_gate_count ) ; case VELOCITY_HIGH : return ( ( int ) velocityHR_gate_count ) ; case SPECTRUM_WIDTH_HIGH : return ( ( int ) spectrumHR_gate_count ) ; case DIFF_REFLECTIVITY_HIGH : return ( ( int ) zdrHR_gate_count ) ; case DIFF_PHASE : return ( ( int ) phiHR_gate_count ) ; case CORRELATION_COEFFICIENT : return ( ( int ) rhoHR_gate_count ) ; } return 0 ; }", "nl": "This method returns the number of gates"}}
{"translation": {"code": "static CrawlableDataset verifyDescendantDataset ( CrawlableDataset ancestorCrDs , String path , CrawlableDatasetFilter filter ) { // Make sure requested path is descendant of ancestor dataset. if ( ! ancestorCrDs . isCollection ( ) ) throw new IllegalArgumentException ( \"Ancestor dataset <\" + ancestorCrDs . getPath ( ) + \"> not a collection.\" ) ; if ( ! path . startsWith ( ancestorCrDs . getPath ( ) ) ) throw new IllegalArgumentException ( \"Dataset path <\" + path + \"> not descendant of given dataset <\" + ancestorCrDs . getPath ( ) + \">.\" ) ; // If path and ancestor are the same, return ancestor. if ( path . length ( ) == ancestorCrDs . getPath ( ) . length ( ) ) return ancestorCrDs ; // Crawl into the dataset collection through each level of the given path // checking that each level is accepted by the given CrawlableDatasetFilter. String remainingPath = path . substring ( ancestorCrDs . getPath ( ) . length ( ) ) ; if ( remainingPath . startsWith ( \"/\" ) ) remainingPath = remainingPath . substring ( 1 ) ; String [ ] pathSegments = remainingPath . split ( \"/\" ) ; CrawlableDataset curCrDs = ancestorCrDs ; for ( int i = 0 ; i < pathSegments . length ; i ++ ) { curCrDs = curCrDs . getDescendant ( pathSegments [ i ] ) ; if ( filter != null ) if ( ! filter . accept ( curCrDs ) ) return null ; } // Only check complete path for existence since speed of check depends on implementation. if ( ! curCrDs . exists ( ) ) return null ; return curCrDs ; }", "nl": "Return the requested dataset if it is the ancestor dataset or an allowed descendant of the ancestor dataset otherwise return null . The given filter determines whether a dataset is allowed or not ."}}
{"translation": {"code": "public InvCatalogImpl generateProxyDsResolverCatalog ( CrawlableDataset catalogCrDs , ProxyDatasetHandler pdh ) throws IOException { throw new java . lang . UnsupportedOperationException ( \"This method not supported by SimpleCatalogBuilder.\" ) ; }", "nl": "Not supported by SimpleCatalogBuilder ."}}
{"translation": {"code": "public Parameter findParameterIgnoreCase ( String name ) { for ( Parameter a : params ) { if ( name . equalsIgnoreCase ( a . getName ( ) ) ) return a ; } return null ; }", "nl": "Convenience function ; look up Parameter by name ignoring case ."}}
{"translation": {"code": "static public CoordinateAxis factory ( NetcdfDataset ncd , VariableDS vds ) { if ( ( vds . getRank ( ) == 0 ) || ( vds . getRank ( ) == 1 ) || ( vds . getRank ( ) == 2 && vds . getDataType ( ) == DataType . CHAR ) ) { return new CoordinateAxis1D ( ncd , vds ) ; } else if ( vds . getRank ( ) == 2 ) return new CoordinateAxis2D ( ncd , vds ) ; else return new CoordinateAxis ( ncd , vds ) ; }", "nl": "Create a coordinate axis from an existing Variable ."}}
{"translation": {"code": "public QuantityDimension getQuantityDimension ( ) { Factor [ ] factors = getFactors ( ) ; for ( int i = factors . length ; -- i >= 0 ; ) { Factor factor = factors [ i ] ; factors [ i ] = new Factor ( ( ( BaseUnit ) factor . getBase ( ) ) . getBaseQuantity ( ) , factor . getExponent ( ) ) ; } return new QuantityDimension ( factors ) ; }", "nl": "Returns the corresponding quantity dimension ."}}
{"translation": {"code": "private boolean match ( InvDataset dataset ) { // Check whether this filter applies to the given dataset. if ( this . getParentDatasetSource ( ) . isCollection ( dataset ) && ! this . applyToCollectionDatasets ) return ( false ) ; if ( ( ! this . getParentDatasetSource ( ) . isCollection ( dataset ) ) && ! this . applyToAtomicDatasets ) return ( false ) ; // Set the default matchPatternTarget so old versions still work. if ( this . matchPatternTarget == null ) { if ( this . getParentDatasetSource ( ) . isCollection ( dataset ) ) { this . setMatchPatternTarget ( \"name\" ) ; } else { this . setMatchPatternTarget ( \"urlPath\" ) ; } } if ( this . type == DatasetFilter . Type . REGULAR_EXPRESSION ) { boolean isMatch ; if ( this . getMatchPatternTarget ( ) . equals ( \"name\" ) ) { java . util . regex . Matcher matcher = this . regExpPattern . matcher ( dataset . getName ( ) ) ; isMatch = matcher . find ( ) ; } else if ( this . getMatchPatternTarget ( ) . equals ( \"urlPath\" ) ) { java . util . regex . Matcher matcher = this . regExpPattern . matcher ( ( ( InvDatasetImpl ) dataset ) . getUrlPath ( ) ) ; isMatch = matcher . find ( ) ; } else { // ToDo deal with any matchPatternTarget (XPath-ish) isMatch = false ; } //      // Invert the meaning of a match (accept things that don't match). //      if ( this.isRejectMatchingDatasets()) //      { //        // If match, return false. //        return( regExpMatch == null ? true : false ); //      } //      // Don't invert (a match is a match). //      else //      { // If match, return true. return ( isMatch ) ; //      } } else { System . err . println ( \"WARNING -- DatasetFilter.accept(): unsupported type\" + \" <\" + this . type . toString ( ) + \">.\" ) ; return ( false ) ; // @todo think about exceptions. //throw new java.lang.Exception( \"DatasetFilter.accept():\" + //  \" unsupported type <\" + this.type.toString() + \">.\"); } }", "nl": "Test whether the given dataset matches the filter criteria ."}}
{"translation": {"code": "public boolean isRegular ( ) { for ( CoordinateAxis axis : coordAxes ) { if ( ! ( axis instanceof CoordinateAxis1D ) ) return false ; if ( ! ( ( CoordinateAxis1D ) axis ) . isRegular ( ) ) return false ; } return true ; }", "nl": "true if all axes are CoordinateAxis1D and are regular"}}
{"translation": {"code": "boolean validate ( StringBuilder out ) { this . isValid = true ; // If log from construction has content, append to validation output msg. if ( this . log . length ( ) > 0 ) { out . append ( this . log ) ; } // Validity check: 'name' cannot be null. (Though, 'name' // can be an empty string.) if ( this . getName ( ) == null ) { isValid = false ; out . append ( \" ** DatasetFilter (4): null value for name is not valid.\" ) ; } // Check that type is not null. if ( this . getType ( ) == null ) { isValid = false ; out . append ( \" ** DatasetFilter (5): null value for type is not valid (set with bad string?).\" ) ; } // Validity check: 'matchPattern' must be null if 'type' value // is not 'RegExp'. if ( this . type == DatasetFilter . Type . REGULAR_EXPRESSION && this . matchPattern == null ) { isValid = false ; out . append ( \" ** DatasetFilter (6): null value for matchPattern not valid when type is 'RegExp'.\" ) ; } if ( this . type != DatasetFilter . Type . REGULAR_EXPRESSION && this . type != null && this . matchPattern != null ) { isValid = false ; out . append ( \" ** DatasetFilter (7): matchPattern value (\" + this . matchPattern + \") must be null if type is not 'RegExp'.\" ) ; } return ( this . isValid ) ; }", "nl": "Validate this DatasetFilter object . Return true if valid false if invalid ."}}
{"translation": {"code": "public VerticalTransform makeVerticalTransform ( NetcdfDataset ds , Dimension timeDim ) { return builder . makeMathTransform ( ds , timeDim , this ) ; }", "nl": "Use the builder to make the Vertical Transform function"}}
{"translation": {"code": "public static CrawlableDataset createCrawlableDataset ( String path , String className , Object configObj ) throws IOException , ClassNotFoundException , NoSuchMethodException , IllegalAccessException , InvocationTargetException , InstantiationException , IllegalArgumentException , NullPointerException // throws CrDsException, IllegalArgumentException { if ( path == null ) throw new NullPointerException ( \"Given path must not be null.\" ) ; String tmpClassName = ( className == null ? defaultClassName : className ) ; // @todo Remove alias until sure how to handle things like \".scour*\" being a regular file. //    if ( CrawlableDatasetAlias.isAlias( tmpPath) ) //        return new CrawlableDatasetAlias( tmpPath, tmpClassName, configObj ); // Get the Class instance for desired CrawlableDataset implementation. Class crDsClass = Class . forName ( tmpClassName ) ; // Check that the Class is a CrawlableDataset. if ( ! CrawlableDataset . class . isAssignableFrom ( crDsClass ) ) { throw new IllegalArgumentException ( \"Requested class <\" + className + \"> not an implementation of thredds.crawlabledataset.CrawlableDataset.\" ) ; } // Instantiate the desired CrawlableDataset. Class [ ] argTypes = { String . class , Object . class } ; Object [ ] args = { path , configObj } ; Constructor constructor = crDsClass . getDeclaredConstructor ( argTypes ) ; try { return ( CrawlableDataset ) constructor . newInstance ( args ) ; } catch ( InvocationTargetException e ) { if ( IOException . class . isAssignableFrom ( e . getCause ( ) . getClass ( ) ) ) throw ( IOException ) e . getCause ( ) ; else throw e ; } }", "nl": "Construct a CrawlableDataset for the given path using the CrawlableDataset implementation indicated by the given class name ."}}
{"translation": {"code": "public static boolean isMine ( NetcdfFile ncfile ) { return ( null != ncfile . findGlobalAttribute ( \"XORIG\" ) ) && ( null != ncfile . findGlobalAttribute ( \"YORIG\" ) ) && ( null != ncfile . findGlobalAttribute ( \"XCELL\" ) ) && ( null != ncfile . findGlobalAttribute ( \"YCELL\" ) ) && ( null != ncfile . findGlobalAttribute ( \"NCOLS\" ) ) && ( null != ncfile . findGlobalAttribute ( \"NROWS\" ) ) ; // M3IOVGGridConvention - is this true for this class ?? // return ncFile.findGlobalAttribute( \"VGLVLS\" ) != null && isValidM3IOFile_( ncFile ); }", "nl": "Do we think this is a M3IO file ."}}
{"translation": {"code": "private void nameDatasetTree ( InvDatasetImpl dataset ) { // If dataset does not have a name, try naming it with dsNamers. // @todo Rethink naming of directories (look at how DatasetFilter deals with collection vs atomic datasets). if ( dataset . getName ( ) . equals ( \"\" ) || ! dataset . hasAccess ( ) ) { logger . debug ( \"nameDatasetTree(): naming dataset ({})...\" , dataset . getUrlPath ( ) ) ; DatasetNamer dsN = null ; for ( int i = 0 ; i < this . datasetNamerList . size ( ) ; i ++ ) { dsN = ( DatasetNamer ) this . datasetNamerList . get ( i ) ; if ( dsN . nameDataset ( dataset ) ) { logger . debug ( \"nameDatasetTree(): ... used namer ({})\" , dsN . getName ( ) ) ; break ; } } } // Try to name any child datasets. InvDatasetImpl curDs = null ; for ( int j = 0 ; j < dataset . getDatasets ( ) . size ( ) ; j ++ ) { curDs = ( InvDatasetImpl ) dataset . getDatasets ( ) . get ( j ) ; logger . debug ( \"nameDatasetTree(): recurse to name child dataset ({})\" , curDs . getUrlPath ( ) ) ; this . nameDatasetTree ( curDs ) ; } return ; }", "nl": "Name the datasets in the given dataset hierarchy using this DatasetSource s list of datasetNamers ."}}
{"translation": {"code": "private void nameDatasetList ( InvDatasetImpl dataset ) { // Create temporary dataset in which to hold named datasets. InvDatasetImpl namedDs = new InvDatasetImpl ( dataset , \"nameDatastList() temp dataset\" , null , null , null ) ; // InvDatasetImpl(parentDs, name, dataType, serviceName, urlPath) dataset . addDataset ( namedDs ) ; // Loop through the DatasetNamers DatasetNamer curNamer = null ; for ( int i = 0 ; i < this . datasetNamerList . size ( ) ; i ++ ) { curNamer = ( DatasetNamer ) this . datasetNamerList . get ( i ) ; logger . debug ( \"nameDatasetList(): trying namer ({})\" , curNamer . getName ( ) ) ; // If the current DatasetNamer adds a new level, create a new dataset. InvDatasetImpl addLevelDs = null ; if ( curNamer . getAddLevel ( ) ) { addLevelDs = new InvDatasetImpl ( null , curNamer . getName ( ) , null , null , null ) ; } // Iterate over remaining unnamed datasets. InvDatasetImpl curDs = null ; java . util . Iterator dsIter = dataset . getDatasets ( ) . iterator ( ) ; while ( dsIter . hasNext ( ) ) { curDs = ( InvDatasetImpl ) dsIter . next ( ) ; logger . debug ( \"nameDatasetList(): try namer on this ds ({}-{})\" , curDs . getName ( ) , curDs . getUrlPath ( ) ) ; // Try to name the current dataset. if ( curNamer . nameDataset ( curDs ) ) { logger . debug ( \"nameDatasetList(): ds named ({})\" , curDs . getName ( ) ) ; // If adding a level, add named datasets to the added level dataset. if ( curNamer . getAddLevel ( ) ) { addLevelDs . addDataset ( curDs ) ; } // Otherwise, add the named datasets to namedDs. else { namedDs . addDataset ( curDs ) ; } // Remove the now-named dataset from list of unnamed datasets. dsIter . remove ( ) ; } } // END - InvDatasetImpl loop // If the namer added a level and a dataset was named by this namer, add the // new level to the list of named datasets. if ( curNamer . getAddLevel ( ) ) { if ( addLevelDs . hasNestedDatasets ( ) ) { namedDs . addDataset ( addLevelDs ) ; } } } // END - DatasetNamer loop namedDs . finish ( ) ; // Once all datasets are named (or unnamable with these DatasetNamers), // add all the datasets in namedDs back into the given containerDataset. if ( logger . isDebugEnabled ( ) ) { logger . debug ( \"nameDatasetList(): number of unnamed datasets is \" + dataset . getDatasets ( ) . size ( ) + \".\" ) ; logger . debug ( \"nameDatasetList(): add named datasets back to container.\" ) ; } for ( int i = 0 ; i < namedDs . getDatasets ( ) . size ( ) ; i ++ ) { dataset . addDataset ( ( InvDatasetImpl ) namedDs . getDatasets ( ) . get ( i ) ) ; } dataset . removeDataset ( namedDs ) ; return ; }", "nl": "Name the datasets contained in the given dataset . The given dataset contains a flat list of datasets ."}}
{"translation": {"code": "private void nameDatasets ( InvDatasetImpl datasetContainer ) { if ( this . getDatasetNamerList ( ) . isEmpty ( ) ) return ; if ( this . isFlatten ( ) ) { logger . debug ( \"nameDatasets(): structure is FLAT calling nameDatasetList()\" ) ; this . nameDatasetList ( datasetContainer ) ; } else { logger . debug ( \"nameDatasets(): structure is DIRECTORY_TREE calling\" + \" nameDatasetTree() on each dataset in dataset container\" ) ; InvDatasetImpl curDs = null ; for ( int j = 0 ; j < datasetContainer . getDatasets ( ) . size ( ) ; j ++ ) { curDs = ( InvDatasetImpl ) datasetContainer . getDatasets ( ) . get ( j ) ; this . nameDatasetTree ( curDs ) ; } } return ; }", "nl": "Use the list of dsNamers to name the given list of datasets ."}}
{"translation": {"code": "private DatasetFilter readDatasetFilterElement ( DatasetSource parentDatasetSource , Element dsFilterElement ) { String name = dsFilterElement . getAttributeValue ( \"name\" ) ; String type = dsFilterElement . getAttributeValue ( \"type\" ) ; String matchPattern = dsFilterElement . getAttributeValue ( \"matchPattern\" ) ; DatasetFilter dsFilter = new DatasetFilter ( parentDatasetSource , name , DatasetFilter . Type . getType ( type ) , matchPattern ) ; String matchPatternTarget = dsFilterElement . getAttributeValue ( \"matchPatternTarget\" ) ; dsFilter . setMatchPatternTarget ( matchPatternTarget ) ; if ( dsFilterElement . getAttributeValue ( \"applyToCollectionDatasets\" ) != null ) { boolean applyToCollectionDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( \"applyToCollectionDatasets\" ) ) . booleanValue ( ) ; dsFilter . setApplyToCollectionDatasets ( applyToCollectionDatasets ) ; } if ( dsFilterElement . getAttributeValue ( \"applyToAtomicDatasets\" ) != null ) { boolean applyToAtomicDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( \"applyToAtomicDatasets\" ) ) . booleanValue ( ) ; dsFilter . setApplyToAtomicDatasets ( applyToAtomicDatasets ) ; } if ( dsFilterElement . getAttributeValue ( \"rejectMatchingDatasets\" ) != null ) { boolean rejectMatchingDatasets = Boolean . valueOf ( dsFilterElement . getAttributeValue ( \"rejectMatchingDatasets\" ) ) . booleanValue ( ) ; dsFilter . setRejectMatchingDatasets ( rejectMatchingDatasets ) ; } return ( dsFilter ) ; }", "nl": "Return a DatasetFilter when given a datasetFilter JDOM element ."}}
{"translation": {"code": "public InvCatalog fullExpand ( ) throws IOException { logger . debug ( \"fullExpand(): expanding DatasetSource named \\\"{}\\\"\" , this . getName ( ) ) ; InvDataset topDs = this . expand ( ) ; InvCatalog generatedCat = topDs . getParentCatalog ( ) ; // Add metadata to all datasets. for ( Iterator it = this . getDatasetEnhancerList ( ) . iterator ( ) ; it . hasNext ( ) ; ) { DatasetEnhancer1 dsE = ( DatasetEnhancer1 ) it . next ( ) ; dsE . addMetadata ( topDs ) ; } // Name all datasets. logger . debug ( \"fullExpand(): naming the datasets.\" ) ; this . nameDatasets ( ( InvDatasetImpl ) topDs ) ; // Sort all datasets logger . debug ( \"fullExpand(): sorting the datasets.\" ) ; this . sortDatasets ( topDs ) ; // Return the generated catalog ( ( InvCatalogImpl ) generatedCat ) . finish ( ) ; return ( generatedCat ) ; }", "nl": "Crawl this DatasetSource and generate a new InvCatalog with all datasets named sorted and organized as defined by this DatasetSource return the newly generated InvCatalog ."}}
{"translation": {"code": "public InvDataset expand ( ) throws IOException { // Get the new catalog being generated and its top-level dataset. this . resultingCatalog = this . createSkeletonCatalog ( prefixUrlPath ) ; this . accessPointDataset = ( InvDataset ) this . resultingCatalog . getDatasets ( ) . get ( 0 ) ; // IOException thrown by createSkeletonCatalog() so this check should not be necessary. if ( ! this . isCollection ( this . accessPointDataset ) ) { String tmpMsg = \"The access point dataset <\" + this . accessPointDataset . getName ( ) + \"> must be a collection dataset.\" ; logger . warn ( \"expand(): {}\" , tmpMsg ) ; throw new IOException ( tmpMsg ) ; } // Recurse into directory structure and expand. expandRecursive ( this . accessPointDataset ) ; // Finish the catalog. ( ( InvCatalogImpl ) this . resultingCatalog ) . finish ( ) ; // Remove empty collection datasets. @todo HACK - should use filters instead. this . recursivelyRemoveEmptyCollectionDatasets ( this . accessPointDataset ) ; // Return the top-level dataset. return ( this . accessPointDataset ) ; }", "nl": "Crawl this DatasetSource and generate a new InvCatalog return the top - level InvDataset ."}}
{"translation": {"code": "public static DatasetSourceType getType ( String name ) { if ( name == null ) return null ; return ( ( DatasetSourceType ) hash . get ( name ) ) ; }", "nl": "Find the DatasetSourceType that matches this name ."}}
{"translation": {"code": "public static String normalizePath ( String path ) { // Replace any occurance of a backslash (\"\\\") with a slash (\"/\"). // NOTE: Both String and Pattern escape backslash, so need four backslashes to find one. // NOTE: No longer replace multiple backslashes with one slash, which allows for UNC pathnames (Windows LAN addresses). //       Was path.replaceAll( \"\\\\\\\\+\", \"/\"); String newPath = path . replaceAll ( \"\\\\\\\\\" , \"/\" ) ; // Remove trailing slashes. while ( newPath . endsWith ( \"/\" ) && ! newPath . equals ( \"/\" ) ) newPath = newPath . substring ( 0 , newPath . length ( ) - 1 ) ; return newPath ; }", "nl": "Normalize the given path so that it can be used in the creation of a CrawlableDataset . This method can be used on absolute or relative paths ."}}
{"translation": {"code": "public void getInfo ( Formatter buf ) { buf . format ( \"%-30s\" , getNameAndDimensions ( ) ) ; buf . format ( \"%-20s\" , getUnitsString ( ) ) ; if ( axisType != null ) { buf . format ( \"%-10s\" , axisType . toString ( ) ) ; } buf . format ( \"%s\" , getDescription ( ) ) ; /* if (isNumeric) {\n     boolean debugCoords = ucar.util.prefs.ui.Debug.isSet(\"Dataset/showCoordValues\");\n     int ndigits = debugCoords ? 9 : 4;\n     for (int i=0; i< getNumElements(); i++) {\n       buf.append(Format.d(getCoordValue(i), ndigits));\n       buf.append(\" \");\n     }\n     if (debugCoords) {\n       buf.append(\"\\n      \");\n       for (int i=0; i<=getNumElements(); i++) {\n         buf.append(Format.d(getCoordEdge(i), ndigits));\n         buf.append(\" \");\n       }\n     }\n   } else {\n     for (int i=0; i< getNumElements(); i++) {\n       buf.append(getCoordName(i));\n       buf.append(\" \");\n     }\n   } */ //buf.append(\"\\n\"); }", "nl": "Get a string representation"}}
{"translation": {"code": "public DoradePARM [ ] getParamList ( ) { int paramCount = 0 ; for ( int i = 0 ; i < nSensors ; i ++ ) paramCount += myRADDs [ i ] . getNParams ( ) ; DoradePARM [ ] list = new DoradePARM [ paramCount ] ; int next = 0 ; for ( int i = 0 ; i < nSensors ; i ++ ) { int nParams = myRADDs [ i ] . getNParams ( ) ; System . arraycopy ( myRADDs [ i ] . getParamList ( ) , 0 , list , next , nParams ) ; next += nParams ; } return list ; }", "nl": "Get the array of available parameter names for this volume ."}}
{"translation": {"code": "public void doOneDataset ( InvDataset ds ) { if ( debug ) System . out . println ( \"doDataset \" + ds . getName ( ) ) ; if ( isDatasetUseable ( ds , messBuffer ) ) { String id = StringUtil2 . replace ( ds . getID ( ) , \"/\" , \"-\" ) ; String fileOutName = fileDir + \"/\" + id + \".dif.xml\" ; try { OutputStream out = new BufferedOutputStream ( new FileOutputStream ( fileOutName ) ) ; // writeOneEntry(ds, System.out, mess); writeOneEntry ( ds , out , messBuffer ) ; out . close ( ) ; messBuffer . append ( \" OK on Write\\n\" ) ; } catch ( IOException ioe ) { messBuffer . append ( \"DIFWriter failed on write \" + ioe . getMessage ( ) + \"\\n\" ) ; log . error ( \"DIFWriter failed on write \" + ioe . getMessage ( ) , ioe ) ; } } }", "nl": "Write a DIF record for a specific dataset"}}
{"translation": {"code": "private org . jdom2 . Element createDatasetFilterElement ( DatasetFilter dsFilter ) { Element dsfElem = new Element ( \"datasetFilter\" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; if ( dsFilter != null ) { // Add 'name' attribute. if ( dsFilter . getName ( ) != null ) { dsfElem . setAttribute ( \"name\" , dsFilter . getName ( ) ) ; } // Add 'type' attribute. if ( dsFilter . getType ( ) != null ) { dsfElem . setAttribute ( \"type\" , dsFilter . getType ( ) . toString ( ) ) ; } // Add 'matchPattern' attribute. if ( dsFilter . getMatchPattern ( ) != null ) { dsfElem . setAttribute ( \"matchPattern\" , dsFilter . getMatchPattern ( ) ) ; } // Add 'matchPatternTarget' attribute. if ( dsFilter . getMatchPatternTarget ( ) != null ) { dsfElem . setAttribute ( \"matchPatternTarget\" , dsFilter . getMatchPatternTarget ( ) ) ; } // Add 'applyToCollectionDatasets' attribute. dsfElem . setAttribute ( \"applyToCollectionDatasets\" , String . valueOf ( dsFilter . isApplyToCollectionDatasets ( ) ) ) ; // Add 'applyToAtomicDatasets' attribute. dsfElem . setAttribute ( \"applyToAtomicDatasets\" , String . valueOf ( dsFilter . isApplyToAtomicDatasets ( ) ) ) ; // Add 'rejectMatchingDatasets' attribute. dsfElem . setAttribute ( \"rejectMatchingDatasets\" , String . valueOf ( dsFilter . isRejectMatchingDatasets ( ) ) ) ; } return ( dsfElem ) ; }", "nl": "Create a DatasetFilter JDOM element"}}
{"translation": {"code": "private org . jdom2 . Element createDatasetNamerElement ( DatasetNamer dsNamer ) { Element dsnElem = new Element ( \"datasetNamer\" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; if ( dsNamer != null ) { // Add 'name' attribute. if ( dsNamer . getName ( ) != null ) { dsnElem . setAttribute ( \"name\" , dsNamer . getName ( ) ) ; } // Add 'addLevel' attribute. dsnElem . setAttribute ( \"addLevel\" , Boolean . toString ( dsNamer . getAddLevel ( ) ) ) ; // Add 'type' attribute. if ( dsNamer . getType ( ) != null ) { dsnElem . setAttribute ( \"type\" , dsNamer . getType ( ) . toString ( ) ) ; } // Add 'matchPattern' attribute. if ( dsNamer . getMatchPattern ( ) != null ) { dsnElem . setAttribute ( \"matchPattern\" , dsNamer . getMatchPattern ( ) ) ; } // Add 'subsitutePattern' attribute. if ( dsNamer . getSubstitutePattern ( ) != null ) { dsnElem . setAttribute ( \"substitutePattern\" , dsNamer . getSubstitutePattern ( ) ) ; } // Add 'attribContainer' attribute. if ( dsNamer . getAttribContainer ( ) != null ) { dsnElem . setAttribute ( \"attribContainer\" , dsNamer . getAttribContainer ( ) ) ; } // Add 'attribName' attribute. if ( dsNamer . getAttribName ( ) != null ) { dsnElem . setAttribute ( \"attribName\" , dsNamer . getAttribName ( ) ) ; } } return ( dsnElem ) ; }", "nl": "Create a DatasetNamer JDOM element"}}
{"translation": {"code": "public byte getScalarByte ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getByte ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type byte ."}}
{"translation": {"code": "private org . jdom2 . Element createDatasetSourceElement ( DatasetSource dsSource ) { Element dssElem = new Element ( \"datasetSource\" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; if ( dsSource != null ) { // Add 'name' attribute. if ( dsSource . getName ( ) != null ) { dssElem . setAttribute ( \"name\" , dsSource . getName ( ) ) ; } // Add 'type' attribute. if ( dsSource . getType ( ) != null ) { dssElem . setAttribute ( \"type\" , dsSource . getType ( ) . toString ( ) ) ; } // Add 'structure' attribute. if ( dsSource . getStructure ( ) != null ) { dssElem . setAttribute ( \"structure\" , dsSource . getStructure ( ) . toString ( ) ) ; } // Add 'accessPoint' attribute. if ( dsSource . getAccessPoint ( ) != null ) { dssElem . setAttribute ( \"accessPoint\" , dsSource . getAccessPoint ( ) ) ; } // Add 'createCatalogRefs' attribute. dssElem . setAttribute ( \"createCatalogRefs\" , Boolean . toString ( dsSource . isCreateCatalogRefs ( ) ) ) ; // Add 'resultService' element ResultService rs = dsSource . getResultService ( ) ; dssElem . addContent ( createResultServiceElement ( rs ) ) ; // Add 'datasetNamer' elements java . util . List list = dsSource . getDatasetNamerList ( ) ; for ( int j = 0 ; j < list . size ( ) ; j ++ ) { DatasetNamer dsNamer = ( DatasetNamer ) list . get ( j ) ; dssElem . addContent ( createDatasetNamerElement ( dsNamer ) ) ; } // Add 'datasetFilter' elements list = dsSource . getDatasetFilterList ( ) ; for ( int j = 0 ; j < list . size ( ) ; j ++ ) { DatasetFilter dsFilter = ( DatasetFilter ) list . get ( j ) ; dssElem . addContent ( createDatasetFilterElement ( dsFilter ) ) ; } } return ( dssElem ) ; }", "nl": "Create a DatasetSource JDOM element"}}
{"translation": {"code": "private static void readStationTable ( ) throws IOException { stationTableHash = new HashMap < String , Station > ( ) ; ClassLoader cl = Level2VolumeScan . class . getClassLoader ( ) ; InputStream is = cl . getResourceAsStream ( \"resources/nj22/tables/nexrad.tbl\" ) ; List < TableParser . Record > recs = TableParser . readTable ( is , \"3,15,46, 54,60d,67d,73d\" , 50000 ) ; for ( TableParser . Record record : recs ) { Station s = new Station ( ) ; s . id = \"K\" + record . get ( 0 ) ; s . name = record . get ( 2 ) + \" \" + record . get ( 3 ) ; s . lat = ( Double ) record . get ( 4 ) * .01 ; s . lon = ( Double ) record . get ( 5 ) * .01 ; s . elev = ( Double ) record . get ( 6 ) ; stationTableHash . put ( s . id , s ) ; if ( showStations ) System . out . println ( \" station= \" + s ) ; } }", "nl": "this is the old Gempak table not as precise"}}
{"translation": {"code": "public byte [ ] getJavaArrayByte ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( byte [ ] ) data . getStorage ( ) ; }", "nl": "Get java byte array for a member of type byte ."}}
{"translation": {"code": "protected void removeDataVariable ( String varName ) { Iterator iter = dataVariables . iterator ( ) ; while ( iter . hasNext ( ) ) { VariableSimpleIF v = ( VariableSimpleIF ) iter . next ( ) ; if ( v . getShortName ( ) . equals ( varName ) ) iter . remove ( ) ; } }", "nl": "reminder for subclasses to set this"}}
{"translation": {"code": "public int getScalarInt ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getInt ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type int ."}}
{"translation": {"code": "public boolean containsAxisType ( AxisType wantAxisType ) { for ( CoordinateAxis ca : coordAxes ) { if ( ca . getAxisType ( ) == wantAxisType ) return true ; } return false ; }", "nl": "Do we have an axes of the given type?"}}
{"translation": {"code": "public boolean containsAxisTypes ( List < AxisType > wantAxes ) { for ( AxisType wantAxisType : wantAxes ) { if ( ! containsAxisType ( wantAxisType ) ) return false ; } return true ; }", "nl": "Do we have all the axes types in the list?"}}
{"translation": {"code": "public int [ ] getJavaArrayInt ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( int [ ] ) data . getStorage ( ) ; }", "nl": "Get java int array for a member of type int ."}}
{"translation": {"code": "private org . jdom2 . Element createCatGenConfigElement ( CatalogGenConfig cgc ) { // @todo Need to deal with the 0.6 and 1.0 namespaces. Element cgcElem = new Element ( \"catalogGenConfig\" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; if ( cgc != null ) { if ( cgc . getType ( ) != null ) { cgcElem . setAttribute ( \"type\" , cgc . getType ( ) . toString ( ) ) ; } // Add 'datasetSource' element DatasetSource dsSource = cgc . getDatasetSource ( ) ; cgcElem . addContent ( createDatasetSourceElement ( dsSource ) ) ; } return ( cgcElem ) ; }", "nl": "Create a catalogGenConfig JDOM element"}}
{"translation": {"code": "public InvCatalog getDirCatalog ( File directory , String filterPattern , boolean sortInIncreasingOrder , boolean addDatasetSize ) { return ( this . getDirCatalog ( directory , filterPattern , sortInIncreasingOrder , null , addDatasetSize , null , null , null ) ) ; }", "nl": "Return a catalog for the given directory ."}}
{"translation": {"code": "public boolean containsDomain ( List < Dimension > wantDimensions ) { for ( Dimension d : wantDimensions ) { if ( ! domain . contains ( d ) ) return false ; } return true ; }", "nl": "Do we have all the dimensions in the list?"}}
{"translation": {"code": "private Object readMetadataContentFromURL ( InvDataset dataset , String urlString ) throws java . net . MalformedURLException , java . io . IOException { // @todo This isn't used anywhere. Remove? Document doc ; try { SAXBuilder builder = new SAXBuilder ( true ) ; doc = builder . build ( urlString ) ; } catch ( JDOMException e ) { log . error ( \"CatGenConfigMetadataFactory parsing error= \\n\" + e . getMessage ( ) ) ; throw new java . io . IOException ( \"CatGenConfigMetadataFactory parsing error= \" + e . getMessage ( ) ) ; } if ( showParsedXML ) { XMLOutputter xmlOut = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; System . out . println ( \"*** catalog/showParsedXML = \\n\" + xmlOut . outputString ( doc ) + \"\\n*******\" ) ; } return ( readMetadataContentJdom ( dataset , doc . getRootElement ( ) ) ) ; }", "nl": "Create an InvMetadata content object from an XML document at a named URL . The content object is an ArrayList of CatalogGenConfig instances ."}}
{"translation": {"code": "public Object readMetadataContent ( InvDataset dataset , org . jdom2 . Element mdataElement ) { log . debug ( \"readMetadataContent(): .\" ) ; // convert to JDOM element //Element mdataElement = builder.build( mdataDomElement ); return readMetadataContentJdom ( dataset , mdataElement ) ; }", "nl": "Create an InvMetadata content object from an org . w3c . dom . Element . The content object is an ArrayList of CatalogGenConfig instances ."}}
{"translation": {"code": "public void addMetadataContent ( org . jdom2 . Element mdataJdomElement , Object contentObject ) { // convert to JDOM element //Element mdataJdomElement = builder.build( mdataElement ); ArrayList catGenConfigList = ( ArrayList ) contentObject ; Iterator iter = catGenConfigList . iterator ( ) ; while ( iter . hasNext ( ) ) { CatalogGenConfig cgc = ( CatalogGenConfig ) iter . next ( ) ; mdataJdomElement . addContent ( createCatGenConfigElement ( cgc ) ) ; } }", "nl": "Serialize the InvMetadata content object to a org . w3c . dom . Element"}}
{"translation": {"code": "public boolean validateMetadataContent ( Object contentObject , StringBuilder out ) { boolean ok = true ; ArrayList catGenConfigList = ( ArrayList ) contentObject ; Iterator iter = catGenConfigList . iterator ( ) ; while ( iter . hasNext ( ) ) { CatalogGenConfig catGenConf = ( CatalogGenConfig ) iter . next ( ) ; ok &= catGenConf . validate ( out ) ; } return ok ; }", "nl": "Validate the content object ."}}
{"translation": {"code": "private CatalogGenConfig readCatGenConfigElement ( InvDataset parentDataset , Element catGenConfElement ) { String type = catGenConfElement . getAttributeValue ( \"type\" ) ; CatalogGenConfig catGenConf = new CatalogGenConfig ( parentDataset , type ) ; // get any datasetSource elements java . util . List list = catGenConfElement . getChildren ( \"datasetSource\" , catGenConfElement . getNamespace ( ) ) ; for ( int i = 0 ; i < list . size ( ) ; i ++ ) { Element dsSourceElement = ( Element ) list . get ( i ) ; catGenConf . setDatasetSource ( readDatasetSourceElement ( parentDataset , dsSourceElement ) ) ; } // @todo Start only allowing datasetSource elements in catalogGenConfig elements. //    // get any datasetNamer elements //    list = catGenConfElement.getChildren( \"datasetNamer\", catGenConfElement.getNamespace() ); //    for (int i=0; i< list.size(); i++) //    { //      Element dsNamerElement = (Element) list.get(i); // //      catGenConf.addDatasetNamer( readDatasetNamerElement( parentDataset, //                                                           dsNamerElement)); //    } return ( catGenConf ) ; }", "nl": "Return a CatalogGenConfig when given a catalogGenConfig JDOM element ."}}
{"translation": {"code": "private DatasetSource readDatasetSourceElement ( InvDataset parentDataset , Element dsSourceElement ) { String name = dsSourceElement . getAttributeValue ( \"name\" ) ; String type = dsSourceElement . getAttributeValue ( \"type\" ) ; String structure = dsSourceElement . getAttributeValue ( \"structure\" ) ; String accessPoint = dsSourceElement . getAttributeValue ( \"accessPoint\" ) ; String createCatalogRefs = dsSourceElement . getAttributeValue ( \"createCatalogRefs\" ) ; // get the resultService element Element resultServiceElement = dsSourceElement . getChild ( \"resultService\" , dsSourceElement . getNamespace ( ) ) ; ResultService resultService = readResultServiceElement ( parentDataset , resultServiceElement ) ; DatasetSource dsSource = DatasetSource . newDatasetSource ( name , DatasetSourceType . getType ( type ) , DatasetSourceStructure . getStructure ( structure ) , accessPoint , resultService ) ; if ( createCatalogRefs != null ) { dsSource . setCreateCatalogRefs ( Boolean . valueOf ( createCatalogRefs ) . booleanValue ( ) ) ; } // get any datasetNamer elements java . util . List list = dsSourceElement . getChildren ( \"datasetNamer\" , dsSourceElement . getNamespace ( ) ) ; for ( int i = 0 ; i < list . size ( ) ; i ++ ) { Element dsNamerElement = ( Element ) list . get ( i ) ; dsSource . addDatasetNamer ( readDatasetNamerElement ( parentDataset , dsNamerElement ) ) ; } // get any datasetFilter elements list = dsSourceElement . getChildren ( \"datasetFilter\" , dsSourceElement . getNamespace ( ) ) ; for ( int i = 0 ; i < list . size ( ) ; i ++ ) { Element dsFilterElement = ( Element ) list . get ( i ) ; dsSource . addDatasetFilter ( readDatasetFilterElement ( dsSource , dsFilterElement ) ) ; } return ( dsSource ) ; }", "nl": "Return a DatasetSource when given a datasetSource JDOM element ."}}
{"translation": {"code": "private DatasetNamer readDatasetNamerElement ( InvDataset parentDataset , Element dsNamerElement ) { String name = dsNamerElement . getAttributeValue ( \"name\" ) ; String addLevel = dsNamerElement . getAttributeValue ( \"addLevel\" ) ; String type = dsNamerElement . getAttributeValue ( \"type\" ) ; String matchPattern = dsNamerElement . getAttributeValue ( \"matchPattern\" ) ; String substitutePattern = dsNamerElement . getAttributeValue ( \"substitutePattern\" ) ; String attribContainer = dsNamerElement . getAttributeValue ( \"attribContainer\" ) ; String attribName = dsNamerElement . getAttributeValue ( \"attribName\" ) ; DatasetNamer dsNamer = new DatasetNamer ( parentDataset , name , addLevel , type , matchPattern , substitutePattern , attribContainer , attribName ) ; return ( dsNamer ) ; }", "nl": "Return a DatasetNamer when given a datasetNamer JDOM element ."}}
{"translation": {"code": "private org . jdom2 . Element createResultServiceElement ( ResultService resultService ) { Element rsElem = new Element ( \"resultService\" , CATALOG_GEN_CONFIG_NAMESPACE_0_5 ) ; if ( resultService != null ) { // Add 'name' attribute. if ( resultService . getName ( ) != null ) { rsElem . setAttribute ( \"name\" , resultService . getName ( ) ) ; } // Add 'serviceType' attribute. if ( resultService . getServiceType ( ) != null ) { rsElem . setAttribute ( \"serviceType\" , resultService . getServiceType ( ) . toString ( ) ) ; } // Add 'base' attribute. if ( resultService . getBase ( ) != null ) { rsElem . setAttribute ( \"base\" , resultService . getBase ( ) ) ; } // Add 'suffix' attribute. if ( resultService . getSuffix ( ) != null ) { rsElem . setAttribute ( \"suffix\" , resultService . getSuffix ( ) ) ; } // Add 'accessPointHeader' attribute. if ( resultService . getAccessPointHeader ( ) != null ) { rsElem . setAttribute ( \"accessPointHeader\" , resultService . getAccessPointHeader ( ) ) ; } } return ( rsElem ) ; }", "nl": "Create a ResultService JDOM element"}}
{"translation": {"code": "public float [ ] getJavaArrayFloat ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( float [ ] ) data . getStorage ( ) ; }", "nl": "Get java float array for a member of type float ."}}
{"translation": {"code": "public float getScalarFloat ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getFloat ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type float ."}}
{"translation": {"code": "public double [ ] getJavaArrayDouble ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( double [ ] ) data . getStorage ( ) ; }", "nl": "Get java double array for a member of type double ."}}
{"translation": {"code": "public char [ ] getJavaArrayChar ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( char [ ] ) data . getStorage ( ) ; }", "nl": "Get java char array for a member of type char ."}}
{"translation": {"code": "public void appendQuery ( StringBuffer sbuff , ArrayList values ) { if ( template != null ) appendQueryFromTemplate ( sbuff , values ) ; else appendQueryFromParamValue ( sbuff , values ) ; }", "nl": "Create the selector result string and append ."}}
{"translation": {"code": "public char getScalarChar ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getChar ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type char ."}}
{"translation": {"code": "private String findAlias ( NetcdfDataset ds , Variable v ) { String alias = ds . findAttValueIgnoreCase ( v , \"coord_axis\" , null ) ; if ( alias == null ) alias = ds . findAttValueIgnoreCase ( v , \"coord_alias\" , \"\" ) ; return alias ; }", "nl": "look for an coord_axis or coord_alias attribute"}}
{"translation": {"code": "public void setStationInfo ( String stnIdVName , String stnDescVName ) { this . stnIdVName = stnIdVName ; this . stnDescVName = stnDescVName ; Variable stationVar = ncfile . findVariable ( stnIdVName ) ; stationIdType = stationVar . getDataType ( ) ; }", "nl": "Set extra information used by station obs datasets ."}}
{"translation": {"code": "public void finish ( ) { if ( init ) return ; init = true ; if ( xlinkHref == null ) return ; xlinkHref = xlinkHref . trim ( ) ; try { this . xlinkUri = dataset . getParentCatalog ( ) . resolveUri ( xlinkHref ) ; } catch ( java . net . URISyntaxException e ) { log . append ( \" ** Error: Bad URL in metadata href = \" ) . append ( xlinkHref ) . append ( \"\\n\" ) ; return ; } // open and read the referenced catalog XML try { if ( converter == null ) { log . append ( \"  **InvMetadata on = (\" ) . append ( this ) . append ( \"): has no converter\\n\" ) ; return ; } contentObject = converter . readMetadataContentFromURL ( dataset , xlinkUri ) ; if ( isThreddsMetadata ) tm = ( ThreddsMetadata ) contentObject ; } catch ( java . io . IOException e ) { log . append ( \"  **InvMetadata on = (\" ) . append ( xlinkUri ) . append ( \"): Exception (\" ) . append ( e . getMessage ( ) ) . append ( \")\\n\" ) ; // e.printStackTrace(); } }", "nl": "Finish getting the metadata if necessary . If this is an XLink this will trigger a read of the href the first time called ."}}
{"translation": {"code": "public long [ ] getJavaArrayLong ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( long [ ] ) data . getStorage ( ) ; }", "nl": "Get java long array for a member of type long ."}}
{"translation": {"code": "public boolean containsAxes ( List < CoordinateAxis > wantAxes ) { for ( CoordinateAxis ca : wantAxes ) { if ( ! containsAxis ( ca . getFullName ( ) ) ) return false ; } return true ; }", "nl": "Do we have all the axes in the list?"}}
{"translation": {"code": "public void addMember ( Member m ) { members . add ( m ) ; if ( memberHash != null ) memberHash . put ( m . getName ( ) , m ) ; }", "nl": "Add a member ."}}
{"translation": {"code": "public boolean containsAxis ( String axisName ) { for ( CoordinateAxis ca : coordAxes ) { if ( ca . getFullName ( ) . equals ( axisName ) ) return true ; } return false ; }", "nl": "Do we have the named axis?"}}
{"translation": {"code": "public String [ ] getJavaArrayString ( StructureMembers . Member m ) { if ( m . getDataType ( ) == DataType . STRING ) { Array data = getArray ( m ) ; int n = m . getSize ( ) ; String [ ] result = new String [ n ] ; for ( int i = 0 ; i < result . length ; i ++ ) result [ i ] = ( String ) data . getObject ( i ) ; return result ; } else if ( m . getDataType ( ) == DataType . CHAR ) { ArrayChar data = ( ArrayChar ) getArray ( m ) ; ArrayChar . StringIterator iter = data . getStringIterator ( ) ; String [ ] result = new String [ iter . getNumElems ( ) ] ; int count = 0 ; while ( iter . hasNext ( ) ) result [ count ++ ] = iter . next ( ) ; return result ; } throw new IllegalArgumentException ( \"getJavaArrayString: not String DataType :\" + m . getDataType ( ) ) ; }", "nl": "LOOK can we optimize ??"}}
{"translation": {"code": "public void subset ( InvDataset ds ) { InvDatasetImpl dataset = ( InvDatasetImpl ) ds ; // Make all inherited metadata local. dataset . transferMetadata ( dataset , true ) ; topDataset = dataset ; datasets . clear ( ) ; // throw away the rest datasets . add ( topDataset ) ; // parent lookups need to be local //InvService service = dataset.getServiceDefault(); //if (service != null) LOOK //  dataset.serviceName = service.getName(); dataset . dataType = dataset . getDataType ( ) ; // all properties need to be local // LOOK dataset.setPropertiesLocal( new ArrayList(dataset.getProperties())); // next part requires this before it dataset . setCatalog ( this ) ; dataset . parent = null ; // any referenced services need to be local List < InvService > services = new ArrayList < InvService > ( dataset . getServicesLocal ( ) ) ; findServices ( services , dataset ) ; dataset . setServicesLocal ( services ) ; finish ( ) ; }", "nl": "Munge this catalog so the given dataset is the top catalog ."}}
{"translation": {"code": "private boolean mark ( DatasetFilter filter , InvDatasetImpl ds ) { if ( ds instanceof InvCatalogRef ) { InvCatalogRef catRef = ( InvCatalogRef ) ds ; if ( ! catRef . isRead ( ) ) return false ; } // recurse into nested datasets first boolean allMarked = true ; for ( InvDataset nested : ds . getDatasets ( ) ) { allMarked &= mark ( filter , ( InvDatasetImpl ) nested ) ; } if ( ! allMarked ) return false ; if ( filter . accept ( ds ) >= 0 ) return false ; // mark for deletion ds . setMark ( true ) ; if ( debugFilter ) System . out . println ( \" mark \" + ds . getName ( ) ) ; return true ; }", "nl": "unread CatalogRefs are always kept ."}}
{"translation": {"code": "private void delete ( InvDatasetImpl ds ) { if ( ds instanceof InvCatalogRef ) { InvCatalogRef catRef = ( InvCatalogRef ) ds ; if ( ! catRef . isRead ( ) ) return ; } Iterator iter = ds . getDatasets ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { InvDatasetImpl nested = ( InvDatasetImpl ) iter . next ( ) ; if ( nested . getMark ( ) ) { iter . remove ( ) ; if ( debugFilter ) System . out . println ( \" remove \" + nested . getName ( ) ) ; } else delete ( nested ) ; } }", "nl": "remove marked datasets"}}
{"translation": {"code": "public long getScalarLong ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getLong ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type long ."}}
{"translation": {"code": "public static java . awt . image . BufferedImage makeGrayscaleImage ( Array ma , IsMissingEvaluator missEval ) { if ( ma . getRank ( ) < 2 ) return null ; if ( ma . getRank ( ) == 3 ) ma = ma . reduce ( ) ; if ( ma . getRank ( ) == 3 ) ma = ma . slice ( 0 , 0 ) ; // we need 2D int h = ma . getShape ( ) [ 0 ] ; int w = ma . getShape ( ) [ 1 ] ; DataBuffer dataBuffer = makeDataBuffer ( ma , missEval ) ; WritableRaster raster = WritableRaster . createInterleavedRaster ( dataBuffer , w , h , //   int w, int h, w , //   int scanlineStride, 1 , //    int pixelStride, new int [ ] { 0 } , //   int bandOffsets[], null ) ; //   Point location) ColorSpace cs = ColorSpace . getInstance ( ColorSpace . CS_GRAY ) ; ComponentColorModel colorModel = new ComponentColorModel ( cs , new int [ ] { 8 } , false , false , Transparency . OPAQUE , DataBuffer . TYPE_BYTE ) ; return new BufferedImage ( colorModel , raster , false , null ) ; }", "nl": "Adapt a rank 2 array into a java . awt . image . BufferedImage . If passed a rank 3 array take first 2D slice ."}}
{"translation": {"code": "public short [ ] getJavaArrayShort ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return ( short [ ] ) data . getStorage ( ) ; }", "nl": "Get java short array for a member of type short ."}}
{"translation": {"code": "public short getScalarShort ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getShort ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type short ."}}
{"translation": {"code": "public java . util . List < String > getMemberNames ( ) { List < String > memberNames = new ArrayList <> ( ) ; for ( Member m : members ) { memberNames . add ( m . getName ( ) ) ; } return memberNames ; }", "nl": "Get the names of the members ."}}
{"translation": {"code": "public Member findMember ( String memberName ) { if ( memberName == null ) return null ; if ( memberHash == null ) { // delay making the hash table until needed int initial_capacity = ( int ) ( members . size ( ) / .75 ) + 1 ; memberHash = new HashMap <> ( initial_capacity ) ; for ( Member m : members ) memberHash . put ( m . getName ( ) , m ) ; } return memberHash . get ( memberName ) ; }", "nl": "Find the member by its name ."}}
{"translation": {"code": "public Array getArray ( StructureMembers . Member m ) { if ( m == null ) throw new IllegalArgumentException ( \"member is null\" ) ; return memberData . get ( m ) ; }", "nl": "Get member data array of any type as an Array ."}}
{"translation": {"code": "public double getScalarDouble ( StructureMembers . Member m ) { Array data = getArray ( m ) ; return data . getDouble ( Index . scalarIndexImmutable ) ; }", "nl": "Get member data of type double ."}}
{"translation": {"code": "public void filter ( DatasetFilter filter ) { mark ( filter , topDataset ) ; delete ( topDataset ) ; this . filter = filter ; }", "nl": "Munge this catalog to remove any dataset that doesnt pass through the filter ."}}
{"translation": {"code": "public URI getStandardUri ( ) { try { InvCatalog cat = dataset . getParentCatalog ( ) ; if ( cat == null ) return new URI ( getUnresolvedUrlName ( ) ) ; return cat . resolveUri ( getUnresolvedUrlName ( ) ) ; } catch ( java . net . URISyntaxException e ) { logger . warn ( \"Error parsing URL= \" + getUnresolvedUrlName ( ) ) ; return null ; } }", "nl": "Construct the standard THREDDS access URI for this dataset access method resolve if the URI is relative ."}}
{"translation": {"code": "private ResultService readResultServiceElement ( InvDataset parentDataset , Element resultServiceElement ) { String name = resultServiceElement . getAttributeValue ( \"name\" ) ; String serviceType = resultServiceElement . getAttributeValue ( \"serviceType\" ) ; String base = resultServiceElement . getAttributeValue ( \"base\" ) ; String suffix = resultServiceElement . getAttributeValue ( \"suffix\" ) ; String accessPointHeader = resultServiceElement . getAttributeValue ( \"accessPointHeader\" ) ; return ( new ResultService ( name , ServiceType . getType ( serviceType ) , base , suffix , accessPointHeader ) ) ; }", "nl": "Return a ResultService when given a resultService JDOM element ."}}
{"translation": {"code": "protected boolean validate ( StringBuilder out ) { this . isValid = true ; // If log from construction has content, append to validation output msg. if ( this . log . length ( ) > 0 ) { out . append ( this . log ) ; } // Check that 'accessPointHeader' attribute is not null. if ( this . getAccessPointHeader ( ) == null ) { this . isValid = false ; out . append ( \" ** ResultService (1): a null 'accessPointHeader' is invalid.\" ) ; } return ( this . isValid ) ; }", "nl": "Validate this ResultService object . Return true if valid false if invalid ."}}
{"translation": {"code": "public StructureDataIterator getStructureIterator ( int bufferSize ) throws java . io . IOException { return ( getRank ( ) < 2 ) ? new Structure . IteratorRank1 ( bufferSize ) : new Structure . Iterator ( bufferSize ) ; }", "nl": "Get an efficient iterator over all the data in the Structure ."}}
{"translation": {"code": "protected float grabFloat ( byte [ ] bytes , int offset ) throws DescriptorException { try { byte [ ] src ; if ( littleEndianData ) { src = new byte [ 4 ] ; src [ 0 ] = bytes [ offset + 3 ] ; src [ 1 ] = bytes [ offset + 2 ] ; src [ 2 ] = bytes [ offset + 1 ] ; src [ 3 ] = bytes [ offset ] ; offset = 0 ; } else { src = bytes ; } DataInputStream stream = new DataInputStream ( new ByteArrayInputStream ( src , offset , 4 ) ) ; return stream . readFloat ( ) ; } catch ( Exception ex ) { throw new DescriptorException ( ex ) ; } }", "nl": "Unpack a four - byte IEEE float from the given byte array ."}}
{"translation": {"code": "public ArrayStructure readStructure ( int start , int count ) throws IOException , ucar . ma2 . InvalidRangeException { if ( getRank ( ) != 1 ) throw new java . lang . UnsupportedOperationException ( \"not a vector structure\" ) ; int [ ] origin = new int [ ] { start } ; int [ ] shape = new int [ ] { count } ; if ( NetcdfFile . debugStructureIterator ) System . out . println ( \"readStructure \" + start + \" \" + count ) ; return ( ArrayStructure ) read ( origin , shape ) ; }", "nl": "For rank 1 array of Structures read count Structures and return the data as an ArrayStructure . Use only when this is a one dimensional array of Structures ."}}
{"translation": {"code": "public final int compareTo ( String string ) { return getID ( ) . length ( ) >= string . length ( ) ? getID ( ) . compareToIgnoreCase ( string ) : getID ( ) . compareToIgnoreCase ( string . substring ( 0 , getID ( ) . length ( ) ) ) ; }", "nl": "Compares this PrefixName with a string ."}}
{"translation": {"code": "private double geoShiftGetXstart ( Array lon , double inc ) { Index ilon = lon . getIndex ( ) ; int [ ] lonShape = lon . getShape ( ) ; IndexIterator lonIter = lon . getIndexIterator ( ) ; double xlon = 0.0 ; LatLonPoint p0 = new LatLonPointImpl ( 0 , lon . getFloat ( ilon . set ( 0 ) ) ) ; LatLonPoint pN = new LatLonPointImpl ( 0 , lon . getFloat ( ilon . set ( lonShape [ 0 ] - 1 ) ) ) ; xlon = p0 . getLongitude ( ) ; while ( lonIter . hasNext ( ) ) { float l = lonIter . getFloatNext ( ) ; LatLonPoint pn = new LatLonPointImpl ( 0 , l ) ; if ( pn . getLongitude ( ) < xlon ) { xlon = pn . getLongitude ( ) ; } } if ( p0 . getLongitude ( ) == pN . getLongitude ( ) ) { xlon = xlon - inc ; } return xlon ; }", "nl": "LOOK WTF ?? is this the seam crossing ??"}}
{"translation": {"code": "protected static int grabInt ( byte [ ] bytes , int offset , boolean littleEndianData ) { int ndx0 = offset + ( littleEndianData ? 3 : 0 ) ; int ndx1 = offset + ( littleEndianData ? 2 : 1 ) ; int ndx2 = offset + ( littleEndianData ? 1 : 2 ) ; int ndx3 = offset + ( littleEndianData ? 0 : 3 ) ; // careful that we only allow sign extension on the highest order byte return ( bytes [ ndx0 ] << 24 | ( bytes [ ndx1 ] & 0xff ) << 16 | ( bytes [ ndx2 ] & 0xff ) << 8 | ( bytes [ ndx3 ] & 0xff ) ) ; }", "nl": "Unpack a four - byte integer from the given byte array ."}}
{"translation": {"code": "protected String makePlural ( final String name ) { String plural ; final int length = name . length ( ) ; final char lastChar = name . charAt ( length - 1 ) ; if ( lastChar != ' ' ) { plural = name + ( lastChar == ' ' || lastChar == ' ' || lastChar == ' ' || name . endsWith ( \"ch\" ) ? \"es\" : \"s\" ) ; } else { if ( length == 1 ) { plural = name + \"s\" ; } else { final char penultimateChar = name . charAt ( length - 2 ) ; plural = ( penultimateChar == ' ' || penultimateChar == ' ' || penultimateChar == ' ' || penultimateChar == ' ' || penultimateChar == ' ' ) ? name + \"s\" : name . substring ( 0 , length - 1 ) + \"ies\" ; } } return plural ; }", "nl": "Returns the plural form of a name . Regular rules are used to generate the plural form ."}}
{"translation": {"code": "public double dot ( MAVector v ) { if ( nelems != v . getNelems ( ) ) throw new IllegalArgumentException ( \"MAVector.dot \" + nelems + \" != \" + v . getNelems ( ) ) ; double sum = 0.0 ; for ( int k = 0 ; k < nelems ; k ++ ) sum += getDouble ( k ) * v . getDouble ( k ) ; return sum ; }", "nl": "Dot product of 2 vectors"}}
{"translation": {"code": "public double norm ( ) { double sum = 0.0 ; for ( int k = 0 ; k < nelems ; k ++ ) { double val = getDouble ( k ) ; sum += val * val ; } return Math . sqrt ( sum ) ; }", "nl": "Get the L2 norm of this vector ."}}
{"translation": {"code": "public void normalize ( ) { double norm = norm ( ) ; if ( norm <= 0.0 ) return ; for ( int k = 0 ; k < nelems ; k ++ ) { double val = getDouble ( k ) ; setDouble ( k , val / norm ) ; } }", "nl": "Normalize this vector so it has norm = 1 . 0 ."}}
{"translation": {"code": "public static boolean isRadialCoordSys ( Formatter parseInfo , CoordinateSystem cs ) { return ( cs . getAzimuthAxis ( ) != null ) && ( cs . getRadialAxis ( ) != null ) && ( cs . getElevationAxis ( ) != null ) ; }", "nl": "Determine if this CoordinateSystem can be made into a RadialCoordSys ."}}
{"translation": {"code": "public double getMaximumRadial ( ) { if ( maxRadial == 0.0 ) { try { Array radialData = getRadialAxisDataCached ( ) ; maxRadial = MAMath . getMaximum ( radialData ) ; String units = getRadialAxis ( ) . getUnitsString ( ) ; SimpleUnit radialUnit = SimpleUnit . factory ( units ) ; maxRadial = radialUnit . convertTo ( maxRadial , SimpleUnit . kmUnit ) ; // convert to km } catch ( IOException e ) { e . printStackTrace ( ) ; } catch ( IllegalArgumentException e ) { e . printStackTrace ( ) ; } } return maxRadial ; }", "nl": "Get the maximum radial distance in km ."}}
{"translation": {"code": "public float [ ] getElevations ( ) { if ( elevations == null ) { elevations = new float [ nRays ] ; for ( int r = 0 ; r < nRays ; r ++ ) { elevations [ r ] = myRYIBs [ r ] . getElevation ( ) ; } } return elevations ; }", "nl": "Get the array of elevations for this sweep ."}}
{"translation": {"code": "private static Prefix getPrefix ( final String string , final Set < Prefix > set ) { for ( final Iterator < Prefix > iter = set . iterator ( ) ; iter . hasNext ( ) ; ) { final Prefix prefix = iter . next ( ) ; final int comp = prefix . compareTo ( string ) ; if ( comp == 0 ) { return prefix ; } if ( comp > 0 ) { break ; } } return null ; }", "nl": "Returns the prefix from the given set with the given identifier ."}}
{"translation": {"code": "public void cleanCache ( File dir , Formatter sbuff , boolean isRoot ) { long now = System . currentTimeMillis ( ) ; File [ ] files = dir . listFiles ( ) ; if ( files == null ) { throw new IllegalStateException ( \"DiskCache2: not a directory or I/O error on dir=\" + dir . getAbsolutePath ( ) ) ; } // check for empty directory if ( ! isRoot && ( files . length == 0 ) ) { long duration = now - dir . lastModified ( ) ; duration /= 1000 * 60 ; // minutes if ( duration > persistMinutes ) { boolean ok = dir . delete ( ) ; if ( ! ok ) cacheLog . error ( \"Unable to delete file \" + dir . getAbsolutePath ( ) ) ; if ( sbuff != null ) sbuff . format ( \" deleted %s %s lastModified= %s%n\" , ok , dir . getPath ( ) , CalendarDate . of ( dir . lastModified ( ) ) ) ; } return ; } // check for expired files for ( File file : files ) { if ( file . isDirectory ( ) ) { cleanCache ( file , sbuff , false ) ; } else { long duration = now - file . lastModified ( ) ; duration /= 1000 * 60 ; // minutes if ( duration > persistMinutes ) { boolean ok = file . delete ( ) ; if ( ! ok ) cacheLog . error ( \"Unable to delete file \" + file . getAbsolutePath ( ) ) ; if ( sbuff != null ) sbuff . format ( \" deleted %s %s lastModified= %s%n\" , ok , file . getPath ( ) , CalendarDate . of ( file . lastModified ( ) ) ) ; } } } }", "nl": "Remove any files or directories whose last modified time greater than persistMinutes"}}
{"translation": {"code": "protected static String peekName ( RandomAccessFile file ) throws DescriptorException { try { long filepos = file . getFilePointer ( ) ; byte [ ] nameBytes = new byte [ 4 ] ; if ( file . read ( nameBytes ) == - 1 ) return null ; // EOF file . seek ( filepos ) ; return new String ( nameBytes , CDM . utf8Charset ) ; } catch ( IOException ex ) { throw new DescriptorException ( ex ) ; } }", "nl": "Return the name of the DORADE descriptor at the current location in the file . The current location will not be changed ."}}
{"translation": {"code": "public void showCache ( PrintStream pw ) { pw . println ( \"Cache files\" ) ; pw . println ( \"Size   LastModified       Filename\" ) ; File dir = new File ( root ) ; File [ ] files = dir . listFiles ( ) ; if ( files != null ) for ( File file : files ) { String org = null ; try { org = URLDecoder . decode ( file . getName ( ) , \"UTF8\" ) ; } catch ( UnsupportedEncodingException e ) { e . printStackTrace ( ) ; } pw . println ( \" \" + file . length ( ) + \" \" + new Date ( file . lastModified ( ) ) + \" \" + org ) ; } }", "nl": "Show cache contents for debugging ."}}
{"translation": {"code": "public static DatasetSourceStructure getStructure ( String name ) { if ( name == null ) return null ; return ( DatasetSourceStructure ) hash . get ( name ) ; }", "nl": "Find the DatasetSourceStructure that matches this name ."}}
{"translation": {"code": "public void writeGrid ( GeoReferencedArray array , boolean greyScale ) throws IOException { CoverageCoordSys gcs = array . getCoordSysForData ( ) ; if ( ! gcs . isRegularSpatial ( ) ) throw new IllegalArgumentException ( \"Must have 1D x and y axes for \" + array . getCoverageName ( ) ) ; Projection proj = gcs . getProjection ( ) ; CoverageCoordAxis1D xaxis = ( CoverageCoordAxis1D ) gcs . getXAxis ( ) ; CoverageCoordAxis1D yaxis = ( CoverageCoordAxis1D ) gcs . getYAxis ( ) ; // latlon coord does not need to be scaled double scaler = ( xaxis . getUnits ( ) . equalsIgnoreCase ( \"km\" ) ) ? 1000.0 : 1.0 ; // data must go from top to bottom double xStart = xaxis . getCoordEdge1 ( 0 ) * scaler ; double yStart = yaxis . getCoordEdge1 ( 0 ) * scaler ; double xInc = xaxis . getResolution ( ) * scaler ; double yInc = Math . abs ( yaxis . getResolution ( ) ) * scaler ; Array data = array . getData ( ) . reduce ( ) ; if ( yaxis . getCoordMidpoint ( 0 ) < yaxis . getCoordMidpoint ( 1 ) ) { data = data . flip ( 0 ) ; yStart = yaxis . getCoordEdgeLast ( ) ; } /*  remove - i think unneeded, monotonic lon handled in CoordinateAxis1D. JC 3/18/2013\n     if (gcs.isLatLon()) {\n      Array lon = xaxis.read();\n      data = geoShiftDataAtLon(data, lon);\n      xStart = geoShiftGetXstart(lon, xInc);\n      //xStart = -180.0;\n    }  */ if ( pageNumber > 1 ) { geotiff . initTags ( ) ; } // write the data first int nextStart = 0 ; MAMath . MinMax dataMinMax = MAMath . getMinMaxSkipMissingData ( data , array ) ; if ( greyScale ) { ArrayByte result = replaceMissingValuesAndScale ( array , data , dataMinMax ) ; nextStart = geotiff . writeData ( ( byte [ ] ) result . getStorage ( ) , pageNumber ) ; } else { ArrayFloat result = replaceMissingValues ( array , data , dataMinMax ) ; nextStart = geotiff . writeData ( ( float [ ] ) result . getStorage ( ) , pageNumber ) ; } // set the width and the height int height = data . getShape ( ) [ 0 ] ; // Y int width = data . getShape ( ) [ 1 ] ; // X writeMetadata ( greyScale , xStart , yStart , xInc , yInc , height , width , pageNumber , nextStart , dataMinMax , proj ) ; pageNumber ++ ; }", "nl": "Write GridCoverage data to the geotiff file ."}}
{"translation": {"code": "public StructureData readStructure ( int index ) throws IOException , ucar . ma2 . InvalidRangeException { Section section = null ; // works for scalars i think if ( getRank ( ) == 1 ) { section = new Section ( ) . appendRange ( index , index ) ; } else if ( getRank ( ) > 1 ) { Index ii = Index . factory ( shape ) ; // convert to nD index ii . setCurrentCounter ( index ) ; int [ ] origin = ii . getCurrentCounter ( ) ; section = new Section ( ) ; for ( int anOrigin : origin ) section . appendRange ( anOrigin , anOrigin ) ; } Array dataArray = read ( section ) ; ArrayStructure data = ( ArrayStructure ) dataArray ; return data . getStructureData ( 0 ) ; }", "nl": "Use this when this is a one dimensional array of Structures or you are doing the index calculation yourself for a multidimension array . This will read only the ith structure and return the data as a StructureData object ."}}
{"translation": {"code": "public float getCellSpacing ( ) throws DescriptorException { float [ ] cellRanges = myCELV . getCellRanges ( ) ; // // use the first cell spacing as our expected value // float cellSpacing = cellRanges [ 1 ] - cellRanges [ 0 ] ; // // Check the rest of the cells against the expected value, allowing // 1% fudge // for ( int i = 2 ; i < cellRanges . length ; i ++ ) { float space = cellRanges [ i ] - cellRanges [ i - 1 ] ; if ( ! Misc . nearlyEquals ( space , cellSpacing ) && ( Math . abs ( space / cellSpacing - 1.0 ) > 0.01 ) ) { throw new DescriptorException ( \"variable cell spacing\" ) ; } } return cellSpacing ; }", "nl": "Get the cell spacing . An exception is thrown if the cell spacing is not constant ."}}
{"translation": {"code": "public void calcElementSize ( ) { int total = 0 ; for ( Variable v : members ) { total += v . getElementSize ( ) * v . getSize ( ) ; } elementSize = total ; }", "nl": "Force recalculation of size of one element of this structure - equals the sum of sizes of its members . This is used only by low level classes like IOSPs ."}}
{"translation": {"code": "@ Override public void setParentGroup ( Group group ) { if ( isImmutable ( ) ) throw new IllegalStateException ( \"Cant modify\" ) ; super . setParentGroup ( group ) ; if ( members != null ) { for ( Variable v : members ) { v . setParentGroup ( group ) ; } } }", "nl": "Set the parent group of this Structure and all member variables ."}}
{"translation": {"code": "public void setMemberVariables ( List < Variable > vars ) { if ( isImmutable ( ) ) throw new IllegalStateException ( \"Cant modify\" ) ; members = new ArrayList <> ( ) ; memberHash = new HashMap <> ( 2 * vars . size ( ) ) ; for ( Variable v : vars ) { addMemberVariable ( v ) ; } }", "nl": "Set the list of member variables ."}}
{"translation": {"code": "public Variable addMemberVariable ( Variable v ) { if ( isImmutable ( ) ) throw new IllegalStateException ( \"Cant modify\" ) ; members . add ( v ) ; memberHash . put ( v . getShortName ( ) , v ) ; v . setParentStructure ( this ) ; return v ; }", "nl": "Add a member variable"}}
{"translation": {"code": "public static UnitID newUnitID ( final String name , final String plural , final String symbol ) { UnitID id ; try { id = name == null ? new UnitSymbol ( symbol ) : UnitName . newUnitName ( name , plural , symbol ) ; } catch ( final NameException e ) { id = null ; // can't happen } return id ; }", "nl": "Factory method for constructing an identifier from a name plural and symbol ."}}
{"translation": {"code": "private void handleSensorInformation ( ) { numSamplesPerBand = Integer . parseInt ( headerInfo . get ( HeaderInfoTitle . SAMPLES_PER_BAND . toString ( ) ) ) ; numSamplesPerBandDim = new Dimension ( this . numSamplesPerBandDimName , numSamplesPerBand ) ; // Read nominal resolution information nominalResolutionAtt = new Attribute ( nominalResolutionAttName , headerInfo . get ( HeaderInfoTitle . NOMINAL_RESOLUTION . toString ( ) ) ) ; // Read bands per scanlin information. bandsPerScanlineAtt = new Attribute ( bandsPerScanlineAttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BANDS_PER_SCANLINE . toString ( ) ) ) ) ; // Read bytes per smaple information bytesPerSampleAtt = new Attribute ( bytesPerSampleAttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTES_PER_SAMPLE . toString ( ) ) ) ) ; // Read byte offset for band 1 information. byteOffsetBand1Att = new Attribute ( byteOffsetBand1AttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTE_OFFSET_BAND_1 . toString ( ) ) ) ) ; // Read byte offset for band 2 information. byteOffsetBand2Att = new Attribute ( byteOffsetBand2AttName , Integer . valueOf ( headerInfo . get ( HeaderInfoTitle . BYTE_OFFSET_BAND_2 . toString ( ) ) ) ) ; // Band 1 description band1Att = new Attribute ( band1AttName , headerInfo . get ( HeaderInfoTitle . BAND_1 . toString ( ) ) ) ; // Band 2 description band2Att = new Attribute ( band2AttName , headerInfo . get ( HeaderInfoTitle . BAND_2 . toString ( ) ) ) ; // Band organization bandOrganizationAtt = new Attribute ( bandOrganizationAttName , headerInfo . get ( HeaderInfoTitle . ORGANIZATION . toString ( ) ) ) ; // thermal offset thermalOffsetAtt = new Attribute ( thermalOffsetAttName , headerInfo . get ( HeaderInfoTitle . THERMAL_OFFSET . toString ( ) ) ) ; // thermal scale thermalScaleAtt = new Attribute ( thermalScaleAttName , headerInfo . get ( HeaderInfoTitle . THERMAL_SCALE . toString ( ) ) ) ; // percent daylight percentDaylightAtt = new Attribute ( percentDaylightAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_DAYLIGHT . toString ( ) ) ) ) ; // percent full moon percentFullMoonAtt = new Attribute ( percentFullMoonAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_FULL_MOON . toString ( ) ) ) ) ; // percent terminator evident percentTerminatorEvidentAtt = new Attribute ( percentTerminatorEvidentAttName , Double . valueOf ( headerInfo . get ( HeaderInfoTitle . PERCENT_TERMINATOR_EVIDENT . toString ( ) ) ) ) ; }", "nl": "Parse the sensor information from the header ."}}
{"translation": {"code": "private void handleSatelliteInformation ( ) { spacecraftIdAtt = new Attribute ( this . spacecraftIdAttName , headerInfo . get ( HeaderInfoTitle . SPACECRAFT_ID . toString ( ) ) ) ; noradIdAtt = new Attribute ( this . noradIdAttName , headerInfo . get ( HeaderInfoTitle . NORAD_ID . toString ( ) ) ) ; }", "nl": "Parse the satellite information from the header ."}}
{"translation": {"code": "boolean isValidFile ( ucar . unidata . io . RandomAccessFile raFile ) { // @todo This method should not be called if read() has or will be called on this instance. this . raFile = raFile ; try { this . actualSize = raFile . length ( ) ; } catch ( IOException e ) { return ( false ) ; } try { this . readHeaderFromFile ( raFile ) ; this . handleFileInformation ( ) ; this . handleProcessingInformation ( ) ; this . handleSatelliteInformation ( ) ; this . handleSensorInformation ( ) ; } catch ( IOException e ) { return ( false ) ; } return ( true ) ; }", "nl": "Check basic DMSP file validity of given random access file ."}}
{"translation": {"code": "protected double grabDouble ( byte [ ] bytes , int offset ) throws DescriptorException { try { byte [ ] src ; if ( littleEndianData ) { src = new byte [ 8 ] ; src [ 0 ] = bytes [ offset + 7 ] ; src [ 1 ] = bytes [ offset + 6 ] ; src [ 2 ] = bytes [ offset + 5 ] ; src [ 3 ] = bytes [ offset + 4 ] ; src [ 4 ] = bytes [ offset + 3 ] ; src [ 5 ] = bytes [ offset + 2 ] ; src [ 6 ] = bytes [ offset + 1 ] ; src [ 7 ] = bytes [ offset ] ; offset = 0 ; } else { src = bytes ; } DataInputStream stream = new DataInputStream ( new ByteArrayInputStream ( src , offset , 8 ) ) ; return stream . readDouble ( ) ; } catch ( Exception ex ) { throw new DescriptorException ( ex ) ; } }", "nl": "Unpack an eight - byte IEEE float from the given byte array ."}}
{"translation": {"code": "public static Converter create ( Unit fromUnit , Unit toUnit ) throws ConversionException { return fromUnit . getConverterTo ( toUnit ) ; }", "nl": "Factory method for creating a unit converter ."}}
{"translation": {"code": "public float [ ] getAzimuths ( ) { if ( azimuths == null ) { azimuths = new float [ nRays ] ; for ( int r = 0 ; r < nRays ; r ++ ) { azimuths [ r ] = myRYIBs [ r ] . getAzimuth ( ) ; } } return azimuths ; }", "nl": "Get the array of azimuths for this sweep ."}}
{"translation": {"code": "public void serialize ( String dataset , DataOutputStream sink , CEEvaluator ce , Object specialO ) throws NoSuchVariableException , DAP2ServerSideException , IOException { if ( org == null ) { super . serialize ( dataset , sink , ce , specialO ) ; return ; } // use the projection info in the original java . util . Enumeration vars = org . getVariables ( ) ; // run through each structure member StructureMembers sm = sdata . getStructureMembers ( ) ; int count = 0 ; while ( vars . hasMoreElements ( ) ) { HasNetcdfVariable sm_org = ( HasNetcdfVariable ) vars . nextElement ( ) ; boolean isProjected = ( ( ServerMethods ) sm_org ) . isProject ( ) ; if ( isProjected ) { StructureMembers . Member m = sm . getMember ( count ) ; sm_org . serialize ( sink , sdata , m ) ; } count ++ ; } }", "nl": "overrride for array of Structures"}}
{"translation": {"code": "public boolean read ( String datasetName , Object specialO ) throws NoSuchVariableException , IOException { // read the scalar structure into memory StructureData sdata = ncVar . readStructure ( ) ; setData ( sdata ) ; return ( false ) ; }", "nl": "called if its scalar"}}
{"translation": {"code": "private void createFromDataset ( NetcdfDataset ncd ) { // get coordinate variables, disjunct from variables for ( CoordinateAxis axis : ncd . getCoordinateAxes ( ) ) { coordvars . put ( axis . getShortName ( ) , axis ) ; } // dup the variable set ddsvars = new ArrayList <> ( 50 ) ; // collect grid array variables and set of coordinate variables used in grids for ( Variable v : ncd . getVariables ( ) ) { if ( coordvars . containsKey ( v . getShortName ( ) ) ) continue ; // skip coordinate variables ddsvars . add ( v ) ; boolean isgridarray = ( v . getRank ( ) > 1 ) && ( v . getDataType ( ) != DataType . STRUCTURE ) && ( v . getParentStructure ( ) == null ) ; if ( ! isgridarray ) continue ; List < Dimension > dimset = v . getDimensions ( ) ; int rank = dimset . size ( ) ; for ( int i = 0 ; isgridarray && i < rank ; i ++ ) { Dimension dim = dimset . get ( i ) ; if ( dim . getShortName ( ) == null ) isgridarray = false ; else { Variable gv = coordvars . get ( dim . getShortName ( ) ) ; if ( gv == null ) isgridarray = false ; } } if ( isgridarray ) { gridarrays . put ( v . getFullName ( ) , v ) ; for ( Dimension dim : dimset ) { Variable gv = coordvars . get ( dim . getShortName ( ) ) ; if ( gv != null ) used . put ( gv . getFullName ( ) , gv ) ; } } } // Create the set of coordinates for ( Variable cv : ncd . getCoordinateAxes ( ) ) { BaseType bt = createVariable ( ncd , cv ) ; addVariable ( bt ) ; } // Create the set of variables for ( Variable cv : ddsvars ) { BaseType bt = createVariable ( ncd , cv ) ; addVariable ( bt ) ; } }", "nl": "take advantage of the work already done by NetcdfDataset"}}
{"translation": {"code": "private BaseType createVariable ( NetcdfFile ncfile , Variable v ) { BaseType bt ; if ( v . getRank ( ) == 0 ) // scalar bt = createScalarVariable ( ncfile , v ) ; else if ( v . getDataType ( ) == DataType . CHAR ) { if ( v . getRank ( ) > 1 ) bt = new NcSDCharArray ( v ) ; else bt = new NcSDString ( v ) ; } else if ( v . getDataType ( ) == DataType . STRING ) { if ( v . getRank ( ) == 0 ) bt = new NcSDString ( v ) ; else bt = new NcSDArray ( v , new NcSDString ( v ) ) ; } else // non-char multidim array bt = createArray ( ncfile , v ) ; return bt ; }", "nl": "turn Variable into opendap variable"}}
{"translation": {"code": "public int writeDirectory ( HttpServletResponse res , File dir , String path ) throws IOException { // error checking if ( dir == null ) { res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return 0 ; } if ( ! dir . exists ( ) || ! dir . isDirectory ( ) ) { res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return 0 ; } // Get directory as HTML String dirHtmlString = getDirectory ( path , dir ) ; thredds . servlet . ServletUtil . setResponseContentLength ( res , dirHtmlString ) ; res . setContentType ( ContentType . html . getContentHeader ( ) ) ; PrintWriter writer = res . getWriter ( ) ; writer . write ( dirHtmlString ) ; writer . flush ( ) ; return dirHtmlString . length ( ) ; }", "nl": "Write a file directory ."}}
{"translation": {"code": "public ucar . unidata . geoloc . Station getSelectedStation ( ) { return ( selected != null ) ? selected . ddStation : null ; }", "nl": "Get the selected station ."}}
{"translation": {"code": "public void save ( ) { if ( catListBox != null ) catListBox . save ( ) ; if ( prefs != null ) { if ( fileChooser != null ) fileChooser . save ( ) ; if ( catgenFileChooser != null ) catgenFileChooser . save ( ) ; prefs . putInt ( HDIVIDER , split . getDividerLocation ( ) ) ; } }", "nl": "Save persistent state ."}}
{"translation": {"code": "public void addAction ( String menuName , Action act ) { act . putValue ( Action . NAME , menuName ) ; super . add ( act ) ; }", "nl": "Add an action to the popup menu . Note that the menuName is made the NAME value of the action ."}}
{"translation": {"code": "public void setStations ( java . util . List < ucar . unidata . geoloc . Station > stns ) { stations = new ArrayList < StationUI > ( stns . size ( ) ) ; stationHash . clear ( ) ; for ( int i = 0 ; i < stns . size ( ) ; i ++ ) { ucar . unidata . geoloc . Station s = ( ucar . unidata . geoloc . Station ) stns . get ( i ) ; StationUI sui = new StationUI ( s ) ; // wrap in a StationUI stations . add ( sui ) ; // wrap in a StationUI stationHash . put ( s . getName ( ) , sui ) ; } posWasCalc = false ; calcWorldPos ( ) ; }", "nl": "Set the list of stations ."}}
{"translation": {"code": "public static synchronized void add ( URL url , SourcePicture sp ) { Tools . log ( \"PictureCache.add: \" + url . toString ( ) ) ; if ( sp . getSourceBufferedImage ( ) == null ) { Tools . log ( \"PictureCache.add: invoked with a null picture! Not cached!\" ) ; return ; } if ( ( maxCache < 1 ) ) { Tools . log ( \"PictureCache.add: cache is diabled. Not adding picture.\" ) ; return ; } if ( isInCache ( url ) ) { Tools . log ( \"Picture \" + url . toString ( ) + \" is already in the cache. Not adding again.\" ) ; return ; } if ( pictureCache . size ( ) >= maxCache ) removeLeastPopular ( ) ; if ( pictureCache . size ( ) < maxCache ) pictureCache . put ( url . toString ( ) , sp ) ; //reportCache();\t }", "nl": "store an image in the cache"}}
{"translation": {"code": "public void setPicture ( URL filenameURL , String legendParam , double rotation ) { legend = legendParam ; centerWhenScaled = true ; sclPic . setScaleSize ( getSize ( ) ) ; sclPic . stopLoadingExcept ( filenameURL ) ; sclPic . loadAndScalePictureInThread ( filenameURL , Thread . MAX_PRIORITY , rotation ) ; }", "nl": "brings up the indicated picture on the display ."}}
{"translation": {"code": "public void setBufferedImage ( BufferedImage img , String statusMessage ) { legend = statusMessage ; centerWhenScaled = true ; Dimension dim = getSize ( ) ; sclPic . setScaleSize ( dim ) ; SourcePicture source = new SourcePicture ( ) ; source . setSourceBufferedImage ( img , statusMessage ) ; sclPic . setSourcePicture ( source ) ; if ( ! scaleToFit ) sclPic . setScaleFactor ( 1.0 ) ; sclPic . scalePicture ( ) ; repaint ( ) ; }", "nl": "sets the buffered image directly ."}}
{"translation": {"code": "public static synchronized void reportCache ( ) { Tools . log ( \"   PictureCache.reportCache: cache contains: \" + Integer . toString ( pictureCache . size ( ) ) + \" max: \" + Integer . toString ( maxCache ) ) ; //Tools.freeMem(); Enumeration e = pictureCache . keys ( ) ; while ( e . hasMoreElements ( ) ) { Tools . log ( \"   Cache contains: \" + ( ( String ) e . nextElement ( ) ) ) ; } Tools . log ( \"  End of cache contents\" ) ; }", "nl": "method to inspect the cache"}}
{"translation": {"code": "public void zoomToFit ( ) { //Tools.log(\"zoomToFit invoked\"); sclPic . setScaleSize ( getSize ( ) ) ; // prevent useless rescale events when the picture is not ready if ( sclPic . getStatusCode ( ) == sclPic . LOADED || sclPic . getStatusCode ( ) == sclPic . READY ) { sclPic . createScaledPictureInThread ( Thread . MAX_PRIORITY ) ; } }", "nl": "this method sets the desired scaled size of the ScalablePicture to the size of the JPanel and fires off a createScaledPictureInThread request if the ScalablePicture has been loaded or is ready ."}}
{"translation": {"code": "public ucar . unidata . geoloc . Station pickClosest ( Point2D pickPt ) { if ( world2Normal == null || pickPt == null || stations . isEmpty ( ) ) return null ; world2Normal . transform ( pickPt , ptN ) ; // work in normalized coordinate space StationUI closest = ( StationUI ) stationGrid . findClosest ( ptN ) ; if ( debug ) System . out . println ( \"closest= \" + closest ) ; setSelectedStation ( closest ) ; return getSelectedStation ( ) ; }", "nl": "Find station closest to this point . Make it the selected station ."}}
{"translation": {"code": "public static void stopBackgroundLoading ( ) { Enumeration e = cacheLoadsInProgress . elements ( ) ; while ( e . hasMoreElements ( ) ) { ( ( SourcePicture ) e . nextElement ( ) ) . stopLoading ( ) ; } }", "nl": "method to stop all background loading"}}
{"translation": {"code": "public static boolean stopBackgroundLoadingExcept ( URL exemptionURL ) { SourcePicture sp ; String exemptionURLString = exemptionURL . toString ( ) ; Enumeration e = cacheLoadsInProgress . elements ( ) ; boolean inProgress = false ; while ( e . hasMoreElements ( ) ) { sp = ( ( SourcePicture ) e . nextElement ( ) ) ; if ( ! sp . getUrlString ( ) . equals ( exemptionURLString ) ) sp . stopLoading ( ) ; else { Tools . log ( \"PictureCache.stopBackgroundLoading: picture was already loading\" ) ; inProgress = true ; } } return inProgress ; }", "nl": "method to stop all background loading except the indicated file . Returns whether the image is already being loaded . True = loading in progress False = not in progress ."}}
{"translation": {"code": "private void makeActionsSystem ( ) { /* aboutAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent evt) {\n        new AboutWindow();\n      }\n    };\n    BAMutil.setActionProperties( aboutAction, null, \"About\", false, 'A', 0); */ /* printAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) {\n        PrinterJob printJob = PrinterJob.getPrinterJob();\n        PageFormat pf = printJob.defaultPage();\n\n        // do we need to rotate ??\n        if (panz.wantRotate( pf.getImageableWidth(), pf.getImageableHeight()))\n          pf.setOrientation( PageFormat.LANDSCAPE);\n        else\n          pf.setOrientation(PageFormat.PORTRAIT);\n\n        printJob.setPrintable(controller.getPrintable(), pf);\n        if (printJob.printDialog()) {\n          try {\n            if (Debug.isSet(\"print.job\")) System.out.println(\"call printJob.print\");\n            printJob.print();\n            if (Debug.isSet(\"print.job\")) System.out.println(\" printJob done\");\n          } catch (Exception PrintException) {\n            PrintException.printStackTrace();\n          }\n        }\n      }\n    };\n    BAMutil.setActionProperties( printAction, \"Print\", \"Print...\", false, 'P', KeyEvent.VK_P);\n\n    sysConfigAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) {\n        if (sysConfigDialog == null)\n          makeSysConfigWindow();\n        sysConfigDialog.show();\n      }\n    };\n    BAMutil.setActionProperties( sysConfigAction, \"Preferences\", \"Configure...\", false, 'C', -1);\n\n    clearDebugFlagsAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) { Debug.clear(); }\n    };\n    BAMutil.setActionProperties( clearDebugFlagsAction, null, \"Clear DebugFlags\", false, 'D', -1);\n\n    clearRecentAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) {\n        recentDatasetList = new ArrayList();\n      }\n    };\n    BAMutil.setActionProperties( clearRecentAction, null, \"Clear Recent Datasets\", false, 'R', -1);\n    */ AbstractAction clearDebugFlagsAction = new AbstractAction ( ) { public void actionPerformed ( ActionEvent e ) { /* Debug.clear(); */ } } ; BAMutil . setActionProperties ( clearDebugFlagsAction , null , \"Clear Debug Flags\" , false , ' ' , - 1 ) ; /* AbstractAction setDebugFlagsAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) {\n        // LOOK set netcdf debug flags\n\n        InvCatalogFactory.debugURL = Debug.isSet(\"InvCatalogFactory/debugURL\");\n        InvCatalogFactory.debugOpen = Debug.isSet(\"InvCatalogFactory/debugOpen\");\n        InvCatalogFactory.debugVersion = Debug.isSet(\"InvCatalogFactory/debugVersion\");\n        InvCatalogFactory.showParsedXML = Debug.isSet(\"InvCatalogFactory/showParsedXML\");\n        InvCatalogFactory.showStackTrace = Debug.isSet(\"InvCatalogFactory/showStackTrace\");\n        InvCatalogFactory.debugXML = Debug.isSet(\"InvCatalogFactory/debugXML\");\n        InvCatalogFactory.debugDBurl = Debug.isSet(\"InvCatalogFactory/debugDBurl\");\n        InvCatalogFactory.debugXMLopen = Debug.isSet(\"InvCatalogFactory/debugXMLopen\");\n        InvCatalogFactory.showCatalogXML = Debug.isSet(\"InvCatalogFactory/showCatalogXML\");\n      }\n    };\n    BAMutil.setActionProperties(setDebugFlagsAction, null, \"Set Debug Flags\", false, 'S', -1);  */ /* exitAction = new AbstractAction() {\n      public void actionPerformed(ActionEvent e) {\n        topLevel.close();\n      }\n    };\n    BAMutil.setActionProperties( exitAction, \"Exit\", \"Exit\", false, 'X', -1); */ }", "nl": "actions that are system - wide"}}
{"translation": {"code": "void validate ( String urlString ) { if ( urlString == null ) return ; URI uri ; try { uri = new URI ( urlString ) ; } catch ( URISyntaxException e ) { javax . swing . JOptionPane . showMessageDialog ( null , \"URISyntaxException on URL (\" + urlString + \") \" + e . getMessage ( ) + \"\\n\" ) ; return ; } String contents = getText ( ) ; //boolean isCatalog = contents.indexOf(\"queryCapability\") < 0; ByteArrayInputStream is = new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) ; try { CatalogBuilder catFactory = new CatalogBuilder ( ) ; Catalog cat = catFactory . buildFromLocation ( urlString , null ) ; boolean isValid = ! catFactory . hasFatalError ( ) ; javax . swing . JOptionPane . showMessageDialog ( this , \"Catalog Validation = \" + isValid + \"\\n\" + catFactory . getErrorMessage ( ) ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } }", "nl": "private DqcFactory dqcFactory = null ;"}}
{"translation": {"code": "private void setSelectedIndex ( int idx ) { if ( zAxis == null ) return ; eventOK = false ; currentIdx = idx ; slider . setValue ( world2slider ( zAxis . getCoordValue ( currentIdx ) ) ) ; eventOK = true ; }", "nl": "set current value - no event"}}
{"translation": {"code": "public int [ ] getModelIndex ( ) { int [ ] modelIndex = new int [ colName . length ] ; TableColumnModel tcm = jtable . getColumnModel ( ) ; for ( int i = 0 ; i < colName . length ; i ++ ) { TableColumn tc = tcm . getColumn ( i ) ; modelIndex [ i ] = tc . getModelIndex ( ) ; } return modelIndex ; }", "nl": "for each column get the model index"}}
{"translation": {"code": "public void addActionSourceListener ( ActionSourceListener l ) { if ( ! eventType . equals ( l . getEventTypeName ( ) ) ) throw new IllegalArgumentException ( \"ActionCoordinator: tried to add ActionSourceListener for wrong kind of Action \" + eventType + \" != \" + l . getEventTypeName ( ) ) ; lm . addListener ( l ) ; l . addActionValueListener ( this ) ; }", "nl": "add an ActionSource listener"}}
{"translation": {"code": "public void appendLine ( String line ) { if ( count >= nlines ) { try { int remove = Math . max ( removeIncr , count - nlines ) ; // nlines may have changed int offset = ta . getLineEndOffset ( remove ) ; ta . replaceRange ( \"\" , 0 , offset ) ; } catch ( Exception e ) { log . error ( \"Problem in TextHistoryPane\" , e ) ; } count = nlines - removeIncr ; } ta . append ( line ) ; ta . append ( \"\\n\" ) ; count ++ ; // scroll to end ta . setCaretPosition ( ta . getText ( ) . length ( ) ) ; }", "nl": "Append this line to the bottom of the JTextArea . A newline is added and JTextArea is scrolled to bottom ; remove lines at top if needed ."}}
{"translation": {"code": "public int compare ( TableRow other , int col ) { String s1 = getValueAt ( col ) . toString ( ) ; String s2 = other . getValueAt ( col ) . toString ( ) ; int ret = s1 . compareToIgnoreCase ( s2 ) ; // break ties if ( ret == 0 ) return compareTie ( other , col ) ; return ret ; }", "nl": "for other behavior override this ; use compareXXX routines ."}}
{"translation": {"code": "public void setCatalog ( String location ) { CatalogBuilder builder = new CatalogBuilder ( ) ; try { Catalog cat = builder . buildFromLocation ( location , null ) ; setCatalog ( cat ) ; } catch ( Exception ioe ) { JOptionPane . showMessageDialog ( this , \"Error opening catalog location \" + location + \" err=\" + builder . getErrorMessage ( ) ) ; } }", "nl": "Set the InvCatalog to display . The catalog is read asynchronously and displayed if successfully read . You must use a PropertyChangeEventListener to be notified if successful ."}}
{"translation": {"code": "private void synchUI ( boolean slidersOK ) { eventOK = false ; if ( slidersOK ) minSlider . setValue ( scale . world2slider ( dateRange . getStart ( ) ) ) ; minField . setValue ( dateRange . getStart ( ) ) ; if ( maxField != null ) { if ( slidersOK ) maxSlider . setValue ( scale . world2slider ( dateRange . getEnd ( ) ) ) ; maxField . setValue ( dateRange . getEnd ( ) ) ; } if ( durationField != null ) durationField . setValue ( dateRange . getDuration ( ) ) ; eventOK = true ; }", "nl": "set values on the UI"}}
{"translation": {"code": "public void restoreState ( PreferencesExt store ) { if ( store == null ) return ; int ncols = table . getColumnCount ( ) ; // stored column order int [ ] modelIndex = ( int [ ] ) store . getBean ( \"ColumnOrder\" , null ) ; if ( ( modelIndex != null ) && ( modelIndex . length == ncols ) ) { // what about invisible ?? // make invisible any not stored boolean [ ] visible = new boolean [ ncols ] ; for ( int aModelIndex : modelIndex ) if ( aModelIndex < ncols ) visible [ aModelIndex ] = true ; // modify popup menu for ( int i = 0 ; i < ncols ; i ++ ) if ( ! visible [ i ] ) { //System.out.println( colName[i]+\" hide \"+i); acts [ i ] . hideColumn ( ) ; acts [ i ] . putValue ( BAMutil . STATE , new Boolean ( false ) ) ; } // now set the header order TableColumnModel tcm = table . getColumnModel ( ) ; int n = Math . min ( modelIndex . length , table . getColumnCount ( ) ) ; for ( int i = 0 ; i < n ; i ++ ) { TableColumn tc = tcm . getColumn ( i ) ; tc . setModelIndex ( modelIndex [ i ] ) ; String name = model . getColumnName ( modelIndex [ i ] ) ; tc . setHeaderValue ( name ) ; tc . setIdentifier ( name ) ; if ( useThreads && ( modelIndex [ i ] == threadCol ) ) { threadHeaderRenderer = new ThreadHeaderRenderer ( threadCol ) ; tc . setHeaderRenderer ( threadHeaderRenderer ) ; } else tc . setHeaderRenderer ( new SortedHeaderRenderer ( name , modelIndex [ i ] ) ) ; } } // set the column widths Object colWidths = store . getBean ( \"ColumnWidths\" , null ) ; if ( colWidths == null ) return ; int [ ] size = ( int [ ] ) colWidths ; setColumnWidths ( size ) ; if ( debug ) { System . out . println ( \" read widths = \" ) ; for ( int aSize : size ) System . out . print ( \" \" + aSize ) ; System . out . println ( ) ; } boolean isThreadsOn = store . getBoolean ( \"isThreadsOn\" , false ) ; if ( useThreads ) { model . setThreadsOn ( isThreadsOn ) ; threadHeaderRenderer . setOn ( isThreadsOn ) ; } int colNo = store . getInt ( \"SortOnCol\" , 0 ) ; boolean reverse = store . getBoolean ( \"SortReverse\" , false ) ; model . setSortCol ( colNo ) ; model . setReverse ( reverse ) ; setSortCol ( colNo , reverse ) ; model . sort ( ) ; table . fireDataChanged ( ) ; } private void setColumnWidths  ( int [ ] sizes ) { TableColumnModel tcm = table . getColumnModel ( ) ; for ( int i = 0 ; i < table . getColumnCount ( ) ; i ++ ) { TableColumn tc = tcm . getColumn ( i ) ; int maxw = ( ( sizes == null ) || ( i >= sizes . length ) ) ? 10 : sizes [ i ] ; //     model.getPreferredWidthForColumn(tc) : sizes[i]; tc . setPreferredWidth ( maxw ) ; } //table.sizeColumnsToFit(0);     //  must be called due to a JTable bug } public void setColOn  ( int colno , boolean state , int pos ) { // System.out.println(\"setColOn \"+colno+\" \"+state+\" \"+pos); acts [ colno ] . putValue ( BAMutil . STATE , new Boolean ( state ) ) ; if ( state ) acts [ colno ] . addAtPos ( pos ) ; else acts [ colno ] . hideColumn ( ) ; }", "nl": "Set the state from the last saved in the PreferencesExt ."}}
{"translation": {"code": "public Iterator getSelectedRows ( ) { TreePath [ ] paths = table . getSelectionPaths ( ) ; if ( ( paths == null ) || ( paths . length < 1 ) ) return null ; HashSet set = new HashSet ( 2 * paths . length ) ; for ( TreePath path : paths ) { model . addRowsToSetFromPath ( table . getTree ( ) , path , set ) ; } return set . iterator ( ) ; }", "nl": "Get the currently selected rows ."}}
{"translation": {"code": "public boolean startProgressMonitorTask ( ProgressMonitorTask pmt ) { if ( busy ) return false ; busy = true ; this . task = pmt ; isCancelled = false ; count = 0 ; setIcon ( icon [ 0 ] ) ; // create timer, whose events happen on the awt event Thread ActionListener watcher = new ActionListener ( ) { public void actionPerformed ( ActionEvent evt ) { //System.out.println(\"timer event\"+evt); if ( isCancelled && ! task . isCancel ( ) ) { task . cancel ( ) ; if ( debug ) System . out . println ( \" task.cancel\" ) ; return ; // give it a chance to finish up } else { // indicate progress count ++ ; setIcon ( icon [ count % 2 ] ) ; if ( debug ) System . out . println ( \" stop count=\" + count ) ; } // need to make sure task acknowledges the cancel; so dont shut down // until the task is done if ( task . isDone ( ) ) { if ( myTimer != null ) myTimer . stop ( ) ; myTimer = null ; if ( task . isError ( ) ) javax . swing . JOptionPane . showMessageDialog ( null , task . getErrorMessage ( ) ) ; if ( task . isSuccess ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"success\" ) ) ; else if ( task . isError ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"error\" ) ) ; else if ( task . isCancel ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"cancel\" ) ) ; else fireEvent ( new ActionEvent ( this , 0 , \"done\" ) ) ; busy = false ; } } } ; myTimer = new javax . swing . Timer ( 1000 , watcher ) ; // every second myTimer . start ( ) ; // do task in a seperate, non-event, thread Thread taskThread = new Thread ( task ) ; taskThread . start ( ) ; return true ; }", "nl": "The given task is run in a background thread . Progress is indicated once a second . You cannot call this method again till the task is completed ."}}
{"translation": {"code": "public void openAll ( boolean includeCatref ) { if ( catalog == null ) return ; open ( ( InvCatalogTreeNode ) model . getRoot ( ) , includeCatref ) ; tree . repaint ( ) ; }", "nl": "Open all nodes of the tree ."}}
{"translation": {"code": "TreePath makeTreePath ( TreeNode node ) { ArrayList < TreeNode > path = new ArrayList <> ( ) ; path . add ( node ) ; TreeNode parent = node . getParent ( ) ; while ( parent != null ) { path . add ( 0 , parent ) ; parent = parent . getParent ( ) ; } Object [ ] paths = path . toArray ( ) ; return new TreePath ( paths ) ; }", "nl": "Create the TreePath corresponding to the given TreeNode ."}}
{"translation": {"code": "public void setSelectedDataset ( Dataset ds ) { if ( ds == null ) return ; TreePath path = makePath ( ds ) ; if ( path == null ) return ; tree . setSelectionPath ( path ) ; tree . scrollPathToVisible ( path ) ; }", "nl": "Set the currently selected InvDataset ."}}
{"translation": {"code": "public void setSelectedStation ( String name ) { StationUI sui = ( StationUI ) stationHash . get ( name ) ; if ( sui != null ) { setSelectedStation ( sui ) ; } }", "nl": "set selected station based on the sttion id ."}}
{"translation": {"code": "static public long swapLong ( byte [ ] b , int offset ) { // 8 bytes long accum = 0 ; long shiftedval ; for ( int shiftBy = 0 , i = offset ; shiftBy < 64 ; shiftBy += 8 , i ++ ) { shiftedval = ( ( long ) ( b [ i ] & 0xff ) ) << shiftBy ; accum |= shiftedval ; } return accum ; }", "nl": "Returns the long resulting from reversing 8 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "public void setStations ( java . util . List stns ) { stnRender . setStations ( stns ) ; redraw ( true ) ; }", "nl": "Set the list of Stations ."}}
{"translation": {"code": "public void setSelectedStation ( String id ) { stnRender . setSelectedStation ( id ) ; selectedStation = stnRender . getSelectedStation ( ) ; assert selectedStation != null ; np . setLatLonCenterMapArea ( selectedStation . getLatitude ( ) , selectedStation . getLongitude ( ) ) ; redraw ( ) ; }", "nl": "Looks for the station with given id . If found makes it current . Redraws ."}}
{"translation": {"code": "protected void redraw ( ) { long tstart = System . currentTimeMillis ( ) ; java . awt . Graphics2D gNP = np . getBufferedImageGraphics ( ) ; if ( gNP == null ) // panel not drawn on screen yet return ; // clear it gNP . setBackground ( np . getBackgroundColor ( ) ) ; java . awt . Rectangle r = gNP . getClipBounds ( ) ; gNP . clearRect ( r . x , r . y , r . width , r . height ) ; if ( regionSelect && geoSelectionMode ) { if ( geoSelection != null ) drawBB ( gNP , geoSelection , Color . cyan ) ; if ( geoBounds != null ) drawBB ( gNP , geoBounds , null ) ; // System.out.println(\"GeoRegionChooser.redraw geoBounds= \"+geoBounds); if ( geoSelection != null ) { // gNP.setColor( Color.orange); Navigation navigate = np . getNavigation ( ) ; double handleSize = RubberbandRectangleHandles . handleSizePixels / navigate . getPixPerWorld ( ) ; Rectangle2D rect = new Rectangle2D . Double ( geoSelection . getX ( ) , geoSelection . getY ( ) , geoSelection . getWidth ( ) , geoSelection . getHeight ( ) ) ; RubberbandRectangleHandles . drawHandledRect ( gNP , rect , handleSize ) ; if ( debug ) System . out . println ( \"GeoRegionChooser.drawHandledRect=\" + handleSize + \" = \" + geoSelection ) ; } } for ( int i = 0 ; i < renderers . size ( ) ; i ++ ) { ucar . nc2 . ui . util . Renderer rend = ( Renderer ) renderers . get ( i ) ; rend . draw ( gNP , atI ) ; } gNP . dispose ( ) ; if ( debug ) { long tend = System . currentTimeMillis ( ) ; System . out . println ( \"StationRegionDateChooser draw time = \" + ( tend - tstart ) / 1000.0 + \" secs\" ) ; } // copy buffer to the screen np . repaint ( ) ; }", "nl": "Redraw the graphics on the screen ."}}
{"translation": {"code": "protected Iterator getShapes ( java . awt . Graphics2D g , AffineTransform normal2device ) { if ( shapeList != null ) return shapeList . iterator ( ) ; if ( Debug . isSet ( \"projection/LatLonShift\" ) ) System . out . println ( \"projection/LatLonShift GisFeatureRenderer.getShapes called\" ) ; ProjectionImpl dataProject = getDataProjection ( ) ; // a list of GisFeatureAdapter-s List featList = getFeatures ( ) ; shapeList = new ArrayList ( featList . size ( ) ) ; Iterator iter = featList . iterator ( ) ; while ( iter . hasNext ( ) ) { AbstractGisFeature feature = ( AbstractGisFeature ) iter . next ( ) ; Shape shape ; if ( dataProject == null ) shape = feature . getShape ( ) ; else if ( dataProject . isLatLon ( ) ) { // always got to run it through if its lat/lon shape = feature . getProjectedShape ( displayProject ) ; //System.out.println(\"getShapes dataProject.isLatLon() \"+displayProject); } else if ( dataProject == displayProject ) { shape = feature . getShape ( ) ; //System.out.println(\"getShapes dataProject == displayProject\"); } else { shape = feature . getProjectedShape ( dataProject , displayProject ) ; //System.out.println(\"getShapes dataProject != displayProject\"); } shapeList . add ( shape ) ; } return shapeList . iterator ( ) ; }", "nl": "get the set of shapes to draw convert projections if need be"}}
{"translation": {"code": "protected int compareBoolean ( TableRow other , int col , boolean b1 , boolean b2 ) { // break ties if ( b1 == b2 ) return compareTie ( other , col ) ; return b1 ? 1 : - 1 ; }", "nl": "for use by the subclass"}}
{"translation": {"code": "public void setCurrentProjection ( ProjectionImpl proj ) { int row ; if ( 0 <= ( row = model . search ( proj ) ) ) { if ( debug ) System . out . println ( \" PTsetCurrentProjection found = \" + row ) ; selectedRow = row ; setRowSelectionInterval ( row , row ) ; } else { if ( debug ) System . out . println ( \" PTsetCurrentProjection not found = \" + row ) ; selectedRow = - 1 ; clearSelection ( ) ; } }", "nl": "set current projection if found else deselect"}}
{"translation": {"code": "public DatasetNode getSelectedDataset ( ) { InvCatalogTreeNode tnode = getSelectedNode ( ) ; return tnode == null ? null : tnode . ds ; }", "nl": "Get the currently selected InvDataset ."}}
{"translation": {"code": "public int [ ] getModelIndex ( ) { int [ ] modelIndex = new int [ model . getColumnCount ( ) ] ; try { TableColumnModel tcm = table . getColumnModel ( ) ; for ( int i = 0 ; i < model . getColumnCount ( ) ; i ++ ) { TableColumn tc = tcm . getColumn ( i ) ; modelIndex [ i ] = tc . getModelIndex ( ) ; } } catch ( java . lang . ArrayIndexOutOfBoundsException e ) { //can happen when model size increases } return modelIndex ; }", "nl": "this array translates the column index to the model index"}}
{"translation": {"code": "public void setProjection ( ProjectionImpl project ) { displayProject = project ; if ( featSetList == null ) return ; Iterator iter = featSetList . iterator ( ) ; while ( iter . hasNext ( ) ) { FeatureSet fs = ( FeatureSet ) iter . next ( ) ; fs . newProjection = true ; } }", "nl": "Sets new projection for subsequent drawing ."}}
{"translation": {"code": "public void paintComponent ( Graphics g ) { int WindowWidth = getSize ( ) . width ; int WindowHeight = getSize ( ) . height ; Tools . log ( \"paintComponent called\" ) ; if ( Dragging == false ) { //otherwise it's already a move Cursor setCursor ( new Cursor ( Cursor . WAIT_CURSOR ) ) ; } if ( sclPic . getScaledPicture ( ) != null ) { Graphics2D g2d = ( Graphics2D ) g ; int X_Offset = ( int ) ( ( double ) ( WindowWidth / 2 ) - ( focusPoint . x * sclPic . getScaleFactor ( ) ) ) ; int Y_Offset = ( int ) ( ( double ) ( WindowHeight / 2 ) - ( focusPoint . y * sclPic . getScaleFactor ( ) ) ) ; // clear damaged component area Rectangle clipBounds = g2d . getClipBounds ( ) ; g2d . setColor ( Color . black ) ; // getBackground()); g2d . fillRect ( clipBounds . x , clipBounds . y , clipBounds . width , clipBounds . height ) ; g2d . drawRenderedImage ( sclPic . getScaledPicture ( ) , AffineTransform . getTranslateInstance ( X_Offset , Y_Offset ) ) ; //g2d.drawImage(sclPic.getScaledPicture(), null, 0, 0); if ( showInfo ) { g2d . setColor ( Color . white ) ; g2d . drawString ( legend , infoPoint . x , infoPoint . y ) ; g2d . drawString ( \"Size: \" + Integer . toString ( sclPic . getOriginalWidth ( ) ) + \" x \" + Integer . toString ( sclPic . getOriginalHeight ( ) ) + \" Offset: \" + X_Offset + \" x \" + Y_Offset + \" Mid: \" + Integer . toString ( focusPoint . x ) + \" x \" + Integer . toString ( focusPoint . y ) + \" Scale: \" + twoDecimalFormatter . format ( sclPic . getScaleFactor ( ) ) , infoPoint . x , infoPoint . y + lineSpacing ) ; /* g2d.drawString(\"File: \" + sclPic.getFilename()\n\t\t\t\t\t\t, infoPoint.x\n\t\t\t\t\t\t, infoPoint.y + (2 * lineSpacing) );\n\t\t\t\tg2d.drawString(\"Loaded in: \" \n\t\t\t\t\t\t+ twoDecimalFormatter.format( sclPic.getSourcePicture().loadTime / 1000F )\n\t\t\t\t\t\t+ \" Seconds\"\n\t\t\t\t\t\t, infoPoint.x\n\t\t\t\t\t\t, infoPoint.y + (3 * lineSpacing) );\n\t\t\t\tg2d.drawString(\"Free memory: \" \n\t\t\t\t\t\t+ Long.toString( Runtime.getRuntime().freeMemory( )/1024/1024, 0 ) \n\t\t\t\t\t\t+ \" MB\"\n\t\t\t\t\t\t, infoPoint.x\n\t\t\t\t\t\t, infoPoint.y + (4 * lineSpacing) ); */ } } else { // paint a black square g . setClip ( 0 , 0 , WindowWidth , WindowHeight ) ; g . setColor ( Color . black ) ; g . fillRect ( 0 , 0 , WindowWidth , WindowHeight ) ; } if ( Dragging == false ) { //otherwise a move Cursor and should remain setCursor ( new Cursor ( Cursor . DEFAULT_CURSOR ) ) ; } }", "nl": "we are overriding the default paintComponent method grabbing the Graphics handle and doing our own drawing here . Esentially this method draws a large black rectangle . A drawRenderedImage is then painted doing an affine transformation on the scaled image to position it so the the desired point is in the middle of the Graphics object . The picture is not scaled here because this is a slow operation and only needs to be done once while moving the image is something the user is likely to do more often ."}}
{"translation": {"code": "public void setGrid ( Rectangle2D bbox , double width , double height ) { offsetX = bbox . getX ( ) ; offsetY = bbox . getY ( ) ; // number of grid cells countX = Math . min ( nx , ( int ) ( bbox . getWidth ( ) / ( scaleOverlap * width ) ) ) ; countY = Math . min ( ny , ( int ) ( bbox . getHeight ( ) / ( scaleOverlap * height ) ) ) ; gridWidth = bbox . getWidth ( ) / countX ; gridHeight = bbox . getHeight ( ) / countY ; if ( debug ) System . out . println ( \"SpatialGrid size \" + gridWidth + \" \" + gridHeight + \" = \" + countX + \" by \" + countY + \" scaleOverlap= \" + scaleOverlap ) ; }", "nl": "Set the grid scale ."}}
{"translation": {"code": "public Dimension preferredLayoutSize ( Container target ) { synchronized ( target . getTreeLock ( ) ) { Dimension dim = new Dimension ( 0 , 0 ) ; for ( int i = 0 ; i < target . getComponentCount ( ) ; i ++ ) { Component m = target . getComponent ( i ) ; if ( m . isVisible ( ) ) { Dimension d = m . getPreferredSize ( ) ; // original // dim.height = Math.max(dim.height, d.height); //if (i > 0) { dim.width += hgap; } // dim.width += d.width; // new  way Point p = m . getLocation ( ) ; dim . width = Math . max ( dim . width , p . x + d . width ) ; dim . height = Math . max ( dim . height , p . y + d . height ) ; } } Insets insets = target . getInsets ( ) ; dim . width += insets . left + insets . right + getHgap ( ) * 2 ; dim . height += insets . top + insets . bottom + getVgap ( ) * 2 ; return dim ; } }", "nl": "deal with having components on more than one line"}}
{"translation": {"code": "public void setSourceBufferedImage ( BufferedImage img , String statusMessage ) { sourcePictureBufferedImage = img ; setStatus ( READY , statusMessage ) ; }", "nl": "sets the buffered image . Unusual method use with care ."}}
{"translation": {"code": "public Dimension getSize ( ) { if ( sourcePictureBufferedImage != null ) return new Dimension ( sourcePictureBufferedImage . getWidth ( ) , sourcePictureBufferedImage . getHeight ( ) ) ; else return new Dimension ( 0 , 0 ) ; }", "nl": "return the size of the image or Zero if there is none"}}
{"translation": {"code": "protected Iterator getShapes ( java . awt . Graphics2D g , AffineTransform normal2device ) { long startTime = System . currentTimeMillis ( ) ; if ( featSetList == null ) { initFeatSetList ( ) ; assert ! featSetList . isEmpty ( ) ; } // which featureSet should we ue? FeatureSet fs = ( FeatureSet ) featSetList . get ( 0 ) ; if ( featSetList . size ( ) > 1 ) { // compute scale double scale = 1.0 ; try { AffineTransform world2device = g . getTransform ( ) ; AffineTransform world2normal = normal2device . createInverse ( ) ; world2normal . concatenate ( world2device ) ; scale = Math . max ( Math . abs ( world2normal . getScaleX ( ) ) , Math . abs ( world2normal . getShearX ( ) ) ) ; // drawing or printing if ( Debug . isSet ( \"GisFeature/showTransform\" ) ) { System . out . println ( \"GisFeature/showTransform: \" + world2normal + \"\\n scale = \" + scale ) ; } } catch ( java . awt . geom . NoninvertibleTransformException e ) { System . out . println ( \" GisRenderFeature: NoninvertibleTransformException on \" + normal2device ) ; } if ( ! displayProject . isLatLon ( ) ) scale *= 111.0 ; // km/deg double minD = Double . MAX_VALUE ; for ( Object aFeatSetList : featSetList ) { FeatureSet tryfs = ( FeatureSet ) aFeatSetList ; double d = Math . abs ( scale * tryfs . minDist - pixelMatch ) ; // we want min features ~ 2 pixels if ( d < minD ) { minD = d ; fs = tryfs ; } } if ( Debug . isSet ( \"GisFeature/MapResolution\" ) ) { System . out . println ( \"GisFeature/MapResolution: scale = \" + scale + \" minDist = \" + fs . minDist ) ; } } // we may have deferred the actual creation of the points if ( fs . featureList == null ) fs . createFeatures ( ) ; // ok, now see if we need to project if ( ! displayProject . equals ( fs . project ) ) { fs . setProjection ( displayProject ) ; } else { // deal with LatLon if ( fs . newProjection && displayProject . isLatLon ( ) ) { fs . setProjection ( displayProject ) ; } } fs . newProjection = false ; if ( Debug . isSet ( \"GisFeature/timing/getShapes\" ) ) { long tookTime = System . currentTimeMillis ( ) - startTime ; System . out . println ( \"timing.getShapes: \" + tookTime * .001 + \" seconds\" ) ; } // so return it, already return fs . getShapes ( ) ; }", "nl": "we have to deal with both projections and resolution - dependence"}}
{"translation": {"code": "private ArrayList makeShapes ( Iterator featList ) { Shape shape ; ArrayList shapeList = new ArrayList ( ) ; ProjectionImpl dataProject = getDataProjection ( ) ; if ( Debug . isSet ( \"GisFeature/MapDraw\" ) ) { System . out . println ( \"GisFeature/MapDraw: makeShapes with \" + displayProject ) ; } /*    if (Debug.isSet(\"bug.drawShapes\")) {\n      int count =0;\n      // make each GisPart a seperate shape for debugging\nfeats:while (featList.hasNext()) {\n        AbstractGisFeature feature = (AbstractGisFeature) featList.next();\n        java.util.Iterator pi = feature.getGisParts();\n        while (pi.hasNext()) {\n          GisPart gp = (GisPart) pi.next();\n          int np = gp.getNumPoints();\n          GeneralPath path = new GeneralPath(GeneralPath.WIND_EVEN_ODD, np);\n          double[] xx = gp.getX();\n          double[] yy = gp.getY();\n          path.moveTo((float) xx[0], (float) yy[0]);\n          if (count == 63)\n                System.out.println(\"moveTo x =\"+xx[0]+\" y= \"+yy[0]);\n          for(int i = 1; i < np; i++) {\n            path.lineTo((float) xx[i], (float) yy[i]);\n            if (count == 63)\n                System.out.println(\"lineTo x =\"+xx[i]+\" y= \"+yy[i]);\n          }\n          shapeList.add(path);\n          if (count == 63)\n            break feats;\n          count++;\n        }\n      }\n      System.out.println(\"bug.drawShapes: #shapes =\" +shapeList.size());\n      return shapeList;\n    }  */ while ( featList . hasNext ( ) ) { AbstractGisFeature feature = ( AbstractGisFeature ) featList . next ( ) ; if ( dataProject . isLatLon ( ) ) // always got to run it through if its lat/lon shape = feature . getProjectedShape ( displayProject ) ; else if ( dataProject == displayProject ) shape = feature . getShape ( ) ; else shape = feature . getProjectedShape ( dataProject , displayProject ) ; shapeList . add ( shape ) ; } return shapeList ; }", "nl": "make an ArrayList of Shapes from the given featureList and current display Projection"}}
{"translation": {"code": "public ucar . unidata . geoloc . Station pick ( Point2D pickPt ) { if ( world2Normal == null || pickPt == null || stations . isEmpty ( ) ) return null ; world2Normal . transform ( pickPt , ptN ) ; // work in normalized coordinate space StationUI closest = ( StationUI ) stationGrid . findIntersection ( ptN ) ; setSelectedStation ( closest ) ; return getSelectedStation ( ) ; }", "nl": "Find station that contains this point . If it exists make it the selected station ."}}
{"translation": {"code": "public boolean stopLoadingExcept ( URL exemptionURL ) { if ( imageUrl == null ) return false ; // has never been used yet if ( pictureStatusCode != LOADING ) { Tools . log ( \"SourcePicture.stopLoadingExcept: called but pointless since image is not LOADING: \" + imageUrl . toString ( ) ) ; return false ; } if ( ! exemptionURL . toString ( ) . equals ( imageUrl . toString ( ) ) ) { Tools . log ( \"SourcePicture.stopLoadingExcept: called with Url \" + exemptionURL . toString ( ) + \" --> stopping loading of \" + imageUrl . toString ( ) ) ; stopLoading ( ) ; return true ; } else return false ; }", "nl": "this method can be invoked to stop the current reader except if it is reading the desired file . It returns true is the desired file is being loaded . Otherwise it returns false ."}}
{"translation": {"code": "public void stopLoading ( ) { if ( imageUrl == null ) return ; // SourcePicture has never been used yet Tools . log ( \"SourcePicture.stopLoading: called on \" + imageUrl ) ; if ( pictureStatusCode == LOADING ) { reader . abort ( ) ; abortFlag = true ; //reader.dispose(); //setStatus( ERROR, \"Cache Loading was stopped \" + imageUrl.toString() ); //sourcePictureBufferedImage = null;  // actually the thread reading the image continues } }", "nl": "this method can be invoked to stop the current reader"}}
{"translation": {"code": "private AffineTransform calcTransform ( Rectangle2D screen , Bounds world ) { // scale to limiting dimension double xs = screen . getWidth ( ) / ( world . getRight ( ) - world . getLeft ( ) ) ; double ys = screen . getHeight ( ) / ( world . getLower ( ) - world . getUpper ( ) ) ; AffineTransform cat = new AffineTransform ( ) ; cat . setToScale ( xs , ys ) ; cat . translate ( - world . getLeft ( ) , - world . getUpper ( ) ) ; if ( debugTransform ) { System . out . println ( \"TPanel calcTransform = \" ) ; System . out . println ( \"  screen = \" + screen ) ; System . out . println ( \"  world = \" + world ) ; System . out . println ( \"  transform = \" + cat . getScaleX ( ) + \" \" + cat . getShearX ( ) + \" \" + cat . getTranslateX ( ) ) ; System . out . println ( \"              \" + cat . getShearY ( ) + \" \" + cat . getScaleY ( ) + \" \" + cat . getTranslateY ( ) ) ; Point2D src = new Point2D . Double ( world . getLeft ( ) , world . getUpper ( ) ) ; Point2D dst = new Point2D . Double ( 0.0 , 0.0 ) ; System . out . println ( \"  upper left pt = \" + src ) ; System . out . println ( \"  transform = \" + cat . transform ( src , dst ) ) ; src = new Point2D . Double ( world . getRight ( ) , world . getLower ( ) ) ; System . out . println ( \"  lower right pt = \" + src ) ; System . out . println ( \"  transform = \" + cat . transform ( src , dst ) ) ; } return cat ; }", "nl": "map world coords to screen coords ."}}
{"translation": {"code": "public void loadPicture ( URL imageUrl , double rotation ) { if ( pictureStatusCode == LOADING ) { stopLoadingExcept ( imageUrl ) ; } this . imageUrl = imageUrl ; this . rotation = rotation ; loadPicture ( ) ; }", "nl": "method to invoke with a filename or URL of a picture that is to be loaded in the main thread ."}}
{"translation": {"code": "public void loadPictureInThread ( URL imageUrl , int priority , double rotation ) { if ( pictureStatusCode == LOADING ) { stopLoadingExcept ( imageUrl ) ; } this . imageUrl = imageUrl ; this . rotation = rotation ; LoadThread t = new LoadThread ( this ) ; t . setPriority ( priority ) ; t . start ( ) ; }", "nl": "method to invoke with a filename or URL of a picture that is to be loaded a new thread . This is handy to update the screen while the loading chuggs along in the background ."}}
{"translation": {"code": "public void draw ( java . awt . Graphics2D g , AffineTransform pixelAT ) { g . setColor ( color ) ; g . setRenderingHint ( RenderingHints . KEY_ANTIALIASING , RenderingHints . VALUE_ANTIALIAS_OFF ) ; g . setStroke ( new java . awt . BasicStroke ( 0.0f ) ) ; Rectangle2D clipRect = ( Rectangle2D ) g . getClip ( ) ; Iterator siter = getShapes ( g , pixelAT ) ; while ( siter . hasNext ( ) ) { Shape s = ( Shape ) siter . next ( ) ; Rectangle2D shapeBounds = s . getBounds2D ( ) ; if ( shapeBounds . intersects ( clipRect ) ) g . draw ( s ) ; } }", "nl": "Draws all the features that are within the graphics clip rectangle using the previously set displayProjection ."}}
{"translation": {"code": "protected void setEditValue ( Object value ) { if ( value == null ) tf . setText ( \"\" ) ; else tf . setText ( value . toString ( ) ) ; // tf.repaint(); }", "nl": "set current value of editComponent"}}
{"translation": {"code": "public void loadPicture ( ) { Tools . log ( \"SourcePicture.loadPicture: \" + imageUrl . toString ( ) + \" loaded into SourcePicture object: \" + Integer . toString ( this . hashCode ( ) ) ) ; //Tools.freeMem(); setStatus ( LOADING , \"Loading: \" + imageUrl . toString ( ) ) ; abortFlag = false ; try { // Java 1.4 way with a Listener ImageInputStream iis = ImageIO . createImageInputStream ( imageUrl . openStream ( ) ) ; Iterator i = ImageIO . getImageReaders ( iis ) ; if ( ! i . hasNext ( ) ) { throw new IOException ( \"No Readers Available!\" ) ; } reader = ( ImageReader ) i . next ( ) ; // grab the first one reader . addIIOReadProgressListener ( imageProgressListener ) ; reader . setInput ( iis ) ; sourcePictureBufferedImage = null ; // try { sourcePictureBufferedImage = reader . read ( 0 ) ; // just get the first image /* } catch ( OutOfMemoryError e ) {\n\t\t\t\tTools.log(\"SourcePicture caught an OutOfMemoryError while loading an image.\" );\n\n\t\t\t\tiis.close();\n\t\t\t\treader.removeIIOReadProgressListener( imageProgressListener );\n\t\t\t\treader.dispose();\n\n\t\t\t\tsetStatus(ERROR, \"Out of Memory Error while reading \" + imageUrl.toString());\n\t\t\t\tsourcePictureBufferedImage = null; \n\t\t\t\t// PictureCache.clear();\n\n\t\t\t\tJOptionPane.showMessageDialog( null,  //deliberately null or it swaps the window\n\t\t\t\t\t\"outOfMemoryError\",\n\t\t\t\t\t\"genericError\",\n\t\t\t\t\tJOptionPane.ERROR_MESSAGE);\n\n\t\t\t\tSystem.gc();\n\t\t\t\tSystem.runFinalization();\n\n\t\t\t\tTools.log(\"JPO has now run a garbage collection and finalization.\");\n\t\t\t\treturn;\n\t\t\t} */ iis . close ( ) ; reader . removeIIOReadProgressListener ( imageProgressListener ) ; //Tools.log(\"!!dispose being called!!\"); reader . dispose ( ) ; if ( ! abortFlag ) { if ( rotation != 0 ) { setStatus ( ROTATING , \"Rotating: \" + imageUrl . toString ( ) ) ; int xRot = sourcePictureBufferedImage . getWidth ( ) / 2 ; int yRot = sourcePictureBufferedImage . getHeight ( ) / 2 ; AffineTransform rotateAf = AffineTransform . getRotateInstance ( Math . toRadians ( rotation ) , xRot , yRot ) ; AffineTransformOp op = new AffineTransformOp ( rotateAf , AffineTransformOp . TYPE_BILINEAR ) ; Rectangle2D newBounds = op . getBounds2D ( sourcePictureBufferedImage ) ; // a simple AffineTransform would give negative top left coordinates --> // do another transform to get 0,0 as top coordinates again. double minX = newBounds . getMinX ( ) ; double minY = newBounds . getMinY ( ) ; AffineTransform translateAf = AffineTransform . getTranslateInstance ( minX * ( - 1 ) , minY * ( - 1 ) ) ; rotateAf . preConcatenate ( translateAf ) ; op = new AffineTransformOp ( rotateAf , AffineTransformOp . TYPE_BILINEAR ) ; newBounds = op . getBounds2D ( sourcePictureBufferedImage ) ; // this piece of code is so essential!!! Otherwise the internal image format // is totally altered and either the AffineTransformOp decides it doesn't // want to rotate the image or web browsers can't read the resulting image. BufferedImage targetImage = new BufferedImage ( ( int ) newBounds . getWidth ( ) , ( int ) newBounds . getHeight ( ) , BufferedImage . TYPE_3BYTE_BGR ) ; sourcePictureBufferedImage = op . filter ( sourcePictureBufferedImage , targetImage ) ; } setStatus ( READY , \"Loaded: \" + imageUrl . toString ( ) ) ; PictureCache . add ( imageUrl , ( SourcePicture ) this . clone ( ) ) ; } else { setStatus ( ERROR , \"Aborted: \" + imageUrl . toString ( ) ) ; sourcePictureBufferedImage = null ; } } catch ( IOException e ) { setStatus ( ERROR , \"Error while reading \" + imageUrl . toString ( ) ) ; sourcePictureBufferedImage = null ; } }", "nl": "loads a picture from the URL in the imageUrl object into the sourcePictureBufferedImage object and updates the status when done or failed ."}}
{"translation": {"code": "public static void main ( String args [ ] ) { boolean usePopup = false ; for ( int i = 0 ; i < args . length ; i ++ ) { if ( args [ i ] . equals ( \"-usePopup\" ) ) usePopup = true ; } try { store = XMLStore . createFromFile ( \"ThreddsDatasetChooser\" , null ) ; p = store . getPreferences ( ) ; } catch ( IOException e ) { System . out . println ( \"XMLStore Creation failed \" + e ) ; } // put it together in a JFrame final JFrame frame = new JFrame ( \"Thredds Dataset Chooser\" ) ; frame . addWindowListener ( new WindowAdapter ( ) { public void windowClosing ( WindowEvent e ) { chooser . save ( ) ; Rectangle bounds = frame . getBounds ( ) ; p . putBeanObject ( FRAME_SIZE , bounds ) ; try { store . save ( ) ; } catch ( IOException ioe ) { ioe . printStackTrace ( ) ; } System . exit ( 0 ) ; } } ) ; chooser = new ThreddsDatasetChooser ( p , null , frame , true , usePopup , false ) ; chooser . setDoResolve ( true ) ; // frame . getContentPane ( ) . add ( chooser ) ; Rectangle bounds = ( Rectangle ) p . getBean ( FRAME_SIZE , new Rectangle ( 50 , 50 , 800 , 450 ) ) ; frame . setBounds ( bounds ) ; frame . pack ( ) ; frame . setBounds ( bounds ) ; frame . setVisible ( true ) ; }", "nl": "Standalone application ."}}
{"translation": {"code": "public Object findIntersection ( Rectangle2D rect ) { double centerX = rect . getX ( ) + rect . getWidth ( ) / 2 ; double centerY = rect . getY ( ) + rect . getHeight ( ) / 2 ; int indexX = ( int ) ( ( centerX - offsetX ) / gridWidth ) ; int indexY = ( int ) ( ( centerY - offsetY ) / gridHeight ) ; // outside box if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) return null ; // check the surrounding points for ( int y = Math . max ( 0 , indexY - 1 ) ; y <= Math . min ( countY - 1 , indexY + 1 ) ; y ++ ) { for ( int x = Math . max ( 0 , indexX - 1 ) ; x <= Math . min ( countX - 1 , indexX + 1 ) ; x ++ ) { GridCell gtest = gridArray [ y ] [ x ] ; if ( ! gtest . used ) continue ; if ( intersectsOverlap ( rect , gtest . objectBB ) ) // hits an adjacent rectangle return gtest . o ; } } return null ; }", "nl": "Check if the given rect intersects an already drawn object"}}
{"translation": {"code": "public TableRow getSelected ( ) { if ( list . size ( ) == 0 ) return null ; int sel = jtable . getSelectedRow ( ) ; if ( sel >= 0 ) return ( TableRow ) list . get ( sel ) ; else return null ; }", "nl": "Get the currently selected row ."}}
{"translation": {"code": "public void incrSelected ( boolean increment ) { if ( list . size ( ) == 0 ) return ; int curr = jtable . getSelectedRow ( ) ; if ( increment && ( curr < list . size ( ) - 1 ) ) setSelected ( curr + 1 ) ; else if ( ! increment && ( curr > 0 ) ) setSelected ( curr - 1 ) ; }", "nl": "Increment or decrement the current selection by one row ."}}
{"translation": {"code": "public boolean markIfClear ( Rectangle2D rect , Object o ) { double centerX = rect . getX ( ) + rect . getWidth ( ) / 2 ; double centerY = rect . getY ( ) + rect . getHeight ( ) / 2 ; int indexX = ( int ) ( ( centerX - offsetX ) / gridWidth ) ; int indexY = ( int ) ( ( centerY - offsetY ) / gridHeight ) ; if ( debugMark ) System . out . println ( \"markIfClear \" + rect + \" \" + indexX + \" \" + indexY ) ; if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) // outside box return false ; GridCell gwant = gridArray [ indexY ] [ indexX ] ; if ( gwant . used ) // already taken return false ; if ( null != findIntersection ( rect ) ) return false ; // its ok to use gwant . used = true ; gwant . objectBB = rect ; gwant . o = o ; return true ; }", "nl": "Check if the given rect intersects an already drawn one . If not set the corresponding cell as marked store object return true meaning ok to draw ."}}
{"translation": {"code": "public Object findIntersection ( Point2D p ) { int indexX = ( int ) ( ( p . getX ( ) - offsetX ) / gridWidth ) ; int indexY = ( int ) ( ( p . getY ( ) - offsetY ) / gridHeight ) ; // outside box if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) return null ; // check the surrounding points for ( int y = Math . max ( 0 , indexY - 1 ) ; y <= Math . min ( countY - 1 , indexY + 1 ) ; y ++ ) { for ( int x = Math . max ( 0 , indexX - 1 ) ; x <= Math . min ( countX - 1 , indexX + 1 ) ; x ++ ) { GridCell gtest = gridArray [ y ] [ x ] ; if ( ! gtest . used ) continue ; if ( gtest . objectBB . contains ( p . getX ( ) , p . getY ( ) ) ) return gtest . o ; } } return null ; }", "nl": "Check if the given point is contained in already drawn object"}}
{"translation": {"code": "public void setCatalog ( Catalog catalog ) { if ( catalog == null ) return ; String catalogName = catalog . getBaseURI ( ) . toString ( ) ; this . catalog = catalog ; // send catalog event setCatalogURL ( catalogName ) ; // display tree // this sends TreeNode events model = new InvCatalogTreeModel ( catalog ) ; tree . setModel ( model ) ; // debug if ( debugTree ) { System . out . println ( \"*** catalog/showJTree =\" ) ; showNode ( tree . getModel ( ) , tree . getModel ( ) . getRoot ( ) ) ; System . out . println ( \"*** \" ) ; } // look for a specific dataset int pos = catalogName . indexOf ( ' ' ) ; if ( pos >= 0 ) { String id = catalogName . substring ( pos + 1 ) ; Dataset dataset = catalog . findDatasetByID ( id ) ; if ( dataset != null ) { setSelectedDataset ( dataset ) ; firePropertyChangeEvent ( new PropertyChangeEvent ( this , \"Selection\" , null , dataset ) ) ; } } // send catalog event firePropertyChangeEvent ( new PropertyChangeEvent ( this , \"Catalog\" , null , catalogName ) ) ; }", "nl": "Set the catalog to be displayed . If ok then a Catalog PropertyChangeEvent is sent ."}}
{"translation": {"code": "public Object findClosest ( Point2D pt ) { Object o = null ; int indexX = ( int ) ( ( pt . getX ( ) - offsetX ) / gridWidth ) ; int indexY = ( int ) ( ( pt . getY ( ) - offsetY ) / gridHeight ) ; if ( debugClosest ) System . out . println ( \"findClosest \" + pt + \" \" + indexX + \" \" + indexY ) ; if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) // outside box return null ; GridCell gwant = gridArray [ indexY ] [ indexX ] ; if ( gwant . used ) // that was easy return gwant . o ; // check the surrounding points along perimeter of increasing diameter for ( int p = 1 ; p < Math . max ( countX - 1 , countY - 1 ) ; p ++ ) if ( null != ( o = findClosestAlongPerimeter ( pt , indexX , indexY , p ) ) ) return o ; return null ; // nothing found }", "nl": "Find the closest marked cell to the given point"}}
{"translation": {"code": "public void start ( java . awt . Component top , String taskName , int progressMaxCount ) { // create ProgressMonitor pm = new javax . swing . ProgressMonitor ( top , taskName , \"\" , 0 , progressMaxCount ) ; pm . setMillisToDecideToPopup ( millisToDecideToPopup ) ; pm . setMillisToPopup ( millisToPopup ) ; // do task in a seperate, non-event, thread taskThread = new Thread ( task ) ; taskThread . start ( ) ; // create timer, whose events happen on the awt event Thread ActionListener watcher = new ActionListener ( ) { public void actionPerformed ( ActionEvent evt ) { secs ++ ; if ( pm . isCanceled ( ) ) { task . cancel ( ) ; } else { // indicate progress String note = task . getNote ( ) ; pm . setNote ( note == null ? secs + \" secs\" : note ) ; int progress = task . getProgress ( ) ; pm . setProgress ( progress <= 0 ? secs : progress ) ; } // need to make sure task acknowledges the cancel; so dont shut down // until the task is done if ( task . isDone ( ) ) { timer . stop ( ) ; pm . close ( ) ; // Toolkit.getDefaultToolkit().beep(); if ( task . isError ( ) ) { javax . swing . JOptionPane . showMessageDialog ( null , task . getErrorMessage ( ) ) ; } if ( task . isSuccess ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"success\" ) ) ; else if ( task . isError ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"error\" ) ) ; else if ( task . isCancel ( ) ) fireEvent ( new ActionEvent ( this , 0 , \"cancel\" ) ) ; else fireEvent ( new ActionEvent ( this , 0 , \"done\" ) ) ; } } } ; timer = new javax . swing . Timer ( 1000 , watcher ) ; // every second timer . start ( ) ; }", "nl": "Call this from awt event thread . The task is run in a background thread ."}}
{"translation": {"code": "public void clear ( ) { for ( int y = 0 ; y < countY ; y ++ ) for ( int x = 0 ; x < countX ; x ++ ) gridArray [ y ] [ x ] . used = false ; }", "nl": "clear all the grid cells"}}
{"translation": {"code": "public void setOverlap ( int overlap ) { // overlap limited to [0, 50%] double dover = Math . max ( 0.0 , Math . min ( .01 * overlap , .50 ) ) ; scaleOverlap = 1.0 - dover ; }", "nl": "Set how much the data may overlap ."}}
{"translation": {"code": "public void setList ( ArrayList rowList ) { this . list = rowList ; if ( list . size ( ) > 0 ) jtable . setRowSelectionInterval ( 0 , 0 ) ; else jtable . clearSelection ( ) ; model . sort ( ) ; jtable . revalidate ( ) ; }", "nl": "Replace the rowList with this one ."}}
{"translation": {"code": "private double distanceSq ( Point2D pt , int indexX , int indexY ) { if ( ( indexX < 0 ) || ( indexX >= countX ) || ( indexY < 0 ) || ( indexY >= countY ) ) // outside bounding box return MAX_DOUBLE ; GridCell gtest = gridArray [ indexY ] [ indexX ] ; if ( ! gtest . used ) // nothing in this cell return MAX_DOUBLE ; // get distance from center of cell Rectangle2D rect = gtest . objectBB ; double dx = rect . getX ( ) + rect . getWidth ( ) / 2 - pt . getX ( ) ; double dy = rect . getY ( ) + rect . getHeight ( ) / 2 - pt . getY ( ) ; return ( dx * dx + dy * dy ) ; }", "nl": "if out of bbox or cell not marked return MAX_DOUBLE"}}
{"translation": {"code": "public CoordinateAxis findAxis ( AxisType type ) { CoordinateAxis result = null ; for ( CoordinateAxis axis : coordAxes ) { AxisType axisType = axis . getAxisType ( ) ; if ( ( axisType != null ) && ( axisType == type ) ) result = lesserRank ( result , axis ) ; } return result ; }", "nl": "Find the CoordinateAxis that has the given AxisType . If more than one return the one with lesser rank ."}}
{"translation": {"code": "private void newScreenSize ( Rectangle b ) { boolean sameSize = ( b . width == myBounds . width ) && ( b . height == myBounds . height ) ; if ( debugBounds ) System . out . println ( \"NavigatedPanel newScreenSize old= \" + myBounds ) ; if ( sameSize && ( b . x == myBounds . x ) && ( b . y == myBounds . y ) ) return ; myBounds . setBounds ( b ) ; if ( sameSize ) return ; if ( debugBounds ) System . out . println ( \"  newBounds = \" + b ) ; // create new buffer the size of the window //if (bImage != null) //  bImage.dispose(); if ( ( b . width > 0 ) && ( b . height > 0 ) ) { bImage = new BufferedImage ( b . width , b . height , BufferedImage . TYPE_INT_RGB ) ; // why RGB ? } else { // why not device dependent? bImage = null ; } navigate . setScreenSize ( b . width , b . height ) ; }", "nl": "when component resizes we need a new buffer"}}
{"translation": {"code": "public void setStructureData ( List < StructureData > structureData ) throws IOException { dataModel = new StructureDataModel ( structureData ) ; initTable ( dataModel ) ; }", "nl": "Set the data as a collection of StructureData ."}}
{"translation": {"code": "public void stretch ( Point p ) { lastPt . x = stretchedPt . x ; lastPt . y = stretchedPt . y ; stretchedPt . x = p . x ; stretchedPt . y = p . y ; Graphics2D g = ( Graphics2D ) component . getGraphics ( ) ; if ( g != null ) { try { g . setXORMode ( component . getBackground ( ) ) ; if ( firstStretch == true ) firstStretch = false ; else drawLast ( g ) ; drawNext ( g ) ; } finally { g . dispose ( ) ; } // try } // if }", "nl": "Erase the last rectangle and draw a new one from the anchor point to this point ."}}
{"translation": {"code": "public Rectangle getBounds ( ) { return new Rectangle ( stretchedPt . x < anchorPt . x ? stretchedPt . x : anchorPt . x , stretchedPt . y < anchorPt . y ? stretchedPt . y : anchorPt . y , Math . abs ( stretchedPt . x - anchorPt . x ) , Math . abs ( stretchedPt . y - anchorPt . y ) ) ; }", "nl": "Get current Bounds"}}
{"translation": {"code": "private void redrawLater ( int delay ) { boolean already = ( redrawTimer != null ) && ( redrawTimer . isRunning ( ) ) ; if ( debugThread ) System . out . println ( \"redrawLater isRunning= \" + already ) ; if ( already ) return ; // initialize Timer the first time if ( redrawTimer == null ) { redrawTimer = new javax . swing . Timer ( 0 , new ActionListener ( ) { public void actionPerformed ( ActionEvent e ) { drawG ( ) ; redrawTimer . stop ( ) ; // one-shot timer } } ) ; } // start the timer running redrawTimer . setDelay ( delay ) ; redrawTimer . start ( ) ; }", "nl": "from panning so wait delay msecs before doing the redraw ."}}
{"translation": {"code": "public void pan ( double deltax , double deltay ) { zoom . push ( ) ; pix_x0 -= deltax ; pix_y0 -= deltay ; fireMapAreaEvent ( ) ; }", "nl": "call this to change the center of the screen s world coordinates . deltax deltay in display coordinates"}}
{"translation": {"code": "public Rectangle lastBounds ( ) { return new Rectangle ( lastPt . x < anchorPt . x ? lastPt . x : anchorPt . x , lastPt . y < anchorPt . y ? lastPt . y : anchorPt . y , Math . abs ( lastPt . x - anchorPt . x ) , Math . abs ( lastPt . y - anchorPt . y ) ) ; }", "nl": "Get previous Bounds"}}
{"translation": {"code": "public ProjectionRect getMapArea ( ProjectionRect rect ) { if ( rect == null ) rect = new ProjectionRect ( ) ; double width = pwidth / pix_per_world ; double height = pheight / pix_per_world ; // center point double wx0 = ( pwidth / 2 - pix_x0 ) / pix_per_world ; double wy0 = ( pix_y0 - pheight / 2 ) / pix_per_world ; rect . setRect ( wx0 - width / 2 , wy0 - height / 2 , // minx, miny width , height ) ; // width, height return rect ; }", "nl": "Get current MapArea ."}}
{"translation": {"code": "public boolean anchor ( Point p ) { firstStretch = true ; anchorPt . x = p . x ; anchorPt . y = p . y ; stretchedPt . x = lastPt . x = anchorPt . x ; stretchedPt . y = lastPt . y = anchorPt . y ; return true ; }", "nl": "Set the anchor point ."}}
{"translation": {"code": "void fireMapAreaEvent ( ) { if ( debugZoom ) System . out . println ( \"NP.fireMapAreaEvent \" ) ; // decide if we need a new Projection: for LatLonProjection only if ( project . isLatLon ( ) ) { LatLonProjection llproj = ( LatLonProjection ) project ; ProjectionRect box = getMapArea ( ) ; double center = llproj . getCenterLon ( ) ; double lonBeg = LatLonPointImpl . lonNormal ( box . getMinX ( ) , center ) ; double lonEnd = lonBeg + box . getMaxX ( ) - box . getMinX ( ) ; boolean showShift = Debug . isSet ( \"projection/LatLonShift\" ) || debugNewProjection ; if ( showShift ) System . out . println ( \"projection/LatLonShift: min,max = \" + box . getMinX ( ) + \" \" + box . getMaxX ( ) + \" beg,end= \" + lonBeg + \" \" + lonEnd + \" center = \" + center ) ; if ( ( lonBeg < center - 180 ) || ( lonEnd > center + 180 ) ) { // got to do it double wx0 = box . getX ( ) + box . getWidth ( ) / 2 ; llproj . setCenterLon ( wx0 ) ; // shift cylinder seam double newWx0 = llproj . getCenterLon ( ) ; // normalize wx0 to [-180,180] setWorldCenterX ( newWx0 ) ; // tell navigation panel to shift if ( showShift ) System . out . println ( \"projection/LatLonShift: shift center to \" + wx0 + \"->\" + newWx0 ) ; // send projection event instead of map area event lmProject . sendEvent ( new NewProjectionEvent ( this , llproj ) ) ; return ; } } // send new map area event lmMapArea . sendEvent ( new NewMapAreaEvent ( this , getMapArea ( ) ) ) ; }", "nl": "called by Navigation"}}
{"translation": {"code": "public void setMapArea ( LatLonRect llbb ) { if ( debugBB ) System . out . println ( \"NP.setMapArea (ll) \" + llbb ) ; navigate . setMapArea ( project . latLonToProjBB ( llbb ) ) ; }", "nl": "Set the Map Area by converting LatLonRect to a ProjectionRect ."}}
{"translation": {"code": "public void setLatLonCenterMapArea ( double lat , double lon ) { ProjectionPoint center = project . latLonToProj ( lat , lon ) ; ProjectionRect ma = getMapArea ( ) ; ma . setX ( center . getX ( ) - ma . getWidth ( ) / 2 ) ; ma . setY ( center . getY ( ) - ma . getHeight ( ) / 2 ) ; setMapArea ( ma ) ; }", "nl": "set the center point of the MapArea"}}
{"translation": {"code": "public void setProjectionImpl ( ProjectionImpl p ) { // transfer selection region to new coord system if ( geoSelection != null ) { LatLonRect geoLL = project . projToLatLonBB ( geoSelection ) ; setGeoSelection ( p . latLonToProjBB ( geoLL ) ) ; } // switch projections project = p ; navigate . setMapArea ( project . getDefaultMapArea ( ) ) ; if ( Debug . isSet ( \"projection/set\" ) || debugNewProjection ) System . out . println ( \"projection/set NP=\" + project ) ; // transfer reference point to new coord system if ( hasReference ) { refWorld . setLocation ( project . latLonToProj ( refLatLon ) ) ; } }", "nl": "Set the Projection change the Map Area to the projection s default ."}}
{"translation": {"code": "private void recalcFromBoundingBox ( ) { if ( debugRecalc ) { System . out . println ( \"Navigation recalcFromBoundingBox= \" + bb ) ; System . out . println ( \"  \" + pwidth + \" \" + pheight ) ; } // decide which dimension is limiting double pixx_per_wx = ( bb . getWidth ( ) == 0.0 ) ? 1 : pwidth / bb . getWidth ( ) ; double pixy_per_wy = ( bb . getHeight ( ) == 0.0 ) ? 1 : pheight / bb . getHeight ( ) ; pix_per_world = Math . min ( pixx_per_wx , pixy_per_wy ) ; // calc the center point double wx0 = bb . getX ( ) + bb . getWidth ( ) / 2 ; double wy0 = bb . getY ( ) + bb . getHeight ( ) / 2 ; // calc offset based on center point pix_x0 = pwidth / 2 - pix_per_world * wx0 ; pix_y0 = pheight / 2 + pix_per_world * wy0 ; if ( debugRecalc ) { System . out . println ( \"Navigation recalcFromBoundingBox done= \" + pix_per_world + \" \" + pix_x0 + \" \" + pix_y0 ) ; System . out . println ( \"  \" + pwidth + \" \" + pheight + \" \" + bb ) ; } }", "nl": "adjust bounding box to fit inside the screen size"}}
{"translation": {"code": "public void addActionsToMenu ( JMenu menu ) { BAMutil . addActionToMenu ( menu , zoomIn ) ; BAMutil . addActionToMenu ( menu , zoomOut ) ; BAMutil . addActionToMenu ( menu , zoomBack ) ; BAMutil . addActionToMenu ( menu , zoomDefault ) ; menu . addSeparator ( ) ; BAMutil . addActionToMenu ( menu , moveUp ) ; BAMutil . addActionToMenu ( menu , moveDown ) ; BAMutil . addActionToMenu ( menu , moveRight ) ; BAMutil . addActionToMenu ( menu , moveLeft ) ; menu . addSeparator ( ) ; BAMutil . addActionToMenu ( menu , setReferenceAction ) ; }", "nl": "Add all of the toolbar s actions to a menu ."}}
{"translation": {"code": "public Point2D worldToScreen ( ProjectionPointImpl w , Point2D p ) { p . setLocation ( pix_per_world * w . getX ( ) + pix_x0 , - pix_per_world * w . getY ( ) + pix_y0 ) ; return p ; }", "nl": "convert a world coordinate to a display point"}}
{"translation": {"code": "public void zoom ( double startx , double starty , double width , double height ) { if ( debugZoom ) System . out . println ( \"zoom \" + startx + \" \" + starty + \" \" + width + \" \" + height + \" \" ) ; if ( ( width < 5 ) || ( height < 5 ) ) return ; zoom . push ( ) ; pix_x0 -= startx + width / 2 - pwidth / 2 ; pix_y0 -= starty + height / 2 - pheight / 2 ; zoom ( pwidth / width ) ; }", "nl": "call this to zoom into a subset of the screen . startx starty are the upper left corner of the box in display coords width height the size of the box in display coords"}}
{"translation": {"code": "public void setMapArea ( ProjectionRect ma ) { if ( debugBB ) System . out . println ( \"NP.setMapArea \" + ma ) ; navigate . setMapArea ( ma ) ; }", "nl": "Set the Map Area ."}}
{"translation": {"code": "public boolean wantRotate ( double displayWidth , double displayHeight ) { getMapArea ( bb ) ; // current world bounding box boolean aspectDisplay = displayHeight < displayWidth ; boolean aspectWorldBB = bb . getHeight ( ) < bb . getWidth ( ) ; return ( aspectDisplay ^ aspectWorldBB ) ; // aspects are different }", "nl": "calculate if we want to rotate based on aspect ratio"}}
{"translation": {"code": "public AffineTransform getTransform ( ) { at . setTransform ( pix_per_world , 0.0 , 0.0 , - pix_per_world , pix_x0 , pix_y0 ) ; if ( debug ) { System . out . println ( \"Navigation getTransform = \" + pix_per_world + \" \" + pix_x0 + \" \" + pix_y0 ) ; System . out . println ( \"  transform = \" + at ) ; } return at ; }", "nl": "Get the affine transform based on screen size and world bounding box"}}
{"translation": {"code": "public double getValue ( ) { if ( ! ( uu instanceof ScaledUnit ) ) return Double . NaN ; ScaledUnit offset = ( ScaledUnit ) uu ; return offset . getScale ( ) ; }", "nl": "Extract the value can only be called for ScaledUnit ."}}
{"translation": {"code": "public double convertTo ( double value , SimpleUnit outputUnit ) throws IllegalArgumentException { try { return uu . convertTo ( value , outputUnit . getUnit ( ) ) ; } catch ( ConversionException e ) { throw new IllegalArgumentException ( e . getMessage ( ) ) ; } }", "nl": "Convert given value of this unit to the new unit ."}}
{"translation": {"code": "static public double getConversionFactor ( String inputUnitString , String outputUnitString ) throws IllegalArgumentException { SimpleUnit inputUnit = SimpleUnit . factory ( inputUnitString ) ; SimpleUnit outputUnit = SimpleUnit . factory ( outputUnitString ) ; return inputUnit . convertTo ( 1.0 , outputUnit ) ; }", "nl": "Get the conversion factor to convert inputUnit to outputUnit ."}}
{"translation": {"code": "static public boolean isTimeUnit ( String unitString ) { SimpleUnit su = factory ( unitString ) ; return su != null && isTimeUnit ( su . getUnit ( ) ) ; }", "nl": "Return true if the given unit is a time Unit eg seconds ."}}
{"translation": {"code": "static public boolean isDateUnit ( ucar . units . Unit uu ) { boolean ok = uu . isCompatible ( dateReferenceUnit ) ; if ( ! ok ) return false ; try { uu . getConverterTo ( dateReferenceUnit ) ; return true ; } catch ( ConversionException e ) { return false ; } }", "nl": "Return true if this ucar . units . Unit is a Date ."}}
{"translation": {"code": "public Date add ( Date d ) { Calendar cal = Calendar . getInstance ( ) ; cal . setTime ( d ) ; cal . add ( Calendar . SECOND , ( int ) getValueInSeconds ( ) ) ; return cal . getTime ( ) ; }", "nl": "Add the time amount to the given Date return a new Date ."}}
{"translation": {"code": "static public SimpleUnit factory ( String name ) { try { return factoryWithExceptions ( name ) ; } catch ( Exception e ) { if ( debugParse ) System . out . println ( \"Parse \" + name + \" got Exception \" + e ) ; return null ; } }", "nl": "Create a SimpleUnit from the given name catch Exceptions ."}}
{"translation": {"code": "static public SimpleUnit factoryWithExceptions ( String name ) throws UnitException { UnitFormat format = UnitFormatManager . instance ( ) ; Unit uu = format . parse ( name ) ; //if (isDateUnit(uu)) return new DateUnit(name); if ( isTimeUnit ( uu ) ) return new TimeUnit ( name ) ; return new SimpleUnit ( uu ) ; }", "nl": "Create a SimpleUnit from the given name allow Exceptions ."}}
{"translation": {"code": "static protected Unit makeUnit ( String name ) throws UnitException { UnitFormat format = UnitFormatManager . instance ( ) ; return format . parse ( name ) ; }", "nl": "need subclass access"}}
{"translation": {"code": "static public boolean isCompatibleWithExceptions ( String unitString1 , String unitString2 ) throws UnitException { UnitFormat format = UnitFormatManager . instance ( ) ; Unit uu1 = format . parse ( unitString1 ) ; Unit uu2 = format . parse ( unitString2 ) ; return uu1 . isCompatible ( uu2 ) ; }", "nl": "Return true if unitString1 is convertible to unitString2"}}
{"translation": {"code": "public float getAzimuth ( ) { if ( message_type != 1 ) return - 1.0f ; if ( Cinrad2IOServiceProvider . isSC ) return 360.0f * azimuth_ang / 65536.0f ; else if ( Cinrad2IOServiceProvider . isCC ) return 360.0f * azimuth_ang / 512.0f ; else if ( Cinrad2IOServiceProvider . isCC20 ) return azimuth_ang * 0.01f ; return 180.0f * azimuth_ang / 32768.0f ; }", "nl": "Get the azimuth in degrees"}}
{"translation": {"code": "public float getElevation ( ) { if ( message_type != 1 ) return - 1.0f ; if ( Cinrad2IOServiceProvider . isSC ) return 120.0f * elevation_ang / 65536.0f ; else if ( Cinrad2IOServiceProvider . isCC ) return elevation_ang * 0.01f ; else if ( Cinrad2IOServiceProvider . isCC20 ) return elevation_ang * 0.01f ; return 180.0f * elevation_ang / 32768.0f ; }", "nl": "Get the elevation angle in degrees"}}
{"translation": {"code": "public boolean accept ( CrawlableDataset dataset ) { Date lastModDate = dataset . lastModified ( ) ; if ( lastModDate != null ) { long now = System . currentTimeMillis ( ) ; if ( now - lastModDate . getTime ( ) > lastModifiedLimitInMillis ) return true ; } return false ; }", "nl": "Accept datasets whose last modified date is at least the last modified limit of milliseconds in the past ."}}
{"translation": {"code": "public void removeLayoutComponent ( Component comp ) { if ( debug ) System . out . println ( \"removeLayoutComponent\" ) ; constraintMap . remove ( comp ) ; globalBounds = null ; }", "nl": "Removes the specified component from the layout ."}}
{"translation": {"code": "public Field . CheckBox addCheckBoxField ( String fldName , String label , boolean defValue ) { Field . CheckBox fld = new Field . CheckBox ( fldName , label , defValue , storeData ) ; addField ( fld ) ; return fld ; }", "nl": "Add a boolean field as a checkbox ."}}
{"translation": {"code": "static public void constructMenu ( JMenu topMenu ) { if ( debug ) System . out . println ( \"Debug.constructMenu \" ) ; if ( topMenu . getItemCount ( ) > 0 ) topMenu . removeAll ( ) ; try { addToMenu ( topMenu , store ) ; // recursive } catch ( BackingStoreException e ) { } topMenu . revalidate ( ) ; }", "nl": "Construct cascading pull - aside menus using the values of the debug flags in the Preferences object ."}}
{"translation": {"code": "static public boolean isSet ( String flagName ) { if ( store == null ) return false ; NamePart np = partit ( flagName ) ; if ( debug ) { try { if ( ( np . storeName . length ( ) > 0 ) && ! store . nodeExists ( np . storeName ) ) System . out . println ( \"Debug.isSet create node = \" + flagName + \" \" + np ) ; else if ( null == store . node ( np . storeName ) . get ( np . keyName , null ) ) System . out . println ( \"Debug.isSet create flag = \" + flagName + \" \" + np ) ; } catch ( BackingStoreException e ) { } } // add it if it doesnt already exist boolean value = store . node ( np . storeName ) . getBoolean ( np . keyName , false ) ; store . node ( np . storeName ) . putBoolean ( np . keyName , value ) ; return value ; }", "nl": "Return the value of the named flag . If it doesnt exist it will be added to the store and the menu with a value of false ."}}
{"translation": {"code": "protected void restoreState ( ) { if ( store == null ) { return ; } ArrayList propColObjs = ( ArrayList ) store . getBean ( \"propertyCol\" , new ArrayList ( ) ) ; HidableTableColumnModel tableColumnModel = ( HidableTableColumnModel ) jtable . getColumnModel ( ) ; int newViewIndex = 0 ; for ( Object propColObj : propColObjs ) { PropertyCol propCol = ( PropertyCol ) propColObj ; try { int currentViewIndex = tableColumnModel . getColumnIndex ( propCol . getName ( ) ) ; // May throw IAE. TableColumn column = tableColumnModel . getColumn ( currentViewIndex ) ; column . setPreferredWidth ( propCol . getWidth ( ) ) ; tableColumnModel . moveColumn ( currentViewIndex , newViewIndex ) ; assert tableColumnModel . getColumn ( newViewIndex ) == column : \"tableColumn wasn't successfully moved.\" ; // We must do this last, since moveColumn() only works on visible columns. tableColumnModel . setColumnVisible ( column , propCol . isVisible ( ) ) ; if ( propCol . isVisible ( ) ) { ++ newViewIndex ; // Don't increment for hidden columns. } } catch ( IllegalArgumentException e ) { logger . debug ( String . format ( \"Column named \\\"%s\\\" was present in the preferences file but not the dataset.\" , propCol . getName ( ) ) , e ) ; } } }", "nl": "Restore state from PreferencesExt"}}
{"translation": {"code": "public ArrayList < Object > getSelectedCells ( ) { ArrayList < Object > list = new ArrayList <> ( ) ; int [ ] viewRowIndices = jtable . getSelectedRows ( ) ; int [ ] viewColumnIndices = jtable . getSelectedColumns ( ) ; for ( int i = 0 ; i < viewRowIndices . length ; i ++ ) for ( int j = 0 ; i < viewColumnIndices . length ; j ++ ) { int modelRowIndex = jtable . convertRowIndexToModel ( viewRowIndices [ i ] ) ; int modelColumnIndex = jtable . convertColumnIndexToModel ( viewColumnIndices [ j ] ) ; list . add ( model . getValueAt ( modelRowIndex , modelColumnIndex ) ) ; } return list ; }", "nl": "Get the currently selected cells . Use this for multiple row selection when columnSelection is on"}}
{"translation": {"code": "public List getSelectedBeans ( ) { ArrayList < Object > list = new ArrayList <> ( ) ; int [ ] viewRowIndices = jtable . getSelectedRows ( ) ; for ( int viewRowIndex : viewRowIndices ) { int modelRowIndex = jtable . convertRowIndexToModel ( viewRowIndex ) ; list . add ( beans . get ( modelRowIndex ) ) ; if ( debugSelected ) System . out . println ( \" bean selected= \" + modelRowIndex + \" \" + beans . get ( modelRowIndex ) ) ; } return list ; }", "nl": "Get the currently selected beans . Use this for multiple selection"}}
{"translation": {"code": "public Object getSelectedBean ( ) { int viewRowIndex = jtable . getSelectedRow ( ) ; if ( viewRowIndex < 0 ) return null ; int modelRowIndex = jtable . convertRowIndexToModel ( viewRowIndex ) ; return ( modelRowIndex < 0 ) || ( modelRowIndex >= beans . size ( ) ) ? null : beans . get ( modelRowIndex ) ; }", "nl": "Get the currently selected bean or null if none selected ."}}
{"translation": {"code": "public Field addField ( Field fld ) { addField ( fld , cursorCol , cursorRow , null ) ; cursorRow ++ ; return fld ; }", "nl": "Add a field created by the user ."}}
{"translation": {"code": "public void setFieldValue ( String name , Object value ) { Field fld = getField ( name ) ; if ( fld == null ) throw new IllegalArgumentException ( \"no field named \" + name ) ; fld . setValue ( value ) ; }", "nl": "Set the current value of the named field"}}
{"translation": {"code": "public Object getFieldValue ( String name ) { Field fld = getField ( name ) ; if ( fld == null ) throw new IllegalArgumentException ( \"no field named \" + name ) ; return fld . getValue ( ) ; }", "nl": "Get current value of the named field"}}
{"translation": {"code": "public Field getField ( String name ) { Field fld = flds . get ( name ) ; if ( fld == null ) return null ; return ( fld instanceof FieldResizable ) ? ( ( FieldResizable ) fld ) . getDelegate ( ) : fld ; }", "nl": "Find the field with the specified name ."}}
{"translation": {"code": "static private void addToMenu ( JMenu menu , Preferences prefs ) throws BackingStoreException { if ( debug ) System . out . println ( \" addMenu \" + prefs . name ( ) ) ; String [ ] keys = prefs . keys ( ) ; for ( String key : keys ) { boolean bval = prefs . getBoolean ( key , false ) ; String fullname = prefs . absolutePath ( ) + \"/\" + key ; menu . add ( new DebugMenuItem ( fullname , key , bval ) ) ; // menu leaf if ( debug ) System . out . println ( \"   leaf= <\" + key + \"><\" + fullname + \">\" ) ; } String [ ] kidName = prefs . childrenNames ( ) ; for ( String aKidName : kidName ) { Preferences pkid = prefs . node ( aKidName ) ; JMenu subMenu = new JMenu ( pkid . name ( ) ) ; menu . add ( subMenu ) ; addToMenu ( subMenu , pkid ) ; } }", "nl": "recursive menu adding"}}
{"translation": {"code": "public void setSelectedBean ( Object bean ) { if ( bean == null ) return ; int modelRowIndex = beans . indexOf ( bean ) ; int viewRowIndex = jtable . convertRowIndexToView ( modelRowIndex ) ; if ( viewRowIndex >= 0 ) jtable . getSelectionModel ( ) . setSelectionInterval ( viewRowIndex , viewRowIndex ) ; makeRowVisible ( viewRowIndex ) ; }", "nl": "Set which row is selected ."}}
{"translation": {"code": "public Field . Int addIntField ( String fldName , String label , int defValue ) { Field . Int fld = new Field . Int ( fldName , label , defValue , storeData ) ; addField ( new FieldResizable ( fld , this ) ) ; return fld ; }", "nl": "Add a field that edits an integer"}}
{"translation": {"code": "static public Frame findActiveFrame ( ) { Frame [ ] frames = JFrame . getFrames ( ) ; for ( Frame frame : frames ) { if ( frame . isVisible ( ) ) return frame ; } return null ; }", "nl": "thanks to Heinz M . Kabutz"}}
{"translation": {"code": "public void addEmptyRow ( int row , int size ) { layoutComponents . add ( new LayoutComponent ( null , size , row , null ) ) ; }", "nl": "Add a seperator after the last field added ."}}
{"translation": {"code": "public void addComponent ( Component comp , int col , int row , String constraint ) { layoutComponents . add ( new LayoutComponent ( comp , col , row , constraint ) ) ; }", "nl": "Add a Component ."}}
{"translation": {"code": "public void addHeading ( String heading , int row ) { layoutComponents . add ( new LayoutComponent ( heading , 0 , row , null ) ) ; }", "nl": "Add a heading at the specified row . this spans all columns"}}
{"translation": {"code": "public Field . TextArea addTextAreaField ( String fldName , String label , String def , int nrows ) { Field . TextArea fld = new Field . TextArea ( fldName , label , def , nrows , storeData ) ; addField ( fld ) ; return fld ; }", "nl": "Add a TextArea field ."}}
{"translation": {"code": "public Field . TextCombo addTextComboField ( String fldName , String label , java . util . Collection defValues , int nKeep , boolean editable ) { Field . TextCombo fld = new Field . TextCombo ( fldName , label , defValues , nKeep , storeData ) ; addField ( fld ) ; fld . setEditable ( editable ) ; return fld ; }", "nl": "Add a text combobox field ."}}
{"translation": {"code": "public Field . Text addTextField ( String fldName , String label , String defValue ) { Field . Text fld = new Field . Text ( fldName , label , defValue , storeData ) ; addField ( new FieldResizable ( fld , this ) ) ; return fld ; }", "nl": "Add a text field ."}}
{"translation": {"code": "public Field . Password addPasswordField ( String fldName , String label , String defValue ) { Field . Password fld = new Field . Password ( fldName , label , defValue , storeData ) ; addField ( new FieldResizable ( fld , this ) ) ; return fld ; }", "nl": "Add a password text field ."}}
{"translation": {"code": "public Field . Double addDoubleField ( String fldName , String label , double defValue ) { Field . Double fld = new Field . Double ( fldName , label , defValue , - 1 , storeData ) ; addField ( new FieldResizable ( fld , this ) ) ; return fld ; }", "nl": "Add a field that edits a double"}}
{"translation": {"code": "public Field . Date addDateField ( String fldName , String label , Date defValue ) { Field . Date fld = new Field . Date ( fldName , label , defValue , storeData ) ; addField ( new FieldResizable ( fld , this ) ) ; return fld ; }", "nl": "Add a field that edits a date"}}
{"translation": {"code": "public Dimension minimumLayoutSize ( Container parent ) { if ( debug ) System . out . println ( \"minimumLayoutSize\" ) ; if ( globalBounds == null ) layoutContainer ( parent ) ; return globalBounds . getSize ( ) ; }", "nl": "Calculates the minimum size dimensions for the specified container given the components it contains ."}}
{"translation": {"code": "public void layoutContainer ( Container target ) { synchronized ( target . getTreeLock ( ) ) { if ( debug ) System . out . println ( name + \" layoutContainer \" ) ; // first layout any nested LayoutM components // it seems that generally Swing laysout from outer to inner ??? int n = target . getComponentCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { Component comp = target . getComponent ( i ) ; if ( comp instanceof Container ) { Container c = ( Container ) comp ; LayoutManager m = c . getLayout ( ) ; if ( m instanceof LayoutM ) m . layoutContainer ( c ) ; } } // now layout this container reset ( target ) ; globalBounds = new Rectangle ( 0 , 0 , 0 , 0 ) ; while ( ! layoutPass ( target ) ) target . setPreferredSize ( globalBounds . getSize ( ) ) ; // ?? } }", "nl": "Lays out the specified container ."}}
{"translation": {"code": "public void addLayoutComponent ( Component comp , Object constraint ) { if ( debug ) System . out . println ( name + \" addLayoutComponent= \" + comp . getClass ( ) . getName ( ) + \" \" + comp . hashCode ( ) + \" \" + constraint ) ; if ( ! ( constraint instanceof Constraint ) ) throw new IllegalArgumentException ( \"MySpringLayout must be Constraint\" ) ; constraintMap . put ( comp , constraint ) ; globalBounds = null ; }", "nl": "Adds the specified component to the layout using the specified constraint object ."}}
{"translation": {"code": "public void invalidateLayout ( Container target ) { if ( debug ) System . out . println ( name + \" invalidateLayout \" ) ; globalBounds = null ; // this probably need to be scheduled later ?? // layoutContainer( target); }", "nl": "Invalidates the layout indicating that if the layout manager has cached information it should be discarded ."}}
{"translation": {"code": "public DataIterator getDataIterator ( ucar . unidata . geoloc . Station s , Date start , Date end ) throws IOException { return new StationDateDataIterator ( s , start , end ) ; }", "nl": "Get data for this Station within the specified date range ."}}
{"translation": {"code": "public DataIterator getDataIterator ( ucar . unidata . geoloc . Station s ) throws IOException { return new StationDataIterator ( s ) ; }", "nl": "Get all data for this Station ."}}
{"translation": {"code": "public List getStations ( ucar . unidata . geoloc . LatLonRect boundingBox ) throws IOException { return typical . getStations ( boundingBox ) ; }", "nl": "Get all the Stations within a bounding box ."}}
{"translation": {"code": "public ucar . unidata . geoloc . Station getStation ( String name ) { return typical . getStation ( name ) ; }", "nl": "Find a Station by name"}}
{"translation": {"code": "private String cloud_hgt2_meters ( String height ) { if ( height . equals ( \"999\" ) ) { return \"30000\" ; } else { //\t\t$meters = 30 * $height ; return Integer . toString ( 30 * Integer . parseInt ( height ) ) ; } }", "nl": "convert cloud height to meters"}}
{"translation": {"code": "public String writeStationCollectionXML ( ) throws IOException { XMLOutputter fmt = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; return fmt . outputString ( makeStationCollectionDocument ( ) ) ; }", "nl": "Write stationCollection XML document"}}
{"translation": {"code": "public String writeStationObsDatasetXML ( ) { XMLOutputter fmt = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; return fmt . outputString ( makeStationObsDatasetDocument ( ) ) ; }", "nl": "Write stationObsDataset XML document"}}
{"translation": {"code": "public Array getValues ( ) { if ( values == null && svalue != null ) { values = Array . factory ( DataType . STRING , new int [ ] { 1 } ) ; values . setObject ( values . getIndex ( ) , svalue ) ; } return values ; }", "nl": "Get the value as an Array ."}}
{"translation": {"code": "public boolean isUnknownUnit ( ) { ucar . units . Unit uu = getUnit ( ) ; if ( uu instanceof ucar . units . UnknownUnit ) return true ; if ( uu instanceof ucar . units . DerivedUnit ) return isUnknownUnit ( ( ucar . units . DerivedUnit ) uu ) ; if ( uu instanceof ucar . units . ScaledUnit ) { ucar . units . ScaledUnit scu = ( ucar . units . ScaledUnit ) uu ; Unit u = scu . getUnit ( ) ; if ( u instanceof ucar . units . UnknownUnit ) return true ; if ( u instanceof ucar . units . DerivedUnit ) return isUnknownUnit ( ( ucar . units . DerivedUnit ) u ) ; } return false ; }", "nl": "Is this an instance of an UnknownUnit?"}}
{"translation": {"code": "public boolean contains ( int want ) { if ( want < first ( ) ) return false ; if ( want > last ( ) ) return false ; if ( stride == 1 ) return true ; return ( want - first ) % stride == 0 ; }", "nl": "Is want contained in this Range?"}}
{"translation": {"code": "static private void transferGroup ( NetcdfFile ds , NetcdfDataset targetDs , Group src , Group targetGroup , ReplaceVariableCheck replaceCheck ) { boolean unlimitedOK = true ; // LOOK why not allowed? // group attributes transferGroupAttributes ( src , targetGroup ) ; // dimensions for ( Dimension d : src . getDimensions ( ) ) { if ( null == targetGroup . findDimensionLocal ( d . getShortName ( ) ) ) { Dimension newd = new Dimension ( d . getShortName ( ) , d . getLength ( ) , d . isShared ( ) , unlimitedOK && d . isUnlimited ( ) , d . isVariableLength ( ) ) ; targetGroup . addDimension ( newd ) ; } } // variables for ( Variable v : src . getVariables ( ) ) { Variable targetV = targetGroup . findVariable ( v . getShortName ( ) ) ; VariableEnhanced targetVe = ( VariableEnhanced ) targetV ; boolean replace = ( replaceCheck != null ) && replaceCheck . replace ( v ) ; // replaceCheck not currently used if ( replace || ( null == targetV ) ) { // replace it if ( ( v instanceof Structure ) && ! ( v instanceof StructureDS ) ) { v = new StructureDS ( targetGroup , ( Structure ) v ) ; // else if (!(v instanceof VariableDS) && !(v instanceof StructureDS)) Doug Lindolm } else if ( ! ( v instanceof VariableDS ) ) { v = new VariableDS ( targetGroup , v , false ) ; // enhancement done by original variable, this is just to reparent to target dataset. } if ( null != targetV ) targetGroup . remove ( targetV ) ; targetGroup . addVariable ( v ) ; // reparent group v . resetDimensions ( ) ; // dimensions will be different } else if ( ! targetV . hasCachedData ( ) && ( targetVe . getOriginalVariable ( ) == null ) ) { // this is the case where we defined the variable, but didnt set its data. we now set it with the first nested // dataset that has a variable with the same name targetVe . setOriginalVariable ( v ) ; } } // nested groups - check if target already has it for ( Group srcNested : src . getGroups ( ) ) { Group nested = targetGroup . findGroup ( srcNested . getShortName ( ) ) ; if ( null == nested ) { nested = new Group ( ds , targetGroup , srcNested . getShortName ( ) ) ; targetGroup . addGroup ( nested ) ; } transferGroup ( ds , targetDs , srcNested , nested , replaceCheck ) ; } }", "nl": "transfer the objects in src group to the target group"}}
{"translation": {"code": "static public Element readRootElement ( String location ) throws IOException { org . jdom2 . Document doc ; try { SAXBuilder builder = new SAXBuilder ( ) ; doc = builder . build ( location ) ; } catch ( JDOMException e ) { throw new IOException ( e . getMessage ( ) ) ; } return doc . getRootElement ( ) ; }", "nl": "Read an XML Document from a URL and return the root element ."}}
{"translation": {"code": "protected long readData ( Layout index , DataType dataType , WritableByteChannel out ) throws java . io . IOException { long count = 0 ; if ( dataType . getPrimitiveClassType ( ) == byte . class || dataType == DataType . CHAR ) { while ( index . hasNext ( ) ) { Layout . Chunk chunk = index . next ( ) ; count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , chunk . getNelems ( ) ) ; } } else if ( dataType . getPrimitiveClassType ( ) == short . class ) { while ( index . hasNext ( ) ) { Layout . Chunk chunk = index . next ( ) ; count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 2 * chunk . getNelems ( ) ) ; } } else if ( dataType . getPrimitiveClassType ( ) == int . class || ( dataType == DataType . FLOAT ) ) { while ( index . hasNext ( ) ) { Layout . Chunk chunk = index . next ( ) ; count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 4 * chunk . getNelems ( ) ) ; } } else if ( ( dataType == DataType . DOUBLE ) || dataType . getPrimitiveClassType ( ) == long . class ) { while ( index . hasNext ( ) ) { Layout . Chunk chunk = index . next ( ) ; count += raf . readToByteChannel ( out , chunk . getSrcPos ( ) , 8 * chunk . getNelems ( ) ) ; } } return count ; }", "nl": "Read data subset from file for a variable to WritableByteChannel . Will send as bigendian since thats what the underlying file has ."}}
{"translation": {"code": "protected Object readData ( Layout index , DataType dataType ) throws java . io . IOException { return IospHelper . readDataFill ( raf , index , dataType , null , - 1 ) ; }", "nl": "Read data subset from file for a variable create primitive array ."}}
{"translation": {"code": "public static TagEnum getTag ( short code ) { TagEnum te = hash . get ( code ) ; if ( te == null ) te = new TagEnum ( \"UNKNOWN\" , \"UNKNOWN\" , code ) ; return te ; }", "nl": "Find the Tag that matches the code ."}}
{"translation": {"code": "private DataType getCoordinateType ( ) { List < Dataset > nestedDatasets = getDatasets ( ) ; DatasetOuterDimension first = ( DatasetOuterDimension ) nestedDatasets . get ( 0 ) ; return first . isStringValued ? DataType . STRING : DataType . DOUBLE ; }", "nl": "What is the data type of the aggregation coordinate ?"}}
{"translation": {"code": "private boolean isTiled ( Variable v ) { for ( Dimension d : v . getDimensions ( ) ) { for ( Range r : section . getRanges ( ) ) { if ( d . getShortName ( ) . equals ( r . getName ( ) ) ) return true ; } } return false ; }", "nl": "a variable is tiled if any of its dimensions are tiled"}}
{"translation": {"code": "static public String cleanCharacterData ( String text ) { if ( text == null ) return null ; boolean bad = false ; for ( int i = 0 , len = text . length ( ) ; i < len ; i ++ ) { int ch = text . charAt ( i ) ; if ( ! org . jdom2 . Verifier . isXMLCharacter ( ch ) ) { bad = true ; break ; } } if ( ! bad ) return text ; StringBuilder sbuff = new StringBuilder ( text . length ( ) ) ; for ( int i = 0 , len = text . length ( ) ; i < len ; i ++ ) { int ch = text . charAt ( i ) ; if ( org . jdom2 . Verifier . isXMLCharacter ( ch ) ) sbuff . append ( ( char ) ch ) ; } return sbuff . toString ( ) ; }", "nl": "Make sure that text is XML safe"}}
{"translation": {"code": "public String writeCDL ( boolean strict ) { Formatter out = new Formatter ( ) ; writeCDL ( out , new Indent ( 2 ) , strict ) ; return out . toString ( ) ; }", "nl": "String representation ."}}
{"translation": {"code": "private int getMaxBytes ( long start ) { int segno = 0 ; while ( start >= segMax [ segno ] ) segno ++ ; return ( int ) ( segMax [ segno ] - start ) ; }", "nl": "how many more bytes are in this segment ?"}}
{"translation": {"code": "public boolean before ( Date d ) { if ( isPresent ( ) ) return false ; return date . isBefore ( CalendarDate . of ( d ) ) ; }", "nl": "Is this date before the given date . if isPresent always false ."}}
{"translation": {"code": "public void setStart ( DateType start ) { this . start = start ; useStart = true ; if ( useEnd ) { this . isMoving = this . start . isPresent ( ) || this . end . isPresent ( ) ; useDuration = false ; recalcDuration ( ) ; } else { this . isMoving = this . start . isPresent ( ) ; this . end = this . start . add ( duration ) ; } checkIfEmpty ( ) ; }", "nl": "Set the starting Date . Makes useStart true . If useEnd recalculate the duration else recalculate end ."}}
{"translation": {"code": "public boolean included ( Date d ) { if ( isEmpty ) return false ; if ( getStart ( ) . after ( d ) ) return false ; if ( getEnd ( ) . before ( d ) ) return false ; return true ; }", "nl": "Determine if the given date is included in this date range . The date range includes the start and end dates ."}}
{"translation": {"code": "public boolean after ( Date d ) { if ( isPresent ( ) ) return true ; return date . isAfter ( CalendarDate . of ( d ) ) ; }", "nl": "Is this date after the given date . if isPresent always true ."}}
{"translation": {"code": "public void setEnd ( DateType end ) { this . end = end ; useEnd = true ; if ( useStart ) { this . isMoving = this . start . isPresent ( ) || this . end . isPresent ( ) ; useDuration = false ; recalcDuration ( ) ; } else { this . isMoving = this . end . isPresent ( ) ; this . start = this . end . subtract ( duration ) ; } checkIfEmpty ( ) ; }", "nl": "Set the ending Date . Makes useEnd true . If useStart recalculate the duration else recalculate start ."}}
{"translation": {"code": "public void setDuration ( TimeDuration duration ) { this . duration = duration ; useDuration = true ; if ( useStart ) { this . isMoving = this . start . isPresent ( ) ; this . end = this . start . add ( duration ) ; useEnd = false ; } else { this . isMoving = this . end . isPresent ( ) ; this . start = this . end . subtract ( duration ) ; } checkIfEmpty ( ) ; }", "nl": "Set the duration of the interval . Makes useDuration true . If useStart recalculate end else recalculate start ."}}
{"translation": {"code": "public Structure select ( String varName ) { List < String > memberNames = new ArrayList <> ( 1 ) ; memberNames . add ( varName ) ; return select ( memberNames ) ; }", "nl": "Create a subset of the Structure consisting only of the one member variable"}}
{"translation": {"code": "public Structure select ( List < String > memberNames ) { Structure result = ( Structure ) copy ( ) ; List < Variable > members = new ArrayList <> ( ) ; for ( String name : memberNames ) { Variable m = findVariable ( name ) ; if ( null != m ) members . add ( m ) ; } result . setMemberVariables ( members ) ; result . isSubset = true ; return result ; }", "nl": "Create a subset of the Structure consisting only of the given member variables"}}
{"translation": {"code": "void addLevels ( List < GridRecord > records ) { for ( GridRecord record : records ) { Double d = new Double ( record . getLevel1 ( ) ) ; if ( ! levels . contains ( d ) ) { levels . add ( d ) ; } if ( dontUseVertical && ( levels . size ( ) > 1 ) ) { if ( GridServiceProvider . debugVert ) { System . out . println ( \"GribCoordSys: unused level coordinate has > 1 levels = \" + verticalName + \" \" + record . getLevelType1 ( ) + \" \" + levels . size ( ) ) ; } } } Collections . sort ( levels ) ; if ( positive . equals ( \"down\" ) ) { Collections . reverse ( levels ) ; // TODO: delete /* for( int i = 0; i < (levels.size()/2); i++ ){\n        Double tmp = (Double) levels.get( i );\n        levels.set( i, levels.get(levels.size() -i -1));\n        levels.set(levels.size() -i -1, tmp );\n     } */ } }", "nl": "Add levels from the GridRecords"}}
{"translation": {"code": "private int coordIndex ( GridRecord record ) { double val = record . getLevel1 ( ) ; double val2 = record . getLevel2 ( ) ; if ( usesBounds && ( val > val2 ) ) { val = record . getLevel2 ( ) ; val2 = record . getLevel1 ( ) ; } for ( int i = 0 ; i < levels . size ( ) ; i ++ ) { LevelCoord lc = ( LevelCoord ) levels . get ( i ) ; if ( usesBounds ) { if ( ucar . nc2 . util . Misc . nearlyEquals ( lc . value1 , val ) && ucar . nc2 . util . Misc . nearlyEquals ( lc . value2 , val2 ) ) { return i ; } } else { if ( ucar . nc2 . util . Misc . nearlyEquals ( lc . value1 , val ) ) { return i ; } } } return - 1 ; }", "nl": "Get the coordinate index for the record"}}
{"translation": {"code": "void addToNetcdfFile ( NetcdfFile ncfile , Group g ) { if ( dontUseVertical ) { return ; } if ( g == null ) { g = ncfile . getRootGroup ( ) ; } String dims = \"time\" ; if ( ! dontUseVertical ) { dims = dims + \" \" + verticalName ; } if ( hcs . isLatLon ( ) ) { dims = dims + \" lat lon\" ; } else { dims = dims + \" y x\" ; } //Collections.sort( levels); int nlevs = levels . size ( ) ; // ncfile.addDimension(g, new Dimension(verticalName, nlevs, true)); // coordinate axis and coordinate system Variable Variable v = new Variable ( ncfile , g , null , verticalName ) ; v . setDataType ( DataType . DOUBLE ) ; v . addAttribute ( new Attribute ( \"long_name\" , lookup . getLevelDescription ( record ) ) ) ; v . addAttribute ( new Attribute ( \"units\" , lookup . getLevelUnit ( record ) ) ) ; // positive attribute needed for CF-1 Height and Pressure if ( positive != null ) { v . addAttribute ( new Attribute ( \"positive\" , positive ) ) ; } if ( units != null ) { AxisType axisType ; if ( SimpleUnit . isCompatible ( \"millibar\" , units ) ) { axisType = AxisType . Pressure ; } else if ( SimpleUnit . isCompatible ( \"m\" , units ) ) { axisType = AxisType . Height ; } else { axisType = AxisType . GeoZ ; } v . addAttribute ( new Attribute ( \"grid_level_type\" , Integer . toString ( record . getLevelType1 ( ) ) ) ) ; v . addAttribute ( new Attribute ( _Coordinate . AxisType , axisType . toString ( ) ) ) ; v . addAttribute ( new Attribute ( _Coordinate . Axes , dims ) ) ; if ( ! hcs . isLatLon ( ) ) { v . addAttribute ( new Attribute ( _Coordinate . Transforms , hcs . getGridName ( ) ) ) ; } } double [ ] data = new double [ nlevs ] ; for ( int i = 0 ; i < levels . size ( ) ; i ++ ) { Double d = ( Double ) levels . get ( i ) ; data [ i ] = d . doubleValue ( ) ; } Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { nlevs } , data ) ; v . setDimensions ( verticalName ) ; v . setCachedData ( dataArray , false ) ; ncfile . addVariable ( g , v ) ; // look for vertical transforms if ( record . getLevelType1 ( ) == 109 ) { findCoordinateTransform ( g , \"Pressure\" , record . getLevelType1 ( ) ) ; } }", "nl": "Add this coordinate system to the netCDF file"}}
{"translation": {"code": "void findCoordinateTransform ( Group g , String nameStartsWith , int levelType ) { // look for variable that uses this coordinate List < Variable > vars = g . getVariables ( ) ; for ( Variable v : vars ) { if ( v . getShortName ( ) . equals ( nameStartsWith ) ) { Attribute att = v . findAttribute ( \"grid_level_type\" ) ; if ( ( att == null ) || ( att . getNumericValue ( ) . intValue ( ) != levelType ) ) { continue ; } v . addAttribute ( new Attribute ( _Coordinate . TransformType , \"Vertical\" ) ) ; v . addAttribute ( new Attribute ( \"transform_name\" , \"Existing3DField\" ) ) ; } } }", "nl": "Find the coordinate transform"}}
{"translation": {"code": "void addDimensionsToNetcdfFile ( NetcdfFile ncfile , Group g ) { if ( dontUseVertical ) { return ; } int nlevs = levels . size ( ) ; ncfile . addDimension ( g , new Dimension ( verticalName , nlevs , true ) ) ; }", "nl": "Add dimensions to the netcdf file"}}
{"translation": {"code": "public static void writeToChannel ( NetcdfFile ncfile , WritableByteChannel wbc ) throws IOException , InvalidRangeException { DataOutputStream stream = new DataOutputStream ( new BufferedOutputStream ( Channels . newOutputStream ( wbc ) , 8000 ) ) ; //DataOutputStream stream = new DataOutputStream(Channels.newOutputStream(wbc));  // buffering seems to improve by 5% N3channelWriter writer = new N3channelWriter ( ncfile ) ; int numrec = ncfile . getUnlimitedDimension ( ) == null ? 0 : ncfile . getUnlimitedDimension ( ) . getLength ( ) ; writer . writeHeader ( stream , numrec ) ; stream . flush ( ) ; writer . writeDataAll ( wbc ) ; }", "nl": "Write ncfile to a WritableByteChannel ."}}
{"translation": {"code": "public DateRange intersect ( DateRange clip ) { if ( isEmpty ) return this ; if ( clip . isEmpty ) return clip ; DateType ss = getStart ( ) ; DateType s = ss . before ( clip . getStart ( ) ) ? clip . getStart ( ) : ss ; DateType ee = getEnd ( ) ; DateType e = ee . before ( clip . getEnd ( ) ) ? ee : clip . getEnd ( ) ; return new DateRange ( s , e , null , resolution ) ; }", "nl": "Intersect with another date range"}}
{"translation": {"code": "public boolean before ( DateType d ) { if ( d . isPresent ( ) ) return true ; if ( isPresent ( ) ) return false ; return date . isBefore ( d . getCalendarDate ( ) ) ; }", "nl": "Is this date before the given date . if d . isPresent always true else if this . isPresent false ."}}
{"translation": {"code": "public void extend ( DateRange dr ) { boolean localEmpty = isEmpty ; if ( localEmpty || dr . getStart ( ) . before ( getStart ( ) ) ) setStart ( dr . getStart ( ) ) ; if ( localEmpty || getEnd ( ) . before ( dr . getEnd ( ) ) ) setEnd ( dr . getEnd ( ) ) ; }", "nl": "Extend this date range by the given one ."}}
{"translation": {"code": "public void setPointFeatureData ( List < PointFeature > obsData ) throws IOException { dataModel = new PointFeatureDataModel ( obsData ) ; initTable ( dataModel ) ; }", "nl": "Set the data as a collection of PointFeature ."}}
{"translation": {"code": "public final void readShort ( short [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { pa [ start + i ] = readShort ( ) ; } }", "nl": "Read an array of shorts"}}
{"translation": {"code": "public final void writeBytes ( char b [ ] , int off , int len ) throws IOException { for ( int i = off ; i < len ; i ++ ) { write ( ( byte ) b [ i ] ) ; } }", "nl": "Writes the character array to the file as a sequence of bytes . Each character in the string is written out in sequence by discarding its high eight bits ."}}
{"translation": {"code": "public final int readIntUnbuffered ( long pos ) throws IOException { byte [ ] bb = new byte [ 4 ] ; read_ ( pos , bb , 0 , 4 ) ; int ch1 = bb [ 0 ] & 0xff ; int ch2 = bb [ 1 ] & 0xff ; int ch3 = bb [ 2 ] & 0xff ; int ch4 = bb [ 3 ] & 0xff ; if ( ( ch1 | ch2 | ch3 | ch4 ) < 0 ) { throw new EOFException ( ) ; } if ( bigEndian ) { return ( ( ch1 << 24 ) + ( ch2 << 16 ) + ( ch3 << 8 ) + ( ch4 ) ) ; } else { return ( ( ch4 << 24 ) + ( ch3 << 16 ) + ( ch2 << 8 ) + ( ch1 ) ) ; } }", "nl": "Read an integer at the given position bypassing all buffering ."}}
{"translation": {"code": "public int read ( ) throws IOException { // If the file position is within the data, return the byte...\r if ( filePosition < dataEnd ) { int pos = ( int ) ( filePosition - bufferStart ) ; filePosition ++ ; return ( buffer [ pos ] & 0xff ) ; // ...or should we indicate EOF...\r } else if ( endOfFile ) { return - 1 ; // ...or seek to fill the buffer, and try again.\r } else { seek ( filePosition ) ; return read ( ) ; } }", "nl": "Read a byte of data from the file blocking until data is available ."}}
{"translation": {"code": "public void flush ( ) throws IOException { if ( bufferModified ) { file . seek ( bufferStart ) ; file . write ( buffer , 0 , dataSize ) ; //System.out.println(\"--flush at \"+bufferStart+\" dataSize= \"+dataSize+ \" filePosition= \"+filePosition);\r bufferModified = false ; } /* check min length\r\n    if (!readonly && (minLength != 0) && (minLength != file.length())) {\r\n      file.setLength(minLength);\r\n    } */ }", "nl": "Copy the contents of the buffer to the disk ."}}
{"translation": {"code": "public void seek ( long pos ) throws IOException { if ( pos < 0 ) throw new java . io . IOException ( \"Negative seek offset\" ) ; // If the seek is into the buffer, just update the file pointer.\r if ( ( pos >= bufferStart ) && ( pos < dataEnd ) ) { filePosition = pos ; return ; } // need new buffer, starting at pos\r readBuffer ( pos ) ; }", "nl": "Set the position in the file for the next read or write ."}}
{"translation": {"code": "public final void readInt ( int [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { pa [ start + i ] = readInt ( ) ; } }", "nl": "Read an array of ints"}}
{"translation": {"code": "public final void readLong ( long [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { pa [ start + i ] = readLong ( ) ; } }", "nl": "Read an array of longs"}}
{"translation": {"code": "public synchronized void close ( ) throws IOException { if ( cache != null ) { if ( cacheState > 0 ) { if ( cacheState == 1 ) { cacheState = 2 ; if ( cache . release ( this ) ) // return true if in the cache, otherwise was opened regular, so must be closed regular\r return ; cacheState = 0 ; // release failed, bail out\r } else { return ; // close has been called more than once - ok\r } } } if ( debugLeaks ) { openFiles . remove ( location ) ; if ( showOpen ) System . out . println ( \"  close \" + location ) ; } if ( file == null ) return ; // If we are writing and the buffer has been modified, flush the contents of the buffer.\r flush ( ) ; // may need to extend file, in case no fill is being used\r // may need to truncate file in case overwriting a longer file\r // use only if minLength is set (by N3iosp)\r long fileSize = file . length ( ) ; if ( ! readonly && ( minLength != 0 ) && ( minLength != fileSize ) ) { file . setLength ( minLength ) ; // System.out.println(\"TRUNCATE!!! minlength=\"+minLength);\r } // Close the underlying file object.\r file . close ( ) ; file = null ; // help the gc\r }", "nl": "Close the file and release any associated system resources ."}}
{"translation": {"code": "public final void readFloat ( float [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { pa [ start + i ] = Float . intBitsToFloat ( readInt ( ) ) ; } }", "nl": "Read an array of floats"}}
{"translation": {"code": "public boolean searchForward ( KMPMatch match , int maxBytes ) throws IOException { long start = getFilePointer ( ) ; long last = ( maxBytes < 0 ) ? length ( ) : Math . min ( length ( ) , start + maxBytes ) ; long needToScan = last - start ; // check what ever is now in the buffer\r int bytesAvailable = ( int ) ( dataEnd - filePosition ) ; if ( bytesAvailable < 1 ) { seek ( filePosition ) ; // read a new buffer\r bytesAvailable = ( int ) ( dataEnd - filePosition ) ; } int bufStart = ( int ) ( filePosition - bufferStart ) ; int scanBytes = ( int ) Math . min ( bytesAvailable , needToScan ) ; int pos = match . indexOf ( buffer , bufStart , scanBytes ) ; if ( pos >= 0 ) { seek ( bufferStart + pos ) ; return true ; } int matchLen = match . getMatchLength ( ) ; needToScan -= scanBytes - matchLen ; while ( needToScan > matchLen ) { readBuffer ( dataEnd - matchLen ) ; // force new buffer\r scanBytes = ( int ) Math . min ( buffer . length , needToScan ) ; pos = match . indexOf ( buffer , 0 , scanBytes ) ; if ( pos > 0 ) { seek ( bufferStart + pos ) ; return true ; } needToScan -= scanBytes - matchLen ; } // failure\r seek ( last ) ; return false ; }", "nl": "Search forward from the current pos looking for a match ."}}
{"translation": {"code": "static public void setDebugLeaks ( boolean b ) { if ( b ) { count_openFiles . set ( 0 ) ; maxOpenFiles . set ( 0 ) ; allFiles = new HashSet <> ( 1000 ) ; } debugLeaks = b ; }", "nl": "Debugging do not use in production . Set counters to zero set debugging on"}}
{"translation": {"code": "public String readString ( int nbytes ) throws IOException { byte [ ] data = new byte [ nbytes ] ; readFully ( data ) ; return new String ( data , CDM . utf8Charset ) ; }", "nl": "Read a String of known length ."}}
{"translation": {"code": "public final void writeBoolean ( boolean [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeBoolean ( pa [ start + i ] ) ; } }", "nl": "Write an array of booleans"}}
{"translation": {"code": "public final void writeShort ( short [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeShort ( pa [ start + i ] ) ; } }", "nl": "Write an array of shorts"}}
{"translation": {"code": "public final void writeChar ( char [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeChar ( pa [ start + i ] ) ; } }", "nl": "Write an array of chars"}}
{"translation": {"code": "public final void writeInt ( int [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeInt ( pa [ start + i ] ) ; } }", "nl": "Write an array of ints"}}
{"translation": {"code": "public final void writeLong ( long [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeLong ( pa [ start + i ] ) ; } }", "nl": "Write an array of longs"}}
{"translation": {"code": "public final void writeFloat ( float [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeFloat ( pa [ start + i ] ) ; } }", "nl": "Write an array of floats"}}
{"translation": {"code": "public final void writeBytes ( String s ) throws IOException { int len = s . length ( ) ; for ( int i = 0 ; i < len ; i ++ ) { write ( ( byte ) s . charAt ( i ) ) ; } }", "nl": "Writes the string to the file as a sequence of bytes . Each character in the string is written out in sequence by discarding its high eight bits ."}}
{"translation": {"code": "public final void readDouble ( double [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { pa [ start + i ] = Double . longBitsToDouble ( readLong ( ) ) ; } }", "nl": "Read an array of doubles"}}
{"translation": {"code": "public final void writeDouble ( double [ ] pa , int start , int n ) throws IOException { for ( int i = 0 ; i < n ; i ++ ) { writeDouble ( pa [ start + i ] ) ; } }", "nl": "Write an array of doubles"}}
{"translation": {"code": "public StationTimeSeriesFeature makeStation ( StructureData stationData , int recnum ) { StationFeature s = ft . makeStation ( stationData ) ; if ( s == null ) return null ; return new StandardStationFeatureImpl ( s , timeUnit , stationData , recnum ) ; }", "nl": "Make a Station from the station data structure ."}}
{"translation": {"code": "public void writeGrid ( GridDataset dataset , GridDatatype grid , Array data , boolean greyScale ) throws IOException { GridCoordSystem gcs = grid . getCoordinateSystem ( ) ; if ( ! gcs . isRegularSpatial ( ) ) { throw new IllegalArgumentException ( \"Must have 1D x and y axes for \" + grid . getFullName ( ) ) ; } CoordinateAxis1D xaxis = ( CoordinateAxis1D ) gcs . getXHorizAxis ( ) ; CoordinateAxis1D yaxis = ( CoordinateAxis1D ) gcs . getYHorizAxis ( ) ; // units may need to be scaled to meters double scaler = ( xaxis . getUnitsString ( ) . equalsIgnoreCase ( \"km\" ) ) ? 1000.0 : 1.0 ; // data must go from top to bottom double xStart = xaxis . getCoordEdge ( 0 ) * scaler ; double yStart = yaxis . getCoordEdge ( 0 ) * scaler ; double xInc = xaxis . getIncrement ( ) * scaler ; double yInc = Math . abs ( yaxis . getIncrement ( ) ) * scaler ; if ( yaxis . getCoordValue ( 0 ) < yaxis . getCoordValue ( 1 ) ) { data = data . flip ( 0 ) ; yStart = yaxis . getCoordEdge ( ( int ) yaxis . getSize ( ) ) * scaler ; } if ( ! xaxis . isRegular ( ) || ! yaxis . isRegular ( ) ) { throw new IllegalArgumentException ( \"Must be evenly spaced grid = \" + grid . getFullName ( ) ) ; } if ( pageNumber > 1 ) { geotiff . initTags ( ) ; } // write it out writeGrid ( grid , data , greyScale , xStart , yStart , xInc , yInc , pageNumber ) ; pageNumber ++ ; }", "nl": "Write GridDatatype data to the geotiff file ."}}
{"translation": {"code": "private CoordVarExtractor findCoordinateAxis ( Table . CoordName coordName , Table t , int nestingLevel ) { if ( t == null ) return null ; String axisName = t . findCoordinateVariableName ( coordName ) ; if ( axisName != null ) { VariableDS v = t . findVariable ( axisName ) ; if ( v != null ) return new CoordVarExtractorVariable ( v , axisName , nestingLevel ) ; if ( t . extraJoins != null ) { for ( Join j : t . extraJoins ) { v = j . findVariable ( axisName ) ; if ( v != null ) return new CoordVarExtractorVariable ( v , axisName , nestingLevel ) ; } } // see if its in the StructureData if ( t instanceof Table . TableSingleton ) { Table . TableSingleton ts = ( Table . TableSingleton ) t ; return new CoordVarStructureData ( axisName , ts . sdata ) ; } // see if its at the top level if ( t instanceof Table . TableTop ) { v = ( VariableDS ) ds . findVariable ( axisName ) ; if ( v != null ) return new CoordVarTop ( v ) ; else return new CoordVarConstant ( coordName . toString ( ) , \"\" , axisName ) ; // assume its the actual value } errlog . format ( \"NestedTable: cant find variable '%s' for coordinate type %s %n\" , axisName , coordName ) ; } // check the parent return findCoordinateAxis ( coordName , t . parent , nestingLevel + 1 ) ; }", "nl": "find a coord axis of the given type in the table and its parents"}}
{"translation": {"code": "private void addDataVariables ( List < VariableSimpleIF > list , Table t ) { if ( t . parent != null ) addDataVariables ( list , t . parent ) ; for ( VariableSimpleIF col : t . cols . values ( ) ) { if ( t . nondataVars . contains ( col . getFullName ( ) ) ) continue ; if ( t . nondataVars . contains ( col . getShortName ( ) ) ) continue ; // fishy list . add ( col ) ; } }", "nl": "use recursion so that parent variables come first"}}
{"translation": {"code": "static public String getCoordinateName ( NetcdfDataset ds , AxisType a ) { List < Variable > varList = ds . getVariables ( ) ; for ( Variable v : varList ) { if ( v instanceof Structure ) { List < Variable > vars = ( ( Structure ) v ) . getVariables ( ) ; for ( Variable vs : vars ) { String axisType = ds . findAttValueIgnoreCase ( vs , _Coordinate . AxisType , null ) ; if ( ( axisType != null ) && axisType . equals ( a . toString ( ) ) ) return vs . getShortName ( ) ; } } else { String axisType = ds . findAttValueIgnoreCase ( v , _Coordinate . AxisType , null ) ; if ( ( axisType != null ) && axisType . equals ( a . toString ( ) ) ) return v . getShortName ( ) ; } } if ( a == AxisType . Lat ) return findVariableName ( ds , \"latitude\" ) ; if ( a == AxisType . Lon ) return findVariableName ( ds , \"longitude\" ) ; if ( a == AxisType . Time ) return findVariableName ( ds , \"time\" ) ; if ( a == AxisType . Height ) { Variable v = findVariable ( ds , \"altitude\" ) ; if ( null == v ) v = findVariable ( ds , \"depth\" ) ; if ( v != null ) return v . getShortName ( ) ; } // I think the CF part is done by the CoordSysBuilder adding the _CoordinateAxisType attrinutes.\r return null ; }", "nl": "Tries to find the coordinate variable of the specified type ."}}
{"translation": {"code": "public void finish ( ) { sequenceOffset = new int [ nelems ] ; total = 0 ; for ( int i = 0 ; i < nelems ; i ++ ) { sequenceOffset [ i ] = total ; total += sequenceLen [ i ] ; } sdata = new StructureData [ nelems ] ; for ( int i = 0 ; i < nelems ; i ++ ) sdata [ i ] = new StructureDataA ( this , sequenceOffset [ i ] ) ; // make the member arrays for ( StructureMembers . Member m : members . getMembers ( ) ) { int [ ] mShape = m . getShape ( ) ; int [ ] shape = new int [ mShape . length + 1 ] ; shape [ 0 ] = total ; System . arraycopy ( mShape , 0 , shape , 1 , mShape . length ) ; // LOOK not doing nested structures Array data = Array . factory ( m . getDataType ( ) , shape ) ; m . setDataArray ( data ) ; } }", "nl": "Call this when you have set all the sequence lengths ."}}
{"translation": {"code": "public ArraySequence getArraySequence ( String memberName ) { StructureMembers . Member m = members . findMember ( memberName ) ; if ( m == null ) throw new IllegalArgumentException ( \"illegal member name =\" + memberName ) ; return getArraySequence ( m ) ; }", "nl": "Get ArraySequence for a member of type Sequence ."}}
{"translation": {"code": "public static String makeSectionSpecString ( Variable v , List < Range > ranges ) throws InvalidRangeException { StringBuilder sb = new StringBuilder ( ) ; makeSpec ( sb , v , ranges ) ; return sb . toString ( ) ; }", "nl": "Make section specification String from a range list for a Variable ."}}
{"translation": {"code": "private static ParsedSectionSpec parseVariableSelector ( Object parent , String selector ) throws InvalidRangeException { String varNameEsc , indexSelect = null ; int pos1 = EscapeStrings . indexOf ( selector , ' ' ) ; if ( pos1 < 0 ) { // no index varNameEsc = selector ; } else { varNameEsc = selector . substring ( 0 , pos1 ) ; int pos2 = selector . indexOf ( ' ' , pos1 + 1 ) ; indexSelect = selector . substring ( pos1 , pos2 ) ; } if ( debugSelector ) System . out . println ( \" parseVariableSection <\" + selector + \"> = <\" + varNameEsc + \">, <\" + indexSelect + \">\" ) ; Variable v = null ; if ( parent instanceof NetcdfFile ) { // then varNameEsc = varFullNameEsc (i.e. includes groups) NetcdfFile ncfile = ( NetcdfFile ) parent ; v = ncfile . findVariable ( varNameEsc ) ; } else if ( parent instanceof Structure ) { // then varNameEsc = memberNameEsc (i.e. includes groups) Structure s = ( Structure ) parent ; v = s . findVariable ( NetcdfFile . makeNameUnescaped ( varNameEsc ) ) ; // s.findVariable wants unescaped version } if ( v == null ) throw new IllegalArgumentException ( \" cant find variable: \" + varNameEsc + \" in selector=\" + selector ) ; if ( v . getDataType ( ) == DataType . SEQUENCE ) indexSelect = null ; // ignore whatever was sent // get the selected Ranges, or all, and add to the list Section section ; if ( indexSelect != null ) { section = new Section ( indexSelect ) ; section = Section . fill ( section , v . getShape ( ) ) ; // Check section has no nulls, set from shape array. } else { section = v . getShapeAsSection ( ) ; // all } return new ParsedSectionSpec ( v , section ) ; }", "nl": "parse variable name and index selector out of the selector String . variable name must be escaped"}}
{"translation": {"code": "private ArrayFloat replaceMissingValues ( IsMissingEvaluator grid , Array data , MAMath . MinMax dataMinMax ) { float minValue = ( float ) ( dataMinMax . min - 1.0 ) ; ArrayFloat floatArray = ( ArrayFloat ) Array . factory ( DataType . FLOAT , data . getShape ( ) ) ; IndexIterator dataIter = data . getIndexIterator ( ) ; IndexIterator floatIter = floatArray . getIndexIterator ( ) ; while ( dataIter . hasNext ( ) ) { float v = dataIter . getFloatNext ( ) ; if ( grid . isMissing ( ( double ) v ) ) { v = minValue ; } floatIter . setFloatNext ( v ) ; } return floatArray ; }", "nl": "Replace missing values with dataMinMax . min - 1 . 0 ; return a floating point data array ."}}
{"translation": {"code": "private ArrayByte replaceMissingValuesAndScale ( IsMissingEvaluator grid , Array data , MAMath . MinMax dataMinMax ) { double scale = 254.0 / ( dataMinMax . max - dataMinMax . min ) ; ArrayByte byteArray = ( ArrayByte ) Array . factory ( DataType . BYTE , data . getShape ( ) ) ; IndexIterator dataIter = data . getIndexIterator ( ) ; IndexIterator resultIter = byteArray . getIndexIterator ( ) ; byte bv ; while ( dataIter . hasNext ( ) ) { double v = dataIter . getDoubleNext ( ) ; if ( grid . isMissing ( v ) ) { bv = 0 ; } else { int iv = ( int ) ( ( v - dataMinMax . min ) * scale + 1 ) ; bv = ( byte ) ( iv & 0xff ) ; } resultIter . setByteNext ( bv ) ; } return byteArray ; }", "nl": "Replace missing values with 0 ; scale other values between 1 and 255 return a byte data array ."}}
{"translation": {"code": "private int process ( Buffer b , InputStream is ) throws IOException { int start = 0 ; while ( start < b . have ) { int matchPos = matcher . indexOf ( b . buff , start , b . have - start ) ; // didnt find \"BUFR\" match if ( matchPos < 0 ) { if ( start == 0 ) // discard all but last 3 bytes return b . have - 3 ; else return start ; // indicates part of the buffer thats not processed } // do we have the length already read ?? if ( matchPos + 6 >= b . have ) { return start ; // this will save the end of the buffer and read more in. } // read BUFR message length int b1 = ( b . buff [ matchPos + 4 ] & 0xff ) ; int b2 = ( b . buff [ matchPos + 5 ] & 0xff ) ; int b3 = ( b . buff [ matchPos + 6 ] & 0xff ) ; int messLen = b1 << 16 | b2 << 8 | b3 ; // System.out.println(\"match at=\" + matchPos + \" len= \" + messLen); // create a task for this message //int headerLen = matchPos - start; MessageTask task = new MessageTask ( messLen ) ; task . header = extractHeader ( start , matchPos , b ) ; // copy message bytes into it int last = matchPos + messLen ; if ( last > b . have ) { task . have = b . have - matchPos ; System . arraycopy ( b . buff , matchPos , task . mess , 0 , task . have ) ; // read the rest of the message if ( ! readBuffer ( is , task . mess , task . have , task . len - task . have ) ) { System . out . println ( \"Failed to read remaining BUFR message\" ) ; break ; } } else { task . have = task . len ; System . arraycopy ( b . buff , matchPos , task . mess , 0 , task . have ) ; } boolean ok = true ; // check on ending for ( int i = task . len - 4 ; i < task . len ; i ++ ) { int bb = task . mess [ i ] ; if ( bb != 55 ) { //System.out.println(\"Missing End of BUFR message at pos=\" + i + \" \" + bb); ok = false ; bad_msgs ++ ; } } try { if ( ok ) messQ . put ( task ) ; total_msgs ++ ; //System.out.println(\" added message \" + task.id + \" start=\" + matchPos + \" end= \" + (matchPos + messLen)); } catch ( InterruptedException e ) { System . out . println ( \" interrupted queue put - assume process exit\" ) ; break ; } start = matchPos + messLen + 1 ; } return - 1 ; }", "nl": "return where in the buffer we got to ."}}
{"translation": {"code": "public void process ( InputStream is ) throws IOException { int pos = - 1 ; Buffer b = null ; while ( true ) { b = ( pos < 0 ) ? readBuffer ( is ) : readBuffer ( is , b , pos ) ; pos = process ( b , is ) ; if ( b . done ) break ; } }", "nl": "Step 1 - read and extract a Bufr Message"}}
{"translation": {"code": "public static void main1 ( String [ ] args ) { if ( INDEX_DIR . exists ( ) ) { System . out . println ( \"Cannot save index to '\" + INDEX_DIR + \"' directory, please delete it first\" ) ; System . exit ( 1 ) ; } LuceneIndexer indexer = new LuceneIndexer ( ) ; Date start = new Date ( ) ; try { IndexWriter writer = new IndexWriter ( INDEX_DIR , new StandardAnalyzer ( ) , true ) ; System . out . println ( \"Indexing to directory '\" + INDEX_DIR + \"'...\" ) ; indexer . indexDocs ( writer , DOC_DIR ) ; System . out . println ( \"Optimizing...\" ) ; writer . optimize ( ) ; writer . close ( ) ; Date end = new Date ( ) ; System . out . println ( end . getTime ( ) - start . getTime ( ) + \" total milliseconds\" ) ; } catch ( IOException e ) { System . out . println ( \" caught a \" + e . getClass ( ) + \"\\n with message: \" + e . getMessage ( ) ) ; } }", "nl": "Index all text files under a directory ."}}
{"translation": {"code": "public void readChars ( char [ ] buffer , int start , int length ) throws IOException { final int end = start + length ; for ( int i = start ; i < end ; i ++ ) { byte b = readByte ( ) ; if ( ( b & 0x80 ) == 0 ) buffer [ i ] = ( char ) ( b & 0x7F ) ; else if ( ( b & 0xE0 ) != 0xE0 ) { buffer [ i ] = ( char ) ( ( ( b & 0x1F ) << 6 ) | ( readByte ( ) & 0x3F ) ) ; } else buffer [ i ] = ( char ) ( ( ( b & 0x0F ) << 12 ) | ( ( readByte ( ) & 0x3F ) << 6 ) | ( readByte ( ) & 0x3F ) ) ; } }", "nl": "Reads UTF - 8 encoded characters into an array ."}}
{"translation": {"code": "public int writeChars ( String s , int start , int length ) throws IOException { final int end = start + length ; int count = 0 ; for ( int i = start ; i < end ; i ++ ) { final int code = ( int ) s . charAt ( i ) ; if ( code >= 0x01 && code <= 0x7F ) { writeByte ( ( byte ) code ) ; count ++ ; } else if ( ( ( code >= 0x80 ) && ( code <= 0x7FF ) ) || code == 0 ) { writeByte ( ( byte ) ( 0xC0 | ( code >> 6 ) ) ) ; writeByte ( ( byte ) ( 0x80 | ( code & 0x3F ) ) ) ; count += 2 ; } else { writeByte ( ( byte ) ( 0xE0 | ( code >>> 12 ) ) ) ; writeByte ( ( byte ) ( 0x80 | ( ( code >> 6 ) & 0x3F ) ) ) ; writeByte ( ( byte ) ( 0x80 | ( code & 0x3F ) ) ) ; count += 3 ; } } return count ; }", "nl": "Writes a sequence of UTF - 8 encoded characters from a string ."}}
{"translation": {"code": "public int writeVInt ( int i ) throws IOException { int count = 0 ; while ( ( i & ~ 0x7F ) != 0 ) { writeByte ( ( byte ) ( ( i & 0x7f ) | 0x80 ) ) ; i >>>= 7 ; count ++ ; } writeByte ( ( byte ) i ) ; return count + 1 ; }", "nl": "Writes an int in a variable - length format . Writes between one and five bytes . Smaller values take fewer bytes . Negative numbers are not supported ."}}
{"translation": {"code": "void scheduleWrite ( Message m ) { q . add ( m ) ; if ( ! isScheduled . getAndSet ( true ) ) { executor . submit ( this ) ; } }", "nl": "put a message on the queue schedule writing if not already scheduled ."}}
{"translation": {"code": "private void recalcDuration ( ) { long min = getStart ( ) . getDate ( ) . getTime ( ) ; long max = getEnd ( ) . getDate ( ) . getTime ( ) ; double secs = .001 * ( max - min ) ; if ( secs < 0 ) secs = 0 ; if ( duration == null ) { try { duration = new TimeDuration ( chooseResolution ( secs ) ) ; } catch ( ParseException e ) { // cant happen throw new RuntimeException ( e ) ; } } if ( resolution == null ) { duration . setValueInSeconds ( secs ) ; } else { // make it a multiple of resolution double resSecs = resolution . getValueInSeconds ( ) ; double closest = Math . round ( secs / resSecs ) ; secs = closest * resSecs ; duration . setValueInSeconds ( secs ) ; } hashCode = 0 ; }", "nl": "assumes not moving"}}
{"translation": {"code": "public void readData ( RandomAccessFile raf , String abbrev , Range gateRange , IndexIterator ii ) throws IOException { long offset = rayOffset ; offset += ( getDataOffset ( abbrev ) * 2 - 2 ) ; raf . seek ( offset ) ; byte [ ] b2 = new byte [ 2 ] ; int dataCount = getGateCount ( abbrev ) ; byte [ ] data = new byte [ dataCount * 2 ] ; raf . readFully ( data ) ; for ( int gateIdx : gateRange ) { if ( gateIdx >= dataCount ) ii . setShortNext ( uf_header2 . missing ) ; else { b2 [ 0 ] = data [ gateIdx * 2 ] ; b2 [ 1 ] = data [ gateIdx * 2 + 1 ] ; short value = getShort ( b2 , 0 ) ; ii . setShortNext ( value ) ; } } }", "nl": "Read data from this ray ."}}
{"translation": {"code": "public boolean delete ( ) { if ( nextFile == null ) return false ; fileList . remove ( nextFile ) ; File f = new File ( \"C:/tmp/deleted/\" + nextFile . getName ( ) ) ; return nextFile . renameTo ( f ) ; }", "nl": "remove last file"}}
{"translation": {"code": "public CoordinateAxis copyNoCache ( ) { CoordinateAxis axis = new CoordinateAxis ( ncd , getParentGroup ( ) , getShortName ( ) , getDataType ( ) , getDimensionsString ( ) , getUnitsString ( ) , getDescription ( ) ) ; // other state axis . axisType = this . axisType ; axis . boundaryRef = this . boundaryRef ; axis . isContiguous = this . isContiguous ; axis . positive = this . positive ; axis . cache = new Variable . Cache ( ) ; // decouple cache return axis ; }", "nl": "Make a copy with an independent cache ."}}
{"translation": {"code": "public int element ( int i ) throws InvalidRangeException { if ( i < 0 ) throw new InvalidRangeException ( \"i must be >= 0\" ) ; if ( i >= length ) throw new InvalidRangeException ( \"i must be < length\" ) ; return first + i * stride ; }", "nl": "Get ith element"}}
{"translation": {"code": "static public String getCoordinateName ( NetcdfDataset ds , AxisType a , Dimension dim ) { String name = getCoordinateName ( ds , a ) ; if ( name == null ) return null ; Variable v = ds . findVariable ( name ) ; if ( v == null ) return null ; if ( v . isScalar ( ) ) return null ; if ( ! v . getDimension ( 0 ) . equals ( dim ) ) return null ; return name ; }", "nl": "Tries to find the coordinate variable of the specified type which has the specified dimension as its firsst dimension"}}
{"translation": {"code": "void addParentJoin ( Cursor cursor ) throws IOException { int level = cursor . currentIndex ; Table t = getTable ( level ) ; if ( t . extraJoins != null ) { List < StructureData > sdata = new ArrayList <> ( 3 ) ; sdata . add ( cursor . tableData [ level ] ) ; for ( Join j : t . extraJoins ) { sdata . add ( j . getJoinData ( cursor ) ) ; } cursor . tableData [ level ] = StructureDataFactory . make ( sdata . toArray ( new StructureData [ sdata . size ( ) ] ) ) ; // LOOK should try to consolidate } }", "nl": "add table join to this cursor level"}}
{"translation": {"code": "public static String unicodeCodePoint2PercentHexString ( int codePoint , String charsetName ) { if ( ! Character . isDefined ( codePoint ) ) throw new IllegalArgumentException ( String . format ( \"Given code point [U+%1$04X - %1$d] not assigned to an abstract character.\" , codePoint ) ) ; if ( Character . getType ( codePoint ) == Character . SURROGATE ) throw new IllegalArgumentException ( String . format ( \"Given code point [U+%1$04X - %1$d] is an unencodable (by itself) surrogate character.\" , codePoint ) ) ; Charset charset = Charset . availableCharsets ( ) . get ( charsetName ) ; if ( charset == null ) throw new IllegalArgumentException ( String . format ( \"Unsupported charset [%s].\" , charsetName ) ) ; char [ ] chars = Character . toChars ( codePoint ) ; ByteBuffer byteBuffer = null ; try { byteBuffer = charset . newEncoder ( ) . encode ( CharBuffer . wrap ( chars ) ) ; } catch ( CharacterCodingException e ) { String message = String . format ( \"Given code point [U+%1$04X - %1$d] cannot be encode in given charset [%2$s].\" , codePoint , charsetName ) ; throw new IllegalArgumentException ( message , e ) ; } byteBuffer . rewind ( ) ; StringBuilder encodedString = new StringBuilder ( ) ; for ( int i = 0 ; i < byteBuffer . limit ( ) ; i ++ ) { String asHex = Integer . toHexString ( byteBuffer . get ( ) & 0xFF ) ; encodedString . append ( \"%\" ) . append ( asHex . length ( ) == 1 ? \"0\" : \"\" ) . append ( asHex ) ; } return encodedString . toString ( ) ; }", "nl": "Return the percentHexOctets string that represents the given Unicode code point in the given character set or null if the given character set cannot encode the given code point ."}}
{"translation": {"code": "@ SuppressWarnings ( { \"SimplifiableIfStatement\" } ) public static boolean validBooleanString ( String boolString ) { if ( boolString == null ) return false ; Matcher m = VALID_CHARACTERS_FOR_BOOLEAN_STRING_PATTERN . matcher ( boolString ) ; if ( ! m . matches ( ) ) return false ; return boolString . equalsIgnoreCase ( \"true\" ) || boolString . equalsIgnoreCase ( \"false\" ) ; }", "nl": "Return true if the given String is true or false ignoring case ."}}
{"translation": {"code": "public static boolean validAlphanumericString ( String alphNumString ) { if ( alphNumString == null ) return false ; Matcher m = VALID_CHARACTERS_FOR_ALPHANUMERIC_STRING_PATTERN . matcher ( alphNumString ) ; return m . matches ( ) ; }", "nl": "Return true if the given String is an alphanumeric string ."}}
{"translation": {"code": "public static boolean validAlphanumericStringConstrainedSet ( String alphNumString , String [ ] constrainedSet , boolean ignoreCase ) { if ( alphNumString == null || constrainedSet == null || constrainedSet . length == 0 ) return false ; Matcher m = VALID_CHARACTERS_FOR_ALPHANUMERIC_STRING_PATTERN . matcher ( alphNumString ) ; if ( ! m . matches ( ) ) return false ; for ( String s : constrainedSet ) { if ( ignoreCase ? alphNumString . equalsIgnoreCase ( s ) : alphNumString . equals ( s ) ) return true ; } return false ; }", "nl": "Return true if the given String is an alphanumeric string and one of the valid strings in the constrained set ."}}
{"translation": {"code": "@ SuppressWarnings ( { \"UnnecessaryContinue\" } ) public static boolean descendOnlyFilePath ( String path ) { String [ ] pathSegments = path . split ( \"/\" ) ; //String[] newPathSegments = new String[pathSegments.length]; int i = 0 ; for ( int indxOrigSegs = 0 ; indxOrigSegs < pathSegments . length ; indxOrigSegs ++ ) { String s = pathSegments [ indxOrigSegs ] ; if ( s . equals ( \".\" ) ) continue ; else if ( s . equals ( \"..\" ) ) { if ( i == 0 ) return false ; i -- ; } else { //newPathSegments[i] = s; i ++ ; } } return true ; }", "nl": "Return true if the given path does not ascend into parent directory ."}}
{"translation": {"code": "public final Unit parse ( final String spec ) throws NoSuchUnitException , UnitParseException , SpecificationException , UnitDBException , PrefixDBException , UnitSystemException { synchronized ( MUTEX ) { return parse ( spec , UnitDBManager . instance ( ) ) ; } }", "nl": "Parses a unit specification . This method is thread - safe ."}}
{"translation": {"code": "public static UnitName newUnitName ( final String name , final String plural ) throws NameException { return newUnitName ( name , plural , null ) ; }", "nl": "Factory method for constructing a UnitName from a name and a plural form of the name ."}}
{"translation": {"code": "public void addSymbol ( final String symbol , final double value ) throws PrefixExistsException { final Prefix prefix = new PrefixSymbol ( symbol , value ) ; symbolSet . add ( prefix ) ; valueMap . put ( new Double ( value ) , prefix ) ; }", "nl": "Adds a prefix symbol to the database ."}}
{"translation": {"code": "public void add ( final UnitDBImpl that ) throws UnitExistsException { unitSet . addAll ( that . unitSet ) ; nameMap . putAll ( that . nameMap ) ; symbolMap . putAll ( that . symbolMap ) ; }", "nl": "Adds all the entries in another UnitDBImpl to this database ."}}
{"translation": {"code": "public void addName ( final String name , final double value ) throws PrefixExistsException { final Prefix prefix = new PrefixName ( name , value ) ; nameSet . add ( prefix ) ; }", "nl": "Adds a prefix to the database by name ."}}
{"translation": {"code": "public void addUnit ( final Unit unit ) throws UnitExistsException , NameException { if ( unit . getName ( ) == null ) { throw new NameException ( \"Unit name can't be null\" ) ; } addByName ( unit . getName ( ) , unit ) ; addByName ( unit . getPlural ( ) , unit ) ; addBySymbol ( unit . getSymbol ( ) , unit ) ; unitSet . add ( unit ) ; }", "nl": "Adds a unit to the database ."}}
{"translation": {"code": "private static final void addUnique ( final Map < String , Unit > map , final String key , final Unit newUnit ) throws UnitExistsException { final Unit oldUnit = map . put ( key , newUnit ) ; if ( oldUnit != null && ! oldUnit . equals ( newUnit ) ) { throw new UnitExistsException ( oldUnit , newUnit ) ; } }", "nl": "Adds a unique unit to a map .."}}
{"translation": {"code": "private final void addBySymbol ( final String symbol , final Unit newUnit ) throws UnitExistsException { if ( symbol != null ) { addUnique ( symbolMap , symbol , newUnit ) ; } }", "nl": "Adds a unit to the database by symbol ."}}
{"translation": {"code": "private final void addByName ( final String name , final Unit newUnit ) throws UnitExistsException { if ( name != null ) { addUnique ( nameMap , canonicalize ( name ) , newUnit ) ; } }", "nl": "Adds a unit to the database by name ."}}
{"translation": {"code": "public Unit get ( final String id ) { Unit unit = getBySymbol ( id ) ; if ( unit == null ) { unit = getByName ( id ) ; } return unit ; }", "nl": "Gets a unit by either name plural or symbol . Retrieving the unit by symbol is attempted before retrieving the unit by name because symbol comparisons are case sensitive and hence should be more robust ."}}
{"translation": {"code": "public final void addSymbol ( final String symbol , final String name ) throws NoSuchUnitException , UnitExistsException { addAlias ( null , name , symbol , null ) ; }", "nl": "Adds a symbol for a unit already in the database ."}}
{"translation": {"code": "public static UnitName newUnitName ( final String name , final String plural , final String symbol ) throws NameException { return new UnitName ( name , plural , symbol ) ; }", "nl": "Factory method for constructing a UnitName from a name a plural form of the name and a symbol ."}}
{"translation": {"code": "public boolean isReciprocalOf ( final Factor that ) { return getBase ( ) . equals ( that . getBase ( ) ) && getExponent ( ) == - that . getExponent ( ) ; }", "nl": "Indicates if this Factor is the reciprocal of another Factor ."}}
{"translation": {"code": "void addDimensionsToNetcdfFile ( NetcdfFile ncfile , Group g ) { if ( ! isVertDimensionUsed ( ) ) return ; int nlevs = levels . size ( ) ; if ( coordValues != null ) nlevs = coordValues . length ; ncfile . addDimension ( g , new Dimension ( getVariableName ( ) , nlevs , true ) ) ; }", "nl": "Add this coord as a dimension to the netCDF file"}}
{"translation": {"code": "private static TimeSeries createDataset ( String name , double base , RegularTimePeriod start , int count ) { TimeSeries series = new TimeSeries ( name , start . getClass ( ) ) ; RegularTimePeriod period = start ; double value = base ; for ( int i = 0 ; i < count ; i ++ ) { series . add ( period , value ) ; period = period . next ( ) ; value = value * ( 1 + ( Math . random ( ) - 0.495 ) / 10.0 ) ; } return series ; }", "nl": "Creates the demo chart ."}}
{"translation": {"code": "private void showTimeSeriesAll ( java . util . List < LogReader . Log > logs ) { TimeSeries bytesSentData = new TimeSeries ( \"Bytes Sent\" , Minute . class ) ; TimeSeries timeTookData = new TimeSeries ( \"Average Latency\" , Minute . class ) ; TimeSeries nreqData = new TimeSeries ( \"Number of Requests\" , Minute . class ) ; String intervalS = \"5 minute\" ; // interval.getText().trim(); // if (intervalS.length() == 0) intervalS = \"5 minute\"; long period = 1000 * 60 * 5 ; try { TimeDuration tu = new TimeDuration ( intervalS ) ; period = ( long ) ( 1000 * tu . getValueInSeconds ( ) ) ; } catch ( Exception e ) { System . out . printf ( \"Illegal Time interval=%s %n\" , intervalS ) ; } long current = 0 ; long bytes = 0 ; long timeTook = 0 ; long total_count = 0 ; long count = 0 ; for ( LogReader . Log log : logs ) { long msecs = log . date ; if ( msecs - current > period ) { if ( current > 0 ) { total_count += count ; addPoint ( bytesSentData , timeTookData , nreqData , new Date ( current ) , bytes , count , timeTook ) ; } bytes = 0 ; count = 0 ; timeTook = 0 ; current = msecs ; } bytes += log . getBytes ( ) ; timeTook += log . getMsecs ( ) ; count ++ ; } if ( count > 0 ) addPoint ( bytesSentData , timeTookData , nreqData , new Date ( current ) , bytes , count , timeTook ) ; total_count += count ; System . out . printf ( \"showTimeSeriesAll: total_count = %d logs = %d%n\" , total_count , logs . size ( ) ) ; MultipleAxisChart mc = new MultipleAxisChart ( \"Access Logs\" , intervalS + \" average\" , \"Mbytes Sent\" , bytesSentData ) ; mc . addSeries ( \"Number of Requests\" , nreqData ) ; mc . addSeries ( \"Average Latency (secs)\" , timeTookData ) ; mc . finish ( new java . awt . Dimension ( 1000 , 1000 ) ) ; //MultipleAxisChart mc = new MultipleAxisChart(\"Bytes Sent\", \"5 min average\", \"Mbytes/sec\", bytesSentData); //Chart c2 = new Chart(\"Average Latency\", \"5 min average\", \"Millisecs\", timeTookData); //Chart c3 = new Chart(\"Number of Requests/sec\", \"5 min average\", \"\", nreqData); timeSeriesPanel . removeAll ( ) ; timeSeriesPanel . add ( mc ) ; }", "nl": "construct the TImeSeries plot for the list of logs passed in"}}
{"translation": {"code": "public static void main ( String [ ] args ) { TimeSeries dataset1 = createDataset ( \"Series 1\" , 100.0 , new Minute ( ) , 200 ) ; MultipleAxisChart demo = new MultipleAxisChart ( \"Multiple Axis Demo 1\" , \"Time of Day\" , \"Primary Range Axis\" , dataset1 ) ; /* AXIS 2\n    NumberAxis axis2 = new NumberAxis(\"Range Axis 2\");\n    axis2.setFixedDimension(10.0);\n    axis2.setAutoRangeIncludesZero(false);\n    plot.setRangeAxis(1, axis2);\n    plot.setRangeAxisLocation(1, AxisLocation.BOTTOM_OR_LEFT); /\n\n    plot.setDataset(1, dataset2);\n    plot.mapDatasetToRangeAxis(1, 1);\n    XYItemRenderer renderer2 = new StandardXYItemRenderer();\n    plot.setRenderer(1, renderer2); */ TimeSeries dataset2 = createDataset ( \"Series 2\" , 1000.0 , new Minute ( ) , 170 ) ; demo . addSeries ( \"Range Axis 2\" , dataset2 ) ; /*     // AXIS 3\n    NumberAxis axis3 = new NumberAxis(\"Range Axis 3\");\n    plot.setRangeAxis(2, axis3);\n\n    XYDataset dataset3 = createDataset(\"Series 3\", 10000.0, new Minute(), 170);\n    plot.setDataset(2, dataset3);\n    plot.mapDatasetToRangeAxis(2, 2);\n    XYItemRenderer renderer3 = new StandardXYItemRenderer();\n    plot.setRenderer(2, renderer3);\n    */ TimeSeries dataset3 = createDataset ( \"Series 3\" , 10000.0 , new Minute ( ) , 170 ) ; demo . addSeries ( \"Range Axis 3\" , dataset3 ) ; /* AXIS 4\n    NumberAxis axis4 = new NumberAxis(\"Range Axis 4\");\n    plot.setRangeAxis(3, axis4);\n\n    XYDataset dataset4 = createDataset(\"Series 4\", 25.0, new Minute(), 200);\n    plot.setDataset(3, dataset4);\n    plot.mapDatasetToRangeAxis(3, 3);\n\n    XYItemRenderer renderer4 = new StandardXYItemRenderer();\n    plot.setRenderer(3, renderer4); */ TimeSeries dataset4 = createDataset ( \"Series 4\" , 25.0 , new Minute ( ) , 200 ) ; demo . addSeries ( \"Range Axis 4\" , dataset4 ) ; demo . finish ( new java . awt . Dimension ( 600 , 270 ) ) ; JFrame frame = new JFrame ( \"Demovabulous \" ) ; frame . getContentPane ( ) . add ( demo , BorderLayout . CENTER ) ; frame . setSize ( 640 , 480 ) ; frame . setVisible ( true ) ; frame . setDefaultCloseOperation ( JFrame . EXIT_ON_CLOSE ) ; }", "nl": "Starting point for the demonstration application ."}}
{"translation": {"code": "@ Override protected Unit myMultiplyBy ( final Unit that ) throws MultiplyException { return that instanceof ScaledUnit ? new ScaledUnit ( getScale ( ) * ( ( ScaledUnit ) that ) . getScale ( ) , getUnit ( ) . multiplyBy ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) : new ScaledUnit ( getScale ( ) , getUnit ( ) . multiplyBy ( that ) ) ; }", "nl": "Multiplies this unit by another unit ."}}
{"translation": {"code": "public float [ ] toDerivedUnit ( final float [ ] input , final float [ ] output ) throws ConversionException { for ( int i = input . length ; -- i >= 0 ; ) { output [ i ] = ( float ) ( Math . exp ( input [ i ] * lnBase ) ) ; } return reference . toDerivedUnit ( output , output ) ; }", "nl": "Converts values in this unit to the equivalent values in the convertible derived unit ."}}
{"translation": {"code": "@ Override protected Unit myRaiseTo ( final int power ) throws RaiseException { if ( power == 0 ) { return DerivedUnitImpl . DIMENSIONLESS ; } if ( power == 1 ) { return this ; } throw new RaiseException ( this ) ; }", "nl": "Raise this unit to a power ."}}
{"translation": {"code": "public final boolean isDimensionless ( ) { for ( int i = _factors . length ; -- i >= 0 ; ) { if ( ! _factors [ i ] . isDimensionless ( ) ) { return false ; } } return true ; }", "nl": "Indicates if this dimension is dimensionless . A dimension is dimensionless if it has no Factor - s or if all Factor - s are themselves dimensionless ."}}
{"translation": {"code": "public static UnknownUnit create ( String name ) throws NameException { UnknownUnit unit ; name = name . toLowerCase ( ) ; synchronized ( map ) { unit = map . get ( name ) ; if ( unit == null ) { unit = new UnknownUnit ( name ) ; map . put ( unit . getName ( ) , unit ) ; map . put ( unit . getPlural ( ) , unit ) ; } } return unit ; }", "nl": "Factory method for constructing an unknown unit from a name ."}}
{"translation": {"code": "protected Factor [ ] pow ( final int power ) { Factor [ ] factors ; if ( power == 0 ) { factors = new Factor [ 0 ] ; } else { factors = getFactors ( ) ; if ( power != 1 ) { for ( int i = factors . length ; -- i >= 0 ; ) { factors [ i ] = factors [ i ] . pow ( power ) ; } } } return factors ; }", "nl": "Raises this dimension to a power ."}}
{"translation": {"code": "protected Factor [ ] mult ( final Dimension that ) { // relys on _factors always sorted final Factor [ ] factors1 = _factors ; final Factor [ ] factors2 = that . _factors ; int i1 = 0 ; int i2 = 0 ; int k = 0 ; Factor [ ] newFactors = new Factor [ factors1 . length + factors2 . length ] ; for ( ; ; ) { if ( i1 == factors1 . length ) { final int n = factors2 . length - i2 ; System . arraycopy ( factors2 , i2 , newFactors , k , n ) ; k += n ; break ; } if ( i2 == factors2 . length ) { final int n = factors1 . length - i1 ; System . arraycopy ( factors1 , i1 , newFactors , k , n ) ; k += n ; break ; } final Factor f1 = factors1 [ i1 ] ; final Factor f2 = factors2 [ i2 ] ; final int comp = f1 . getID ( ) . compareTo ( f2 . getID ( ) ) ; if ( comp < 0 ) { newFactors [ k ++ ] = f1 ; i1 ++ ; } else if ( comp == 0 ) { final int exponent = f1 . getExponent ( ) + f2 . getExponent ( ) ; if ( exponent != 0 ) { newFactors [ k ++ ] = new Factor ( f1 , exponent ) ; } i1 ++ ; i2 ++ ; } else { newFactors [ k ++ ] = f2 ; i2 ++ ; } } if ( k < newFactors . length ) { final Factor [ ] tmp = new Factor [ k ] ; System . arraycopy ( newFactors , 0 , tmp , 0 , k ) ; newFactors = tmp ; } return newFactors ; }", "nl": "Multiplies this dimension by another dimension ."}}
{"translation": {"code": "public final Factor [ ] getFactors ( ) { final Factor [ ] factors = new Factor [ _factors . length ] ; System . arraycopy ( _factors , 0 , factors , 0 , factors . length ) ; return factors ; }", "nl": "Returns the array of Factor - s constituting this dimension ."}}
{"translation": {"code": "public String makeLabel ( final String quantityID ) { final StringBuilder buf = new StringBuilder ( quantityID ) ; if ( quantityID . contains ( \" \" ) ) { buf . insert ( 0 , ' ' ) . append ( ' ' ) ; } buf . append ( ' ' ) ; final int start = buf . length ( ) ; buf . append ( toString ( ) ) ; if ( buf . substring ( start ) . indexOf ( ' ' ) != - 1 ) { buf . insert ( start , ' ' ) . append ( ' ' ) ; } return buf . toString ( ) ; }", "nl": "Returns a label for a quantity in this unit ."}}
{"translation": {"code": "public boolean isCompatible ( final Unit that ) { // jeffm: for some reason just calling getDerivedUnit().equals(...) // with jikes 1.1.7 as the compiler causes the jvm to crash. // The Unit u1=... does not crash. final Unit u1 = getDerivedUnit ( ) ; return u1 . equals ( that . getDerivedUnit ( ) ) ; // return getDerivedUnit().equals(that.getDerivedUnit()); }", "nl": "Indicates if numeric values in this unit are convertible with another unit ."}}
{"translation": {"code": "private static UnitName dimensionlessID ( ) { UnitName id ; try { id = UnitName . newUnitName ( \"1\" , \"1\" , \"1\" ) ; } catch ( final NameException e ) { id = null ; } return id ; }", "nl": "Returns the identifiers associated with the dimensionless derived unit ."}}
{"translation": {"code": "@ Override protected Unit myDivideBy ( final Unit that ) throws OperationException { return that instanceof ScaledUnit ? new ScaledUnit ( getScale ( ) / ( ( ScaledUnit ) that ) . getScale ( ) , getUnit ( ) . divideBy ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) : new ScaledUnit ( getScale ( ) , getUnit ( ) . divideBy ( that ) ) ; }", "nl": "Divides this unit by another unit ."}}
{"translation": {"code": "@ Override protected Unit myDivideBy ( final Unit that ) throws OperationException { Unit result ; if ( dimension . getRank ( ) == 0 ) { result = that . raiseTo ( - 1 ) ; } else { if ( ! ( that instanceof DerivedUnit ) ) { result = that . divideInto ( this ) ; } else { final UnitDimension thatDimension = ( ( DerivedUnit ) that ) . getDimension ( ) ; result = thatDimension . getRank ( ) == 0 ? this : new DerivedUnitImpl ( dimension . divideBy ( thatDimension ) ) ; } } return result ; }", "nl": "Divides this derived unit by another ."}}
{"translation": {"code": "public final float [ ] toDerivedUnit ( final float [ ] input , final float [ ] output ) { if ( input != output ) { System . arraycopy ( input , 0 , output , 0 , input . length ) ; } return output ; }", "nl": "Converts numerical values from this unit to the derived unit . Obviously the numerical values are unchanged ."}}
{"translation": {"code": "@ Override public final boolean isCompatible ( final Unit that ) { final DerivedUnit unit = that . getDerivedUnit ( ) ; return equals ( unit ) || isReciprocalOf ( unit ) ; }", "nl": "Indicates if values in this unit are convertible with another unit ."}}
{"translation": {"code": "public final boolean isReciprocalOf ( final Dimension that ) { final Factor [ ] theseFactors = _factors ; final Factor [ ] thoseFactors = that . _factors ; boolean isReciprocalOf ; if ( theseFactors . length != thoseFactors . length ) { isReciprocalOf = false ; } else { int i ; for ( i = theseFactors . length ; -- i >= 0 ; ) { if ( ! theseFactors [ i ] . isReciprocalOf ( thoseFactors [ i ] ) ) { break ; } } isReciprocalOf = i < 0 ; } return isReciprocalOf ; }", "nl": "Indicates if this Dimension is the reciprocal of another dimension ."}}
{"translation": {"code": "@ Override protected Unit myMultiplyBy ( final Unit that ) throws MultiplyException { Unit result ; if ( dimension . getRank ( ) == 0 ) { result = that ; } else { if ( ! ( that instanceof DerivedUnit ) ) { result = that . multiplyBy ( this ) ; } else { final UnitDimension thatDimension = ( ( DerivedUnit ) that ) . getDimension ( ) ; result = thatDimension . getRank ( ) == 0 ? this : new DerivedUnitImpl ( dimension . multiplyBy ( thatDimension ) ) ; } } return result ; }", "nl": "Multiplies this derived unit by another ."}}
{"translation": {"code": "@ Override protected Unit myDivideInto ( final Unit that ) throws OperationException { return that instanceof ScaledUnit ? new ScaledUnit ( ( ( ScaledUnit ) that ) . getScale ( ) / getScale ( ) , getUnit ( ) . divideInto ( ( ( ScaledUnit ) that ) . getUnit ( ) ) ) : new ScaledUnit ( 1 / getScale ( ) , getUnit ( ) . divideInto ( that ) ) ; }", "nl": "Divides this unit into another unit ."}}
{"translation": {"code": "@ Override protected Unit myDivideInto ( final Unit that ) throws OperationException { return that instanceof OffsetUnit ? getUnit ( ) . divideInto ( ( ( OffsetUnit ) that ) . getUnit ( ) ) : getUnit ( ) . divideInto ( that ) ; }", "nl": "Divide this unit into another unit ."}}
{"translation": {"code": "public double toDerivedUnit ( final double amount ) throws ConversionException { if ( ! ( _unit instanceof DerivableUnit ) ) { throw new ConversionException ( this , getDerivedUnit ( ) ) ; } return ( ( DerivableUnit ) _unit ) . toDerivedUnit ( amount * getScale ( ) ) ; }", "nl": "Converts a numeric value from this unit to the underlying derived unit ."}}
{"translation": {"code": "public double fromDerivedUnit ( final double amount ) throws ConversionException { if ( ! ( _unit instanceof DerivableUnit ) ) { throw new ConversionException ( getDerivedUnit ( ) , this ) ; } return ( ( DerivableUnit ) getUnit ( ) ) . fromDerivedUnit ( amount ) - getOffset ( ) ; }", "nl": "Converts a value in the convertible derived unit to the equivalent value in this unit ."}}
{"translation": {"code": "public float [ ] toDerivedUnit ( final float [ ] input , final float [ ] output ) throws ConversionException { final float scale = ( float ) getScale ( ) ; for ( int i = input . length ; -- i >= 0 ; ) { output [ i ] = input [ i ] * scale ; } if ( ! ( _unit instanceof DerivableUnit ) ) { throw new ConversionException ( this , getDerivedUnit ( ) ) ; } return ( ( DerivableUnit ) getUnit ( ) ) . toDerivedUnit ( output , output ) ; }", "nl": "Converts numeric values from this unit to the underlying derived unit ."}}
{"translation": {"code": "public double fromDerivedUnit ( final double amount ) throws ConversionException { if ( ! ( _unit instanceof DerivableUnit ) ) { throw new ConversionException ( getDerivedUnit ( ) , this ) ; } return ( ( DerivableUnit ) getUnit ( ) ) . fromDerivedUnit ( amount ) / getScale ( ) ; }", "nl": "Converts a numeric value from the underlying derived unit to this unit ."}}
{"translation": {"code": "public String getCanonicalString ( ) { return DerivedUnitImpl . DIMENSIONLESS . equals ( _unit ) ? Double . toString ( getScale ( ) ) : Double . toString ( getScale ( ) ) + \" \" + _unit . toString ( ) ; }", "nl": "Returns the canonical string representation of the unit ."}}
{"translation": {"code": "public double toDerivedUnit ( final double amount ) throws ConversionException { if ( ! ( _unit instanceof DerivableUnit ) ) { throw new ConversionException ( this , getDerivedUnit ( ) ) ; } return ( ( DerivableUnit ) getUnit ( ) ) . toDerivedUnit ( amount + getOffset ( ) ) ; }", "nl": "Converts a value in this unit to the equivalent value in the convertible derived unit ."}}
{"translation": {"code": "public static synchronized BaseUnit getOrCreate ( final UnitName id , final BaseQuantity baseQuantity ) throws NameException , UnitExistsException { BaseUnit baseUnit ; final BaseUnit nameUnit = nameMap . get ( id ) ; final BaseUnit quantityUnit = quantityMap . get ( baseQuantity ) ; if ( nameUnit != null || quantityUnit != null ) { baseUnit = nameUnit != null ? nameUnit : quantityUnit ; if ( ( nameUnit != null && ! baseQuantity . equals ( nameUnit . getBaseQuantity ( ) ) ) || ( quantityUnit != null && ! id . equals ( quantityUnit . getUnitName ( ) ) ) ) { throw new UnitExistsException ( \"Attempt to incompatibly redefine base unit \\\"\" + baseUnit + ' ' ) ; } } else { baseUnit = new BaseUnit ( id , baseQuantity ) ; quantityMap . put ( baseQuantity , baseUnit ) ; nameMap . put ( id , baseUnit ) ; } return baseUnit ; }", "nl": "Factory method for creating a new BaseUnit or obtaining a previously - created one ."}}
{"translation": {"code": "@ Override protected Unit myRaiseTo ( final int power ) throws RaiseException { return new ScaledUnit ( Math . pow ( getScale ( ) , power ) , getUnit ( ) . raiseTo ( power ) ) ; }", "nl": "Raises this unit to a power ."}}
{"translation": {"code": "public static RegExpAndDurationTimeCoverageEnhancer getInstanceToMatchOnDatasetName ( String matchPattern , String substitutionPattern , String duration ) { return new RegExpAndDurationTimeCoverageEnhancer ( matchPattern , substitutionPattern , duration , MatchTarget . DATASET_NAME ) ; }", "nl": "Factory method that returns a RegExpAndDurationTimeCoverageEnhancer instance that will apply the match pattern to the dataset name ."}}
{"translation": {"code": "public static RegExpAndDurationTimeCoverageEnhancer getInstanceToMatchOnDatasetPath ( String matchPattern , String substitutionPattern , String duration ) { return new RegExpAndDurationTimeCoverageEnhancer ( matchPattern , substitutionPattern , duration , MatchTarget . DATASET_PATH ) ; }", "nl": "Factory method that returns a RegExpAndDurationTimeCoverageEnhancer instance that will apply the match pattern to the dataset path ."}}
{"translation": {"code": "public Match match ( String path ) { SortedMap < String , Match > tail = treeMap . tailMap ( path ) ; if ( tail . isEmpty ( ) ) return null ; String after = tail . firstKey ( ) ; //System.out.println(\"  \"+path+\"; after=\"+afterPath);\r if ( path . startsWith ( after ) ) // common case\r return treeMap . get ( after ) ; // have to check more, until no common starting chars\r for ( String key : tail . keySet ( ) ) { if ( path . startsWith ( key ) ) return treeMap . get ( key ) ; // terminate when there's no match at all.\r if ( StringUtil2 . match ( path , key ) == 0 ) break ; } return null ; }", "nl": "Find the longest match ."}}
{"translation": {"code": "public void addDirectoryScan ( String dirName , String suffix , String regexpPatternString , String subdirsS , String olderS , Object auxInfo ) { CompositeMFileFilter filters = new CompositeMFileFilter ( ) ; if ( null != regexpPatternString ) filters . addIncludeFilter ( new RegExpMatchOnName ( regexpPatternString ) ) ; else if ( suffix != null ) filters . addIncludeFilter ( new WildcardMatchOnPath ( \"*\" + suffix + \"$\" ) ) ; if ( olderS != null ) { try { TimeDuration tu = new TimeDuration ( olderS ) ; filters . addAndFilter ( new LastModifiedLimit ( ( long ) ( 1000 * tu . getValueInSeconds ( ) ) ) ) ; } catch ( Exception e ) { logger . error ( collectionName + \": Invalid time unit for olderThan = {}\" , olderS ) ; } } boolean wantSubdirs = true ; if ( ( subdirsS != null ) && subdirsS . equalsIgnoreCase ( \"false\" ) ) wantSubdirs = false ; CollectionConfig mc = new CollectionConfig ( dirName , dirName , wantSubdirs , filters , auxInfo ) ; // create name\r StringBuilder sb = new StringBuilder ( dirName ) ; if ( wantSubdirs ) sb . append ( \"**/\" ) ; if ( null != regexpPatternString ) sb . append ( regexpPatternString ) ; else if ( suffix != null ) sb . append ( suffix ) ; else sb . append ( \"noFilter\" ) ; collectionName = sb . toString ( ) ; scanList . add ( mc ) ; }", "nl": "Add a directory scan to the collection"}}
{"translation": {"code": "@ Override public boolean isScanNeeded ( ) { // see if we need to recheck\r if ( recheck == null ) { logger . debug ( \"{}: scan not needed, recheck null\" , collectionName ) ; return false ; } if ( ! hasScans ( ) ) { logger . debug ( \"{}: scan not needed, no scanners\" , collectionName ) ; return false ; } synchronized ( this ) { if ( map == null && ! isStatic ( ) ) { logger . debug ( \"{}: scan needed, never scanned\" , collectionName ) ; return true ; } } Date now = new Date ( ) ; Date lastCheckedDate = new Date ( getLastScanned ( ) ) ; Date need = recheck . add ( lastCheckedDate ) ; if ( now . before ( need ) ) { logger . debug ( \"{}: scan not needed, last scanned={}, now={}\" , collectionName , lastCheckedDate , now ) ; return false ; } return true ; }", "nl": "Compute if synchronous scan is needed . True if recheck is true and enough time has elapsed ."}}
{"translation": {"code": "public static List < InvCatalogRef > findAllCatRefsInDatasetTree ( List < InvDataset > datasets , StringBuilder log , boolean onlyRelativeUrls ) { List < InvCatalogRef > catRefList = new ArrayList < InvCatalogRef > ( ) ; for ( InvDataset invds : datasets ) { InvDatasetImpl curDs = ( InvDatasetImpl ) invds ; if ( curDs instanceof InvDatasetScan ) continue ; if ( curDs instanceof InvCatalogRef ) { InvCatalogRef catRef = ( InvCatalogRef ) curDs ; String name = catRef . getName ( ) ; String href = catRef . getXlinkHref ( ) ; URI uri ; try { uri = new URI ( href ) ; } catch ( URISyntaxException e ) { log . append ( log . length ( ) > 0 ? \"\\n\" : \"\" ) . append ( \"***WARN - CatalogRef [\" ) . append ( name ) . append ( \"] with bad HREF [\" ) . append ( href ) . append ( \"] \" ) ; continue ; } if ( onlyRelativeUrls && uri . isAbsolute ( ) ) continue ; catRefList . add ( catRef ) ; continue ; } if ( curDs . hasNestedDatasets ( ) ) catRefList . addAll ( findAllCatRefsInDatasetTree ( curDs . getDatasets ( ) , log , onlyRelativeUrls ) ) ; } return catRefList ; }", "nl": "Find all catalogRef elements in the dataset tree formed by the given dataset list ."}}
{"translation": {"code": "@ Override public PointFeatureCollection flatten ( List < String > stationNames , CalendarDateRange dateRange , List < VariableSimpleIF > varList ) throws IOException { if ( ( stationNames == null ) || ( stationNames . size ( ) == 0 ) ) return new StationTimeSeriesCollectionFlattened ( this , dateRange ) ; List < StationFeature > subsetStations = getStationHelper ( ) . getStationFeaturesFromNames ( stationNames ) ; return new StationTimeSeriesCollectionFlattened ( new StationSubset ( this , subsetStations ) , dateRange ) ; }", "nl": "might need to override for efficiency"}}
{"translation": {"code": "public void addDimensionsToNetcdfFile ( NetcdfFile ncfile , Group g ) { ncfile . addDimension ( g , new Dimension ( getName ( ) , getNEnsembles ( ) , true ) ) ; }", "nl": "Add this as a dimension to a netCDF file"}}
{"translation": {"code": "public void extend ( Date d ) { if ( d . before ( getStart ( ) . getDate ( ) ) ) setStart ( new DateType ( false , d ) ) ; if ( getEnd ( ) . before ( d ) ) setEnd ( new DateType ( false , d ) ) ; }", "nl": "Extend this date range by the given Date ."}}
{"translation": {"code": "StationFeature makeStation ( StructureData stationData ) { if ( stnVE . isMissing ( stationData ) ) return null ; String stationName = stnVE . getCoordValueAsString ( stationData ) ; String stationDesc = ( stnDescVE == null ) ? \"\" : stnDescVE . getCoordValueAsString ( stationData ) ; String stnWmoId = ( wmoVE == null ) ? \"\" : wmoVE . getCoordValueAsString ( stationData ) ; double lat = latVE . getCoordValue ( stationData ) ; double lon = lonVE . getCoordValue ( stationData ) ; double elev = ( stnAltVE == null ) ? Double . NaN : stnAltVE . getCoordValue ( stationData ) ; // missing lat, lon means skip this station if ( Double . isNaN ( lat ) || Double . isNaN ( lon ) ) return null ; return new StationFeatureImpl ( stationName , stationDesc , stnWmoId , lat , lon , elev , - 1 , stationData ) ; }", "nl": "also called from StandardPointFeatureIterator"}}
{"translation": {"code": "public int hideMember ( Member m ) { if ( m == null ) return - 1 ; int index = members . indexOf ( m ) ; members . remove ( m ) ; if ( memberHash != null ) memberHash . remove ( m . getName ( ) ) ; return index ; }", "nl": "Remove the given member"}}
{"translation": {"code": "public static double [ ] ECFtoLLA ( double x , double y , double z , double a , double b ) { double longitude = Math . atan2 ( y , x ) ; double ePrimeSquared = ( a * a - b * b ) / ( b * b ) ; double p = Math . sqrt ( x * x + y * y ) ; double theta = Math . atan ( ( z * a ) / ( p * b ) ) ; double sineTheta = Math . sin ( theta ) ; double cosTheta = Math . cos ( theta ) ; double f = 1 / 298.257223563 ; double e2 = 2 * f - f * f ; double top = z + ePrimeSquared * b * sineTheta * sineTheta * sineTheta ; double bottom = p - e2 * a * cosTheta * cosTheta * cosTheta ; double geodeticLat = Math . atan ( top / bottom ) ; double sineLat = Math . sin ( geodeticLat ) ; double N = a / Math . sqrt ( 1 - e2 * sineLat * sineLat ) ; double altitude = ( p / Math . cos ( geodeticLat ) ) - N ; // maintain longitude btw -PI and PI\r if ( longitude > Math . PI ) { longitude -= 2 * Math . PI ; } else if ( longitude < - Math . PI ) { longitude += 2 * Math . PI ; } return new double [ ] { geodeticLat , longitude , altitude } ; }", "nl": "comparing api to others"}}
{"translation": {"code": "static public List < String > getAllFiles ( ) { if ( null == allFiles ) return null ; List < String > result = new ArrayList <> ( ) ; result . addAll ( allFiles ) ; Collections . sort ( result ) ; return result ; }", "nl": "Debugging do not use ."}}
{"translation": {"code": "private Array makeC ( Array s , double a , double b ) { int nz = ( int ) s . getSize ( ) ; Index sIndex = s . getIndex ( ) ; if ( a == 0 ) return s ; // per R. Signell, USGS\r ArrayDouble . D1 c = new ArrayDouble . D1 ( nz ) ; double fac1 = 1.0 - b ; double denom1 = 1.0 / Math . sinh ( a ) ; double denom2 = 1.0 / ( 2.0 * Math . tanh ( 0.5 * a ) ) ; for ( int i = 0 ; i < nz ; i ++ ) { double sz = s . getDouble ( sIndex . set ( i ) ) ; double term1 = fac1 * Math . sinh ( a * sz ) * denom1 ; double term2 = b * ( Math . tanh ( a * ( sz + 0.5 ) ) * denom2 - 0.5 ) ; c . set ( i , term1 + term2 ) ; } return c ; }", "nl": "Make the C array"}}
{"translation": {"code": "private double [ ] extrapinterpolate ( double [ ] array ) { int n = array . length ; double [ ] d = new double [ n + 1 ] ; //end points from linear extrapolation\r //equations confirmed by Christopher Lindholm\r d [ 0 ] = 1.5 * array [ 0 ] - 0.5 * array [ 1 ] ; d [ n ] = 1.5 * array [ n - 1 ] - 0.5 * array [ n - 2 ] ; //inner points from simple average\r for ( int i = 1 ; i < n ; i ++ ) { d [ i ] = 0.5 * ( array [ i - 1 ] + array [ i ] ) ; } return d ; }", "nl": "Add one element to the array by linear interpolation and extrapolation at the ends ."}}
{"translation": {"code": "public VerticalTransform subset ( Range t_range , Range z_range , Range y_range , Range x_range ) throws ucar . ma2 . InvalidRangeException { return new VerticalTransformSubset ( this , t_range , z_range , y_range , x_range ) ; }", "nl": "Create a subset of this VerticalTransform ."}}
{"translation": {"code": "private ArrayDouble . D3 addStagger ( ArrayDouble . D3 array , int dimIndex ) { //ADD: assert 0<=dimIndex<=2\r int [ ] shape = array . getShape ( ) ; int [ ] newShape = new int [ 3 ] ; System . arraycopy ( shape , 0 , newShape , 0 , 3 ) ; newShape [ dimIndex ] ++ ; int ni = newShape [ 0 ] ; int nj = newShape [ 1 ] ; int nk = newShape [ 2 ] ; ArrayDouble . D3 newArray = new ArrayDouble . D3 ( ni , nj , nk ) ; //Index newIndex = newArray.getIndex();\r //extract 1d array to be extended\r int n = shape [ dimIndex ] ; //length of extracted array\r double [ ] d = new double [ n ] ; //tmp array to hold extracted values\r int [ ] eshape = new int [ 3 ] ; //shape of extracted array\r int [ ] neweshape = new int [ 3 ] ; //shape of new array slice to write into\r for ( int i = 0 ; i < 3 ; i ++ ) { eshape [ i ] = ( i == dimIndex ) ? n : 1 ; neweshape [ i ] = ( i == dimIndex ) ? n + 1 : 1 ; } int [ ] origin = new int [ 3 ] ; try { //loop through the other 2 dimensions and \"extrapinterpolate\" the other\r for ( int i = 0 ; i < ( ( dimIndex == 0 ) ? 1 : ni ) ; i ++ ) { for ( int j = 0 ; j < ( ( dimIndex == 1 ) ? 1 : nj ) ; j ++ ) { for ( int k = 0 ; k < ( ( dimIndex == 2 ) ? 1 : nk ) ; k ++ ) { origin [ 0 ] = i ; origin [ 1 ] = j ; origin [ 2 ] = k ; IndexIterator it = array . section ( origin , eshape ) . getIndexIterator ( ) ; for ( int l = 0 ; l < n ; l ++ ) { d [ l ] = it . getDoubleNext ( ) ; //get the original values\r } double [ ] d2 = extrapinterpolate ( d ) ; //compute new values\r //define slice of new array to write into\r IndexIterator newit = newArray . section ( origin , neweshape ) . getIndexIterator ( ) ; for ( int l = 0 ; l < n + 1 ; l ++ ) { newit . setDoubleNext ( d2 [ l ] ) ; } } } } } catch ( InvalidRangeException e ) { //ADD: report error?\r return null ; } return newArray ; }", "nl": "Add 1 to the size of the array for the given dimension . Use linear average and interpolation to fill in the values ."}}
{"translation": {"code": "public void save ( ) { collectionNameTable . saveState ( false ) ; dataTable . saveState ( false ) ; prefs . putBeanObject ( \"InfoWindowBounds\" , infoWindow . getBounds ( ) ) ; prefs . putInt ( \"splitPos\" , split . getDividerLocation ( ) ) ; }", "nl": "private MetadataManager mm ;"}}
{"translation": {"code": "void finish ( ) { gridList = new ArrayList <> ( uvHash . values ( ) ) ; Collections . sort ( gridList ) ; // find the common coordinates\r for ( GridVariable grid : gridList ) { grid . finish ( ) ; } // assign sequence number for time\r int seqno = 0 ; for ( TimeCoord tc : timeCoords ) tc . setId ( seqno ++ ) ; // assign sequence number for vertical coords with same name\r HashMap < String , List < VertCoord > > map = new HashMap <> ( ) ; for ( VertCoord vc : vertCoords ) { List < VertCoord > list = map . get ( vc . getName ( ) ) ; if ( list == null ) { list = new ArrayList <> ( ) ; map . put ( vc . getName ( ) , list ) ; } list . add ( vc ) ; } for ( List < VertCoord > list : map . values ( ) ) { if ( list . size ( ) > 0 ) { int count = 0 ; for ( VertCoord vc : list ) { if ( count > 0 ) vc . setName ( vc . getName ( ) + count ) ; count ++ ; } } } }", "nl": "call after adding all runs"}}
{"translation": {"code": "private FmrcInv makeFmrcInv ( Formatter debug ) throws IOException { try { Map < CalendarDate , FmrInv > fmrMap = new HashMap <> ( ) ; // all files are grouped by run date in an FmrInv\r List < FmrInv > fmrList = new ArrayList <> ( ) ; // an fmrc is a collection of fmr\r // get the inventory, sorted by path\r for ( MFile f : manager . getFilesSorted ( ) ) { Map < String , String > filesRunDateMap = ( ( MFileCollectionManager ) manager ) . getFilesRunDateMap ( ) ; CalendarDate runDate ; if ( ! filesRunDateMap . isEmpty ( ) ) { // run time has been defined in NcML FMRC agg by the coord attribute,\r // so explicitly set it in the dataset using the _Coordinate.ModelBaseDate\r // global attribute, otherwise the run time offsets might be incorrectly\r // computed if the incorrect run date is found in GridDatasetInv.java (line\r // 177 with comment // Look: not really right )\r runDate = CalendarDate . parseISOformat ( null , filesRunDateMap . get ( f . getPath ( ) ) ) ; Element element = new Element ( \"netcdf\" , ncNSHttps ) ; Element runDateAttr = ncmlWriter . makeAttributeElement ( new Attribute ( _Coordinate . ModelRunDate , runDate . toString ( ) ) ) ; config . innerNcml = element . addContent ( runDateAttr ) ; } GridDatasetInv inv ; try { inv = GridDatasetInv . open ( manager , f , config . innerNcml ) ; // inventory is discovered for each GDS\r } catch ( IOException ioe ) { logger . warn ( \"Error opening \" + f . getPath ( ) + \"(skipped)\" , ioe ) ; continue ; // skip\r } runDate = inv . getRunDate ( ) ; if ( debug != null ) debug . format ( \"  opened %s rundate = %s%n\" , f . getPath ( ) , inv . getRunDateString ( ) ) ; // add to fmr for that rundate\r FmrInv fmr = fmrMap . get ( runDate ) ; if ( fmr == null ) { fmr = new FmrInv ( runDate ) ; fmrMap . put ( runDate , fmr ) ; fmrList . add ( fmr ) ; } fmr . addDataset ( inv , debug ) ; } if ( debug != null ) debug . format ( \"%n\" ) ; // finish the FmrInv\r Collections . sort ( fmrList ) ; for ( FmrInv fmr : fmrList ) { fmr . finish ( ) ; if ( logger . isDebugEnabled ( ) ) logger . debug ( \"Fmrc:\" + config . name + \": made fmr with rundate=\" + fmr . getRunDate ( ) + \" nfiles= \" + fmr . getFiles ( ) . size ( ) ) ; } return new FmrcInv ( \"fmrc:\" + manager . getCollectionName ( ) , fmrList , config . fmrcConfig . regularize ) ; } catch ( Throwable t ) { logger . error ( \"makeFmrcInv\" , t ) ; throw new RuntimeException ( t ) ; } }", "nl": "scan has been done create FmrcInv"}}
{"translation": {"code": "static public void normalize ( EnsCoord result , List < EnsCoord > ecList ) { List < EnsCoord > extra = new ArrayList <> ( ) ; for ( EnsCoord ec : ecList ) { if ( ! result . equalsData ( ec ) ) { // differences can only be greater\r extra . add ( ec ) ; } } if ( extra . size ( ) == 0 ) return ; for ( EnsCoord ec : extra ) { if ( ec . getNEnsembles ( ) < result . getNEnsembles ( ) ) continue ; result = ec ; } }", "nl": "Extend result with all the values in the list of EnsCoord"}}
{"translation": {"code": "public String writeXML ( Date lastModified ) { XMLOutputter fmt = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; return fmt . outputString ( writeDocument ( lastModified ) ) ; }", "nl": "Write the XML representation to a String ."}}
{"translation": {"code": "static public NcmlCollectionReader open ( String ncmlLocation , Formatter errlog ) throws IOException { if ( ! ncmlLocation . startsWith ( \"http:\" ) && ! ncmlLocation . startsWith ( \"file:\" ) ) ncmlLocation = \"file:\" + ncmlLocation ; URL url = new URL ( ncmlLocation ) ; org . jdom2 . Document doc ; try { SAXBuilder builder = new SAXBuilder ( ) ; if ( debugURL ) System . out . println ( \" NetcdfDataset URL = <\" + url + \">\" ) ; doc = builder . build ( url ) ; } catch ( JDOMException e ) { throw new IOException ( e . getMessage ( ) ) ; } if ( debugXML ) System . out . println ( \" SAXBuilder done\" ) ; return readXML ( doc , errlog , ncmlLocation ) ; }", "nl": "Read an NcML file from a URL location and construct a NcmlCollectionReader from its scan or scanFmrc element ."}}
{"translation": {"code": "public long readToByteChannel11 ( ucar . nc2 . Variable v2 , Section section , WritableByteChannel channel ) throws java . io . IOException , ucar . ma2 . InvalidRangeException { Array data = readData ( v2 , section ) ; float [ ] ftdata = new float [ ( int ) data . getSize ( ) ] ; byte [ ] bytedata = new byte [ ( int ) data . getSize ( ) * 4 ] ; IndexIterator iter = data . getIndexIterator ( ) ; int i = 0 ; ByteBuffer buffer = ByteBuffer . allocateDirect ( bytedata . length ) ; while ( iter . hasNext ( ) ) { ftdata [ i ] = iter . getFloatNext ( ) ; bytedata [ i ] = new Float ( ftdata [ i ] ) . byteValue ( ) ; buffer . put ( bytedata [ i ] ) ; i ++ ; } buffer = ByteBuffer . wrap ( bytedata ) ; // write the bytes to the channel\r int count = channel . write ( buffer ) ; System . out . println ( \"COUNT=\" + count ) ; // check if all bytes where written\r if ( buffer . hasRemaining ( ) ) { // if not all bytes were written, move the unwritten bytes to the beginning and\r // set position just after the last unwritten byte\r buffer . compact ( ) ; } else { buffer . clear ( ) ; } return ( long ) count ; }", "nl": "Read data from a top level Variable and send data to a WritableByteChannel ."}}
{"translation": {"code": "static float calcAz ( short az0 , short az1 ) { // output in deg\r float azim0 = calcAngle ( az0 ) ; float azim1 = calcAngle ( az1 ) ; float d = 0.0f ; d = Math . abs ( azim0 - azim1 ) ; if ( ( az0 < 0 ) & ( az1 > 0 ) ) { d = Math . abs ( 360.0f - azim0 ) + Math . abs ( azim1 ) ; } double temp = azim0 + d * 0.5 ; if ( temp > 360.0 ) { temp -= 360.0 ; } BigDecimal bd = new BigDecimal ( temp ) ; BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; return result . floatValue ( ) ; }", "nl": "Calculate azimuth of a ray"}}
{"translation": {"code": "static float calcData ( Map < String , Number > recHdr , short dty , byte data ) { short [ ] coef = { 1 , 2 , 3 , 4 } ; // MultiPRF modes\r short multiprf = recHdr . get ( \"multiprf\" ) . shortValue ( ) ; float vNyq = recHdr . get ( \"vNyq\" ) . floatValue ( ) ; double temp = - 999.99 ; switch ( dty ) { default : // dty=1,2 -total_power, reflectivity (dBZ)\r if ( data != 0 ) { temp = ( ( ( int ) data & 0xFF ) - 64 ) * 0.5 ; } break ; case 3 : // dty=3 - mean velocity (m/sec)\r if ( data != 0 ) { temp = ( ( ( ( int ) data & 0xFF ) - 128 ) / 127.0 ) * vNyq * coef [ multiprf ] ; } break ; case 4 : // dty=4 - spectrum width (m/sec)\r if ( data != 0 ) { double v = ( ( ( ( int ) data & 0xFF ) - 128 ) / 127.0 ) * vNyq * coef [ multiprf ] ; temp = ( ( ( int ) data & 0xFF ) / 256.0 ) * v ; } break ; case 5 : // dty=5 - differential reflectivity (dB)\r if ( data != 0 ) { temp = ( ( ( ( int ) data & 0xFF ) - 128 ) / 16.0 ) ; } break ; } BigDecimal bd = new BigDecimal ( temp ) ; BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; return result . floatValue ( ) ; }", "nl": "Calculate data values from raw ingest data"}}
{"translation": {"code": "public Array readIntData ( LayoutRegular index , Variable v2 ) throws IOException { int [ ] var = ( int [ ] ) ( v2 . read ( ) . get1DJavaArray ( v2 . getDataType ( ) ) ) ; int [ ] data = new int [ ( int ) index . getTotalNelems ( ) ] ; while ( index . hasNext ( ) ) { Layout . Chunk chunk = index . next ( ) ; System . arraycopy ( var , ( int ) chunk . getSrcPos ( ) / 4 , data , ( int ) chunk . getDestElem ( ) , chunk . getNelems ( ) ) ; } return Array . factory ( v2 . getDataType ( ) , new int [ ] { ( int ) index . getTotalNelems ( ) } , data ) ; }", "nl": "Read data from a top level Variable of INTEGER data type and return a memory resident Array ."}}
{"translation": {"code": "public Array readData1 ( ucar . nc2 . Variable v2 , Section section ) throws IOException , InvalidRangeException { //doData(raf, ncfile, varList);\r int [ ] sh = section . getShape ( ) ; Array temp = Array . factory ( v2 . getDataType ( ) , sh ) ; long pos0 = 0 ; // Suppose that the data has LayoutRegular\r LayoutRegular index = new LayoutRegular ( pos0 , v2 . getElementSize ( ) , v2 . getShape ( ) , section ) ; if ( v2 . getShortName ( ) . startsWith ( \"time\" ) | v2 . getShortName ( ) . startsWith ( \"numGates\" ) ) { temp = readIntData ( index , v2 ) ; } else { temp = readFloatData ( index , v2 ) ; } return temp ; }", "nl": "Read data from a top level Variable and return a memory resident Array ."}}
{"translation": {"code": "public boolean isValidFile ( ucar . unidata . io . RandomAccessFile raf ) { try { raf . order ( RandomAccessFile . LITTLE_ENDIAN ) ; // The first struct in the file is the product_hdr, which will have the\r // standard structure_header, followed by other embedded structures.\r // Each of these structures also have a structure header. To validate\r // the file we check for a product_hdr (by looking for type 27 in the\r // structure_header), then a product_configuration structure (by looking\r // for type 26 in its structure_header), then checking that that\r // the product_configuration does indicate a type of RAW data (type 15)\r raf . seek ( 0 ) ; short [ ] data = new short [ 13 ] ; raf . readShort ( data , 0 , 13 ) ; return ( data [ 0 ] == ( short ) 27 && data [ 6 ] == ( short ) 26 && data [ 12 ] == ( short ) 15 ) ; } catch ( IOException ioe ) { System . out . println ( \"In isValidFile(): \" + ioe . toString ( ) ) ; return false ; } }", "nl": "Check if this is a valid SIGMET - IRIS file for this IOServiceProvider ."}}
{"translation": {"code": "@ Override protected StationHelper createStationHelper ( ) throws IOException { // read in all the stations with the \"stations\" query StationHelper stationHelper = new StationHelper ( ) ; try ( InputStream in = CdmRemote . sendQuery ( null , uri , \"req=stations\" ) ) { PointStream . MessageType mtype = PointStream . readMagic ( in ) ; if ( mtype != PointStream . MessageType . StationList ) { throw new RuntimeException ( \"Station Request: bad response\" ) ; } int len = NcStream . readVInt ( in ) ; byte [ ] b = new byte [ len ] ; NcStream . readFully ( in , b ) ; PointStreamProto . StationList stationsp = PointStreamProto . StationList . parseFrom ( b ) ; for ( ucar . nc2 . ft . point . remote . PointStreamProto . Station sp : stationsp . getStationsList ( ) ) { //        Station s = new StationImpl(sp.getId(), sp.getDesc(), sp.getWmoId(), sp.getLat(), sp.getLon(), sp.getAlt()); stationHelper . addStation ( new StationFeatureStream ( null , null ) ) ; // LOOK WRONG } return stationHelper ; } }", "nl": "initialize the stationHelper ."}}
{"translation": {"code": "static public float swapFloat ( byte [ ] b , int offset ) { int accum = 0 ; for ( int shiftBy = 0 , i = offset ; shiftBy < 32 ; shiftBy += 8 , i ++ ) accum |= ( [ i ] & 0xff ) << shiftBy ; return Float . intBitsToFloat ( accum ) ; }", "nl": "Returns the float resulting from reversing 4 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "static public char swapChar ( byte [ ] b , int offset ) { // 2 bytes int low = b [ offset ] & 0xff ; int high = b [ offset + 1 ] & 0xff ; return ( char ) ( high << 8 | low ) ; }", "nl": "Returns the char resulting from swapping 2 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "public BoolFunction getBoolFunction ( String name ) throws NoSuchFunctionException { if ( ! boolFunctions . containsKey ( name ) ) { loadNewFunction ( name ) ; } return ( BoolFunction ) boolFunctions . get ( name ) ; }", "nl": "Retrieves a boolean function from the library . If the function is not found the library will attempt to load it using the mechanism described in the class documentation ."}}
{"translation": {"code": "public String getDatasetFilename ( ) { String s = getEncodedName ( ) ; System . out . println ( s ) ; return ( s ) ; }", "nl": "Get the dataset filename ."}}
{"translation": {"code": "public void add ( ServerSideFunction function ) { if ( function instanceof BoolFunction ) { boolFunctions . put ( function . getName ( ) , function ) ; } if ( function instanceof BTFunction ) { btFunctions . put ( function . getName ( ) , function ) ; } }", "nl": "Adds a function to the library . The function will be inspected to determine whether it is a boolean or BaseType function ."}}
{"translation": {"code": "public TopLevelClause newRelOpClause ( int operator , SubClause lhs , List rhs ) throws DAP2ServerSideException { return new RelOpClause ( operator , lhs , rhs ) ; }", "nl": "Generates a clause which which compares subclauses using one of the relative operators supported by the Operator class ."}}
{"translation": {"code": "public TopLevelClause newBoolFunctionClause ( String functionName , List children ) throws DAP2ServerSideException , NoSuchFunctionException { BoolFunction function = functionLibrary . getBoolFunction ( functionName ) ; if ( function == null ) { if ( functionLibrary . getBTFunction ( functionName ) != null ) { throw new NoSuchFunctionException ( \"The function \" + functionName + \"() does not return a \" + \"boolean value, and must be used in a comparison or \" + \"as an argument to another function.\" ) ; } else { throw new NoSuchFunctionException ( \"This server does not support a \" + functionName + \"() function\" ) ; } } return new BoolFunctionClause ( function , children ) ; }", "nl": "Generates a clause which invokes a function that returns a boolean value ."}}
{"translation": {"code": "public SubClause newBTFunctionClause ( String functionName , List children ) throws DAP2ServerSideException , NoSuchFunctionException { BTFunction function = functionLibrary . getBTFunction ( functionName ) ; if ( function == null ) { if ( functionLibrary . getBoolFunction ( functionName ) != null ) { throw new NoSuchFunctionException ( \"The function \" + functionName + \"() cannot be used as a \" + \"sub-expression in a constraint clause\" ) ; } else { throw new NoSuchFunctionException ( \"This server does not support a \" + functionName + \"() function\" ) ; } } return new BTFunctionClause ( function , children ) ; }", "nl": "Generates a clause which invokes a function that returns a BaseType ."}}
{"translation": {"code": "protected void loadNewFunction ( String name ) { try { String fullName = prefix + name ; Class value = Class . forName ( fullName ) ; if ( ( ServerSideFunction . class ) . isAssignableFrom ( value ) ) { add ( ( ServerSideFunction ) value . newInstance ( ) ) ; return ; } } catch ( ClassNotFoundException e ) { } catch ( IllegalAccessException e ) { } catch ( InstantiationException e ) { } }", "nl": "Tries to load a function with the given name ."}}
{"translation": {"code": "public BTFunction getBTFunction ( String name ) throws NoSuchFunctionException { if ( ! btFunctions . containsKey ( name ) ) { loadNewFunction ( name ) ; } return ( BTFunction ) btFunctions . get ( name ) ; }", "nl": "Retrieves a BaseType function from the library . If the function is not found the library will attempt to load it using the mechanism described in the class documentation ."}}
{"translation": {"code": "public synchronized void sendEventExcludeSource ( java . util . EventObject event ) { if ( ! hasListeners || ! enabled ) return ; Object source = event . getSource ( ) ; Object [ ] args = new Object [ 1 ] ; args [ 0 ] = event ; // send event to all listeners except the source ListIterator iter = listeners . listIterator ( ) ; while ( iter . hasNext ( ) ) { Object client = iter . next ( ) ; if ( client == source ) continue ; try { method . invoke ( client , args ) ; } catch ( IllegalAccessException | InvocationTargetException | IllegalArgumentException e ) { e . printStackTrace ( ) ; if ( e . getCause ( ) != null ) e . getCause ( ) . printStackTrace ( ) ; // iter.remove(); logger . error ( \"ListenerManager calling \" + method + \" threw exception \" , e ) ; } } }", "nl": "Send an event to all registered listeners except the named one ."}}
{"translation": {"code": "public synchronized void sendEvent ( java . util . EventObject event ) { if ( ! hasListeners || ! enabled ) return ; Object [ ] args = new Object [ 1 ] ; args [ 0 ] = event ; // send event to all listeners ListIterator iter = listeners . listIterator ( ) ; while ( iter . hasNext ( ) ) { Object client = iter . next ( ) ; try { method . invoke ( client , args ) ; } catch ( IllegalAccessException e ) { logger . error ( \"ListenerManager IllegalAccessException\" , e ) ; iter . remove ( ) ; } catch ( IllegalArgumentException e ) { logger . error ( \"ListenerManager IllegalArgumentException\" , e ) ; iter . remove ( ) ; } catch ( InvocationTargetException e ) { // logger.error(\"ListenerManager InvocationTargetException on \" + method+ \" threw exception \" + e.getTargetException(), e); throw new RuntimeException ( e . getCause ( ) ) ; // pass exception to the caller of sendEvent() } } }", "nl": "Send an event to all registered listeners . If an exception is thrown remove the Listener from the list"}}
{"translation": {"code": "public synchronized void addListener ( Object l ) { if ( ! listeners . contains ( l ) ) { listeners . add ( l ) ; hasListeners = true ; } else logger . warn ( \"ListenerManager.addListener already has Listener \" + l ) ; }", "nl": "Add a listener ."}}
{"translation": {"code": "public synchronized void removeListener ( Object l ) { if ( listeners . contains ( l ) ) { listeners . remove ( l ) ; hasListeners = ( listeners . size ( ) > 0 ) ; } else logger . warn ( \"ListenerManager.removeListener couldnt find Listener \" + l ) ; }", "nl": "Remove a listener ."}}
{"translation": {"code": "public static LatLonPointImpl findPoint ( Earth e , LatLonPoint pt1 , double az , double dist , LatLonPointImpl result ) { return findPoint ( e , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , az , dist , result ) ; }", "nl": "Calculate a position given an azimuth and distance from another point ."}}
{"translation": {"code": "public void extend ( LatLonPoint p ) { if ( contains ( p ) ) return ; double lat = p . getLatitude ( ) ; double lon = p . getLongitude ( ) ; // lat is easy to deal with\r if ( lat > upperRight . getLatitude ( ) ) { upperRight . setLatitude ( lat ) ; } if ( lat < lowerLeft . getLatitude ( ) ) { lowerLeft . setLatitude ( lat ) ; } // lon is uglier\r if ( allLongitude ) { // do nothing\r } else if ( crossDateline ) { // bounding box crosses the +/- 180 seam\r double d1 = lon - upperRight . getLongitude ( ) ; double d2 = lowerLeft . getLongitude ( ) - lon ; if ( ( d1 > 0.0 ) && ( d2 > 0.0 ) ) { // needed ?\r if ( d1 > d2 ) { lowerLeft . setLongitude ( lon ) ; } else { upperRight . setLongitude ( lon ) ; } } } else { // normal case\r if ( lon > upperRight . getLongitude ( ) ) { if ( lon - upperRight . getLongitude ( ) > lowerLeft . getLongitude ( ) - lon + 360 ) { crossDateline = true ; lowerLeft . setLongitude ( lon ) ; } else { upperRight . setLongitude ( lon ) ; } } else if ( lon < lowerLeft . getLongitude ( ) ) { if ( lowerLeft . getLongitude ( ) - lon > lon + 360.0 - upperRight . getLongitude ( ) ) { crossDateline = true ; upperRight . setLongitude ( lon ) ; } else { lowerLeft . setLongitude ( lon ) ; } } } // recalc delta, center\r width = upperRight . getLongitude ( ) - lowerLeft . getLongitude ( ) ; lon0 = ( upperRight . getLongitude ( ) + lowerLeft . getLongitude ( ) ) / 2 ; if ( crossDateline ) { width += 360 ; lon0 -= 180 ; } this . allLongitude = this . allLongitude || ( this . width >= 360.0 ) ; }", "nl": "Extend the bounding box to contain this point"}}
{"translation": {"code": "public LatLonRect intersect ( LatLonRect clip ) { double latMin = Math . max ( getLatMin ( ) , clip . getLatMin ( ) ) ; double latMax = Math . min ( getLatMax ( ) , clip . getLatMax ( ) ) ; double deltaLat = latMax - latMin ; if ( deltaLat < 0 ) return null ; // lon as always is a pain : if not intersection, try +/- 360\r double lon1min = getLonMin ( ) ; double lon1max = getLonMax ( ) ; double lon2min = clip . getLonMin ( ) ; double lon2max = clip . getLonMax ( ) ; if ( ! intersect ( lon1min , lon1max , lon2min , lon2max ) ) { lon2min = clip . getLonMin ( ) + 360 ; lon2max = clip . getLonMax ( ) + 360 ; if ( ! intersect ( lon1min , lon1max , lon2min , lon2max ) ) { lon2min = clip . getLonMin ( ) - 360 ; lon2max = clip . getLonMax ( ) - 360 ; } } // we did our best to find an intersection\r double lonMin = Math . max ( lon1min , lon2min ) ; double lonMax = Math . min ( lon1max , lon2max ) ; double deltaLon = lonMax - lonMin ; if ( deltaLon < 0 ) return null ; return new LatLonRect ( new LatLonPointImpl ( latMin , lonMin ) , deltaLat , deltaLon ) ; }", "nl": "Create the instersection of this LatLon with the given one"}}
{"translation": {"code": "public static void main ( String [ ] args ) { //Bearing         workBearing = new Bearing();\r LatLonPointImpl pt1 = new LatLonPointImpl ( 40 , - 105 ) ; LatLonPointImpl pt2 = new LatLonPointImpl ( 37.4 , - 118.4 ) ; Bearing b = calculateBearing ( pt1 , pt2 , null ) ; System . out . println ( \"Bearing from \" + pt1 + \" to \" + pt2 + \" = \\n\\t\" + b ) ; LatLonPointImpl pt3 = new LatLonPointImpl ( ) ; pt3 = findPoint ( pt1 , b . getAngle ( ) , b . getDistance ( ) , pt3 ) ; System . out . println ( \"using first point, angle and distance, found second point at \" + pt3 ) ; pt3 = findPoint ( pt2 , b . getBackAzimuth ( ) , b . getDistance ( ) , pt3 ) ; System . out . println ( \"using second point, backazimuth and distance, found first point at \" + pt3 ) ; /*  uncomment for timing tests\r\n        for(int j=0;j<10;j++) {\r\n            long t1 = System.currentTimeMillis();\r\n            for(int i=0;i<30000;i++) {\r\n                workBearing = Bearing.calculateBearing(42.5,-93.0,\r\n                                                       48.9,-117.09,workBearing);\r\n            }\r\n            long t2 = System.currentTimeMillis();\r\n            System.err.println (\"time:\" + (t2-t1));\r\n        }\r\n        */ }", "nl": "Test the calculations - forward and back"}}
{"translation": {"code": "public static LatLonPointImpl findPoint ( LatLonPoint pt1 , double az , double dist , LatLonPointImpl result ) { return findPoint ( defaultEarth , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , az , dist , result ) ; }", "nl": "Calculate a position given an azimuth and distance from another point . Uses default Earth ."}}
{"translation": {"code": "public boolean containedIn ( LatLonRect b ) { return ( b . getWidth ( ) >= width ) && b . contains ( upperRight ) && b . contains ( lowerLeft ) ; }", "nl": "Determine if this bounding box is contained in another LatLonRect ."}}
{"translation": {"code": "@ Override public ProjectionImpl constructCopy ( ) { ProjectionImpl result = new LambertConformal ( getOriginLat ( ) , getOriginLon ( ) , getParallelOne ( ) , getParallelTwo ( ) , getFalseEasting ( ) , getFalseNorthing ( ) , earth_radius ) ; result . setDefaultMapArea ( defaultMapArea ) ; result . setName ( name ) ; return result ; }", "nl": "lon naught ??"}}
{"translation": {"code": "public static Bearing calculateBearing ( Earth e , LatLonPoint pt1 , LatLonPoint pt2 , Bearing result ) { return calculateBearing ( e , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , pt2 . getLatitude ( ) , pt2 . getLongitude ( ) , result ) ; }", "nl": "Calculate the bearing between the 2 points . See calculateBearing below ."}}
{"translation": {"code": "@ Override public ProjectionImpl constructCopy ( ) { ProjectionImpl result = ( saveParams == null ) ? new UtmProjection ( getZone ( ) , isNorth ( ) ) : new UtmProjection ( saveParams . a , saveParams . f , getZone ( ) , isNorth ( ) ) ; result . setDefaultMapArea ( defaultMapArea ) ; result . setName ( name ) ; return result ; }", "nl": "needed for constructCopy"}}
{"translation": {"code": "private void readObject ( ObjectInputStream s ) throws IOException , ClassNotFoundException { double x = s . readDouble ( ) ; double y = s . readDouble ( ) ; double w = s . readDouble ( ) ; double h = s . readDouble ( ) ; setRect ( x , y , w , h ) ; }", "nl": "Read the object from the input stream of the serialized object"}}
{"translation": {"code": "private void writeObject ( ObjectOutputStream s ) throws IOException { s . writeDouble ( getX ( ) ) ; s . writeDouble ( getY ( ) ) ; s . writeDouble ( getWidth ( ) ) ; s . writeDouble ( getHeight ( ) ) ; }", "nl": "Wrtie the object to the output stream"}}
{"translation": {"code": "static public String lonToString ( double lon , int ndec ) { double wlon = lonNormal ( lon ) ; boolean is_east = ( wlon >= 0.0 ) ; if ( ! is_east ) wlon = - wlon ; String f = \"%.\" + ndec + \"f\" ; Formatter latBuff = new Formatter ( ) ; latBuff . format ( f , wlon ) ; latBuff . format ( \"%s\" , is_east ? \"E\" : \"W\" ) ; return latBuff . toString ( ) ; }", "nl": "Make a nicely formatted representation of a longitude eg 120 . 3W or 99 . 99E ."}}
{"translation": {"code": "public String toWKS ( ) { StringBuilder sbuff = new StringBuilder ( ) ; sbuff . append ( \"PROJCS[\\\"\" ) . append ( getName ( ) ) . append ( \"\\\",\" ) ; if ( true ) { sbuff . append ( \"GEOGCS[\\\"Normal Sphere (r=6371007)\\\",\" ) ; sbuff . append ( \"DATUM[\\\"unknown\\\",\" ) ; sbuff . append ( \"SPHEROID[\\\"sphere\\\",6371007,0]],\" ) ; } else { sbuff . append ( \"GEOGCS[\\\"WGS 84\\\",\" ) ; sbuff . append ( \"DATUM[\\\"WGS_1984\\\",\" ) ; sbuff . append ( \"SPHEROID[\\\"WGS 84\\\",6378137,298.257223563],\" ) ; sbuff . append ( \"TOWGS84[0,0,0,0,0,0,0]],\" ) ; } sbuff . append ( \"PRIMEM[\\\"Greenwich\\\",0],\" ) ; sbuff . append ( \"UNIT[\\\"degree\\\",0.0174532925199433]],\" ) ; sbuff . append ( \"PROJECTION[\\\"Lambert_Conformal_Conic_1SP\\\"],\" ) ; sbuff . append ( \"PARAMETER[\\\"latitude_of_origin\\\",\" ) . append ( getOriginLat ( ) ) . append ( \"],\" ) ; // LOOK assumes getOriginLat = getParellel\r sbuff . append ( \"PARAMETER[\\\"central_meridian\\\",\" ) . append ( getOriginLon ( ) ) . append ( \"],\" ) ; sbuff . append ( \"PARAMETER[\\\"scale_factor\\\",1],\" ) ; sbuff . append ( \"PARAMETER[\\\"false_easting\\\",\" ) . append ( falseEasting ) . append ( \"],\" ) ; sbuff . append ( \"PARAMETER[\\\"false_northing\\\",\" ) . append ( falseNorthing ) . append ( \"],\" ) ; return sbuff . toString ( ) ; }", "nl": "Create a WKS string"}}
{"translation": {"code": "static public String latToString ( double lat , int ndec ) { boolean is_north = ( lat >= 0.0 ) ; if ( ! is_north ) lat = - lat ; String f = \"%.\" + ndec + \"f\" ; Formatter latBuff = new Formatter ( ) ; latBuff . format ( f , lat ) ; latBuff . format ( \"%s\" , is_north ? \"N\" : \"S\" ) ; return latBuff . toString ( ) ; }", "nl": "Make a nicely formatted representation of a latitude eg 40 . 34N or 12 . 9S ."}}
{"translation": {"code": "static public boolean betweenLon ( double lon , double lonBeg , double lonEnd ) { lonBeg = lonNormal ( lonBeg , lon ) ; lonEnd = lonNormal ( lonEnd , lon ) ; return ( lon >= lonBeg ) && ( lon <= lonEnd ) ; }", "nl": "Test if point lies between two longitudes deal with wrapping ."}}
{"translation": {"code": "public static Bearing calculateBearing ( LatLonPoint pt1 , LatLonPoint pt2 , Bearing result ) { return calculateBearing ( defaultEarth , pt1 . getLatitude ( ) , pt1 . getLongitude ( ) , pt2 . getLatitude ( ) , pt2 . getLongitude ( ) , result ) ; }", "nl": "Calculate the bearing between the 2 points . See calculateBearing below . Uses default Earth object ."}}
{"translation": {"code": "public static LatLonPointImpl findPoint ( double lat1 , double lon1 , double az , double dist , LatLonPointImpl result ) { return findPoint ( defaultEarth , lat1 , lon1 , az , dist , result ) ; }", "nl": "Calculate a position given an azimuth and distance from another point . See details below . Uses default Earth ."}}
{"translation": {"code": "public void extend ( LatLonRect r ) { Preconditions . checkNotNull ( r ) ; // lat is easy\r double latMin = r . getLatMin ( ) ; double latMax = r . getLatMax ( ) ; if ( latMax > upperRight . getLatitude ( ) ) { upperRight . setLatitude ( latMax ) ; } if ( latMin < lowerLeft . getLatitude ( ) ) { lowerLeft . setLatitude ( latMin ) ; } // lon is uglier\r if ( allLongitude ) return ; // everything is reletive to current LonMin\r double lonMin = getLonMin ( ) ; double lonMax = getLonMax ( ) ; double nlonMin = LatLonPointImpl . lonNormal ( r . getLonMin ( ) , lonMin ) ; double nlonMax = nlonMin + r . getWidth ( ) ; lonMin = Math . min ( lonMin , nlonMin ) ; lonMax = Math . max ( lonMax , nlonMax ) ; width = lonMax - lonMin ; allLongitude = width >= 360.0 ; if ( allLongitude ) { width = 360.0 ; lonMin = - 180.0 ; } else { lonMin = LatLonPointImpl . lonNormal ( lonMin ) ; } lowerLeft . setLongitude ( lonMin ) ; upperRight . setLongitude ( lonMin + width ) ; lon0 = lonMin + width / 2 ; crossDateline = lowerLeft . getLongitude ( ) > upperRight . getLongitude ( ) ; }", "nl": "Extend the bounding box to contain the given rectangle"}}
{"translation": {"code": "public String getClassName ( ) { String className = getClass ( ) . getName ( ) ; int index = className . lastIndexOf ( \".\" ) ; if ( index >= 0 ) { className = className . substring ( index + 1 ) ; } return className ; }", "nl": "Get the name of the type of the projection ."}}
{"translation": {"code": "public static CalendarPeriod . Field fromUnitString ( String udunit ) { udunit = udunit . trim ( ) ; udunit = udunit . toLowerCase ( ) ; if ( udunit . equals ( \"s\" ) ) return Field . Second ; if ( udunit . equals ( \"ms\" ) ) return Field . Millisec ; // eliminate plurals\r if ( udunit . endsWith ( \"s\" ) ) udunit = udunit . substring ( 0 , udunit . length ( ) - 1 ) ; switch ( udunit ) { case \"second\" : case \"sec\" : return Field . Second ; case \"millisecond\" : case \"millisec\" : case \"msec\" : return Field . Millisec ; case \"minute\" : case \"min\" : return Field . Minute ; case \"hour\" : case \"hr\" : case \"h\" : return Field . Hour ; case \"day\" : case \"d\" : return Field . Day ; case \"month\" : case \"mon\" : return Field . Month ; case \"year\" : case \"yr\" : return Field . Year ; default : throw new IllegalArgumentException ( \"cant convert \" + udunit + \" to CalendarPeriod\" ) ; } }", "nl": "Convert a period string into a CalendarPeriod . Field ."}}
{"translation": {"code": "protected void addParameter ( String name , String value ) { atts . add ( new Parameter ( name , value ) ) ; }", "nl": "Add an attribute to this projection"}}
{"translation": {"code": "public static EarthEllipsoid getType ( int epsgId ) { Collection < EarthEllipsoid > all = getAll ( ) ; for ( EarthEllipsoid ellipsoid : all ) { if ( ellipsoid . epsgId == epsgId ) { return ellipsoid ; } } return null ; }", "nl": "Find the EarthEllipsoid that matches this EPSG Id ."}}
{"translation": {"code": "public static EarthEllipsoid getType ( String name ) { if ( name == null ) return null ; return hash . get ( name ) ; }", "nl": "Find the EarthEllipsoid that matches this name ."}}
{"translation": {"code": "public String paramsToString ( ) { Formatter f = new Formatter ( ) ; f . format ( \"origin lat,lon=%f,%f parellels=%f,%f earth=%s\" , lat0deg , lon0deg , par1deg , par2deg , earth ) ; return f . toString ( ) ; }", "nl": "Create a String of the parameters ."}}
{"translation": {"code": "ProjectionRect latLonToProjBB2 ( LatLonRect latlonRect ) { double minx , maxx , miny , maxy ; LatLonPointImpl llpt = latlonRect . getLowerLeftPoint ( ) ; LatLonPointImpl urpt = latlonRect . getUpperRightPoint ( ) ; LatLonPointImpl lrpt = latlonRect . getLowerRightPoint ( ) ; LatLonPointImpl ulpt = latlonRect . getUpperLeftPoint ( ) ; if ( isLatLon ( ) ) { minx = getMinOrMaxLon ( llpt . getLongitude ( ) , ulpt . getLongitude ( ) , true ) ; miny = Math . min ( llpt . getLatitude ( ) , lrpt . getLatitude ( ) ) ; maxx = getMinOrMaxLon ( urpt . getLongitude ( ) , lrpt . getLongitude ( ) , false ) ; maxy = Math . min ( ulpt . getLatitude ( ) , urpt . getLatitude ( ) ) ; } else { ProjectionPoint ll = latLonToProj ( llpt , new ProjectionPointImpl ( ) ) ; ProjectionPoint ur = latLonToProj ( urpt , new ProjectionPointImpl ( ) ) ; ProjectionPoint lr = latLonToProj ( lrpt , new ProjectionPointImpl ( ) ) ; ProjectionPoint ul = latLonToProj ( ulpt , new ProjectionPointImpl ( ) ) ; minx = Math . min ( ll . getX ( ) , ul . getX ( ) ) ; miny = Math . min ( ll . getY ( ) , lr . getY ( ) ) ; maxx = Math . max ( ur . getX ( ) , lr . getX ( ) ) ; maxy = Math . max ( ul . getY ( ) , ur . getY ( ) ) ; } return new ProjectionRect ( minx , miny , maxx , maxy ) ; }", "nl": "Alternate way to calculate latLonToProjBB originally in GridCoordSys . Difficult to do this in a general way ."}}
{"translation": {"code": "public static String getHeader ( ) { StringBuilder headerB = new StringBuilder ( 60 ) ; headerB . append ( \"Name\" ) ; Format . tab ( headerB , 20 , true ) ; headerB . append ( \"Class\" ) ; Format . tab ( headerB , 40 , true ) ; headerB . append ( \"Parameters\" ) ; return headerB . toString ( ) ; }", "nl": "Get a header for display ."}}
{"translation": {"code": "private double computeRho ( double lat ) { return earth_radius * Math . sqrt ( C - 2 * n * Math . sin ( lat ) ) / n ; }", "nl": "Compute the RHO parameter"}}
{"translation": {"code": "public ProjectionRect [ ] latLonToProjRect ( LatLonRect latlonR ) { double lat0 = latlonR . getLowerLeftPoint ( ) . getLatitude ( ) ; double height = Math . abs ( latlonR . getUpperRightPoint ( ) . getLatitude ( ) - lat0 ) ; double width = latlonR . getWidth ( ) ; double lon0 = LatLonPointImpl . lonNormal ( latlonR . getLowerLeftPoint ( ) . getLongitude ( ) , centerLon ) ; double lon1 = LatLonPointImpl . lonNormal ( latlonR . getUpperRightPoint ( ) . getLongitude ( ) , centerLon ) ; ProjectionRect [ ] rects = new ProjectionRect [ ] { new ProjectionRect ( ) , new ProjectionRect ( ) } ; if ( lon0 < lon1 ) { rects [ 0 ] . setRect ( lon0 , lat0 , width , height ) ; rects [ 1 ] = null ; } else { double y = centerLon + 180 - lon0 ; rects [ 0 ] . setRect ( lon0 , lat0 , y , height ) ; rects [ 1 ] . setRect ( lon1 - width + y , lat0 , width - y , height ) ; } return rects ; }", "nl": "Split a latlon rectangle to the equivalent ProjectionRect using this LatLonProjection to split it at the seam if needed ."}}
{"translation": {"code": "public void setBitOffset ( DataDescriptor dkey ) { if ( bitPosition == null ) bitPosition = new HashMap < DataDescriptor , Integer > ( 2 * parent . getSubKeys ( ) . size ( ) ) ; bitPosition . put ( dkey , bitOffset ) ; bitOffset += dkey . getBitWidth ( ) ; }", "nl": "not used yet"}}
{"translation": {"code": "private void processBufrMessageAsDataset ( MessageScanner scan , Message m , Counter counter ) throws Exception { byte [ ] mbytes = scan . getMessageBytes ( m ) ; NetcdfFile ncfile = NetcdfFile . openInMemory ( \"test\" , mbytes , \"ucar.nc2.iosp.bufr.BufrIosp\" ) ; Sequence obs = ( Sequence ) ncfile . findVariable ( BufrIosp2 . obsRecord ) ; StructureDataIterator sdataIter = obs . getStructureIterator ( - 1 ) ; processSequence ( obs , sdataIter , counter ) ; }", "nl": "convert one message ino a NetcdfDataset and print data"}}
{"translation": {"code": "public int scanBufrFile ( String filename , Counter total ) throws Exception { int count = 0 ; try ( RandomAccessFile raf = new RandomAccessFile ( filename , \"r\" ) ) { MessageScanner scan = new MessageScanner ( raf ) ; while ( scan . hasNext ( ) ) { Message m = scan . next ( ) ; if ( m == null ) continue ; try { if ( showMess ) out . format ( \"%sMessage %d header=%s%n\" , indent , count , m . getHeader ( ) ) ; count ++ ; Counter counter = new Counter ( ) ; processBufrMessageAsDataset ( scan , m , counter ) ; if ( showMess ) out . format ( \"%scount=%d miss=%d%n\" , indent , counter . nvals , counter . nmiss ) ; total . add ( counter ) ; } catch ( Exception e ) { System . out . printf ( \"  BARF:%s on %s%n\" , e . getMessage ( ) , m . getHeader ( ) ) ; indent . setIndentLevel ( 0 ) ; } } } return count ; }", "nl": "open the file and extract BUFR messages"}}
{"translation": {"code": "static public void transferInfo ( List < DataDescriptor > fromList , List < DataDescriptor > toList ) { // get info from proto message\r if ( fromList . size ( ) != toList . size ( ) ) throw new IllegalArgumentException ( \"list sizes dont match \" + fromList . size ( ) + \" != \" + toList . size ( ) ) ; for ( int i = 0 ; i < fromList . size ( ) ; i ++ ) { DataDescriptor from = fromList . get ( i ) ; DataDescriptor to = toList . get ( i ) ; to . refersTo = from . refersTo ; to . name = from . name ; if ( from . getSubKeys ( ) != null ) transferInfo ( from . getSubKeys ( ) , to . getSubKeys ( ) ) ; } }", "nl": "Transfer info from the proto message to another message with the exact same structure ."}}
{"translation": {"code": "int countBits ( ) { int total_nbits = 0 ; total_nbytesCDM = 0 ; for ( DataDescriptor dd : subKeys ) { if ( dd . subKeys != null ) { total_nbits += dd . countBits ( ) ; total_nbytesCDM += dd . total_nbytesCDM ; } else if ( dd . f == 0 ) { total_nbits += dd . bitWidth ; total_nbytesCDM += dd . getByteWidthCDM ( ) ; } } // replication\r if ( replication > 1 ) { total_nbits *= replication ; total_nbytesCDM *= replication ; } return total_nbits ; }", "nl": "count the bits used by the data in this dd and its children only accurate for not compressed and not variable length"}}
{"translation": {"code": "private static int int4 ( int a , int b , int c , int d ) { // all bits set to ones\r if ( a == 0xff && b == 0xff && c == 0xff && d == 0xff ) return UNDEFINED ; return ( 1 - ( ( a & 128 ) >> 6 ) ) * ( ( a & 127 ) << 24 | b << 16 | c << 8 | d ) ; }", "nl": "Convert 4 bytes into a signed integer ."}}
{"translation": {"code": "public int ncounters ( ) { if ( nested == null ) return 1 ; else { int ncounters = 0 ; for ( BitCounterCompressed [ ] counters : nested ) { if ( counters == null ) continue ; for ( BitCounterCompressed counter : counters ) if ( counter != null ) ncounters += counter . ncounters ( ) ; } return ncounters ; } }", "nl": "Number of nested fields"}}
{"translation": {"code": "int countBits ( int startBit ) { countBits = replicationCountSize ; this . startBit = new int [ nrows ] ; for ( int i = 0 ; i < nrows ; i ++ ) { this . startBit [ i ] = startBit + countBits ; if ( debug ) System . out . println ( \" BitCounterUncompressed row \" + i + \" startBit=\" + this . startBit [ i ] ) ; for ( DataDescriptor nd : parent . subKeys ) { BitCounterUncompressed [ ] bitCounter = ( subCounters == null ) ? null : subCounters . get ( nd ) ; if ( bitCounter == null ) // a regular field\r countBits += nd . getBitWidth ( ) ; else { if ( debug ) System . out . println ( \" ---------> nested \" + nd . getFxyName ( ) + \" starts at =\" + ( startBit + countBits ) ) ; countBits += bitCounter [ i ] . countBits ( startBit + countBits ) ; if ( debug ) System . out . println ( \" <--------- nested \" + nd . getFxyName ( ) + \" ends at =\" + ( startBit + countBits ) ) ; } } } return countBits ; }", "nl": "total bits of this table and all subtables"}}
{"translation": {"code": "private List < DataDescriptor > replicate ( List < DataDescriptor > keys ) { List < DataDescriptor > tree = new ArrayList < DataDescriptor > ( ) ; Iterator < DataDescriptor > dkIter = keys . iterator ( ) ; while ( dkIter . hasNext ( ) ) { DataDescriptor dk = dkIter . next ( ) ; if ( dk . f == 1 ) { dk . subKeys = new ArrayList < DataDescriptor > ( ) ; dk . replication = dk . y ; // replication count\r if ( dk . replication == 0 ) { // delayed replication\r root . isVarLength = true ; // variable sized data == deferred replication == sequence data\r // the next one is the replication count size : does not count in field count (x)\r DataDescriptor replication = dkIter . next ( ) ; if ( replication . y == 0 ) dk . replicationCountSize = 1 ; // ??\r else if ( replication . y == 1 ) dk . replicationCountSize = 8 ; else if ( replication . y == 2 ) dk . replicationCountSize = 16 ; else if ( replication . y == 11 ) dk . repetitionCountSize = 8 ; else if ( replication . y == 12 ) dk . repetitionCountSize = 16 ; else log . error ( \"Unknown replication type= \" + replication ) ; } // transfer to the subKey list\r for ( int j = 0 ; j < dk . x && dkIter . hasNext ( ) ; j ++ ) { dk . subKeys . add ( dkIter . next ( ) ) ; } // recurse\r dk . subKeys = replicate ( dk . subKeys ) ; } else if ( ( dk . f == 3 ) && ( dk . subKeys != null ) ) { dk . subKeys = replicate ( dk . subKeys ) ; // do at all levels\r } tree . add ( dk ) ; } return tree ; }", "nl": "look for replication move replicated items into subtree"}}
{"translation": {"code": "public BitCounterUncompressed makeNested ( DataDescriptor subKey , int n , int row , int replicationCountSize ) { if ( subCounters == null ) subCounters = new HashMap < DataDescriptor , BitCounterUncompressed [ ] > ( 5 ) ; // assumes DataDescriptor.equals is ==\r BitCounterUncompressed [ ] subCounter = subCounters . get ( subKey ) ; if ( subCounter == null ) { subCounter = new BitCounterUncompressed [ nrows ] ; // one for each row in this table\r subCounters . put ( subKey , subCounter ) ; } BitCounterUncompressed rc = new BitCounterUncompressed ( subKey , n , replicationCountSize ) ; subCounter [ row ] = rc ; return rc ; }", "nl": "Track nested Tables ."}}
{"translation": {"code": "public final List < String > getDescriptors ( ) { List < String > desc = new ArrayList < String > ( ) ; for ( short fxy : descriptors ) desc . ( Descriptor . makeString ( fxy ) ) ; return desc ; }", "nl": "get list of data descriptors as Strings"}}
{"translation": {"code": "static public boolean isValidFile ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { raf . seek ( 0 ) ; if ( ! raf . searchForward ( matcher , 40 * 1000 ) ) return false ; // must find \"BUFR\" in first 40k\r raf . skipBytes ( 4 ) ; BufrIndicatorSection is = new BufrIndicatorSection ( raf ) ; if ( is . getBufrEdition ( ) > 4 ) return false ; // if(is.getBufrLength() > MAX_MESSAGE_SIZE) return false;\r return ! ( is . getBufrLength ( ) > raf . length ( ) ) ; }", "nl": "is this a valid BUFR file ."}}
{"translation": {"code": "private List < DataDescriptor > decode ( List < Short > keyDesc , BufrTableLookup lookup ) { if ( keyDesc == null ) return null ; List < DataDescriptor > keys = new ArrayList < DataDescriptor > ( ) ; for ( short id : keyDesc ) { DataDescriptor dd = new DataDescriptor ( id , lookup ) ; keys . add ( dd ) ; if ( dd . f == 3 ) { TableD . Descriptor tdd = lookup . getDescriptorTableD ( dd . fxy ) ; if ( tdd == null || tdd . getSequence ( ) == null ) { dd . bad = true ; } else { dd . name = tdd . getName ( ) ; dd . subKeys = decode ( tdd . getSequence ( ) , lookup ) ; } } } return keys ; }", "nl": "convert ids to DataDescriptors expand table D"}}
{"translation": {"code": "public void setBitOffset ( int bitOffset ) throws IOException { if ( bitOffset % 8 == 0 ) { raf . seek ( startPos + bitOffset / 8 ) ; bitPos = 0 ; bitBuf = 0 ; } else { raf . seek ( startPos + bitOffset / 8 ) ; bitPos = 8 - ( bitOffset % 8 ) ; bitBuf = ( byte ) raf . read ( ) ; bitBuf &= 0xff >> ( 8 - bitPos ) ; // mask off consumed bits      \r } }", "nl": "Position file at bitOffset from startPos"}}
{"translation": {"code": "public long bits2UInt ( int nb ) throws IOException { assert nb <= 64 ; assert nb >= 0 ; long result = 0 ; int bitsLeft = nb ; while ( bitsLeft > 0 ) { // we ran out of bits - fetch the next byte...\r if ( bitPos == 0 ) { bitBuf = nextByte ( ) ; bitPos = BIT_LENGTH ; } // -- retrieve bit from current byte ----------\r // how many bits to read from the current byte\r int size = Math . min ( bitsLeft , bitPos ) ; // move my part to start\r int myBits = bitBuf >> ( bitPos - size ) ; // mask-off sign-extending\r myBits &= BYTE_BITMASK ; // mask-off bits of next value\r myBits &= ~ ( BYTE_BITMASK << size ) ; // -- put bit to result ----------------------\r // where to place myBits inside of result\r int shift = bitsLeft - size ; assert shift >= 0 ; // put it there\r result |= myBits << shift ; // -- put bit to result ----------------------\r // update information on what we consumed\r bitsLeft -= size ; bitPos -= size ; } return result ; }", "nl": "Read the next nb bits and return an Unsigned Long ."}}
{"translation": {"code": "public long bits2SInt ( int nb ) throws IOException { long result = bits2UInt ( nb ) ; // check if we're negative\r if ( getBit ( result , nb ) ) { // it's negative! reset leading bit\r result = setBit ( result , nb , false ) ; // build 2's-complement\r result = ~ result & LONG_BITMASK ; result = result + 1 ; } return result ; }", "nl": "Read the next nb bits and return an Signed Long ."}}
{"translation": {"code": "public final CalendarDate getReferenceTime ( ) { int sec = ( second < 0 || second > 59 ) ? 0 : second ; return CalendarDate . of ( null , year , month , day , hour , minute , sec ) ; }", "nl": "return record header time as a CalendarDate"}}
{"translation": {"code": "DataDescriptor makeAssociatedField ( int bitWidth ) { DataDescriptor assDD = new DataDescriptor ( ) ; assDD . name = name + \"_associated_field\" ; assDD . units = \"\" ; assDD . refVal = 0 ; assDD . scale = 0 ; assDD . bitWidth = bitWidth ; assDD . type = 0 ; assDD . f = 0 ; assDD . x = 31 ; assDD . y = 22 ; assDD . fxy = ( short ) ( ( f << 14 ) + ( x << 8 ) + ( y ) ) ; return assDD ; }", "nl": "for associated fields"}}
{"translation": {"code": "public static GradsAttribute parseAttribute ( String attrSpec ) { String [ ] toks = attrSpec . split ( \"\\\\s+\" ) ; StringBuffer buf = new StringBuffer ( ) ; for ( int i = 4 ; i < toks . length ; i ++ ) { buf . append ( toks [ i ] ) ; buf . append ( \" \" ) ; } // toks[0] is \"@\" return new GradsAttribute ( toks [ 1 ] , toks [ 2 ] , toks [ 3 ] , buf . toString ( ) . trim ( ) ) ; }", "nl": "Parse an attribute spec"}}
{"translation": {"code": "@ Override public void open ( RandomAccessFile raff , NetcdfFile ncfile , CancelTask cancelTask ) throws IOException { super . open ( raff , ncfile , cancelTask ) ; int pos = location . lastIndexOf ( \".\" ) ; String ext = location . substring ( pos ) ; File file = new File ( location ) ; File stnFile = getStnFile ( location ) ; if ( stnFile == null ) throw new FileNotFoundException ( \"Station File does not exist=\" + location ) ; if ( ext . equals ( IDX_EXT ) ) { stnRaf = RandomAccessFile . acquire ( stnFile . getPath ( ) ) ; } else if ( ext . equals ( DAT_EXT ) ) { stnRaf = RandomAccessFile . acquire ( stnFile . getPath ( ) ) ; dataRaf = raff ; //extract the station id\r String name = file . getName ( ) ; stationId = name . substring ( 0 , name . length ( ) - DAT_EXT . length ( ) ) ; } else { // pointed to the station file\r stnRaf = raff ; dataDir = new File ( file . getParentFile ( ) , DAT_DIR ) ; } NcmlConstructor ncmlc = new NcmlConstructor ( ) ; if ( ! ncmlc . populateFromResource ( \"resources/nj22/iosp/igra-por.ncml\" , ncfile ) ) { throw new IllegalStateException ( ncmlc . getErrlog ( ) . toString ( ) ) ; } ncfile . finish ( ) ; //dataVinfo = setVinfo(dataRaf, ncfile, dataPattern, \"all_data\");\r stnVinfo = setVinfo ( stnRaf , ncfile , stnPattern , \"station\" ) ; seriesVinfo = setVinfo ( stnRaf , ncfile , dataHeaderPattern , \"station.time_series\" ) ; profileVinfo = setVinfo ( stnRaf , ncfile , dataPattern , \"station.time_series.levels\" ) ; StructureMembers . Member m = stnVinfo . sm . findMember ( STNID ) ; StructureDataRegexp . VinfoField f = ( StructureDataRegexp . VinfoField ) m . getDataObject ( ) ; stn_fldno = f . fldno ; /* make index file if needed\r\n    File idxFile = new File(base + IDX_EXT);\r\n    if (!idxFile.exists())\r\n      makeIndex(stnVinfo, dataVinfo, idxFile);\r\n    else\r\n      readIndex(idxFile.getPath());  */ }", "nl": "if a DAT file"}}
{"translation": {"code": "private File getStnFile ( String location ) { File file = new File ( location ) ; File stnFile = new File ( file . getParentFile ( ) , STN_FILE ) ; if ( ! stnFile . exists ( ) ) { if ( file . getParentFile ( ) == null ) return null ; stnFile = new File ( file . getParentFile ( ) . getParentFile ( ) , STN_FILE ) ; if ( ! stnFile . exists ( ) ) return null ; } return stnFile ; }", "nl": "stn file must be in the same directory or one up"}}
{"translation": {"code": "public String replaceFileTemplate ( String filespec , int ensIndex ) { return filespec . replaceAll ( ENS_TEMPLATE_ID , getEnsembleNames ( ) . get ( ensIndex ) ) ; }", "nl": "Replace the ensemble template parameter in a filename"}}
{"translation": {"code": "public GradsTimeStruct makeTimeStruct ( int timeIndex ) { double tVal = getValues ( ) [ timeIndex ] ; Date d = DateUnit . getStandardDate ( tVal + \" \" + getUnit ( ) ) ; Calendar calendar = Calendar . getInstance ( ) ; calendar . setTimeZone ( java . util . TimeZone . getTimeZone ( \"GMT\" ) ) ; calendar . setTime ( d ) ; return makeTimeStruct ( calendar ) ; }", "nl": "Make a time struct from the index ."}}
{"translation": {"code": "private GradsTimeStruct makeTimeStruct ( Calendar calendar ) { GradsTimeStruct ts = new GradsTimeStruct ( ) ; ts . year = calendar . get ( Calendar . YEAR ) ; ts . month = calendar . get ( Calendar . MONTH ) + 1 ; // MONTH is zero based ts . day = calendar . get ( Calendar . DAY_OF_MONTH ) ; ts . hour = calendar . get ( Calendar . HOUR_OF_DAY ) ; ts . minute = calendar . get ( Calendar . MINUTE ) ; ts . jday = calendar . get ( Calendar . DAY_OF_YEAR ) ; return ts ; }", "nl": "Make a GradsTimeStruct from the calendar state"}}
{"translation": {"code": "public static boolean hasTimeTemplate ( String template ) { for ( int i = 0 ; i < timeTemplates . length ; i ++ ) { if ( template . indexOf ( timeTemplates [ i ] ) >= 0 ) { return true ; } } return false ; }", "nl": "Does this file definition have a time template in it?"}}
{"translation": {"code": "public static double [ ] getGaussianLatitudes ( String type , int start , int num ) throws IllegalArgumentException { double [ ] baseArray = null ; start -- ; // it's one based if ( type . equalsIgnoreCase ( GAUST62 ) ) { baseArray = gltst62 ; } else if ( type . equalsIgnoreCase ( GAUSR15 ) ) { baseArray = glts15 ; } else if ( type . equalsIgnoreCase ( GAUSR20 ) ) { baseArray = glts20 ; } else if ( type . equalsIgnoreCase ( GAUSR30 ) ) { baseArray = glts30 ; } else if ( type . equalsIgnoreCase ( GAUSR40 ) ) { baseArray = glats ; } else { throw new IllegalArgumentException ( \"Unsupported type: \" + type ) ; } if ( start + num > baseArray . length ) { throw new IllegalArgumentException ( \"Maximum \" + baseArray . length + \" latitudes exceeded\" ) ; } double [ ] retVals = new double [ num ] ; for ( int i = 0 ; i < num ; i ++ ) { retVals [ i ] = baseArray [ start + i ] ; } return retVals ; }", "nl": "Get the latitude values for the given type ."}}
{"translation": {"code": "public Date getDate ( ) { Calendar calendar = Calendar . getInstance ( TimeZone . getTimeZone ( \"GMT\" ) ) ; calendar . set ( Calendar . YEAR , year ) ; calendar . set ( Calendar . MONTH , month - 1 ) ; // MONTH is zero based calendar . set ( Calendar . DAY_OF_MONTH , day ) ; calendar . set ( Calendar . HOUR_OF_DAY , hour ) ; calendar . set ( Calendar . MINUTE , minute ) ; calendar . set ( Calendar . SECOND , 0 ) ; calendar . set ( Calendar . MILLISECOND , 0 ) ; return calendar . getTime ( ) ; }", "nl": "Return this as a java Date object"}}
{"translation": {"code": "public boolean evalClauses ( Object specialO ) throws NoSuchVariableException , DAP2ServerSideException , IOException { boolean result = true ; Enumeration ec = getClauses ( ) ; while ( ec . hasMoreElements ( ) && result == true ) { Object o = ec . nextElement ( ) ; if ( _Debug ) { System . out . println ( \"Evaluating clause: \" + ec . nextElement ( ) ) ; } result = ( ( TopLevelClause ) o ) . evaluate ( ) ; } // Hack: pop the projections of all DArrayDimensions that // have been pushed. return ( result ) ; }", "nl": "Evaluate all of the Clauses in the Clause vector ."}}
{"translation": {"code": "public void printConstraint ( PrintWriter pw ) { Enumeration ec = getClauses ( ) ; boolean first = true ; while ( ec . hasMoreElements ( ) ) { Clause cl = ( Clause ) ec . nextElement ( ) ; if ( ! first ) pw . print ( \" & \" ) ; cl . printConstraint ( pw ) ; first = false ; } pw . flush ( ) ; }", "nl": "Print all of the Clauses in the Clause vector ."}}
{"translation": {"code": "public void parseConstraint ( ReqState rs ) throws ParseException , opendap . dap . DAP2Exception , NoSuchVariableException , NoSuchFunctionException , InvalidOperatorException , InvalidParameterException , SBHException , WrongTypeException { parseConstraint ( rs . getConstraintExpression ( ) , rs . getRequestURL ( ) . toString ( ) ) ; }", "nl": "Convenience wrapper for parseConstraint ."}}
{"translation": {"code": "int getIndex ( GridRecord record ) { Double d = new Double ( record . getLevel1 ( ) ) ; return levels . indexOf ( d ) ; }", "nl": "Get the index of a particular GridRecord"}}
{"translation": {"code": "public final String getParam ( String key ) { String value = paramStr . get ( key ) ; if ( value == null ) { // check the dbl and int tables Double result = paramDbl . get ( key ) ; if ( result != null ) { value = result . toString ( ) ; } else { Integer intResult = paramInt . get ( key ) ; if ( intResult != null ) { value = intResult . toString ( ) ; } } // save it back off to the string table for next time if ( value != null ) { paramStr . put ( key , value ) ; } } if ( debug && value == null ) { System . out . println ( key + \" value not found\" ) ; } return value ; }", "nl": "gets a param and value ."}}
{"translation": {"code": "public static boolean compare ( GridDefRecord local , GridDefRecord other ) { java . util . Set < String > keys = local . getKeys ( ) ; java . util . Set < String > okeys = other . getKeys ( ) ; if ( keys . size ( ) != okeys . size ( ) ) return false ; for ( String key : keys ) { if ( key . equals ( WIND_FLAG ) || key . equals ( RESOLUTION ) || key . equals ( VECTOR_COMPONENT_FLAG ) || key . equals ( GDS_KEY ) ) continue ; String val = local . getParam ( key ) ; String oval = other . getParam ( key ) ; // if ( val . matches ( \"^[0-9]+\\\\.[0-9]*\" ) ) { //double double d = local . getDouble ( key ) ; double od = other . getDouble ( key ) ; if ( ! Misc . nearlyEquals ( d , od ) ) return false ; } else if ( val . matches ( \"^[0-9]+\" ) ) { // int if ( ! val . equals ( oval ) ) return false ; } else { // String if ( ! val . equals ( oval ) ) return false ; } } return true ; }", "nl": "Compare GridDefRecords the numerics will use nearlyEquals so values that differ in 3 or 4th decimal places will return equal . This is being coded because the NDFD model dx differ in the 3 decimal place otherwise equal ."}}
{"translation": {"code": "static public ProjectionImpl factory ( Projection proj ) { if ( proj instanceof ProjectionImpl ) { return ( ProjectionImpl ) proj ; } return new ProjectionAdapter ( proj ) ; }", "nl": "Create a ProjectionImpl from the projection"}}
{"translation": {"code": "static public CalendarDateUnit of ( String calendarName , String udunitString ) { Calendar calt = Calendar . get ( calendarName ) ; if ( calt == null ) calt = Calendar . getDefault ( ) ; return new CalendarDateUnit ( calt , udunitString ) ; }", "nl": "Create a CalendarDateUnit from a calendar name and a udunit string = unit since calendarDate"}}
{"translation": {"code": "public void finish ( ) { if ( gcs . size ( ) == 1 ) return ; if ( gcs . size ( ) == 2 ) { List hcs = getHorizCoordSys ( ) ; GridDefRecord . compare ( ( GridDefRecord ) hcs . get ( 0 ) , ( GridDefRecord ) hcs . get ( 1 ) ) ; } }", "nl": "compares GDS for duplicates"}}
{"translation": {"code": "public CalendarDate makeCalendarDate ( double value ) { if ( isCalendarField ) return baseDate . add ( CalendarPeriod . of ( ( int ) value , periodField ) ) ; // LOOK int vs double\r else return baseDate . add ( value , periodField ) ; }", "nl": "inverse of makeOffsetFromRefDate"}}
{"translation": {"code": "private double [ ] rotate ( double [ ] lonlat , double rot1 , double rot2 , double s ) { /* original code\r\n      double e = DEG2RAD * (lonlat[0] - rot1); //east\r\n      double n = DEG2RAD * lonlat[1]; //north\r\n      double cn = Math.cos(n);\r\n      double x = cn * Math.cos(e);\r\n      double y = cn * Math.sin(e);\r\n      double z = Math.sin(n);\r\n      double x2 = cosDlat * x + s * z;\r\n      double z2 = -s * x + cosDlat * z;\r\n      double R = Math.sqrt(x2 * x2 + y * y);\r\n      double e2 = Math.atan2(y, x2);\r\n      double n2 = Math.atan2(z2, R);\r\n      double rlon = RAD2DEG * e2 - rot2;\r\n      double rlat = RAD2DEG * n2;\r\n      return new double[]{rlon, rlat};\r\n     */ double e = Math . toRadians ( lonlat [ 0 ] - rot1 ) ; //east\r double n = Math . toRadians ( lonlat [ 1 ] ) ; //north\r double cn = Math . cos ( n ) ; double x = cn * Math . cos ( e ) ; double y = cn * Math . sin ( e ) ; double z = Math . sin ( n ) ; double x2 = cosDlat * x + s * z ; double z2 = - s * x + cosDlat * z ; double R = Math . sqrt ( x2 * x2 + y * y ) ; double e2 = Math . atan2 ( y , x2 ) ; double n2 = Math . atan2 ( z2 , R ) ; double rlon = Math . toDegrees ( e2 ) - rot2 ; double rlat = Math . toDegrees ( n2 ) ; return new double [ ] { rlon , rlat } ; }", "nl": "Tor s transform algorithm renamed to rotate for clarity"}}
{"translation": {"code": "public static CalendarDate parseUdunits ( String calendarName , String udunits ) { int pos = udunits . indexOf ( ' ' ) ; if ( pos < 0 ) return null ; String valString = udunits . substring ( 0 , pos ) . trim ( ) ; String unitString = udunits . substring ( pos + 1 ) . trim ( ) ; CalendarDateUnit cdu = CalendarDateUnit . of ( calendarName , unitString ) ; double val = Double . parseDouble ( valString ) ; return cdu . makeCalendarDate ( val ) ; }", "nl": "Get CalendarDate from udunit date string"}}
{"translation": {"code": "public static CalendarDate of ( long msecs ) { // Constructs an instance set to the milliseconds from 1970-01-01T00:00:00Z using ISOChronology in the specified time zone.\r DateTime dt = new DateTime ( msecs , DateTimeZone . UTC ) ; return new CalendarDate ( null , dt ) ; }", "nl": "Create CalendarDate from msecs since epoch Uses standard Calendar ."}}
{"translation": {"code": "public static void tab ( StringBuffer sbuff , int tabStop , boolean alwaysOne ) { int len = sbuff . length ( ) ; if ( tabStop > len ) { sbuff . setLength ( tabStop ) ; for ( int i = len ; i < tabStop ; i ++ ) { sbuff . setCharAt ( i , ' ' ) ; } } else if ( alwaysOne ) { sbuff . setLength ( len + 1 ) ; sbuff . setCharAt ( len , ' ' ) ; } }", "nl": "Blank fill sbuff with blanks until position tabStop ."}}
{"translation": {"code": "public static String pad ( String s , int width , boolean rightJustify ) { if ( s . length ( ) >= width ) { return s ; } StringBuilder sbuff = new StringBuilder ( width ) ; int need = width - s . length ( ) ; sbuff . setLength ( need ) ; for ( int i = 0 ; i < need ; i ++ ) { sbuff . setCharAt ( i , ' ' ) ; } if ( rightJustify ) { sbuff . append ( s ) ; } else { sbuff . insert ( 0 , s ) ; } return sbuff . toString ( ) ; }", "nl": "Create a new string by padding the existing one with blanks to specified width . Do nothing if length is already greater or equal to width ."}}
{"translation": {"code": "public static String i ( int v , int width ) { return pad ( Integer . toString ( v ) , width , true ) ; }", "nl": "Format an integer value ."}}
{"translation": {"code": "public static String l ( long v , int width ) { return pad ( Long . toString ( v ) , width , true ) ; }", "nl": "Format a long value ."}}
{"translation": {"code": "public static String formatByteSize ( double size ) { String unit = null ; if ( size > 1.0e15 ) { unit = \"Pbytes\" ; size *= 1.0e-15 ; } else if ( size > 1.0e12 ) { unit = \"Tbytes\" ; size *= 1.0e-12 ; } else if ( size > 1.0e9 ) { unit = \"Gbytes\" ; size *= 1.0e-9 ; } else if ( size > 1.0e6 ) { unit = \"Mbytes\" ; size *= 1.0e-6 ; } else if ( size > 1.0e3 ) { unit = \"Kbytes\" ; size *= 1.0e-3 ; } else { unit = \"bytes\" ; } return Format . d ( size , 4 ) + \" \" + unit ; }", "nl": "Nicely formatted representation of bytes eg turn 5 . 636E7 into"}}
{"translation": {"code": "private static void show ( double d , int sigfig ) { System . out . println ( \"Format.d(\" + d + \",\" + sigfig + \") == \" + Format . d ( d , sigfig ) ) ; }", "nl": "Show the value of a double to the significant figures"}}
{"translation": {"code": "static public CalendarDateUnit withCalendar ( Calendar calt , String udunitString ) { if ( calt == null ) calt = Calendar . getDefault ( ) ; return new CalendarDateUnit ( calt , udunitString ) ; }", "nl": "Create a CalendarDateUnit from a calendar and a udunit string = unit since calendarDate"}}
{"translation": {"code": "private static void show2 ( double d , int dec_places ) { System . out . println ( \"Format.dfrac(\" + d + \",\" + dec_places + \") == \" + Format . dfrac ( d , dec_places ) ) ; }", "nl": "Show the value of a double with specified number of decimal places"}}
{"translation": {"code": "static org . joda . time . Period convertToPeriod ( int value , String udunit ) { if ( udunit . endsWith ( \"s\" ) ) udunit = udunit . substring ( 0 , udunit . length ( ) - 1 ) ; switch ( udunit ) { case \"msec\" : return Period . millis ( value ) ; case \"sec\" : return Period . seconds ( value ) ; case \"minute\" : return Period . minutes ( value ) ; case \"hour\" : case \"hr\" : return Period . hours ( value ) ; case \"day\" : return Period . days ( value ) ; case \"week\" : return Period . weeks ( value ) ; case \"month\" : return Period . months ( value ) ; case \"year\" : return Period . years ( value ) ; } throw new IllegalArgumentException ( \"cant convert \" + udunit + \" to Joda Period\" ) ; }", "nl": "Convert a time udunit string"}}
{"translation": {"code": "public static CalendarDate of ( java . util . Date date ) { DateTime dt = new DateTime ( date , DateTimeZone . UTC ) ; return new CalendarDate ( null , dt ) ; }", "nl": "Create CalendarDate from a java . util . Date . Uses standard Calendar ."}}
{"translation": {"code": "public static CalendarDate of ( Calendar cal , int year , int monthOfYear , int dayOfMonth , int hourOfDay , int minuteOfHour , int secondOfMinute ) { Chronology base = Calendar . getChronology ( cal ) ; /* if (base == null)\r\n      base = ISOChronology.getInstanceUTC(); // already in UTC\r\n    else\r\n      base = ZonedChronology.getInstance( base, DateTimeZone.UTC); // otherwise wrap it to be in UTC  */ DateTime dt = new DateTime ( year , monthOfYear , dayOfMonth , hourOfDay , minuteOfHour , secondOfMinute , base ) ; if ( ! Calendar . isDefaultChronology ( cal ) ) dt = dt . withChronology ( Calendar . getChronology ( cal ) ) ; dt = dt . withZone ( DateTimeZone . UTC ) ; return new CalendarDate ( cal , dt ) ; }", "nl": "Get Calendar date from fields . Uses UTZ time zone"}}
{"translation": {"code": "@ Override public ProjectionImpl constructCopy ( ) { ProjectionImpl result = new VerticalPerspectiveView ( getOriginLat ( ) , getOriginLon ( ) , R , getHeight ( ) , false_east , false_north ) ; result . setDefaultMapArea ( defaultMapArea ) ; result . setName ( name ) ; return result ; }", "nl": "map limit circle of this radius from the origin p 173"}}
{"translation": {"code": "static public CalendarDateRange of ( DateRange dr ) { if ( dr == null ) return null ; return CalendarDateRange . of ( dr . getStart ( ) . getDate ( ) , dr . getEnd ( ) . getDate ( ) ) ; }", "nl": "Does not handle non - standard calendars"}}
{"translation": {"code": "private boolean scanFirstTime ( ) throws IOException { Map < String , MFile > newMap = new HashMap <> ( ) ; if ( ! hasScans ( ) ) { map = newMap ; return false ; } reallyScan ( newMap ) ; // deleteOld(newMap); // ?? hmmmmm LOOK this seems wrong; maintainence in background ?? generally collection doesnt exist\r // implement olderThan\r if ( olderThanInMsecs > 0 ) { long olderThan = System . currentTimeMillis ( ) - olderThanInMsecs ; // new files must be older than this.\r Iterator < MFile > iter = newMap . values ( ) . iterator ( ) ; // need iterator so we can remove()\r while ( iter . hasNext ( ) ) { MFile newFile = iter . next ( ) ; String path = newFile . getPath ( ) ; if ( newFile . getLastModified ( ) > olderThan ) { // the file is too new\r iter . remove ( ) ; logger . debug ( \"{}: scan found new Dataset but its too recently modified = {}\" , collectionName , path ) ; } } } map = newMap ; this . lastScanned = System . currentTimeMillis ( ) ; this . lastChanged . set ( this . lastScanned ) ; logger . debug ( \"{} : initial scan found n datasets = {} \" , collectionName , map . keySet ( ) . size ( ) ) ; return map . keySet ( ) . size ( ) > 0 ; }", "nl": "only called from synch methods"}}
{"translation": {"code": "protected CalendarDate calcTime ( int startIndex ) { int year = GribNumbers . int2 ( getOctet ( startIndex ++ ) , getOctet ( startIndex ++ ) ) ; int month = getOctet ( startIndex ++ ) ; int day = getOctet ( startIndex ++ ) ; int hour = getOctet ( startIndex ++ ) ; int minute = getOctet ( startIndex ++ ) ; int second = getOctet ( startIndex ++ ) ; if ( ( year == 0 ) && ( month == 0 ) && ( day == 0 ) && ( hour == 0 ) && ( minute == 0 ) && ( second == 0 ) ) return CalendarDate . UNKNOWN ; // href.t00z.prob.f36.grib2\r if ( hour > 23 ) { day += ( hour / 24 ) ; hour = hour % 24 ; } return CalendarDate . of ( null , year , month , day , hour , minute , second ) ; }", "nl": "null means use refTime"}}
{"translation": {"code": "@ Nullable public static Grib2Pds factory ( int template , byte [ ] input ) { switch ( template ) { case 0 : return new Grib2Pds0 ( input ) ; case 1 : return new Grib2Pds1 ( input ) ; case 2 : return new Grib2Pds2 ( input ) ; case 5 : return new Grib2Pds5 ( input ) ; case 6 : return new Grib2Pds6 ( input ) ; case 8 : return new Grib2Pds8 ( input ) ; case 9 : return new Grib2Pds9 ( input ) ; case 10 : return new Grib2Pds10 ( input ) ; case 11 : return new Grib2Pds11 ( input ) ; case 12 : return new Grib2Pds12 ( input ) ; case 15 : return new Grib2Pds15 ( input ) ; case 30 : return new Grib2Pds30 ( input ) ; case 31 : return new Grib2Pds31 ( input ) ; case 48 : return new Grib2Pds48 ( input ) ; case 61 : return new Grib2Pds61 ( input ) ; default : log . warn ( \"Missing template \" + template ) ; return null ; } }", "nl": "Factory for Grib2Pds"}}
{"translation": {"code": "public static Grib2Gds factory ( int template , byte [ ] data ) { Grib2Gds result ; switch ( template ) { case 0 : result = new LatLon ( data ) ; break ; case 1 : result = new RotatedLatLon ( data ) ; break ; case 10 : result = new Mercator ( data ) ; break ; case 20 : result = new PolarStereographic ( data ) ; break ; case 30 : result = new LambertConformal ( data , 30 ) ; break ; case 31 : result = new AlbersEqualArea ( data ) ; break ; case 40 : result = new GaussLatLon ( data ) ; break ; case 50 : // Spherical Harmonic Coefficients BOGUS\r result = new GdsSpherical ( data , template ) ; break ; case 90 : result = new SpaceViewPerspective ( data ) ; break ; // LOOK NCEP specific\r case 204 : result = new CurvilinearOrthogonal ( data ) ; break ; case 32769 : result = new RotatedLatLon32769 ( data ) ; break ; default : throw new UnsupportedOperationException ( \"Unsupported GDS type = \" + template ) ; } result . finish ( ) ; // stuff that cant be done in the constructor\r return result ; }", "nl": "reletive error in position - GRIB numbers sometimes miscoded"}}
{"translation": {"code": "@ Nullable public byte [ ] getBitmap ( RandomAccessFile raf ) throws IOException { if ( startingPosition <= 0 ) { throw new IllegalStateException ( \"Grib1 Bit map has bad starting position\" ) ; } raf . seek ( startingPosition ) ; // octet 1-3 (length of section)\r int length = GribNumbers . uint3 ( raf ) ; // octet 4 unused bits\r raf . read ( ) ; // unused\r // octets 5-6\r int bm = raf . readShort ( ) ; if ( bm != 0 ) { logger . warn ( \"Grib1 Bit map section pre-defined (provided by center) bitmap number = {}\" , bm ) ; return null ; } // not sure if length is set correctly when pre-define bitmap is used, so  wait until that to test\r // seeing a -1, bail out\r if ( length <= 6 || length > 10e6 ) { // look max  ??\r return null ; } // read the bits as integers\r int n = length - 6 ; byte [ ] data = new byte [ n ] ; raf . readFully ( data ) ; return data ; }", "nl": "Read the bitmap array when needed return null if none ."}}
{"translation": {"code": "double applyScaleFactor ( int scale , int value ) { return ( ( scale == 0 ) || ( scale == 255 ) || ( value == 0 ) ) ? value : value * Math . pow ( 10 , - scale ) ; }", "nl": "Apply scale factor to value return a double result ."}}
{"translation": {"code": "public float [ ] readData ( RandomAccessFile raf , long drsPos ) throws IOException { raf . seek ( drsPos ) ; Grib2SectionDataRepresentation drs = new Grib2SectionDataRepresentation ( raf ) ; Grib2SectionBitMap bms = new Grib2SectionBitMap ( raf ) ; Grib2SectionData dataSection = new Grib2SectionData ( raf ) ; Grib2Gds gds = getGDS ( ) ; Grib2DataReader reader = new Grib2DataReader ( drs . getDataTemplate ( ) , gdss . getNumberPoints ( ) , drs . getDataPoints ( ) , getScanMode ( ) , gds . getNxRaw ( ) , dataSection . getStartingPosition ( ) , dataSection . getMsgLength ( ) ) ; Grib2Drs gdrs = drs . getDrs ( raf ) ; float [ ] data = reader . getData ( raf , bms , gdrs ) ; if ( gds . isThin ( ) ) data = QuasiRegular . convertQuasiGrid ( data , gds . getNptsInLine ( ) , gds . getNxRaw ( ) , gds . getNyRaw ( ) , GribData . getInterpolationMethod ( ) ) ; lastRecordRead = this ; return data ; }", "nl": "Read data array"}}
{"translation": {"code": "@ Nullable public byte [ ] getBitmap ( RandomAccessFile raf ) throws IOException { // no bitMap\r if ( bitMapIndicator == 255 ) return null ; // LOOK: bitMapIndicator=254 == previously defined bitmap\r if ( bitMapIndicator == 254 ) logger . debug ( \"HEY bitMapIndicator=254 previously defined bitmap\" ) ; if ( bitMapIndicator != 0 ) { throw new UnsupportedOperationException ( \"Grib2 Bit map section pre-defined (provided by center) = \" + bitMapIndicator ) ; } raf . seek ( startingPosition ) ; int length = GribNumbers . int4 ( raf ) ; raf . skipBytes ( 2 ) ; byte [ ] data = new byte [ length - 6 ] ; raf . readFully ( data ) ; return data ; }", "nl": "Read the bit map array ."}}
{"translation": {"code": "public CalendarDate getReferenceDate ( ) { return CalendarDate . of ( null , year , month , day , hour , minute , second ) ; }", "nl": "reference reference or base time as Dare ."}}
{"translation": {"code": "public String getFileType ( ) { String type = \"Unknown\" ; switch ( dmLabel . kftype ) { case MFSN : type = \"Sounding\" ; break ; case MFSF : type = \"Surface\" ; break ; default : } if ( ! subType . equals ( \"\" ) ) { type = type + \" (\" + subType + \")\" ; } return type ; }", "nl": "Get the type for this file"}}
{"translation": {"code": "public void setValues ( float [ ] values ) { vals = values ; proj = GempakUtil . ST_ITOC ( Float . floatToIntBits ( vals [ 1 ] ) ) . trim ( ) ; addParam ( PROJ , proj ) ; addParam ( GDS_KEY , this . toString ( ) ) ; setParams ( ) ; }", "nl": "Set the grid nav block values"}}
{"translation": {"code": "public Key findKey ( String name ) { if ( keys == null ) { return null ; } // search rows for ( Key key : keys . kkrow ) { if ( key . name . equals ( name ) ) { return key ; } } // search columns for ( Key key : keys . kkcol ) { if ( key . name . equals ( name ) ) { return key ; } } return null ; }", "nl": "Find a key with the given name"}}
{"translation": {"code": "public float [ ] DM_RPKG ( int isword , int nword , int decimalScale ) throws IOException { // from DM_RPKG // read the data packing type float [ ] data ; int ipktyp = DM_RINT ( isword ) ; int iiword = isword + 1 ; int lendat = nword - 1 ; if ( ipktyp == MDGNON ) { // no packing data = new float [ lendat ] ; DM_RFLT ( iiword , data ) ; return data ; } int iiw ; int irw ; if ( ipktyp == MDGDIF ) { iiw = 4 ; irw = 3 ; } else if ( ipktyp == MDGRB2 ) { iiw = 4 ; irw = 1 ; } else { iiw = 3 ; irw = 2 ; } int [ ] iarray = new int [ iiw ] ; float [ ] rarray = new float [ irw ] ; DM_RINT ( iiword , iarray ) ; iiword = iiword + iiw ; lendat = lendat - iiw ; DM_RFLT ( iiword , rarray ) ; iiword = iiword + irw ; lendat = lendat - irw ; if ( ipktyp == MDGRB2 ) { data = unpackGrib2Data ( iiword , lendat , iarray , rarray ) ; return data ; } int nbits = iarray [ 0 ] ; int misflg = iarray [ 1 ] ; boolean miss = misflg != 0 ; int kxky = iarray [ 2 ] ; // int mword = kxky; int kx = 0 ; if ( iiw == 4 ) { kx = iarray [ 3 ] ; } float ref = rarray [ 0 ] ; float scale = rarray [ 1 ] ; float difmin = 0 ; if ( irw == 3 ) { difmin = rarray [ 2 ] ; } data = unpackData ( iiword , lendat , ipktyp , kxky , nbits , ref , scale , miss , difmin , kx , decimalScale ) ; return data ; }", "nl": "Unpack a packed grid"}}
{"translation": {"code": "protected static String getBits ( int b ) { Formatter s = new Formatter ( ) ; for ( int i = 31 ; i >= 0 ; i -- ) { if ( ( b & ( 1 << i ) ) != 0 ) { s . format ( \"1\" ) ; } else { s . format ( \"0\" ) ; } if ( i % 8 == 0 ) { s . format ( \"|\" ) ; } } return s . toString ( ) ; }", "nl": "Get a bit string for an integer"}}
{"translation": {"code": "public static void main ( String [ ] args ) throws IOException { String file = \"GRID2001\" ; if ( args . length > 0 ) { file = args [ 0 ] ; } McIDASGridReader mg = new McIDASGridReader ( file ) ; GridIndex gridIndex = mg . getGridIndex ( ) ; List grids = gridIndex . getGridRecords ( ) ; System . out . println ( \"found \" + grids . size ( ) + \" grids\" ) ; int num = Math . min ( grids . size ( ) , 10 ) ; for ( int i = 0 ; i < num ; i ++ ) { System . out . println ( grids . get ( i ) ) ; } }", "nl": "for testing purposes"}}
{"translation": {"code": "private void getNextByte ( ) throws IOException { if ( ! needToSwap ) { // Get the next byte from the RandomAccessFile bitBuf = rf . read ( ) ; } else { if ( next == 3 ) { bitBuf = ch3 ; } else if ( next == 2 ) { bitBuf = ch2 ; } else if ( next == 1 ) { bitBuf = ch1 ; } else { ch1 = rf . read ( ) ; ch2 = rf . read ( ) ; ch3 = rf . read ( ) ; ch4 = rf . read ( ) ; bitBuf = ch4 ; next = 4 ; } next -- ; } }", "nl": "Get the next byte"}}
{"translation": {"code": "private void initTables ( ) { try { GempakGridParameterTable . addParameters ( \"resources/nj22/tables/gempak/wmogrib3.tbl\" ) ; GempakGridParameterTable . addParameters ( \"resources/nj22/tables/gempak/ncepgrib2.tbl\" ) ; } catch ( Exception e ) { System . out . println ( \"unable to init tables\" ) ; } }", "nl": "Initialize the parameter tables ."}}
{"translation": {"code": "public boolean sync ( ) throws IOException { if ( ( gemreader . getInitFileSize ( ) < raf . length ( ) ) && extendIndex ) { gemreader . init ( true ) ; GridIndex index = gemreader . getGridIndex ( ) ; // reconstruct the ncfile objects ncfile . empty ( ) ; open ( index , null ) ; return true ; } return false ; }", "nl": "Sync the file"}}
{"translation": {"code": "public String getProjName ( int type ) { String projName ; switch ( type ) { case PSEUDO_MERCATOR : case PSEUDO_MERCATOR_GENERAL : projName = \"MERC\" ; break ; case PS_OR_LAMBERT_CONIC : projName = ( vals [ 38 ] == vals [ 39 ] ) ? \"PS\" : \"CONF\" ; break ; case EQUIDISTANT : projName = \"EQUI\" ; break ; case LAMBERT_CONFORMAL_TANGENT : projName = \"CONF\" ; break ; default : projName = \"NAV\" + type ; } return projName ; }", "nl": "Get the name for the projection type"}}
{"translation": {"code": "public final String getLevelUnit ( GridRecord gr ) { if ( cust != null ) { String result = cust . getLevelUnits ( gr . getLevelType1 ( ) ) ; if ( result != null ) return result ; } return visad . jmet . MetUnits . makeSymbol ( ( ( McIDASGridRecord ) gr ) . getLevelUnitName ( ) ) ; }", "nl": "gets the LevelUnit ."}}
{"translation": {"code": "public void printGrids ( ) { List < GridRecord > gridList = gridIndex . getGridRecords ( ) ; if ( gridList == null ) return ; System . out . println ( \"  NUM       TIME1              TIME2           LEVL1 LEVL2  VCORD PARM\" ) ; for ( GridRecord aGridList : gridList ) { System . out . println ( aGridList ) ; } }", "nl": "Print out the grids ."}}
{"translation": {"code": "public int getGridPackingType ( int gridNumber ) throws IOException { // See DM_RDTR int irow = 1 ; // Always 1 for grids if ( ( gridNumber < 1 ) || ( gridNumber > dmLabel . kcol ) ) { logWarning ( \"bad grid number \" + gridNumber ) ; return - 9 ; } int iprt = getPartNumber ( \"GRID\" ) ; if ( iprt == 0 ) { logWarning ( \"couldn't find part: GRID\" ) ; return - 10 ; } // gotta subtract 1 because parts are 1 but List is 0 based DMPart part = parts . get ( iprt - 1 ) ; // check for valid data type if ( part . ktyprt != MDGRID ) { logWarning ( \"Not a valid type: \" + GempakUtil . getDataType ( part . ktyprt ) ) ; return - 21 ; } int ilenhd = part . klnhdr ; int ipoint = dmLabel . kpdata + ( irow - 1 ) * dmLabel . kcol * dmLabel . kprt + ( gridNumber - 1 ) * dmLabel . kprt + ( iprt - 1 ) ; // From DM_RPKG int istart = DM_RINT ( ipoint ) ; if ( istart == 0 ) { return - 15 ; } int length = DM_RINT ( istart ) ; int isword = istart + 1 ; if ( length <= ilenhd ) { logWarning ( \"length (\" + length + \") is less than header length (\" + ilenhd + \")\" ) ; return - 15 ; } else if ( Math . abs ( length ) > 10000000 ) { logWarning ( \"length is huge: \" + length ) ; return - 34 ; } int [ ] header = new int [ ilenhd ] ; DM_RINT ( isword , header ) ; // int nword = length - ilenhd; isword += ilenhd ; // read the data packing type return DM_RINT ( isword ) ; }", "nl": "Get the grid packing type"}}
{"translation": {"code": "public GempakGridRecord findGrid ( String parm ) { List < GridRecord > gridList = gridIndex . getGridRecords ( ) ; if ( gridList == null ) { return null ; } for ( GridRecord grid : gridList ) { GempakGridRecord gh = ( GempakGridRecord ) grid ; if ( gh . param . trim ( ) . equals ( parm ) ) { return gh ; } } return null ; }", "nl": "Find the first grid with this name"}}
{"translation": {"code": "public int getLevelType1 ( ) { // TODO:  flush this out int gribLevel = getDirBlock ( ) [ 51 ] ; int levelType = 0 ; if ( ! ( ( gribLevel == McIDASUtil . MCMISSING ) || ( gribLevel == 0 ) ) ) { levelType = gribLevel ; } else { levelType = 1 ; } return levelType ; }", "nl": "Get the type for the first level of this GridRecord"}}
{"translation": {"code": "private float [ ] unpackGrib2Data ( int iiword , int lendat , int [ ] iarray , float [ ] rarray ) throws IOException { long start = getOffset ( iiword ) ; rf . seek ( start ) ; Grib2Record gr = makeGribRecord ( rf , start ) ; float [ ] data = gr . readData ( rf ) ; if ( ( ( iarray [ 3 ] >> 6 ) & 1 ) == 0 ) { // -y scanning - flip data = gb2_ornt ( iarray [ 1 ] , iarray [ 2 ] , iarray [ 3 ] , data ) ; } return data ; }", "nl": "Read packed Grib2 data"}}
{"translation": {"code": "private float [ ] unpackGrib1Data ( int iiword , int nword , int kxky , int nbits , float ref , float scale , boolean miss , int decimalScale ) throws IOException { //System.out.println(\"decimal scale = \" + decimalScale); float [ ] values = new float [ kxky ] ; bitPos = 0 ; bitBuf = 0 ; next = 0 ; ch1 = 0 ; ch2 = 0 ; ch3 = 0 ; ch4 = 0 ; rf . seek ( getOffset ( iiword ) ) ; int idat ; // save a pow call if we can float scaleFactor = ( decimalScale == 0 ) ? 1.f : ( float ) Math . pow ( 10.0 , - decimalScale ) ; //float scaleFactor = (float) Math.pow(10.0, -decimalScale); for ( int i = 0 ; i < values . length ; i ++ ) { idat = bits2UInt ( nbits ) ; if ( miss && ( idat == IMISSD ) ) { values [ i ] = IMISSD ; } else { values [ i ] = ( ref + scale * idat ) * scaleFactor ; } /*\n            if (i < 25) {\n                System.out.println(\"values[\" + i + \"] = \" + values[i]);\n            }\n            */ } return values ; }", "nl": "Read packed Grib1 data using ucar . grib code"}}
{"translation": {"code": "public final String getLevelName ( GridRecord gr ) { if ( cust != null ) { String result = cust . getLevelNameShort ( gr . getLevelType1 ( ) ) ; if ( result != null ) return result ; } String levelUnit = getLevelUnit ( gr ) ; if ( levelUnit != null ) { int level1 = ( int ) gr . getLevel1 ( ) ; int level2 = ( int ) gr . getLevel2 ( ) ; if ( levelUnit . equalsIgnoreCase ( \"hPa\" ) ) { return \"pressure\" ; } else if ( level1 == 1013 ) { return \"mean sea level\" ; } else if ( level1 == 0 ) { return \"tropopause\" ; } else if ( level1 == 1001 ) { return \"surface\" ; } else if ( level2 != 0 ) { return \"layer\" ; } } return \"\" ; }", "nl": "gets the LevelName ."}}
{"translation": {"code": "private synchronized float [ ] DP_UGRB ( int [ ] idata , int kxky , int nbits , float qmin , float scale , boolean misflg , int decimalScale ) throws IOException { float scaleFactor = ( decimalScale == 0 ) ? 1.f : ( float ) Math . pow ( 10.0 , - decimalScale ) ; // //Check for valid input. // float [ ] grid = new float [ kxky ] ; if ( ( nbits <= 1 ) || ( nbits > 31 ) ) { return grid ; } if ( scale == 0. ) { return grid ; } // //Compute missing data value. // int imax = ( int ) ( Math . pow ( 2 , nbits ) - 1 ) ; // //Retrieve data points from buffer. // int iword = 0 ; int ibit = 1 ; // 1 based bit position for ( int i = 0 ; i < kxky ; i ++ ) { // //    Get the integer from the buffer. // int jshft = nbits + ibit - 33 ; int idat = 0 ; idat = ( jshft < 0 ) ? idata [ iword ] >>> Math . abs ( jshft ) : idata [ iword ] << jshft ; idat = idat & imax ; // //    Check to see if packed integer overflows into next word. LOOK fishy bit operations // if ( jshft > 0 ) { jshft -= 32 ; int idat2 = 0 ; idat2 = idata [ iword + 1 ] >>> Math . abs ( jshft ) ; idat = idat | idat2 ; } // //    Compute value of word. // if ( ( idat == imax ) && misflg ) { grid [ i ] = RMISSD ; } else { grid [ i ] = ( qmin + idat * scale ) * scaleFactor ; } // //    Set location for next word. // ibit += nbits ; if ( ibit > 32 ) { ibit -= 32 ; iword ++ ; } /*\n            if (i < 25) {\n                System.out.println(\"grid[\"+i+\"]: \" + grid[i]);\n            }\n            */ } return grid ; }", "nl": "Unpack grib data packed into ints"}}
{"translation": {"code": "public final String getLevelDescription ( GridRecord gr ) { if ( cust != null ) { String result = cust . getLevelDescription ( gr . getLevelType1 ( ) ) ; if ( result != null ) return result ; } // TODO:  flesh this out return getLevelName ( gr ) ; }", "nl": "gets the LevelDescription ."}}
{"translation": {"code": "private synchronized float [ ] unpackData ( int iiword , int nword , int ipktyp , int kxky , int nbits , float ref , float scale , boolean miss , float difmin , int kx , int decimalScale ) throws IOException { if ( ipktyp == MDGGRB ) { if ( ! useDP ) { return unpackGrib1Data ( iiword , nword , kxky , nbits , ref , scale , miss , decimalScale ) ; } else { if ( nword * 32 < kxky * nbits ) { // to account for badly written files nword ++ ; } int [ ] ksgrid = new int [ nword ] ; DM_RINT ( iiword , ksgrid ) ; return DP_UGRB ( ksgrid , kxky , nbits , ref , scale , miss , decimalScale ) ; } } else if ( ipktyp == MDGNMC ) { return null ; } else if ( ipktyp == MDGDIF ) { return null ; } return null ; }", "nl": "Read packed data"}}
{"translation": {"code": "private double [ ] makeDoubleArray ( int [ ] ints ) { double [ ] newArray = new double [ ints . length ] ; for ( int i = 0 ; i < ints . length ; i ++ ) { newArray [ i ] = ints [ i ] ; } return newArray ; }", "nl": "make a double array out of an int array"}}
{"translation": {"code": "public float [ ] readGrid ( McIDASGridRecord gr ) throws IOException { float [ ] data ; //try { int te = ( gr . getOffsetToHeader ( ) + 64 ) * 4 ; int rows = gr . getRows ( ) ; int cols = gr . getColumns ( ) ; rf . seek ( te ) ; float scale = ( float ) gr . getParamScale ( ) ; data = new float [ rows * cols ] ; rf . order ( needToSwap ? RandomAccessFile . LITTLE_ENDIAN : RandomAccessFile . BIG_ENDIAN ) ; // int n = 0; // store such that 0,0 is in lower left corner... for ( int nc = 0 ; nc < cols ; nc ++ ) { for ( int nr = 0 ; nr < rows ; nr ++ ) { int temp = rf . readInt ( ) ; // check for missing value data [ ( rows - nr - 1 ) * cols + nc ] = ( temp == McIDASUtil . MCMISSING ) ? Float . NaN : ( ( float ) temp ) / scale ; } } rf . order ( RandomAccessFile . BIG_ENDIAN ) ; //} catch (Exception esc) { //  System.out.println(esc); //} return data ; }", "nl": "Read the grid"}}
{"translation": {"code": "public float [ ] DM_UNPK ( DMPart part , int [ ] ibitst ) { int nparms = part . kparms ; int nwordp = part . kwordp ; int npack = ( ibitst . length - 1 ) / nwordp + 1 ; if ( npack * nwordp != ibitst . length ) { //logError(\"number of packed records not correct\"); // System.out.println(\"number of packed records not correct: \" //                   + npack * nwordp + \" vs. \" + ibitst.length); return null ; } float [ ] data = new float [ nparms * npack ] ; PackingInfo pkinf = part . packInfo ; int ir = 0 ; int ii = 0 ; for ( int pack = 0 ; pack < npack ; pack ++ ) { // //  Move bitstring into internal words.  TODO: necessary? // int [ ] jdata = new int [ nwordp ] ; System . arraycopy ( ibitst , ii , jdata , 0 , nwordp ) ; // //  Extract each data value. // for ( int idata = 0 ; idata < nparms ; idata ++ ) { // //  Extract correct bits from words using shift and mask //  operations. // int jbit = pkinf . nbitsc [ idata ] ; int jsbit = pkinf . isbitc [ idata ] ; int jshift = 1 - jsbit ; int jsword = pkinf . iswrdc [ idata ] ; int jword = jdata [ jsword ] ; // use >>> to shift avoid carrying sign along int mask = mskpat >>> ( 32 - jbit ) ; int ifield = jword >>> Math . abs ( jshift ) ; ifield = ifield & mask ; if ( ( jsbit + jbit - 1 ) > 32 ) { jword = jdata [ jsword + 1 ] ; jshift = jshift + 32 ; int iword = jword << jshift ; iword = iword & mask ; ifield = ifield | iword ; } // //  The integer data is now in ifield.  Use the scaling and //  offset terms to convert to REAL data. // if ( ifield == pkinf . imissc [ idata ] ) { data [ ir + idata ] = RMISSD ; } else { data [ ir + idata ] = ( ifield + pkinf . koffst [ idata ] ) * ( float ) pkinf . scalec [ idata ] ; } } ir += nparms ; ii += nwordp ; } return data ; }", "nl": "Unpack an array of packed integers ."}}
{"translation": {"code": "protected List < String > makeDateList ( boolean unique ) { Key date = dateTimeKeys . get ( 0 ) ; Key time = dateTimeKeys . get ( 1 ) ; List < int [ ] > toCheck ; if ( date . type . equals ( ROW ) ) { toCheck = headers . rowHeaders ; } else { toCheck = headers . colHeaders ; } List < String > fileDates = new ArrayList <> ( ) ; for ( int [ ] header : toCheck ) { if ( header [ 0 ] != IMISSD ) { // convert to GEMPAK date/time int idate = header [ date . loc + 1 ] ; int itime = header [ time . loc + 1 ] ; // TODO: Add in the century String dateTime = GempakUtil . TI_CDTM ( idate , itime ) ; fileDates . add ( dateTime ) ; } } if ( unique && ! fileDates . isEmpty ( ) ) { SortedSet < String > uniqueTimes = Collections . synchronizedSortedSet ( new TreeSet < String > ( ) ) ; uniqueTimes . addAll ( fileDates ) ; fileDates . clear ( ) ; fileDates . addAll ( uniqueTimes ) ; } return fileDates ; }", "nl": "Get the list of dates"}}
{"translation": {"code": "public final int getProjectionType ( GridDefRecord gds ) { String name = getProjectionName ( gds ) . trim ( ) ; switch ( name ) { case \"MERC\" : return Mercator ; case \"CONF\" : return LambertConformal ; case \"PS\" : return PolarStereographic ; default : return - 1 ; } }", "nl": "gets the ProjectionType ."}}
{"translation": {"code": "public ProjectionCT makeCoordinateTransform ( AttributeContainer ctv , String units ) { int [ ] area = getIntArray ( ctv , McIDASAreaProjection . ATTR_AREADIR ) ; int [ ] nav = getIntArray ( ctv , McIDASAreaProjection . ATTR_NAVBLOCK ) ; int [ ] aux = null ; if ( ctv . findAttributeIgnoreCase ( McIDASAreaProjection . ATTR_AUXBLOCK ) != null ) { aux = getIntArray ( ctv , McIDASAreaProjection . ATTR_AUXBLOCK ) ; } // not clear if its ok if aux is null, coverity is complaining\r McIDASAreaProjection proj = new McIDASAreaProjection ( area , nav , aux ) ; return new ProjectionCT ( ctv . getName ( ) , \"FGDC\" , proj ) ; }", "nl": "Make the coordinate transform"}}
{"translation": {"code": "private int [ ] getIntArray ( AttributeContainer ctv , String attName ) { Attribute att = ctv . findAttribute ( attName ) ; if ( att == null ) { throw new IllegalArgumentException ( \"McIDASArea coordTransformVariable \" + ctv . getName ( ) + \" must have \" + attName + \" attribute\" ) ; } Array arr = att . getValues ( ) ; return ( int [ ] ) arr . get1DJavaArray ( int . class ) ; }", "nl": "get the int array from the variable attribute"}}
{"translation": {"code": "public final boolean isVerticalCoordinate ( GridRecord gr ) { if ( cust != null ) { return cust . isVerticalCoordinate ( gr . getLevelType1 ( ) ) ; } int type = gr . getLevelType1 ( ) ; if ( ( ( McIDASGridRecord ) gr ) . hasGribInfo ( ) ) { if ( type == 20 ) { return true ; } if ( type == 100 ) { return true ; } if ( type == 101 ) { return true ; } if ( ( type >= 103 ) && ( type <= 128 ) ) { return true ; } if ( type == 141 ) { return true ; } if ( type == 160 ) { return true ; } } else if ( getLevelUnit ( gr ) . equals ( \"hPa\" ) ) { return true ; } return false ; }", "nl": "is this a VerticalCoordinate ."}}
{"translation": {"code": "public boolean isLayer ( GridRecord gr ) { if ( cust != null ) { return cust . isLayer ( gr . getLevelType1 ( ) ) ; } if ( gr . getLevel2 ( ) == 0 ) { return false ; } return true ; }", "nl": "Is this a layer?"}}
{"translation": {"code": "public boolean sync ( ) { try { if ( ! mcGridReader . init ( ) ) { return false ; } GridIndex index = mcGridReader . getGridIndex ( ) ; // reconstruct the ncfile objects ncfile . empty ( ) ; open ( index , null ) ; return true ; } catch ( IOException ioe ) { return false ; } }", "nl": "Sync and extend"}}
{"translation": {"code": "public final boolean isPositiveUp ( GridRecord gr ) { int type = gr . getLevelType1 ( ) ; if ( ( type == 1 ) || ( type == 5 ) ) { return false ; } return true ; }", "nl": "is this a PositiveUp VerticalCoordinate ."}}
{"translation": {"code": "static public String substitute ( String original , String [ ] match , String [ ] subst ) { boolean ok = true ; for ( String aMatch : match ) { if ( original . contains ( aMatch ) ) { ok = false ; break ; } } if ( ok ) { return original ; } // gotta do it;\r StringBuilder sb = new StringBuilder ( original ) ; for ( int i = 0 ; i < match . length ; i ++ ) { substitute ( sb , match [ i ] , subst [ i ] ) ; } return sb . toString ( ) ; }", "nl": "Find all occurences of match strings in original and substitute the corresponding subst string ."}}
{"translation": {"code": "static public void remove ( StringBuilder sb , String out ) { int i = 0 ; while ( i < sb . length ( ) ) { int c = sb . charAt ( i ) ; boolean ok = true ; for ( int j = 0 ; j < out . length ( ) ; j ++ ) { if ( out . charAt ( j ) == c ) { sb . delete ( i , i + 1 ) ; ok = false ; break ; } } if ( ok ) i ++ ; } }", "nl": "Remove any of the characters in out from sb"}}
{"translation": {"code": "static public void unreplace ( StringBuilder sb , String out , char in ) { int pos ; while ( 0 <= ( pos = sb . indexOf ( out ) ) ) { sb . setCharAt ( pos , in ) ; sb . delete ( pos + 1 , pos + out . length ( ) ) ; } }", "nl": "Replace any String out in sb with char in ."}}
{"translation": {"code": "static public void replace ( StringBuilder sb , String out , String in ) { for ( int i = 0 ; i < sb . length ( ) ; i ++ ) { int c = sb . charAt ( i ) ; for ( int j = 0 ; j < out . length ( ) ; j ++ ) { if ( out . charAt ( j ) == c ) sb . setCharAt ( i , in . charAt ( j ) ) ; } } }", "nl": "Replace any of the characters from out with corresponding character from in"}}
{"translation": {"code": "static public String trim ( String s , int bad ) { int len = s . length ( ) ; int st = 0 ; while ( ( st < len ) && ( s . charAt ( st ) == bad ) ) { st ++ ; } while ( ( st < len ) && ( s . charAt ( len - 1 ) == bad ) ) { len -- ; } return ( ( st > 0 ) || ( len < s . length ( ) ) ) ? s . substring ( st , len ) : s ; }", "nl": "Remove bad char from beginning or end of string"}}
{"translation": {"code": "static public void substitute ( StringBuilder sbuff , String match , String subst ) { int pos , fromIndex = 0 ; int substLen = subst . length ( ) ; int matchLen = match . length ( ) ; while ( 0 <= ( pos = sbuff . indexOf ( match , fromIndex ) ) ) { sbuff . replace ( pos , pos + matchLen , subst ) ; fromIndex = pos + substLen ; // make sure dont get into an infinite loop\r } }", "nl": "Find all occurences of the match in original and substitute the subst string directly into the original ."}}
{"translation": {"code": "static public String substitute ( String original , String match , String subst ) { String s = original ; int pos ; while ( 0 <= ( pos = s . indexOf ( match ) ) ) { StringBuilder sb = new StringBuilder ( s ) ; s = sb . replace ( pos , pos + match . length ( ) , subst ) . toString ( ) ; } return s ; }", "nl": "Find all occurrences of the match in original and substitute the subst string ."}}
{"translation": {"code": "public static String cleanup ( byte [ ] h ) { byte [ ] bb = new byte [ h . length ] ; int count = 0 ; for ( byte b : h ) { if ( b >= 32 && b < 127 ) bb [ count ++ ] = b ; } return new String ( bb , 0 , count , CDM . utf8Charset ) ; }", "nl": "Delete any non - printable characters"}}
{"translation": {"code": "static public int match ( String s1 , String s2 ) { int i = 0 ; while ( ( i < s1 . length ( ) ) && ( i < s2 . length ( ) ) ) { if ( s1 . charAt ( i ) != s2 . charAt ( i ) ) { break ; } i ++ ; } return i ; }", "nl": "Count number of chars that match in two strings starting from front ."}}
{"translation": {"code": "static public String allow ( String x , String allowChars , char replaceChar ) { boolean ok = true ; for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { char c = x . charAt ( pos ) ; if ( ! ( Character . isLetterOrDigit ( c ) || ( 0 <= allowChars . indexOf ( c ) ) ) ) { ok = false ; break ; } } if ( ok ) return x ; // gotta do it\r StringBuilder sb = new StringBuilder ( x ) ; for ( int pos = 0 ; pos < sb . length ( ) ; pos ++ ) { char c = sb . charAt ( pos ) ; if ( Character . isLetterOrDigit ( c ) || ( 0 <= allowChars . indexOf ( c ) ) ) { continue ; } sb . setCharAt ( pos , replaceChar ) ; } return sb . toString ( ) ; }", "nl": "Replace any char not alphanumeric or in allowChars by replaceChar ."}}
{"translation": {"code": "static public String filter ( String x , String okChars ) { boolean ok = true ; for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { char c = x . charAt ( pos ) ; if ( ! ( Character . isLetterOrDigit ( c ) || ( 0 <= okChars . indexOf ( c ) ) ) ) { ok = false ; break ; } } if ( ok ) { return x ; } // gotta do it\r StringBuilder sb = new StringBuilder ( x . length ( ) ) ; for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { char c = x . charAt ( pos ) ; if ( Character . isLetterOrDigit ( c ) || ( 0 <= okChars . indexOf ( c ) ) ) { sb . append ( c ) ; } } return sb . toString ( ) ; }", "nl": "Remove any char not alphanumeric or in okChars ."}}
{"translation": {"code": "static public String replace ( String s , char out , String in ) { if ( s . indexOf ( out ) < 0 ) { return s ; } // gotta do it\r StringBuilder sb = new StringBuilder ( s ) ; replace ( sb , out , in ) ; return sb . toString ( ) ; }", "nl": "Replace any char out in s with in ."}}
{"translation": {"code": "static public String replace ( String x , char [ ] replaceChar , String [ ] replaceWith ) { // common case no replacement\r boolean ok = true ; for ( char aReplaceChar : replaceChar ) { int pos = x . indexOf ( aReplaceChar ) ; ok = ( pos < 0 ) ; if ( ! ok ) break ; } if ( ok ) return x ; // gotta do it\r StringBuilder sb = new StringBuilder ( x ) ; for ( int i = 0 ; i < replaceChar . length ; i ++ ) { int pos = x . indexOf ( replaceChar [ i ] ) ; if ( pos >= 0 ) { replace ( sb , replaceChar [ i ] , replaceWith [ i ] ) ; } } return sb . toString ( ) ; }", "nl": "Replace all occurrences of any char in replaceChar with corresponding String in replaceWith"}}
{"translation": {"code": "static public String removeFromEnd ( String s , int c ) { if ( 0 > s . indexOf ( c ) ) // none\r return s ; int len = s . length ( ) ; while ( ( s . charAt ( len - 1 ) == c ) && ( len > 0 ) ) len -- ; if ( len == s . length ( ) ) return s ; return s . substring ( 0 , len ) ; }", "nl": "Remove all occurrences of the character c at the end of s ."}}
{"translation": {"code": "static public String remove ( String s , String sub ) { int len = sub . length ( ) ; int pos ; while ( 0 <= ( pos = s . indexOf ( sub ) ) ) { s = s . substring ( 0 , pos ) + s . substring ( pos + len ) ; } return s ; }", "nl": "Remove all occurrences of the substring sub in the string s ."}}
{"translation": {"code": "static public String remove ( String s , int c ) { if ( 0 > s . indexOf ( c ) ) { // none\r return s ; } StringBuilder buff = new StringBuilder ( s ) ; int i = 0 ; while ( i < buff . length ( ) ) { if ( buff . charAt ( i ) == c ) { buff . deleteCharAt ( i ) ; } else { i ++ ; } } return buff . toString ( ) ; }", "nl": "Remove all occurrences of the character c in the string s ."}}
{"translation": {"code": "static public String makeValidCdmObjectName ( String name ) { name = name . trim ( ) ; // common case no change\r boolean ok = true ; for ( int i = 0 ; i < name . length ( ) ; i ++ ) { int c = name . charAt ( i ) ; if ( c < 0x20 ) ok = false ; if ( c == ' ' ) ok = false ; if ( c == ' ' ) ok = false ; if ( ! ok ) break ; } if ( ok ) return name ; StringBuilder sbuff = new StringBuilder ( name . length ( ) ) ; for ( int i = 0 , len = name . length ( ) ; i < len ; i ++ ) { int c = name . charAt ( i ) ; if ( ( c == ' ' ) || ( c == ' ' ) ) sbuff . append ( ' ' ) ; else if ( c >= 0x20 ) sbuff . append ( ( char ) c ) ; } return sbuff . toString ( ) ; }", "nl": "transform embedded space to _"}}
{"translation": {"code": "public static String replace ( String string , String pattern , String value ) { if ( pattern . length ( ) == 0 ) return string ; if ( ! string . contains ( pattern ) ) return string ; // ok gotta do it\r StringBuilder returnValue = new StringBuilder ( ) ; int patternLength = pattern . length ( ) ; while ( true ) { int idx = string . indexOf ( pattern ) ; if ( idx < 0 ) break ; returnValue . append ( string . substring ( 0 , idx ) ) ; if ( value != null ) returnValue . append ( value ) ; string = string . substring ( idx + patternLength ) ; } returnValue . append ( string ) ; return returnValue . toString ( ) ; }", "nl": "Replaces all occurrences of pattern in string with value"}}
{"translation": {"code": "protected void makeCoordinateSystemsMaximal ( NetcdfDataset ncDataset ) { boolean requireCompleteCoordSys = ! ncDataset . getEnhanceMode ( ) . contains ( NetcdfDataset . Enhance . IncompleteCoordSystems ) ; for ( VarProcess vp : varList ) { VariableEnhanced ve = ( VariableEnhanced ) vp . v ; if ( vp . hasCoordinateSystem ( ) || ! vp . isData ( ) ) continue ; // look through all axes that fit\r List < CoordinateAxis > axisList = new ArrayList <> ( ) ; List < CoordinateAxis > axes = ncDataset . getCoordinateAxes ( ) ; for ( CoordinateAxis axis : axes ) { if ( isCoordinateAxisForVariable ( axis , ve ) ) axisList . add ( axis ) ; } if ( axisList . size ( ) < 2 ) continue ; String csName = CoordinateSystem . makeName ( axisList ) ; CoordinateSystem cs = ncDataset . findCoordinateSystem ( csName ) ; boolean okToBuild = false ; // do coordinate systems need to be complete?\r // default enhance mode is yes, they must be complete\r if ( requireCompleteCoordSys ) { if ( cs != null ) { // only build if coordinate system is complete\r okToBuild = cs . isComplete ( ve ) ; } } else { // coordinate system can be incomplete, so we're ok to build if we find something\r okToBuild = true ; } if ( cs != null && okToBuild ) { ve . addCoordinateSystem ( cs ) ; parseInfo . format ( \" assigned maximal CoordSystem '%s' for var= %s%n\" , cs . getName ( ) , ve . getFullName ( ) ) ; } else { CoordinateSystem csnew = new CoordinateSystem ( ncDataset , axisList , null ) ; // again, do coordinate systems need to be complete?\r // default enhance mode is yes, they must be complete\r if ( requireCompleteCoordSys ) { // only build if new coordinate system is complete\r okToBuild = csnew . isComplete ( ve ) ; } if ( okToBuild ) { csnew . setImplicit ( true ) ; ve . addCoordinateSystem ( csnew ) ; ncDataset . addCoordinateSystem ( csnew ) ; parseInfo . format ( \" created maximal CoordSystem '%s' for var= %s%n\" , csnew . getName ( ) , ve . getFullName ( ) ) ; } } } }", "nl": "If a variable still doesnt have a coordinate system use hueristics to try to find one that was probably forgotten . Examine existing CS . create a subset of axes that fits the variable . Choose the one with highest rank . It must have X Y or lat lon . If so add it ."}}
{"translation": {"code": "static public VariableDS makeDummyTransformVariable ( NetcdfDataset ds , CoordinateTransform ct ) { VariableDS v = new VariableDS ( ds , null , null , ct . getName ( ) , DataType . CHAR , \"\" , null , null ) ; List < Parameter > params = ct . getParameters ( ) ; for ( Parameter p : params ) { if ( p . isString ( ) ) v . addAttribute ( new Attribute ( p . getName ( ) , p . getStringValue ( ) ) ) ; else { double [ ] data = p . getNumericValues ( ) ; Array dataA = Array . factory ( DataType . DOUBLE , new int [ ] { data . length } , data ) ; v . addAttribute ( new Attribute ( p . getName ( ) , dataA ) ) ; } } v . addAttribute ( new Attribute ( _Coordinate . TransformType , ct . getTransformType ( ) . toString ( ) ) ) ; // fake data\r Array data = Array . factory ( DataType . CHAR , new int [ ] { } , new char [ ] { ' ' } ) ; v . setCachedData ( data , true ) ; return v ; }", "nl": "Create a dummy Coordinate Transform Variable based on the given CoordinateTransform . This creates a scalar Variable with dummy data and adds the Parameters of the CoordinateTransform as attributes ."}}
{"translation": {"code": "static public CoordinateTransform makeCoordinateTransform ( NetcdfDataset ds , AttributeContainer ctv , Formatter parseInfo , Formatter errInfo ) { // standard name\r String transform_name = ctv . findAttValueIgnoreCase ( \"transform_name\" , null ) ; if ( null == transform_name ) transform_name = ctv . findAttValueIgnoreCase ( \"Projection_Name\" , null ) ; // these names are from CF - dont want to have to duplicate\r if ( null == transform_name ) transform_name = ctv . findAttValueIgnoreCase ( CF . GRID_MAPPING_NAME , null ) ; if ( null == transform_name ) transform_name = ctv . findAttValueIgnoreCase ( CF . STANDARD_NAME , null ) ; if ( null == transform_name ) { parseInfo . format ( \"**Failed to find Coordinate Transform name from Variable= %s%n\" , ctv ) ; return null ; } transform_name = transform_name . trim ( ) ; // do we have a transform registered for this ?\r Class builderClass = null ; for ( Transform transform : transformList ) { if ( transform . transName . equals ( transform_name ) ) { builderClass = transform . transClass ; break ; } } if ( null == builderClass ) { parseInfo . format ( \"**Failed to find CoordTransBuilder name= %s from Variable= %s%n\" , transform_name , ctv ) ; return null ; } // get an instance of that class\r Object builderObject ; try { builderObject = builderClass . newInstance ( ) ; } catch ( InstantiationException | IllegalAccessException e ) { log . error ( \"Cant create new instance \" + builderClass . getName ( ) , e ) ; return null ; } if ( null == builderObject ) { // cant happen - because this was tested in registerTransform()\r parseInfo . format ( \"**Failed to build CoordTransBuilder object from class= %s for Variable= %s%n\" , builderClass . getName ( ) , ctv ) ; return null ; } CoordinateTransform ct ; if ( builderObject instanceof VertTransformBuilderIF ) { VertTransformBuilderIF vertBuilder = ( VertTransformBuilderIF ) builderObject ; vertBuilder . setErrorBuffer ( errInfo ) ; ct = vertBuilder . makeCoordinateTransform ( ds , ctv ) ; } else if ( builderObject instanceof HorizTransformBuilderIF ) { HorizTransformBuilderIF horizBuilder = ( HorizTransformBuilderIF ) builderObject ; horizBuilder . setErrorBuffer ( errInfo ) ; String units = AbstractTransformBuilder . getGeoCoordinateUnits ( ds , ctv ) ; // barfola\r ct = horizBuilder . makeCoordinateTransform ( ctv , units ) ; } else { log . error ( \"Illegals class \" + builderClass . getName ( ) ) ; return null ; } if ( ct != null ) { parseInfo . format ( \" Made Coordinate transform %s from variable %s: %s%n\" , transform_name , ctv . getName ( ) , builderObject . getClass ( ) . getName ( ) ) ; } return ct ; }", "nl": "Make a CoordinateTransform object from the parameters in a Coordinate Transform Variable using an intrinsic or registered CoordTransBuilder ."}}
{"translation": {"code": "static public List < String > breakupConventionNames ( String convAttValue ) { List < String > names = new ArrayList <> ( ) ; if ( ( convAttValue . indexOf ( ' ' ) > 0 ) || ( convAttValue . indexOf ( ' ' ) > 0 ) ) { StringTokenizer stoke = new StringTokenizer ( convAttValue , \",;\" ) ; while ( stoke . hasMoreTokens ( ) ) { String name = stoke . nextToken ( ) ; names . add ( name . trim ( ) ) ; } } else if ( ( convAttValue . indexOf ( ' ' ) > 0 ) ) { StringTokenizer stoke = new StringTokenizer ( convAttValue , \"/\" ) ; while ( stoke . hasMoreTokens ( ) ) { String name = stoke . nextToken ( ) ; names . add ( name . trim ( ) ) ; } } else { StringTokenizer stoke = new StringTokenizer ( convAttValue , \" \" ) ; while ( stoke . hasMoreTokens ( ) ) { String name = stoke . nextToken ( ) ; names . add ( name . trim ( ) ) ; } } return names ; }", "nl": "Breakup list of Convention names in the Convention attribute in CF compliant way ."}}
{"translation": {"code": "@ Override public void buildCoordinateSystems ( NetcdfDataset ncDataset ) { // put status info into parseInfo that can be shown to someone trying to debug this process\r parseInfo . format ( \"Parsing with Convention = %s%n\" , conventionName ) ; // Bookkeeping info for each variable is kept in the VarProcess inner class\r addVariables ( ncDataset , ncDataset . getVariables ( ) , varList ) ; // identify which variables are coordinate axes\r findCoordinateAxes ( ncDataset ) ; // identify which variables are used to describe coordinate system\r findCoordinateSystems ( ncDataset ) ; // identify which variables are used to describe coordinate transforms\r findCoordinateTransforms ( ncDataset ) ; // turn Variables into CoordinateAxis objects\r makeCoordinateAxes ( ncDataset ) ; // make Coordinate Systems for all Coordinate Systems Variables\r makeCoordinateSystems ( ncDataset ) ; // assign explicit CoordinateSystem objects to variables\r assignCoordinateSystemsExplicit ( ncDataset ) ; // assign implicit CoordinateSystem objects to variables\r makeCoordinateSystemsImplicit ( ncDataset ) ; // optionally assign implicit CoordinateSystem objects to variables that dont have one yet\r if ( useMaximalCoordSys ) makeCoordinateSystemsMaximal ( ncDataset ) ; // make Coordinate Transforms\r makeCoordinateTransforms ( ncDataset ) ; // assign Coordinate Transforms\r assignCoordinateTransforms ( ncDataset ) ; if ( debug ) System . out . println ( \"parseInfo = \\n\" + parseInfo . toString ( ) ) ; }", "nl": "Heres where the work is to identify coordinate axes and coordinate systems ."}}
{"translation": {"code": "protected void addCoordinateVariable ( Dimension dim , VarProcess vp ) { List < VarProcess > list = coordVarMap . get ( dim ) ; if ( list == null ) { list = new ArrayList <> ( ) ; coordVarMap . put ( dim , list ) ; } if ( ! list . contains ( vp ) ) list . add ( vp ) ; }", "nl": "track coordinate variables"}}
{"translation": {"code": "protected void findCoordinateSystems ( NetcdfDataset ncDataset ) { for ( VarProcess vp : varList ) { if ( vp . coordSys != null ) { StringTokenizer stoker = new StringTokenizer ( vp . coordSys ) ; while ( stoker . hasMoreTokens ( ) ) { String vname = stoker . nextToken ( ) ; VarProcess ap = findVarProcess ( vname , vp ) ; if ( ap != null ) { if ( ! ap . isCoordinateSystem ) parseInfo . format ( \" CoordinateSystem = %s added; referenced from var= %s%n\" , vname , vp . v . getFullName ( ) ) ; ap . isCoordinateSystem = true ; } else { parseInfo . format ( \"***Cant find coordSystem %s referenced from var= %s%n\" , vname , vp . v . getFullName ( ) ) ; userAdvice . format ( \"***Cant find coordSystem %s referenced from var= %s%n\" , vname , vp . v . getFullName ( ) ) ; } } } } }", "nl": "Identify coordinate systems set VarProcess . isCoordinateSystem = true . Default is to look for those referenced by _CoordinateSystems attribute ."}}
{"translation": {"code": "protected void makeCoordinateSystems ( NetcdfDataset ncDataset ) { for ( VarProcess vp : varList ) { if ( vp . isCoordinateSystem ) { vp . makeCoordinateSystem ( ) ; } } }", "nl": "Take all previously identified Coordinate Systems and create a CoordinateSystem object ."}}
{"translation": {"code": "protected boolean isCoordinateAxisForVariable ( Variable axis , VariableEnhanced v ) { List < Dimension > varDims = v . getDimensionsAll ( ) ; List < Dimension > axisDims = axis . getDimensionsAll ( ) ; // a CHAR variable must really be a STRING, so leave out the last (string length) dimension\r int checkDims = axisDims . size ( ) ; if ( axis . getDataType ( ) == DataType . CHAR ) checkDims -- ; for ( int i = 0 ; i < checkDims ; i ++ ) { Dimension axisDim = axisDims . get ( i ) ; if ( ! varDims . contains ( axisDim ) ) { return false ; } } return true ; }", "nl": "Does this axis fit this variable . True if all of the dimensions in the axis also appear in the variable . If char variable last dimension is left out ."}}
{"translation": {"code": "protected void findCoordinateAxes ( NetcdfDataset ncDataset ) { for ( VarProcess vp : varList ) { if ( vp . coordAxes != null ) findCoordinateAxes ( vp , vp . coordAxes ) ; if ( vp . coordinates != null ) findCoordinateAxes ( vp , vp . coordinates ) ; } }", "nl": "Identify coordinate axes set VarProcess . isCoordinateAxis = true . Default is to look for those referenced by _CoordinateAxes attribute . Note coordinate variables are already identified ."}}
{"translation": {"code": "private void jumptoThreddsDatatype ( thredds . client . catalog . Access invAccess ) { if ( invAccess == null ) { return ; } thredds . client . catalog . Service s = invAccess . getService ( ) ; if ( s . getType ( ) == ServiceType . HTTPServer ) { downloadFile ( invAccess . getStandardUrlName ( ) ) ; return ; } if ( s . getType ( ) == ServiceType . WMS ) { openWMSDataset ( invAccess . getStandardUrlName ( ) ) ; return ; } if ( s . getType ( ) == ServiceType . CdmrFeature ) { openCoverageDataset ( invAccess . getWrappedUrlName ( ) ) ; return ; } thredds . client . catalog . Dataset ds = invAccess . getDataset ( ) ; if ( ds . getFeatureType ( ) == null ) { // if no feature type, just open as a NetcdfDataset\r try { openNetcdfFile ( threddsDataFactory . openDataset ( invAccess , true , null , null ) ) ; } catch ( IOException ioe ) { JOptionPane . showMessageDialog ( null , \"Error on setThreddsDatatype = \" + ioe . getMessage ( ) ) ; } return ; } DataFactory . Result threddsData = null ; try { threddsData = threddsDataFactory . openFeatureDataset ( invAccess , null ) ; if ( threddsData . fatalError ) { JOptionPane . showMessageDialog ( null , \"Failed to open err=\" + threddsData . errLog ) ; return ; } jumptoThreddsDatatype ( threddsData ) ; } catch ( IOException ioe ) { ioe . printStackTrace ( ) ; JOptionPane . showMessageDialog ( null , \"Error on setThreddsDatatype = \" + ioe . getMessage ( ) ) ; if ( threddsData != null ) { try { threddsData . close ( ) ; } catch ( IOException ioe2 ) { // Okay to fall through?\r } } } }", "nl": "jump to the appropriate tab based on datatype of InvAccess"}}
{"translation": {"code": "private void jumptoThreddsDatatype ( DataFactory . Result threddsData ) { if ( threddsData . fatalError ) { JOptionPane . showMessageDialog ( this , \"Cant open dataset=\" + threddsData . errLog ) ; try { threddsData . close ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } return ; } if ( threddsData . featureType . isCoverageFeatureType ( ) ) { if ( threddsData . featureDataset instanceof FeatureDatasetCoverage ) { makeComponent ( ftTabPane , \"Coverages\" ) ; coveragePanel . setDataset ( threddsData . featureDataset ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( coveragePanel ) ; } else if ( threddsData . featureDataset instanceof GridDataset ) { makeComponent ( ftTabPane , \"Grids\" ) ; gridPanel . setDataset ( ( GridDataset ) threddsData . featureDataset ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( gridPanel ) ; } } else if ( threddsData . featureType == FeatureType . IMAGE ) { makeComponent ( ftTabPane , \"Images\" ) ; imagePanel . setImageLocation ( threddsData . imageURL ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( imagePanel ) ; } else if ( threddsData . featureType == FeatureType . RADIAL ) { makeComponent ( ftTabPane , \"Radial\" ) ; radialPanel . setDataset ( ( RadialDatasetSweep ) threddsData . featureDataset ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( radialPanel ) ; } else if ( threddsData . featureType . isPointFeatureType ( ) ) { makeComponent ( ftTabPane , \"PointFeature\" ) ; pointFeaturePanel . setPointFeatureDataset ( ( PointDatasetImpl ) threddsData . featureDataset ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( pointFeaturePanel ) ; } else if ( threddsData . featureType == FeatureType . STATION_RADIAL ) { makeComponent ( ftTabPane , \"StationRadial\" ) ; stationRadialPanel . setStationRadialDataset ( threddsData . featureDataset ) ; tabbedPane . setSelectedComponent ( ftTabPane ) ; ftTabPane . setSelectedComponent ( stationRadialPanel ) ; } }", "nl": "Jump to the appropriate tab based on datatype of threddsData"}}
{"translation": {"code": "private static void setDataset ( ) { // do it in the swing event thread\r SwingUtilities . invokeLater ( ( ) -> { int pos = wantDataset . indexOf ( ' ' ) ; if ( pos > 0 ) { final String catName = wantDataset . substring ( 0 , pos ) ; // {catalog}#{dataset}\r if ( catName . endsWith ( \".xml\" ) ) { ui . makeComponent ( null , \"THREDDS\" ) ; ui . threddsUI . setDataset ( wantDataset ) ; ui . tabbedPane . setSelectedComponent ( ui . threddsUI ) ; } return ; } // default\r ui . openNetcdfFile ( wantDataset ) ; } ) ; }", "nl": "Handle messages ."}}
{"translation": {"code": "int readTop ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { int pos = 0 ; // long     actualSize = 0;\r raf . seek ( pos ) ; int readLen = 35 ; // Read in the contents of the NEXRAD Level III product head\r byte [ ] b = new byte [ readLen ] ; int rc = raf . read ( b ) ; if ( rc != readLen ) { return 0 ; } // check\r if ( ( convertunsignedByte2Short ( b [ 0 ] ) != 0x00 ) || ( convertunsignedByte2Short ( b [ 1 ] ) != 0xF0 ) || ( convertunsignedByte2Short ( b [ 2 ] ) != 0x09 ) ) { return 0 ; } String pidd = new String ( b , 15 , 5 , CDM . utf8Charset ) ; if ( pidd . contains ( \"NOWRA\" ) || pidd . contains ( \"USRAD\" ) || pidd . contains ( \"NEX\" ) ) { return 1 ; } else { return 0 ; } }", "nl": "read the header of input file and parsing the NOWRAD part"}}
{"translation": {"code": "public static int shortsToInt ( short s1 , short s2 , boolean swapBytes ) { byte [ ] b = new byte [ 4 ] ; b [ 0 ] = ( byte ) ( s1 >>> 8 ) ; b [ 1 ] = ( byte ) ( s1 >>> 0 ) ; b [ 2 ] = ( byte ) ( s2 >>> 8 ) ; b [ 3 ] = ( byte ) ( s2 >>> 0 ) ; return bytesToInt ( b , false ) ; }", "nl": "convert two short into a integer"}}
{"translation": {"code": "public static int bytesToInt ( byte [ ] bytes , boolean swapBytes ) { byte a = bytes [ 0 ] ; byte b = bytes [ 1 ] ; byte c = bytes [ 2 ] ; byte d = bytes [ 3 ] ; if ( swapBytes ) { return ( ( a & 0xff ) ) + ( ( b & 0xff ) << 8 ) + ( ( c & 0xff ) << 16 ) + ( ( d & 0xff ) << 24 ) ; } else { return ( ( a & 0xff ) << 24 ) + ( ( b & 0xff ) << 16 ) + ( ( c & 0xff ) << 8 ) + ( ( d & 0xff ) ) ; } }", "nl": "convert bytes into integer"}}
{"translation": {"code": "private void setThreddsDatatype ( thredds . client . catalog . Dataset invDataset , String wants ) { if ( invDataset == null ) return ; boolean wantsViewer = wants . equals ( \"File\" ) ; boolean wantsCoordSys = wants . equals ( \"CoordSys\" ) ; try { // just open as a NetcdfDataset\r if ( wantsViewer ) { openNetcdfFile ( threddsDataFactory . openDataset ( invDataset , true , null , null ) ) ; return ; } if ( wantsCoordSys ) { NetcdfDataset ncd = threddsDataFactory . openDataset ( invDataset , true , null , null ) ; ncd . enhance ( ) ; // make sure its enhanced\r openCoordSystems ( ncd ) ; return ; } // otherwise do the datatype thing\r DataFactory . Result threddsData = threddsDataFactory . openFeatureDataset ( invDataset , null ) ; if ( threddsData . fatalError ) { JOptionPane . showMessageDialog ( null , \"Failed to open err=\" + threddsData . errLog ) ; return ; } jumptoThreddsDatatype ( threddsData ) ; } catch ( IOException ioe ) { JOptionPane . showMessageDialog ( null , \"Error on setThreddsDatatype = \" + ioe . getMessage ( ) ) ; ioe . printStackTrace ( ) ; } }", "nl": "Jump to the appropriate tab based on datatype of InvDataset"}}
{"translation": {"code": "static public java . util . Date getDate ( int julianDays , int msecs ) { long total = ( ( long ) ( julianDays - 1 ) ) * 24 * 3600 * 1000 + msecs ; return new Date ( total ) ; }", "nl": "get jave date"}}
{"translation": {"code": "DodsV findDodsV ( String name , boolean useDone ) { for ( DodsV dodsV : children ) { if ( useDone && dodsV . isDone ) continue ; // LOOK useDone ??\r if ( ( name == null ) || ( dodsV == null ) || ( dodsV . bt == null ) ) { logger . warn ( \"Corrupted structure\" ) ; continue ; } if ( name . equals ( dodsV . bt . getEncodedName ( ) ) ) return dodsV ; } return null ; }", "nl": "Search the immediate children for a BaseType with given name ."}}
{"translation": {"code": "DodsV findDataV ( DodsV ddsV ) { if ( ddsV . parent . bt != null ) { DodsV parentV = findDataV ( ddsV . parent ) ; if ( parentV == null ) // dataDDS may not have the structure wrapper\r return findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; return parentV . findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; } DodsV dataV = findDodsV ( ddsV . bt . getEncodedName ( ) , true ) ; /* if ((dataV == null) && (ddsV.bt instanceof DGrid)) { // when asking for the Grid array\r\n      DodsV gridArray = (DodsV) ddsV.children.get(0);\r\n      return findDodsV( gridArray.bt.getName(), dataVlist, true);\r\n    } */ return dataV ; }", "nl": "find the DodsV object in the dataVlist corresponding to the ddsV"}}
{"translation": {"code": "public Array convert ( DodsV dataV ) throws IOException , DAP2Exception { // scalars\r if ( dataV . darray == null ) { if ( dataV . bt instanceof DStructure ) { ArrayStructure structArray = makeArrayStructure ( dataV ) ; iconvertDataStructure ( ( DStructure ) dataV . bt , structArray . getStructureMembers ( ) ) ; return structArray ; } else if ( dataV . bt instanceof DGrid ) { throw new IllegalStateException ( \"DGrid without a darray\" ) ; } else if ( dataV . bt instanceof DSequence ) { ArrayStructure structArray = makeArrayStructure ( dataV ) ; iconvertDataSequenceArray ( ( DSequence ) dataV . bt , structArray . getStructureMembers ( ) ) ; return structArray ; } else { // scalar\r DataType dtype = dataV . getDataType ( ) ; Array scalarData = Array . factory ( dtype , new int [ 0 ] ) ; IndexIterator scalarIndex = scalarData . getIndexIterator ( ) ; iconvertDataPrimitiveScalar ( dataV . bt , scalarIndex ) ; return scalarData ; } } // arrays\r if ( dataV . darray != null ) { if ( dataV . bt instanceof DStructure ) { ArrayStructure structArray = makeArrayStructure ( dataV ) ; iconvertDataStructureArray ( dataV . darray , structArray . getStructureMembers ( ) ) ; return structArray ; } else if ( dataV . bt instanceof DString ) { return convertStringArray ( dataV . darray ) ; } else { // the DGrid case comes here also\r // create the array, using  DODS internal array so there's no copying\r opendap . dap . PrimitiveVector pv = dataV . darray . getPrimitiveVector ( ) ; Object storage = pv . getInternalStorage ( ) ; DataType dtype = dataV . getDataType ( ) ; return Array . factory ( dtype , makeShape ( dataV . darray ) , storage ) ; } } String mess = \"Unknown baseType \" + dataV . bt . getClass ( ) . getName ( ) + \" name=\" + dataV . getEncodedName ( ) ; logger . error ( mess ) ; throw new IllegalStateException ( mess ) ; }", "nl": "Convert a DataDDS into an Array"}}
{"translation": {"code": "public Array convertNestedVariable ( ucar . nc2 . Variable v , List < Range > section , DodsV dataV , boolean flatten ) throws IOException , DAP2Exception { Array data = convertTopVariable ( v , section , dataV ) ; if ( flatten ) { ArrayStructure as = ( ArrayStructure ) data ; // make list of names\r List < String > names = new ArrayList <> ( ) ; Variable nested = v ; while ( nested . isMemberOfStructure ( ) ) { names . add ( 0 , nested . getShortName ( ) ) ; nested = nested . getParentStructure ( ) ; } StructureMembers . Member m = findNested ( as , names , v . getShortName ( ) ) ; Array mdata = m . getDataArray ( ) ; if ( mdata instanceof ArraySequenceNested ) { // gotta unroll\r ArraySequenceNested arraySeq = ( ArraySequenceNested ) mdata ; return arraySeq . flatten ( ) ; } return mdata ; } return data ; }", "nl": "Convert a DataDDS into an Array for a Structure member variable ."}}
{"translation": {"code": "public Array convertTopVariable ( ucar . nc2 . Variable v , List < Range > section , DodsV dataV ) throws IOException , DAP2Exception { Array data = convert ( dataV ) ; // arrays\r if ( ( dataV . darray != null ) && ( dataV . bt instanceof DString ) ) { if ( v . getDataType ( ) == DataType . STRING ) return convertStringArray ( data , v ) ; else if ( v . getDataType ( ) == DataType . CHAR ) return convertStringArrayToChar ( dataV . darray , v , section ) ; else { String mess = \"DODSVariable convertArray String invalid dataType= \" + v . getDataType ( ) ; logger . error ( mess ) ; throw new IllegalArgumentException ( mess ) ; } } if ( ( dataV . bt instanceof DString ) && ( v . getDataType ( ) == DataType . CHAR ) ) { // special case: convert String back to CHAR\r return convertStringToChar ( data , v ) ; } return data ; /* else { // the DGrid case comes here also\r\n         // create the array, using  DODS internal array so there's no copying\r\n        dods.dap.PrimitiveVector pv = dataV.darray.getPrimitiveVector();\r\n        Object storage = pv.getInternalStorage();\r\n        //storage = widenArray( pv, storage); // LOOK data conversion if needed\r\n        int[] shape = (section == null) ? v.getShape() : Range.getShape(section);\r\n        return Array.factory( v.getDataType().getPrimitiveClassType(), shape, storage);\r\n      }   */ }", "nl": "Convert a DataDDS into an Array for a top level variable ie not a Structure member variable ."}}
{"translation": {"code": "void parseDAS ( DAS das ) throws IOException { Enumeration tableNames = das . getNames ( ) ; while ( tableNames . hasMoreElements ( ) ) { String tableName = ( String ) tableNames . nextElement ( ) ; AttributeTable attTable = das . getAttributeTableN ( tableName ) ; if ( tableName . equals ( \"NC_GLOBAL\" ) || tableName . equals ( \"HDF_GLOBAL\" ) ) { addAttributeTable ( this , attTable , tableName , true ) ; } else if ( tableName . equals ( \"DODS_EXTRA\" ) || tableName . equals ( \"EXTRA_DIMENSION\" ) ) { // handled seperately in DODSNetcdfFile\r continue ; } else { DodsV dodsV = findDodsV ( tableName , false ) ; // short name matches the table name\r if ( dodsV != null ) { addAttributeTable ( dodsV , attTable , tableName , true ) ; } else { dodsV = findTableDotDelimited ( tableName ) ; if ( dodsV != null ) { addAttributeTable ( dodsV , attTable , tableName , true ) ; } else { if ( debugAttributes ) System . out . println ( \"DODSNetcdf getAttributes CANT find <\" + tableName + \"> add to globals\" ) ; addAttributeTable ( this , attTable , tableName , false ) ; } } } } }", "nl": "Parse the DAS assign attribute tables to the DodsV objects . Nested attribute tables are supposed to follow the tree we construct with dodsV so its easy to assign to correct dodsV ."}}
{"translation": {"code": "static public boolean isBufrTable ( short fxy ) { int f = ( fxy & 0xC000 ) >> 14 ; int x = ( fxy & 0x3F00 ) >> 8 ; int y = ( fxy & 0xFF ) ; return ( f == 0 ) && ( x == 0 ) && ( y < 13 ) ; }", "nl": "contains a BUFR table entry"}}
{"translation": {"code": "static public String getDataCategory ( int cat ) { if ( tableA == null ) init ( ) ; String result = tableA . get ( cat ) ; return result != null ? result : \"Unknown category=\" + cat ; }", "nl": "data category name from table A"}}
{"translation": {"code": "public int subtract ( CalendarDate start , CalendarDate end ) { long diff = end . getDifferenceInMsecs ( start ) ; int thislen = millisecs ( ) ; if ( ( diff % thislen != 0 ) ) log . warn ( \"roundoff error\" ) ; return ( int ) ( diff / thislen ) ; }", "nl": "Subtract two dates return difference in units of this period . If not even will round down and log a warning"}}
{"translation": {"code": "public double getValueInMillisecs ( ) { if ( field == CalendarPeriod . Field . Month ) return 30.0 * 24.0 * 60.0 * 60.0 * 1000.0 * value ; else if ( field == CalendarPeriod . Field . Year ) return 365.0 * 24.0 * 60.0 * 60.0 * 1000.0 * value ; else return millisecs ( ) ; }", "nl": "Get the duration in milliseconds - +"}}
{"translation": {"code": "public static CalendarPeriod of ( int value , Field field ) { CalendarPeriod want = new CalendarPeriod ( value , field ) ; if ( cache == null ) return want ; CalendarPeriod got = cache . getIfPresent ( want ) ; if ( got != null ) return got ; cache . put ( want , want ) ; return want ; }", "nl": "minimize memory use by interning . wacko shit in GribPartitionBuilder TimeCoordinate whoduhthunk?"}}
{"translation": {"code": "public static int TI_DAYM ( int iyear , int imon ) { int iday = 0 ; if ( ( imon > 0 ) && ( imon < 13 ) ) { //  Pick the number of days for the given month.\r iday = month [ imon - 1 ] ; if ( ( imon == 2 ) && LEAP ( iyear ) ) { iday = iday + 1 ; } } return iday ; }", "nl": "This subroutine returns the number of days in the given month . The year must be a full four - digit year ."}}
{"translation": {"code": "public static String TI_ITOC ( int [ ] idtarr ) { String dattim ; String date , time ; //   Put array values into variables.\r int iyear = idtarr [ 0 ] ; int imonth = idtarr [ 1 ] ; int iday = idtarr [ 2 ] ; int ihour = idtarr [ 3 ] ; int iminut = idtarr [ 4 ] ; //  Check for leap year.\r //int ndays = TI_DAYM(iyear, imonth);\r iyear = iyear % 100 ; //  Check that each of these values is valid.\r /*  TODO: Check these\r\n            IF  ( iyear .lt. 0 )  iret = -7\r\n            IF  ( ( imonth .lt. 1 ) .or. ( imonth .gt. 12 ) ) iret = -8\r\n            IF  ( ( iday   .lt. 1 ) .or. ( iday   .gt. ndays ) )\r\n         +                                                    iret = -9\r\n            IF  ( ( ihour  .lt. 0 ) .or. ( ihour  .gt. 24 ) ) iret = -10\r\n            IF  ( ( iminut .lt. 0 ) .or. ( iminut .gt. 60 ) ) iret = -11\r\n            IF  ( iret .ne. 0 )  RETURN\r\n        */ //  Get the date and time.\r int idate = iyear * 10000 + imonth * 100 + iday ; int itime = ihour * 100 + iminut ; //  Convert date and time to character strings.\r //  Fill in blanks with zeroes.\r date = StringUtil2 . padZero ( idate , 6 ) ; time = StringUtil2 . padZero ( itime , 4 ) ; dattim = date + \"/\" + time ; return dattim ; }", "nl": "This subroutine converts an integer time array into a standard GEMPAK time . The integers are checked for validity ."}}
{"translation": {"code": "public static String TG_ITOC ( int [ ] intdtf ) { String gdattim = \"\" ; //Check for the blank time which may be found.\r if ( ( intdtf [ 0 ] == 0 ) && ( intdtf [ 1 ] == 0 ) && ( intdtf [ 2 ] == 0 ) ) { return gdattim ; } //  Put the date and time into the character time.\r gdattim = TI_CDTM ( intdtf [ 0 ] , intdtf [ 1 ] ) ; //  Decode the forecast information if there is any.\r if ( intdtf [ 2 ] != 0 ) { String [ ] timeType = TG_CFTM ( intdtf [ 2 ] ) ; String ftype = timeType [ 0 ] ; String ftime = timeType [ 1 ] ; //      Combine two parts into string.\r gdattim = gdattim . substring ( 0 , 11 ) + ftype + ftime ; } return gdattim ; }", "nl": "This subroutine converts an integer time array containing the date time and forecast time into a GEMPAK grid time ."}}
{"translation": {"code": "public static String getGridPackingName ( int pktyp ) { String packingType = \"UNKNOWN\" ; switch ( pktyp ) { case GempakConstants . MDGNON : packingType = \"MDGNON\" ; break ; case GempakConstants . MDGGRB : packingType = \"MDGGRB\" ; break ; case GempakConstants . MDGNMC : packingType = \"MDGNMC\" ; break ; case GempakConstants . MDGDIF : packingType = \"MDGDIF\" ; break ; case GempakConstants . MDGDEC : packingType = \"MDGDEC\" ; break ; case GempakConstants . MDGRB2 : packingType = \"MDGRB2\" ; break ; default : break ; } return packingType ; }", "nl": "Get a name for the grid packing type"}}
{"translation": {"code": "public static String getDataType ( int typrt ) { String dataType = \"\" + typrt ; switch ( typrt ) { case GempakConstants . MDREAL : dataType = \"MDREAL\" ; break ; case GempakConstants . MDINTG : dataType = \"MDINTG\" ; break ; case GempakConstants . MDCHAR : dataType = \"MDCHAR\" ; break ; case GempakConstants . MDRPCK : dataType = \"MDRPCK\" ; break ; case GempakConstants . MDGRID : dataType = \"MDGRID\" ; break ; default : break ; } return dataType ; }", "nl": "Get a name for the data packing type"}}
{"translation": {"code": "public static int [ ] TG_FTOI ( int [ ] iftime , int start ) { int [ ] intdtf = new int [ 3 ] ; // If there is no forecast information, the string is stored as\r // date and time.\r if ( iftime [ start ] < 100000000 ) { intdtf [ 0 ] = iftime [ start ] ; intdtf [ 1 ] = iftime [ start + 1 ] ; intdtf [ 2 ] = 0 ; //  Otherwise, decode date/time and forecast info from the\r //  two integers. \r } else { //  The first word contains MMDDYYHHMM.  This must be turned\r //  into YYMMDD and HHMM.\r intdtf [ 0 ] = iftime [ start ] / 10000 ; intdtf [ 1 ] = iftime [ start ] - intdtf [ 0 ] * 10000 ; int mmdd = intdtf [ 0 ] / 100 ; int iyyy = intdtf [ 0 ] - mmdd * 100 ; intdtf [ 0 ] = iyyy * 10000 + mmdd ; //  The forecast time remains the same.\r intdtf [ 2 ] = iftime [ start + 1 ] ; } return intdtf ; }", "nl": "This subroutine converts the two integers stored in a grid file into three integers containing the date time and forecast time ."}}
{"translation": {"code": "public static String padRight ( String s , int desiredLength , String padString ) { StringBuilder ret = new StringBuilder ( s ) ; while ( ret . length ( ) < desiredLength ) { ret . append ( padString ) ; } return ret . toString ( ) ; }", "nl": "Pad the given string with padString on the right up to the given length ."}}
{"translation": {"code": "private List < String > SN_CKUA ( ) { List < String > types = new ArrayList <> ( ) ; boolean above = false ; boolean done = false ; String partToCheck ; while ( ! done ) { // check for mandatory groups\r for ( int group = 0 ; group < belowGroups . length ; group ++ ) { if ( above ) { partToCheck = aboveGroups [ group ] ; } else { partToCheck = belowGroups [ group ] ; } if ( checkForValidGroup ( partToCheck , parmLists [ group ] ) ) { types . add ( partToCheck ) ; } } if ( ! above ) { above = true ; } else { done = true ; } } return types ; }", "nl": "This subroutine checks the parts in a sounding data set for the unmerged data types ."}}
{"translation": {"code": "public static String padLeft ( String s , int desiredLength , String padString ) { while ( s . length ( ) < desiredLength ) { s = padString + s ; } return s ; }", "nl": "Pad the given string with padString on the left up to the given length ."}}
{"translation": {"code": "public static int [ ] swp4 ( int [ ] values , int startIndex , int number ) { for ( int i = startIndex ; i < startIndex + number ; i ++ ) { values [ i ] = Integer . reverseBytes ( values [ i ] ) ; } return values ; }", "nl": "Swap the order of the integers in place ."}}
{"translation": {"code": "public static String LV_CCRD ( int ivcord ) { //Translate known vertical coordinates or look for parameter name.\r String vcoord = \"\" ; //Check for numeric vertical coordinates.\r if ( ( ivcord >= 0 ) && ( ivcord < vertCoords . length ) ) { vcoord = vertCoords [ ivcord ] ; } else if ( ivcord > 100 ) { //     Check for character name as vertical coordinate.  Check that\r //     each character is an alphanumeric character.\r vcoord = ST_ITOC ( ivcord ) ; /*\r\n              Check for bad values\r\n\r\n                DO  i = 1, 4\r\n                    v = vcoord (i:i)\r\n                    IF  ( ( ( v .lt. 'A' ) .or. ( v .gt. 'Z' ) ) .and.\r\n     +                    ( ( v .lt. '0' ) .or. ( v .gt. '9' ) ) )  THEN\r\n                        ier = -1\r\n                    END IF\r\n                END DO\r\n            END IF\r\n            */ } return vcoord ; }", "nl": "This subroutine translates a numeric value for IVCORD into its character value in VCOORD ."}}
{"translation": {"code": "public GempakParameter getParameter ( String name ) { GempakParameter param = paramMap . get ( name ) ; if ( param == null ) { // try the regex list\r Set < String > keys = templateParamMap . keySet ( ) ; if ( ! keys . isEmpty ( ) ) { for ( String key : keys ) { Pattern p = Pattern . compile ( key ) ; Matcher m = p . matcher ( name ) ; if ( m . matches ( ) ) { //System.out.println(\"found match \" + key + \" for \" + name);\r String value = m . group ( 1 ) ; GempakParameter match = templateParamMap . get ( key ) ; param = new GempakParameter ( match . getNumber ( ) , name , match . getDescription ( ) + \" (\" + value + \" hour)\" , match . getUnit ( ) , match . getDecimalScale ( ) ) ; paramMap . put ( name , param ) ; break ; } } } } return param ; }", "nl": "Get the parameter for the given name"}}
{"translation": {"code": "static public long copyRafB ( ucar . unidata . io . RandomAccessFile raf , long offset , long length , OutputStream out , byte [ ] buffer ) throws IOException { int bufferSize = buffer . length ; long want = length ; raf . seek ( offset ) ; while ( want > 0 ) { int len = ( int ) Math . min ( want , bufferSize ) ; int bytesRead = raf . read ( buffer , 0 , len ) ; if ( bytesRead <= 0 ) break ; out . write ( buffer , 0 , bytesRead ) ; want -= bytesRead ; } out . flush ( ) ; return length - want ; }", "nl": "Copy part of a RandomAccessFile to output stream specify internal buffer size"}}
{"translation": {"code": "static public void writeToFile ( String contents , File file ) throws IOException { try ( FileOutputStream fout = new FileOutputStream ( file ) ) { OutputStreamWriter fw = new OutputStreamWriter ( fout , CDM . utf8Charset ) ; UnsynchronizedBufferedWriter writer = new UnsynchronizedBufferedWriter ( fw ) ; writer . write ( contents ) ; writer . flush ( ) ; } }", "nl": "Write String contents to a file using UTF - 8 encoding ."}}
{"translation": {"code": "static public void writeToFile ( String contents , String fileOutName ) throws IOException { writeToFile ( contents , new File ( fileOutName ) ) ; }", "nl": "Write contents to a file using UTF - 8 encoding ."}}
{"translation": {"code": "static public long writeToFile ( InputStream in , String fileOutName ) throws IOException { try ( FileOutputStream fout = new FileOutputStream ( fileOutName ) ) { OutputStream out = new BufferedOutputStream ( fout ) ; return IO . copy ( in , out ) ; } finally { if ( null != in ) in . close ( ) ; } }", "nl": "copy input stream to file . close input stream when done ."}}
{"translation": {"code": "public String getCFFeatureType ( ) { if ( gemreader . getFileSubType ( ) . equals ( GempakSurfaceFileReader . SHIP ) ) { return CF . FeatureType . point . toString ( ) ; } return CF . FeatureType . timeSeries . toString ( ) ; }", "nl": "Get the CF feature type"}}
{"translation": {"code": "static public void copyDirTree ( String fromDirName , String toDirName ) throws IOException { File fromDir = new File ( fromDirName ) ; File toDir = new File ( toDirName ) ; if ( ! fromDir . exists ( ) ) return ; if ( ! toDir . exists ( ) ) { if ( ! toDir . mkdirs ( ) ) { throw new IOException ( \"Could not create directory: \" + toDir ) ; } } File [ ] files = fromDir . listFiles ( ) ; if ( files != null ) for ( File f : files ) { if ( f . isDirectory ( ) ) copyDirTree ( f . getAbsolutePath ( ) , toDir . getAbsolutePath ( ) + \"/\" + f . getName ( ) ) ; else copyFile ( f . getAbsolutePath ( ) , toDir . getAbsolutePath ( ) + \"/\" + f . getName ( ) ) ; } }", "nl": "Copy an entire directory tree ."}}
{"translation": {"code": "static public String readFile ( String filename ) throws IOException { try ( FileInputStream fin = new FileInputStream ( filename ) ) { InputStreamReader reader = new InputStreamReader ( fin , CDM . utf8Charset ) ; StringWriter swriter = new StringWriter ( 50000 ) ; UnsynchronizedBufferedWriter writer = new UnsynchronizedBufferedWriter ( swriter ) ; writer . write ( reader ) ; return swriter . toString ( ) ; } }", "nl": "Read the contents from the named file and place into a String assuming UTF - 8 encoding ."}}
{"translation": {"code": "static public void copyFileB ( File fileIn , OutputStream out , int bufferSize ) throws IOException { try ( FileInputStream fin = new FileInputStream ( fileIn ) ) { InputStream in = new BufferedInputStream ( fin ) ; IO . copyB ( in , out , bufferSize ) ; } }", "nl": "copy file to output stream specify internal buffer size"}}
{"translation": {"code": "static public void writeContents ( String contents , OutputStream os ) throws IOException { ByteArrayInputStream bin = new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) ; IO . copy ( bin , os ) ; }", "nl": "Wite the contents from the String to a Stream"}}
{"translation": {"code": "static public byte [ ] readContentsToByteArray ( InputStream is ) throws IOException { ByteArrayOutputStream bout = new ByteArrayOutputStream ( 10 * default_file_buffersize ) ; IO . copy ( is , bout ) ; return bout . toByteArray ( ) ; }", "nl": "Read the contents from the inputStream and place into a byte array with any error messages put in the return String ."}}
{"translation": {"code": "static public String readContents ( InputStream is , String charset ) throws IOException { ByteArrayOutputStream bout = new ByteArrayOutputStream ( 10 * default_file_buffersize ) ; IO . copy ( is , bout ) ; return bout . toString ( charset ) ; }", "nl": "Read the contents from the inputStream and place into a String with any error messages put in the return String ."}}
{"translation": {"code": "static public byte [ ] readFileToByteArray ( String filename ) throws IOException { try ( FileInputStream fin = new FileInputStream ( filename ) ) { InputStream in = new BufferedInputStream ( fin ) ; return readContentsToByteArray ( in ) ; } }", "nl": "Read the file and place contents into a byte array with any error messages put in the return String ."}}
{"translation": {"code": "static public long copyB ( InputStream in , OutputStream out , int bufferSize ) throws IOException { long totalBytesRead = 0 ; int done = 0 , next = 1 ; byte [ ] buffer = new byte [ bufferSize ] ; while ( true ) { int n = in . read ( buffer ) ; if ( n == - 1 ) break ; out . write ( buffer , 0 , n ) ; totalBytesRead += n ; if ( showCopy ) { done += n ; if ( done > 1000 * 1000 * next ) { System . out . println ( next + \" Mb\" ) ; next ++ ; } } } out . flush ( ) ; return totalBytesRead ; }", "nl": "copy all bytes from in to out specify buffer size"}}
{"translation": {"code": "public void addParameters ( String tbl ) throws IOException { try ( InputStream is = getInputStream ( tbl ) ) { if ( is == null ) { throw new IOException ( \"Unable to open \" + tbl ) ; } String content = readContents ( is ) ; // LOOK this is silly - should just read one line at a time\r // List           lines   = StringUtil.split(content, \"\\n\", false);\r String [ ] lines = content . split ( \"\\n\" ) ; List < String [ ] > result = new ArrayList <> ( ) ; for ( String line : lines ) { //String line  = (String) lines.get(i);\r String tline = line . trim ( ) ; if ( tline . length ( ) == 0 ) { continue ; } if ( tline . startsWith ( \"!\" ) ) { continue ; } String [ ] words = new String [ indices . length ] ; for ( int idx = 0 ; idx < indices . length ; idx ++ ) { if ( indices [ idx ] >= tline . length ( ) ) { continue ; } if ( indices [ idx ] + lengths [ idx ] > tline . length ( ) ) { words [ idx ] = line . substring ( indices [ idx ] ) ; } else { words [ idx ] = line . substring ( indices [ idx ] , indices [ idx ] + lengths [ idx ] ) ; } //if (trimWords) {\r words [ idx ] = words [ idx ] . trim ( ) ; //}\r } result . add ( words ) ; } for ( String [ ] aResult : result ) { GempakParameter p = makeParameter ( aResult ) ; if ( p != null ) { if ( p . getName ( ) . contains ( \"(\" ) ) { templateParamMap . put ( p . getName ( ) , p ) ; } else { paramMap . put ( p . getName ( ) , p ) ; } } } } }", "nl": "Add parameters from the table"}}
{"translation": {"code": "private GempakParameter makeParameter ( String [ ] words ) { int num = 0 ; String description ; if ( words [ 0 ] != null ) { num = ( int ) Double . parseDouble ( words [ 0 ] ) ; } if ( ( words [ 3 ] == null ) || words [ 3 ] . equals ( \"\" ) ) { // no param name\r return null ; } String name = words [ 3 ] ; if ( name . contains ( \"-\" ) ) { int first = name . indexOf ( \"-\" ) ; int last = name . lastIndexOf ( \"-\" ) ; StringBuilder buf = new StringBuilder ( name . substring ( 0 , first ) ) ; buf . append ( \"(\" ) ; for ( int i = first ; i <= last ; i ++ ) { buf . append ( \"\\\\d\" ) ; } buf . append ( \")\" ) ; buf . append ( name . substring ( last + 1 ) ) ; name = buf . toString ( ) ; } if ( ( words [ 1 ] == null ) || words [ 1 ] . equals ( \"\" ) ) { description = words [ 3 ] ; } else { description = words [ 1 ] ; } String unit = words [ 2 ] ; if ( unit != null ) { unit = unit . replaceAll ( \"\\\\*\\\\*\" , \"\" ) ; if ( unit . equals ( \"-\" ) ) { unit = \"\" ; } } int decimalScale ; try { decimalScale = Integer . parseInt ( words [ 4 ] . trim ( ) ) ; } catch ( NumberFormatException ne ) { decimalScale = 0 ; } return new GempakParameter ( num , name , description , unit , decimalScale ) ; }", "nl": "Make a parameter from the tokens"}}
{"translation": {"code": "static public boolean featureTypeOk ( FeatureType want , FeatureType facType ) { if ( want == null ) return true ; if ( want == facType ) return true ; if ( want == FeatureType . ANY_POINT ) { return facType . isPointFeatureType ( ) ; } if ( facType == FeatureType . ANY_POINT ) { return want . isPointFeatureType ( ) ; } if ( want == FeatureType . COVERAGE ) { return facType . isCoverageFeatureType ( ) ; } if ( want == FeatureType . GRID ) { // for backwards compatibility\r return facType . isCoverageFeatureType ( ) ; } if ( want == FeatureType . SIMPLE_GEOMETRY ) { return facType . isCoverageFeatureType ( ) ; } if ( want == FeatureType . UGRID ) { return facType . isUnstructuredGridFeatureType ( ) ; } return false ; }", "nl": "Determine if factory type matches wanted feature type ."}}
{"translation": {"code": "static public FeatureDataset open ( FeatureType wantFeatureType , String location , ucar . nc2 . util . CancelTask task , Formatter errlog ) throws IOException { // special processing for thredds: datasets\r if ( location . startsWith ( DataFactory . SCHEME ) ) { DataFactory . Result result = new DataFactory ( ) . openFeatureDataset ( wantFeatureType , location , task ) ; errlog . format ( \"%s\" , result . errLog ) ; if ( ! featureTypeOk ( wantFeatureType , result . featureType ) ) { errlog . format ( \"wanted %s but dataset is of type %s%n\" , wantFeatureType , result . featureType ) ; result . close ( ) ; return null ; } return result . featureDataset ; // special processing for cdmrFeature: datasets\r } else if ( location . startsWith ( CdmrFeatureDataset . SCHEME ) ) { Optional < FeatureDataset > opt = CdmrFeatureDataset . factory ( wantFeatureType , location ) ; if ( opt . isPresent ( ) ) return opt . get ( ) ; errlog . format ( \"%s\" , opt . getErrorMessage ( ) ) ; return null ; // special processing for collection: datasets\r } else if ( location . startsWith ( ucar . nc2 . ft . point . collection . CompositeDatasetFactory . SCHEME ) ) { String spec = location . substring ( CompositeDatasetFactory . SCHEME . length ( ) ) ; MFileCollectionManager dcm = MFileCollectionManager . open ( spec , spec , null , errlog ) ; // LOOK we dont have a name\r return CompositeDatasetFactory . factory ( location , wantFeatureType , dcm , errlog ) ; } DatasetUrl durl = DatasetUrl . findDatasetUrl ( location ) ; // Cache ServiceType so we don't have to keep figuring it out\r if ( durl . serviceType == null ) { // skip GRIB check for anything not a plain ole file\r // check if its GRIB, may not have to go through NetcdfDataset\r Optional < FeatureDatasetCoverage > opt = CoverageDatasetFactory . openGrib ( location ) ; if ( opt . isPresent ( ) ) { // its a GRIB file\r return opt . get ( ) ; } else if ( ! opt . getErrorMessage ( ) . startsWith ( CoverageDatasetFactory . NOT_GRIB_FILE ) && ! opt . getErrorMessage ( ) . startsWith ( CoverageDatasetFactory . NO_GRIB_CLASS ) ) { errlog . format ( \"%s%n\" , opt . getErrorMessage ( ) ) ; // its a GRIB file with an error\r return null ; } } // otherwise open as NetcdfDataset and run it through the FeatureDatasetFactories\r NetcdfDataset ncd = NetcdfDataset . acquireDataset ( durl , true , task ) ; FeatureDataset fd = wrap ( wantFeatureType , ncd , task , errlog ) ; if ( fd == null ) ncd . close ( ) ; return fd ; }", "nl": "Open a dataset as a FeatureDataset ."}}
{"translation": {"code": "static public FeatureType findFeatureType ( NetcdfFile ncd ) { // search for explicit featureType global attribute\r String cdm_datatype = ncd . findAttValueIgnoreCase ( null , CF . FEATURE_TYPE , null ) ; if ( cdm_datatype == null ) cdm_datatype = ncd . findAttValueIgnoreCase ( null , \"cdm_data_type\" , null ) ; if ( cdm_datatype == null ) cdm_datatype = ncd . findAttValueIgnoreCase ( null , \"cdm_datatype\" , null ) ; if ( cdm_datatype == null ) cdm_datatype = ncd . findAttValueIgnoreCase ( null , \"thredds_data_type\" , null ) ; if ( cdm_datatype != null ) { for ( FeatureType ft : FeatureType . values ( ) ) if ( cdm_datatype . equalsIgnoreCase ( ft . name ( ) ) ) { if ( debug ) System . out . println ( \" wrapUnknown found cdm_datatype \" + cdm_datatype ) ; return ft ; } } CF . FeatureType cff = CF . FeatureType . getFeatureTypeFromGlobalAttribute ( ncd ) ; if ( cff != null ) return CF . FeatureType . convert ( cff ) ; return null ; }", "nl": "Try to determine the feature type of the dataset by examining its metadata ."}}
{"translation": {"code": "static public FeatureDataset wrap ( FeatureType wantFeatureType , NetcdfDataset ncd , ucar . nc2 . util . CancelTask task , Formatter errlog ) throws IOException { if ( debug ) System . out . println ( \"wrap \" + ncd . getLocation ( ) + \" want = \" + wantFeatureType ) ; // the case where we dont know what type it is\r if ( ( wantFeatureType == null ) || ( wantFeatureType == FeatureType . ANY ) ) { return wrapUnknown ( ncd , task , errlog ) ; } // find a Factory that claims this dataset by passing back an \"analysis result\" object\r Object analysis = null ; FeatureDatasetFactory useFactory = null ; for ( Factory fac : factoryList ) { if ( ! featureTypeOk ( wantFeatureType , fac . featureType ) ) continue ; if ( debug ) System . out . println ( \" wrap try factory \" + fac . factory . getClass ( ) . getName ( ) ) ; analysis = fac . factory . isMine ( wantFeatureType , ncd , errlog ) ; if ( analysis != null ) { useFactory = fac . factory ; break ; } } if ( null == useFactory ) { errlog . format ( \"**Failed to find FeatureDatasetFactory for= %s datatype=%s%n\" , ncd . getLocation ( ) , wantFeatureType ) ; return null ; } // this call must be thread safe - done by implementation\r return useFactory . open ( wantFeatureType , ncd , analysis , task , errlog ) ; }", "nl": "Wrap a NetcdfDataset as a FeatureDataset ."}}
{"translation": {"code": "public PrimitiveVector subset ( int start , int stop , int stride ) { BooleanPrimitiveVector n = new BooleanPrimitiveVector ( getTemplate ( ) ) ; stride = Math . max ( stride , 1 ) ; stop = Math . max ( start , stop ) ; int length = 1 + ( stop - start ) / stride ; n . setLength ( length ) ; int count = 0 ; for ( int i = start ; i <= stop ; i += stride ) { n . setValue ( count , vals [ i ] ) ; count ++ ; } return n ; }", "nl": "Create a new primitive vector using a subset of the data ."}}
{"translation": {"code": "public final void setValue ( int i , BaseType newVal ) { vals [ i ] = newVal ; BaseType parent = ( BaseType ) getTemplate ( ) . getParent ( ) ; vals [ i ] . setParent ( parent ) ; }", "nl": "Set the i th value of the array ."}}
{"translation": {"code": "@ Override public void setClearName ( String clearname ) { super . setClearName ( clearname ) ; if ( _attr != null ) _attr . setClearName ( clearname ) ; if ( _attrTbl != null ) _attrTbl . setClearName ( clearname ) ; }", "nl": "Sets the unencoded name of the class instance ."}}
{"translation": {"code": "private void parseAliases ( Element e , String indent ) throws DASException { parseLevel ++ ; String subIndent = indent + \"    \" ; if ( _Debug ) System . out . println ( indent + \"Parsing Aliases: \" ) ; if ( _Debug ) System . out . println ( subIndent + \"currentBT: \" + currentBT . getTypeName ( ) + \" \" + currentBT . getClearName ( ) ) ; // Get the Alias elements\r for ( Element aliasElement : e . getChildren ( \"Alias\" , opendapNameSpace ) ) { String name = null ; Attribute nameAttr = aliasElement . getAttribute ( \"name\" ) ; // no need to check that the getAttribute call worked because the Schema enforces\r // the presence of the \"name\" attribute for the <Alias> tag in the OPeNDAP namespace\r name = nameAttr . getValue ( ) ; String attributeName = null ; Attribute attributeAttr = aliasElement . getAttribute ( \"Attribute\" ) ; // no need to check that the getAttribute call worked because the Schema enforces\r // the presence of the \"Attribute\" attribute for the <Alias> tag in the OPeNDAP namespace\r attributeName = attributeAttr . getValue ( ) ; if ( _Debug ) { System . out . println ( subIndent + \"The name '\" + name + \"' is aliased to dds attribute: '\" + attributeName + \"'\" ) ; } // Add the Alias to the appropriate container.\r if ( currentAT == null ) currentBT . addAttributeAlias ( name , attributeName ) ; else currentAT . addAlias ( name , attributeName ) ; } parseLevel -- ; }", "nl": "Parse all of the Alias tags in this element of the XML document . Add each one to the correct Attribute Table ."}}
{"translation": {"code": "private void parseGrid ( Element gridElement , String indent ) throws DASException , NoSuchTypeException , BadSemanticsException { parseLevel ++ ; // Grab the parent object (which better be a Grid!)\r // just to elminate the hassle of casting everytime...\r DGrid myGrid = ( DGrid ) parentDC ; if ( _Debug ) { System . out . println ( \"Parsing Grid Element: \" + gridElement ) ; System . out . println ( \"Grid Elements: \" ) ; //showXMLElement(gridElement, indent);\r for ( Element element : gridElement . getChildren ( ) ) System . out . println ( element ) ; } // Get and parse the grid's Array element.\r String eName = \"Array\" ; if ( _Debug ) { System . out . println ( \"Parsing Array element.\" ) ; System . out . println ( \"Asking for element: '\" + eName + \"' in namespace: '\" + opendapNameSpace + \"'\" ) ; } Element arrayElement = gridElement . getChild ( eName , opendapNameSpace ) ; if ( _Debug ) System . out . println ( \"Got Array element: \" + arrayElement ) ; DArray gridArray = ( DArray ) newBaseType ( arrayElement ) ; parseArray ( arrayElement , gridArray , indent + \"    \" ) ; // Add it to the Grid\r myGrid . addVariable ( gridArray , DGrid . ARRAY ) ; // Get the Map elements\r eName = \"Map\" ; if ( _Debug ) { System . out . println ( \"Parsing Map elements.\" ) ; System . out . println ( \"Asking for element: '\" + eName + \"' in namespace: '\" + opendapNameSpace + \"'\" ) ; } List < Element > mapElements = gridElement . getChildren ( \"Map\" , opendapNameSpace ) ; // Make sure the number of Map elements matches the dimension of the Grid Array.\r if ( mapElements . size ( ) != gridArray . numDimensions ( ) ) throw new BadSemanticsException ( \"Error in Grid syntax: \" + \"The number of Map arrays must \" + \"equal the number of dimensions \" + \"of the data array.\" ) ; // Parse each Map element and poke it into the Grid.\r for ( Element mapElement : mapElements ) { DArray thisMap = ( DArray ) newBaseType ( mapElement ) ; parseArray ( mapElement , thisMap , indent + \"    \" ) ; if ( thisMap . numDimensions ( ) != 1 ) throw new BadSemanticsException ( \"Error in Grid syntax: \" + \"Maps may have only one dimension.\" ) ; myGrid . addVariable ( thisMap , DGrid . MAPS ) ; } parseLevel -- ; }", "nl": "Grids are unusual examples of DConstructor and require special handling when parsing ."}}
{"translation": {"code": "public long skip ( long n ) { if ( bytesRemaining >= n ) { bytesRemaining -= n ; return n ; } else { int oldBytesRemaining = bytesRemaining ; bytesRemaining = 0 ; return oldBytesRemaining ; } }", "nl": "Skips over and discards n bytes of data from the input stream ."}}
{"translation": {"code": "private void parseBase ( Element e , String indent ) throws DASException , NoSuchTypeException , BadSemanticsException { parseLevel ++ ; String type = e . getName ( ) ; if ( type . equals ( \"Attribute\" ) ) { // Do nothing here, the Attributes get parsed when the BaseType's\r // get built. This conditional basically serves as a \"trap\" to\r // ignore the <Attribute> tag.\r } else if ( type . equals ( \"Alias\" ) ) { // Do nothing here, the Aliases get parsed when the BaseType's\r // get built. This conditional basically serves as a \"trap\" to\r // ignore the <Alias> tag.\r } else if ( type . equals ( \"dataBLOB\" ) ) { // dataBLOB?\r // The schema says that the href attribute is\r // required for the dataBLOB element.\r org . jdom2 . Attribute hrefAttr = e . getAttribute ( \"href\" ) ; // Since it's required we know that the getAttribute()\r // method is not going to return null.\r String contentID = hrefAttr . getValue ( ) ; if ( _Debug ) System . out . println ( \"Found dataBLOB element. contentID=\\\"\" + contentID + \"\\\"\" ) ; dds . setBlobContentID ( contentID ) ; } else { // What's left must be a OPeNDAP BaseType\r if ( _Debug ) System . out . println ( \"Parsing new BaseType element. Parse level: \" + parseLevel ) ; if ( _Debug ) showXMLElement ( e , indent ) ; // Go get a new BaseType formed from this element\r BaseType bt = newBaseType ( e ) ; // Set it's parent.\r // bt.setParent(parentDC);\r // Add it to it's parent (container)\r parentDC . addVariable ( bt ) ; // Now we need to make sure this particular BaseType\r // derived element isn't some special type that needs\r // additional parsing:\r // Is it a container?\r if ( bt instanceof DConstructor ) { // Up date the parsers state, (cache my parent)\r DConstructor myParentDC = parentDC ; parentDC = ( DConstructor ) bt ; try { // Grids are special containers, handle them\r if ( bt instanceof DGrid ) { parseGrid ( e , indent ) ; } else { // Otherwise, recurse on the children\r for ( Element child : e . getChildren ( ) ) { parseBase ( child , indent + \"    \" ) ; } } } finally { // restore my parent\r parentDC = myParentDC ; } } else if ( bt instanceof DArray ) { // Array's are special, better build it if it is one\r if ( _Debug ) System . out . println ( \"Parsing Array instance.  Array name: '\" + bt . getClearName ( ) + \"'\" ) ; parseArray ( e , ( DArray ) bt , indent ) ; } } parseLevel -- ; }", "nl": "This method recursively travels through the DOM tree locating BaseType derived nodes and placing them in the DDS . The structure of the BaseType derived elements in the XML instance document is captured in the DOM object that is being parsed . This structure again reflected in the resulting DDS ."}}
{"translation": {"code": "protected void writeMarker ( DataOutputStream sink , byte marker ) throws IOException { //for(int i=0; i<4; i++)\r sink . writeByte ( marker ) ; sink . writeByte ( ( byte ) 0 ) ; sink . writeByte ( ( byte ) 0 ) ; sink . writeByte ( ( byte ) 0 ) ; }", "nl": "Writes a marker byte to the output stream ."}}
{"translation": {"code": "private void oldDeserialize ( DataInputStream source , ServerVersion sv , StatusUI statusUI ) throws IOException , DataReadException { try { for ( ; ; ) { deserializeSingle ( source , sv , statusUI ) ; } } catch ( EOFException e ) { } }", "nl": "The old deserialize protocol has a number of limitations stemming from its inability to tell when the sequence is finished . It s really only good for a Dataset containing a single sequence or where the sequence is the last thing in the dataset . To handle this we just read single instances until we get an IOException then stop ."}}
{"translation": {"code": "public BaseType getVariable ( int row , String name ) throws NoSuchVariableException { int dotIndex = name . indexOf ( ' ' ) ; if ( dotIndex != - 1 ) { // name contains \".\"\r String aggregate = name . substring ( 0 , dotIndex ) ; String field = name . substring ( dotIndex + 1 ) ; BaseType aggRef = getVariable ( aggregate ) ; if ( aggRef instanceof DConstructor ) return ( ( DConstructor ) aggRef ) . getVariable ( field ) ; // recurse\r else ; // fall through to throw statement\r } else { Vector selectedRow = ( Vector ) allValues . elementAt ( row ) ; for ( Enumeration e = selectedRow . elements ( ) ; e . hasMoreElements ( ) ; ) { BaseType v = ( BaseType ) e . nextElement ( ) ; if ( v . getEncodedName ( ) . equals ( name ) ) return v ; } } throw new NoSuchVariableException ( \"DSequence: getVariable()\" ) ; }", "nl": "Returns the named variable in the given row of the sequence ."}}
{"translation": {"code": "private byte readMarker ( DataInputStream source ) throws IOException { byte marker = source . readByte ( ) ; // pad out to a multiple of four bytes\r byte unused ; for ( int i = 0 ; i < 3 ; i ++ ) unused = source . readByte ( ) ; return marker ; }", "nl": "Reads a marker byte from the input stream ."}}
{"translation": {"code": "public int read ( byte b [ ] , int off , int len ) throws IOException { if ( len <= 0 ) { return 0 ; } int c = read ( ) ; if ( c == - 1 ) return - 1 ; b [ off ] = ( byte ) c ; // We've read one byte successfully, let's try for more\r int i = 1 ; try { for ( ; i < len ; i ++ ) { c = read ( ) ; if ( c == - 1 ) { break ; } b [ off + i ] = ( byte ) c ; } } catch ( IOException e ) { } return i ; }", "nl": "Reads up to len bytes of data from this input stream into an array of bytes . This method blocks until some input is available ."}}
{"translation": {"code": "private void getMoreBytes ( ) throws IOException { currentOffset = 0 ; // reset current array offset to 0\r int bytesRead = 0 ; // bytes read so far\r int lookingFor = 0 ; // character in endSequence to look for\r for ( ; bytesRead < lineBuf . length ; bytesRead ++ ) { int c = in . read ( ) ; if ( c == - 1 ) break ; // break on EOL and return what we have so far\r lineBuf [ bytesRead ] = ( byte ) c ; if ( lineBuf [ bytesRead ] == endSequence [ lookingFor ] ) { lookingFor ++ ; if ( lookingFor == endSequence . length ) { endFound = true ; break ; } } else if ( lineBuf [ bytesRead ] == endSequence [ 0 ] ) { // CHANGED JC\r lookingFor = 1 ; } else { lookingFor = 0 ; } } bytesRemaining = bytesRead ; // number of bytes we've read\r }", "nl": "Get more bytes into buffer . Stop when endSequence is found ."}}
{"translation": {"code": "public void readData ( InputStream is , StatusUI statusUI ) throws IOException , EOFException , DAP2Exception { /* ByteArrayOutputStream bout = new ByteArrayOutputStream(50 * 1000);\r\n      copy(is, bout);\r\n      LogStream.dbg.printf(\" readData size=%d %n\",bout.size());\r\n      LogStream.dbg.logflush();\r\n      ByteArrayInputStream bufferedIS = new ByteArrayInputStream( bout.toByteArray());  */ //statusUI = new Counter();\r // Buffer the input stream for better performance\r BufferedInputStream bufferedIS = new BufferedInputStream ( is ) ; // Use a DataInputStream for deserialize\r DataInputStream dataIS = new DataInputStream ( bufferedIS ) ; for ( Enumeration e = getVariables ( ) ; e . hasMoreElements ( ) ; ) { if ( statusUI != null && statusUI . userCancelled ( ) ) throw new DataReadException ( \"User cancelled\" ) ; ClientIO bt = ( ClientIO ) e . nextElement ( ) ; /* if (true) {\r\n            BaseType btt = (BaseType) bt;\r\n            System.out.printf(\"Deserializing: %s (%s) %n\", btt.getEncodedName(), ((BaseType) bt).getTypeName());\r\n          } */ bt . deserialize ( dataIS , ver , statusUI ) ; } //LogStream.out.printf(\"Deserializing: total size = %s %n\", counter);\r // notify GUI of finished download\r if ( statusUI != null ) statusUI . finished ( ) ; }", "nl": "Read the data stream from the given InputStream . In the C ++ version this code was in Connect ."}}
{"translation": {"code": "public final void externalize ( OutputStream os , boolean compress , boolean headers ) throws IOException { // First, print headers\r if ( headers ) { PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( os , Util . UTF8 ) ) ; pw . println ( \"HTTP/1.0 200 OK\" ) ; pw . println ( \"XDAP: \" + ServerVersion . DAP2_PROTOCOL_VERSION ) ; pw . println ( \"XDODS-Server: DODS/\" + ServerVersion . DAP2_PROTOCOL_VERSION ) ; pw . println ( \"Content-type: application/octet-stream\" ) ; pw . println ( \"Content-Description: dods-data\" ) ; if ( compress ) { pw . println ( \"Content-Encoding: deflate\" ) ; } pw . println ( ) ; pw . flush ( ) ; } // Buffer the output stream for better performance\r OutputStream bufferedOS ; if ( compress ) { // need a BufferedOutputStream - 3X performance - LOOK: why ??\r bufferedOS = new BufferedOutputStream ( new DeflaterOutputStream ( os ) ) ; } else { bufferedOS = new BufferedOutputStream ( os ) ; } // Redefine PrintWriter here, so the DDS is also compressed if necessary\r PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( bufferedOS , Util . UTF8 ) ) ; print ( pw ) ; // pw.println(\"Data:\");  // JCARON CHANGED\r pw . flush ( ) ; bufferedOS . write ( \"\\nData:\\n\" . getBytes ( CDM . utf8Charset ) ) ; // JCARON CHANGED\r bufferedOS . flush ( ) ; // Use a DataOutputStream for serialize\r DataOutputStream dataOS = new DataOutputStream ( bufferedOS ) ; for ( Enumeration e = getVariables ( ) ; e . hasMoreElements ( ) ; ) { ClientIO bt = ( ClientIO ) e . nextElement ( ) ; bt . externalize ( dataOS ) ; } // Note: for DeflaterOutputStream, flush() is not sufficient to flush\r // all buffered data\r dataOS . close ( ) ; }", "nl": "Dump the dataset using externalize methods . This should create a multipart Mime document with the binary representation of the DDS that is currently in memory ."}}
{"translation": {"code": "public synchronized Object get ( Object key ) { int index = keys . indexOf ( key ) ; if ( index != - 1 ) return elements . elementAt ( index ) ; else return null ; }", "nl": "Returns the value to which the key is mapped in this table ."}}
{"translation": {"code": "public void SetHasValue ( int type ) { this . type = type ; if ( debug ) { System . out . println ( \"sw = \" + ( char ) sw + \"; type = \" + type + \"; set = \" + set + \"; val = \" + val ) ; } }", "nl": "Set the value type of the option switch to the type passed"}}
{"translation": {"code": "public void write ( byte [ ] b , int off , int len ) throws IOException { count += len ; super . write ( b , off , len ) ; }", "nl": "Writes an array of bytes to the compressed output stream . This method will block until all the bytes are written ."}}
{"translation": {"code": "public static void probeObject ( Object o ) { Class c = o . getClass ( ) ; Class interfaces [ ] = c . getInterfaces ( ) ; Class parent = c . getSuperclass ( ) ; Method m [ ] = c . getMethods ( ) ; System . out . println ( \"********* OBJECT PROBE *********\" ) ; System . out . println ( \"Class Name:  \" + c . getName ( ) ) ; System . out . println ( \"Super Class: \" + parent . getName ( ) ) ; System . out . println ( \"Interfaces: \" ) ; for ( int i = 0 ; i < interfaces . length ; i ++ ) { System . out . println ( \"    \" + interfaces [ i ] . getName ( ) ) ; } System . out . println ( \"Methods:\" ) ; for ( int i = 0 ; i < m . length ; i ++ ) { Class params [ ] = m [ i ] . getParameterTypes ( ) ; Class excepts [ ] = m [ i ] . getExceptionTypes ( ) ; Class ret = m [ i ] . getReturnType ( ) ; System . out . print ( \"    \" + ret . getName ( ) + \"  \" + m [ i ] . getName ( ) + \"(\" ) ; for ( int j = 0 ; j < params . length ; j ++ ) { if ( j > 0 ) System . out . print ( \", \" ) ; System . out . print ( params [ j ] . getName ( ) ) ; } System . out . print ( \")  throws \" ) ; for ( int j = 0 ; j < excepts . length ; j ++ ) { if ( j > 0 ) System . out . print ( \", \" ) ; System . out . print ( excepts [ j ] . getName ( ) ) ; } System . out . println ( \"\" ) ; } System . out . println ( \"******************\" ) ; }", "nl": "Show me lots of stuff about the passed in object"}}
{"translation": {"code": "public synchronized Object put ( Object key , Object value ) throws NullPointerException { if ( key == null || value == null ) throw new NullPointerException ( ) ; int index = keys . indexOf ( key ) ; if ( index != - 1 ) { Object prev = elements . elementAt ( index ) ; elements . setElementAt ( value , index ) ; return prev ; } else { keys . addElement ( key ) ; elements . addElement ( value ) ; return null ; } }", "nl": "Maps the specified key to the specified value in this table ."}}
{"translation": {"code": "void makeVerticalTransform ( GridDataset gds , Formatter parseInfo ) { if ( vt != null ) return ; // already done\r if ( vCT == null ) return ; // no vt\r vt = vCT . makeVerticalTransform ( gds . getNetcdfDataset ( ) , timeDim ) ; if ( vt == null ) { if ( parseInfo != null ) parseInfo . format ( \"  - ERR can't make VerticalTransform = %s%n\" , vCT . getVerticalTransformType ( ) ) ; } else { if ( parseInfo != null ) parseInfo . format ( \"  - VerticalTransform = %s%n\" , vCT . getVerticalTransformType ( ) ) ; } }", "nl": "we have to delay making these since we dont identify the dimensions specifically until now"}}
{"translation": {"code": "private void setCalTypeAttributes ( Variable image , int calType ) { String longName = \"image values\" ; //String unit     = \"\";\r switch ( calType ) { case Calibrator . CAL_ALB : longName = \"albedo\" ; //unit     = \"%\";\r break ; case Calibrator . CAL_BRIT : longName = \"brightness values\" ; break ; case Calibrator . CAL_TEMP : longName = \"temperature\" ; //unit     = \"K\";\r break ; case Calibrator . CAL_RAD : longName = \"pixel radiance values\" ; //unit     = \"mW/m2/sr/cm-1\";\r break ; case Calibrator . CAL_RAW : longName = \"raw image values\" ; break ; default : break ; } image . addAttribute ( new Attribute ( \"long_name\" , longName ) ) ; if ( calUnit != null ) { image . addAttribute ( new Attribute ( CDM . UNITS , calUnit ) ) ; } if ( calScale != 1.f ) { image . addAttribute ( new Attribute ( \"scale_factor\" , calScale ) ) ; } }", "nl": "Set the long name and units for the calibration type"}}
{"translation": {"code": "@ Override public int [ ] findXYindexFromCoord ( double x_coord , double y_coord , int [ ] result ) { if ( result == null ) result = new int [ 2 ] ; if ( ( horizXaxis instanceof CoordinateAxis1D ) && ( horizYaxis instanceof CoordinateAxis1D ) ) { result [ 0 ] = ( ( CoordinateAxis1D ) horizXaxis ) . findCoordElement ( x_coord ) ; result [ 1 ] = ( ( CoordinateAxis1D ) horizYaxis ) . findCoordElement ( y_coord ) ; return result ; } else if ( ( horizXaxis instanceof CoordinateAxis2D ) && ( horizYaxis instanceof CoordinateAxis2D ) ) { if ( g2d == null ) g2d = new GridCoordinate2D ( ( CoordinateAxis2D ) horizYaxis , ( CoordinateAxis2D ) horizXaxis ) ; int [ ] result2 = new int [ 2 ] ; boolean found = g2d . findCoordElement ( y_coord , x_coord , result2 ) ; if ( found ) { result [ 0 ] = result2 [ 1 ] ; result [ 1 ] = result2 [ 0 ] ; } else { result [ 0 ] = - 1 ; result [ 1 ] = - 1 ; } return result ; } // cant happen\r throw new IllegalStateException ( \"GridCoordSystem.findXYindexFromCoord\" ) ; }", "nl": "Given a point in x y coordinate space find the x y index in the coordinate system ."}}
{"translation": {"code": "@ Override public int [ ] findXYindexFromCoordBounded ( double x_coord , double y_coord , int [ ] result ) { if ( result == null ) result = new int [ 2 ] ; if ( ( horizXaxis instanceof CoordinateAxis1D ) && ( horizYaxis instanceof CoordinateAxis1D ) ) { result [ 0 ] = ( ( CoordinateAxis1D ) horizXaxis ) . findCoordElementBounded ( x_coord ) ; result [ 1 ] = ( ( CoordinateAxis1D ) horizYaxis ) . findCoordElementBounded ( y_coord ) ; return result ; } else if ( ( horizXaxis instanceof CoordinateAxis2D ) && ( horizYaxis instanceof CoordinateAxis2D ) ) { if ( g2d == null ) g2d = new GridCoordinate2D ( ( CoordinateAxis2D ) horizYaxis , ( CoordinateAxis2D ) horizXaxis ) ; int [ ] result2 = new int [ 2 ] ; g2d . findCoordElement ( y_coord , x_coord , result2 ) ; // returns best guess\r result [ 0 ] = result2 [ 1 ] ; result [ 1 ] = result2 [ 0 ] ; return result ; } // cant happen\r throw new IllegalStateException ( \"GridCoordSystem.findXYindexFromCoord\" ) ; }", "nl": "Given a point in x y coordinate space find the x y index in the coordinate system . If outside the range the closest point is returned eg 0 or n - 1 depending on if the coordinate is too small or too large ."}}
{"translation": {"code": "@ Override public int [ ] findXYindexFromLatLon ( double lat , double lon , int [ ] result ) { Projection dataProjection = getProjection ( ) ; ProjectionPoint pp = dataProjection . latLonToProj ( new LatLonPointImpl ( lat , lon ) , new ProjectionPointImpl ( ) ) ; return findXYindexFromCoord ( pp . getX ( ) , pp . getY ( ) , result ) ; }", "nl": "Given a lat lon point find the x y index in the coordinate system ."}}
{"translation": {"code": "@ Override public int [ ] findXYindexFromLatLonBounded ( double lat , double lon , int [ ] result ) { Projection dataProjection = getProjection ( ) ; ProjectionPoint pp = dataProjection . latLonToProj ( new LatLonPointImpl ( lat , lon ) , new ProjectionPointImpl ( ) ) ; return findXYindexFromCoordBounded ( pp . getX ( ) , pp . getY ( ) , result ) ; }", "nl": "Given a lat lon point find the x y index in the coordinate system . If outside the range the closest point is returned"}}
{"translation": {"code": "@ Override public Array reallyRead ( Variable mainv , Section section , CancelTask cancelTask ) throws IOException , InvalidRangeException { FmrcInvLite . Gridset . Grid gridLite = ( FmrcInvLite . Gridset . Grid ) mainv . getSPobject ( ) ; // read the original type - if its been promoted to a new type, the conversion happens after this read\r DataType dtype = ( mainv instanceof VariableDS ) ? ( ( VariableDS ) mainv ) . getOriginalDataType ( ) : mainv . getDataType ( ) ; Array allData = Array . factory ( dtype , section . getShape ( ) ) ; int destPos = 0 ; // assumes the first two dimensions are runtime and time: LOOK: ensemble ??\r List < Range > ranges = section . getRanges ( ) ; Range runRange = ranges . get ( 0 ) ; Range timeRange = ranges . get ( 1 ) ; List < Range > innerSection = ranges . subList ( 2 , ranges . size ( ) ) ; // keep track of open file - must be local variable for thread safety\r HashMap < String , NetcdfDataset > openFilesRead = new HashMap <> ( ) ; try { // iterate over the desired runs\r for ( int runIdx : runRange ) { //Date runDate = vstate.runTimes.get(runIdx);\r // iterate over the desired forecast times\r for ( int timeIdx : timeRange ) { Array result = null ; // find the inventory for this grid, runtime, and hour\r TimeInventory . Instance timeInv = gridLite . getInstance ( runIdx , timeIdx ) ; if ( timeInv != null ) { if ( debugRead ) System . out . printf ( \"HIT %d %d \" , runIdx , timeIdx ) ; result = read ( timeInv , gridLite . name , innerSection , openFilesRead ) ; // may return null\r result = MAMath . convert ( result , dtype ) ; // just in case it need to be converted\r } // missing data\r if ( result == null ) { int [ ] shape = new Section ( innerSection ) . getShape ( ) ; result = ( ( VariableDS ) mainv ) . getMissingDataArray ( shape ) ; // fill with missing values\r if ( debugRead ) System . out . printf ( \"MISS %d %d \" , runIdx , timeIdx ) ; } if ( debugRead ) System . out . printf ( \"%d %d reallyRead %s %d bytes start at %d total size is %d%n\" , runIdx , timeIdx , mainv . getFullName ( ) , result . getSize ( ) , destPos , allData . getSize ( ) ) ; Array . arraycopy ( result , 0 , allData , destPos , ( int ) result . getSize ( ) ) ; destPos += result . getSize ( ) ; } } return allData ; } finally { // close any files used during this operation\r closeAll ( openFilesRead ) ; } }", "nl": "here is where agg variables get read"}}
{"translation": {"code": "private void setAreaDirectoryAttributes ( Variable v ) { if ( ( dirBlock == null ) || ( ad == null ) ) { return ; } for ( int i = 1 ; i < 14 ; i ++ ) { if ( i == 7 ) { continue ; } v . addAttribute ( new Attribute ( getADDescription ( i ) , dirBlock [ i ] ) ) ; } }", "nl": "Set the area directory attributes on the variable"}}
{"translation": {"code": "public static boolean isValidFile ( RandomAccessFile raf ) { String fileName = raf . getLocation ( ) ; AreaFile af = null ; try { af = new AreaFile ( fileName ) ; // LOOK opening again not ok for isValidFile\r return true ; } catch ( AreaFileException e ) { return false ; // barfola\r } finally { if ( af != null ) af . close ( ) ; // LOOK need to look at this code\r } }", "nl": "Check to see if this is a valid AREA file ."}}
{"translation": {"code": "@ Override public boolean isZPositive ( ) { if ( vertZaxis == null ) return false ; if ( vertZaxis . getPositive ( ) != null ) { return vertZaxis . getPositive ( ) . equalsIgnoreCase ( ucar . nc2 . constants . CF . POSITIVE_UP ) ; } if ( vertZaxis . getAxisType ( ) == AxisType . Height ) return true ; return vertZaxis . getAxisType ( ) != AxisType . Pressure ; }", "nl": "true if increasing z coordinate values means up in altitude"}}
{"translation": {"code": "private int getCalType ( String calName ) { int calTypeOut = Calibrator . CAL_NONE ; if ( calName . trim ( ) . equals ( \"ALB\" ) ) { calTypeOut = Calibrator . CAL_ALB ; } else if ( calName . trim ( ) . equals ( \"BRIT\" ) ) { calTypeOut = Calibrator . CAL_BRIT ; } else if ( calName . trim ( ) . equals ( \"RAD\" ) ) { calTypeOut = Calibrator . CAL_RAD ; } else if ( calName . trim ( ) . equals ( \"RAW\" ) ) { calTypeOut = Calibrator . CAL_RAW ; } else if ( calName . trim ( ) . equals ( \"TEMP\" ) ) { calTypeOut = Calibrator . CAL_TEMP ; } return calTypeOut ; }", "nl": "Get the calibration type from the name"}}
{"translation": {"code": "public void getRemoteFiles ( final CancelTask _cancel ) { this . cancel = _cancel ; String urls = config . getServerPrefix ( ) + \"/thredds/admin/log/\" + type + \"/\" ; ta . append ( String . format ( \"Download URL = %s%n\" , urls ) ) ; String contents = null ; try ( HTTPMethod method = HTTPFactory . Get ( session , urls ) ) { int statusCode = method . execute ( ) ; if ( statusCode == 200 ) contents = method . getResponseAsString ( ) ; if ( ( contents == null ) || ( contents . length ( ) == 0 ) ) { ta . append ( String . format ( \"Failed to get logs at URL = %s%n%n\" , urls ) ) ; return ; } else { ta . append ( String . format ( \"Logs at URL = %s%n%s%n\" , urls , contents ) ) ; } } catch ( Throwable t ) { ta . append ( String . format ( \"Failed to get logs at URL = %s error = %s%n%n\" , urls , t . getMessage ( ) ) ) ; t . printStackTrace ( ) ; return ; } // update text area in background  http://technobuz.com/2009/05/update-jtextarea-dynamically/\r final String list = contents ; SwingWorker worker = new SwingWorker < String , Void > ( ) { @ Override protected String doInBackground ( ) throws Exception { try { ta . append ( String . format ( \"Local log files stored in = %s%n%n\" , localDir ) ) ; String [ ] lines = list . split ( \"\\n\" ) ; for ( String line : lines ) { new RemoteLog ( line . trim ( ) ) ; if ( cancel . isCancel ( ) ) { break ; } } } catch ( Throwable t ) { t . printStackTrace ( ) ; } return null ; } public void done ( ) { if ( cancel . isCancel ( ) ) ta . append ( String . format ( \"Download was cancelled for %s%n\" , type ) ) ; else ta . append ( String . format ( \"Download complete for %s%n\" , type ) ) ; } } ; // do in background\r worker . execute ( ) ; }", "nl": "copy remote files to localDir"}}
{"translation": {"code": "static public List < Record > readTable ( String urlString , String format , int maxLines ) throws IOException , NumberFormatException { InputStream ios ; if ( urlString . startsWith ( \"http:\" ) ) { URL url = new URL ( urlString ) ; ios = url . openStream ( ) ; } else { ios = new FileInputStream ( urlString ) ; } return readTable ( ios , format , maxLines ) ; }", "nl": "Reads a URL or file in as a table ."}}
{"translation": {"code": "public void writeXML ( NetcdfDataset ncd , OutputStream os , boolean showCoords , String uri ) throws IOException { // Output the document, use standard formatter\r //XMLOutputter fmt = new XMLOutputter(\"  \", true);\r //fmt.setLineSeparator(\"\\n\");\r XMLOutputter fmt = new XMLOutputter ( Format . getPrettyFormat ( ) ) ; fmt . output ( makeDocument ( ncd , showCoords , uri ) , os ) ; }", "nl": "Write a NetcdfDataset as an NcML - G document to the specified stream ."}}
{"translation": {"code": "public void addItem ( Object item ) { if ( item == null ) return ; for ( int i = 0 ; i < getItemCount ( ) ; i ++ ) { if ( item . equals ( getItemAt ( i ) ) ) { if ( i == 0 ) { setSelectedIndex ( 0 ) ; return ; // already there\r } removeItemAt ( i ) ; } } // add as first in the list\r insertItemAt ( item , 0 ) ; setSelectedIndex ( 0 ) ; }", "nl": "Add the item to the top of the list . If it already exists move it to the top ."}}
{"translation": {"code": "public long calcCRC ( ) { long crc ; if ( rawData == null ) crc = predefinedGridDefinitionCenter << 16 + predefinedGridDefinition ; else { CRC32 crc32 = new CRC32 ( ) ; crc32 . update ( rawData ) ; crc = crc32 . getValue ( ) ; } return crc ; }", "nl": "Calculate the CRC of the entire byte array"}}
{"translation": {"code": "public static float [ ] readData ( RandomAccessFile raf , long startPos ) throws IOException { raf . seek ( startPos ) ; Grib1Record gr = new Grib1Record ( raf ) ; return gr . readData ( raf ) ; }", "nl": "Read data array by first reading in GribRecord . All sections are read in so scanMode is from the datafile not the index ."}}
{"translation": {"code": "public static void main ( String [ ] args ) throws IOException { int count = 0 ; String file = ( args . length > 0 ) ? args [ 0 ] : \"Q:/cdmUnitTest/formats/grib1/ECMWF.hybrid.grib1\" ; RandomAccessFile raf = new RandomAccessFile ( file , \"r\" ) ; System . out . printf ( \"Read %s%n\" , raf . getLocation ( ) ) ; Grib1RecordScanner scan = new Grib1RecordScanner ( raf ) ; while ( scan . hasNext ( ) ) { scan . next ( ) ; count ++ ; } raf . close ( ) ; System . out . printf ( \"count=%d%n\" , count ) ; }", "nl": "Count the number of records in a grib1 file ."}}
{"translation": {"code": "public static Grib1Gds factory ( int center , int gridNumber ) { if ( center == 7 ) { return factoryNCEP ( gridNumber ) ; } else throw new IllegalArgumentException ( \"Dont have predefined GDS \" + gridNumber + \" from \" + center ) ; }", "nl": "Constructs a Grib1Gds object from a pds and predefined tables ."}}
{"translation": {"code": "private Grib1Record readRecord ( Grib1IndexProto . Grib1Record p ) { Grib1SectionIndicator is = new Grib1SectionIndicator ( p . getGribMessageStart ( ) , p . getGribMessageLength ( ) ) ; Grib1SectionProductDefinition pds = new Grib1SectionProductDefinition ( p . getPds ( ) . toByteArray ( ) ) ; Grib1SectionGridDefinition gds = pds . gdsExists ( ) ? gdsList . get ( p . getGdsIdx ( ) ) : new Grib1SectionGridDefinition ( pds ) ; Grib1SectionBitMap bms = pds . bmsExists ( ) ? new Grib1SectionBitMap ( p . getBmsPos ( ) ) : null ; Grib1SectionBinaryData dataSection = new Grib1SectionBinaryData ( p . getDataPos ( ) , p . getDataLen ( ) ) ; return new Grib1Record ( p . getHeader ( ) . toByteArray ( ) , is , gds , pds , bms , dataSection ) ; }", "nl": "deserialize the Grib1Record object"}}
{"translation": {"code": "public String getTimeCoord ( ) { if ( isInterval ( ) ) { int [ ] intv = getInterval ( ) ; return intv [ 0 ] + \"-\" + intv [ 1 ] ; } return Integer . toString ( getForecastTime ( ) ) ; }", "nl": "A string representation of the time coordinate whether its an interval or not ."}}
{"translation": {"code": "public static GribIndex readOrCreateIndexFromSingleFile ( boolean isGrib1 , MFile mfile , CollectionUpdateType force , org . slf4j . Logger logger ) throws IOException { GribIndex index = isGrib1 ? new Grib1Index ( ) : new Grib2Index ( ) ; if ( ! index . readIndex ( mfile . getPath ( ) , mfile . getLastModified ( ) , force ) ) { // heres where the index date is checked against the data file\r index . makeIndex ( mfile . getPath ( ) , null ) ; logger . debug ( \"  Index written: {} == {} records\" , mfile . getName ( ) + GBX9_IDX , index . getNRecords ( ) ) ; } else if ( debug ) { logger . debug ( \"  Index read: {} == {} records\" , mfile . getName ( ) + GBX9_IDX , index . getNRecords ( ) ) ; } return index ; }", "nl": "Create a gbx9 index from a single grib1 or grib2 file . Use the existing index if it already exists ."}}
{"translation": {"code": "public FeatureType getFirstFeatureType ( ) { for ( NestedTable nt : leaves ) { if ( nt . hasCoords ( ) ) return nt . getFeatureType ( ) ; } return null ; }", "nl": "for debugging messages"}}
{"translation": {"code": "static public TableAnalyzer factory ( TableConfigurer tc , FeatureType wantFeatureType , NetcdfDataset ds ) throws IOException { // Create a TableAnalyzer with this TableConfigurer (may be null)\r TableAnalyzer analyzer = new TableAnalyzer ( ds , tc ) ; if ( tc != null ) { if ( tc . getConvName ( ) == null ) analyzer . userAdvice . format ( \" No 'Conventions' global attribute.%n\" ) ; else analyzer . userAdvice . format ( \" Conventions global attribute = %s %n\" , tc . getConvName ( ) ) ; // add the convention name used\r if ( tc . getConvUsed ( ) != null ) { analyzer . setConventionUsed ( tc . getConvUsed ( ) ) ; if ( ! tc . getConvUsed ( ) . equals ( tc . getConvName ( ) ) ) analyzer . userAdvice . format ( \" TableConfigurer used = \" + tc . getConvUsed ( ) + \".%n\" ) ; } } else { analyzer . userAdvice . format ( \" No TableConfigurer found, using default analysis.%n\" ) ; } // construct the nested table object\r analyzer . analyze ( wantFeatureType ) ; return analyzer ; }", "nl": "Create a TableAnalyser for this dataset with the given TableConfigurer"}}
{"translation": {"code": "private void analyze ( FeatureType wantFeatureType ) throws IOException { // for netcdf-3 files, convert record dimension to structure\r // LOOK may be problems when served via opendap\r boolean structAdded = ( Boolean ) ds . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; if ( tc == null ) { makeTablesDefault ( structAdded ) ; makeNestedTables ( ) ; } else { configResult = tc . getConfig ( wantFeatureType , ds , errlog ) ; if ( configResult != null ) addTableRecurse ( configResult ) ; // kinda stupid\r else { // use default\r makeTablesDefault ( structAdded ) ; makeNestedTables ( ) ; } } // find the leaves\r for ( TableConfig config : tableSet ) { if ( config . children == null ) { // its a leaf\r NestedTable flatTable = new NestedTable ( ds , config , errlog ) ; leaves . add ( flatTable ) ; } } if ( PointDatasetStandardFactory . showTables ) getDetailInfo ( new Formatter ( System . out ) ) ; }", "nl": "Make a NestedTable object for the dataset ."}}
{"translation": {"code": "public static int int2 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; return int2 ( a , b ) ; }", "nl": "Convert 2 bytes into a signed integer ."}}
{"translation": {"code": "public static long int8 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; int c = raf . read ( ) ; int d = raf . read ( ) ; int e = raf . read ( ) ; int f = raf . read ( ) ; int g = raf . read ( ) ; int h = raf . read ( ) ; return ( 1 - ( ( a & 128 ) >> 6 ) ) * ( ( long ) ( a & 127 ) << 56 | ( long ) b << 48 | ( long ) c << 40 | ( long ) d << 32 | e << 24 | f << 16 | g << 8 | h ) ; }", "nl": "Convert 8 bytes into a signed long ."}}
{"translation": {"code": "public static int int3 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; int c = raf . read ( ) ; return int3 ( a , b , c ) ; }", "nl": "Convert 3 bytes into a signed integer ."}}
{"translation": {"code": "public static float float4 ( int a , int b , int c , int d ) { int sgn , mant , exp ; mant = b << 16 | c << 8 | d ; if ( mant == 0 ) { return 0.0f ; } sgn = - ( ( ( a & 128 ) >> 6 ) - 1 ) ; exp = ( a & 127 ) - 64 ; return ( float ) ( sgn * Math . pow ( 16.0 , exp - 6 ) * mant ) ; }", "nl": "Convert 4 bytes to a float ."}}
{"translation": {"code": "public static float float4 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; int c = raf . read ( ) ; int d = raf . read ( ) ; return float4 ( a , b , c , d ) ; }", "nl": "Convert 4 bytes into a float value ."}}
{"translation": {"code": "public static int uint3 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; int c = raf . read ( ) ; return uint3 ( a , b , c ) ; }", "nl": "Convert 3 bytes into an unsigned integer ."}}
{"translation": {"code": "public static int uint2 ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; int b = raf . read ( ) ; return uint2 ( a , b ) ; }", "nl": "Convert 2 bytes into an unsigned integer ."}}
{"translation": {"code": "public final boolean isThin ( ) { if ( rawData == null ) return false ; int octet5 = getOctet ( 5 ) ; int nv = getOctet ( 4 ) ; return ( octet5 != 255 ) && ( nv == 0 || nv == 255 ) ; }", "nl": "is a thin grid"}}
{"translation": {"code": "public void setGaussianLats ( int nparallels , float la1 , float la2 ) { log . debug ( \"la1 {}, la2 {}\" , la1 , la2 ) ; if ( this . gaussLats != null ) throw new RuntimeException ( \"Cant modify GdsHorizCoordSys\" ) ; int nlats = ( 2 * nparallels ) ; GaussianLatitudes gaussLats = GaussianLatitudes . factory ( nlats ) ; int bestStartIndex = 0 , bestEndIndex = 0 ; double bestStartDiff = Double . MAX_VALUE ; double bestEndDiff = Double . MAX_VALUE ; for ( int i = 0 ; i < nlats ; i ++ ) { double diff = Math . abs ( gaussLats . latd [ i ] - la1 ) ; if ( diff < bestStartDiff ) { bestStartDiff = diff ; bestStartIndex = i ; } diff = Math . abs ( gaussLats . latd [ i ] - la2 ) ; if ( diff < bestEndDiff ) { bestEndDiff = diff ; bestEndIndex = i ; } } log . debug ( \"first pass: bestStartIndex {}, bestEndIndex {}\" , bestStartIndex , bestEndIndex ) ; if ( Math . abs ( bestEndIndex - bestStartIndex ) + 1 != nyRaw ) { log . warn ( \"GRIB gaussian lats: NP != NY, use NY\" ) ; // see email from Toussaint@dkrz.de datafil:\r nlats = nyRaw ; gaussLats = GaussianLatitudes . factory ( nlats ) ; bestStartIndex = 0 ; bestEndIndex = nyRaw - 1 ; } boolean goesUp = bestEndIndex > bestStartIndex ; log . debug ( \"bestStartIndex {}, bestEndIndex {}, goesUp {}\" , bestStartIndex , bestEndIndex , goesUp ) ; // create the data\r int useIndex = bestStartIndex ; float [ ] data = new float [ nyRaw ] ; float [ ] gaussw = new float [ nyRaw ] ; for ( int i = 0 ; i < nyRaw ; i ++ ) { data [ i ] = ( float ) gaussLats . latd [ useIndex ] ; gaussw [ i ] = ( float ) gaussLats . gaussw [ useIndex ] ; log . trace ( \"i {}, useIndex {}, data {}, gaussw {}\" , i , useIndex , data [ i ] , gaussw [ i ] ) ; if ( goesUp ) { useIndex ++ ; } else { useIndex -- ; } } this . gaussLats = Array . factory ( DataType . FLOAT , new int [ ] { nyRaw } , data ) ; this . gaussw = Array . factory ( DataType . FLOAT , new int [ ] { nyRaw } , gaussw ) ; }", "nl": "some weird adjustment for la1 and la2 ."}}
{"translation": {"code": "public static String getZisPositive ( String zaxisName , String vertCoordUnits ) { if ( vertCoordUnits == null ) return CF . POSITIVE_UP ; if ( vertCoordUnits . isEmpty ( ) ) return CF . POSITIVE_UP ; if ( SimpleUnit . isCompatible ( \"millibar\" , vertCoordUnits ) ) return CF . POSITIVE_DOWN ; if ( SimpleUnit . isCompatible ( \"m\" , vertCoordUnits ) ) return CF . POSITIVE_UP ; // dunno - make it up\r return CF . POSITIVE_UP ; }", "nl": "Guess the value of ZisPositive based on z axis name and units"}}
{"translation": {"code": "public static String getParameterIgnoreCase ( HttpServletRequest req , String paramName ) { Enumeration e = req . getParameterNames ( ) ; while ( e . hasMoreElements ( ) ) { String s = ( String ) e . nextElement ( ) ; if ( s . equalsIgnoreCase ( paramName ) ) return req . getParameter ( s ) ; } return null ; }", "nl": "Return the value of the given parameter for the given request . Should only be used if the parameter is known to only have one value . If used on a multi - valued parameter the first value is returned ."}}
{"translation": {"code": "public static String getRequest ( HttpServletRequest req ) { String query = req . getQueryString ( ) ; return getRequestBase ( req ) + ( query == null ? \"\" : \"?\" + query ) ; }", "nl": "The entire request including query string"}}
{"translation": {"code": "public static URI getRequestURI ( HttpServletRequest req ) { try { return new URI ( getRequestBase ( req ) ) ; } catch ( URISyntaxException e ) { e . printStackTrace ( ) ; return null ; } }", "nl": "The request base as a URI"}}
{"translation": {"code": "public static void returnString ( String contents , HttpServletResponse res ) throws IOException { try { ServletOutputStream out = res . getOutputStream ( ) ; IO . copy ( new ByteArrayInputStream ( contents . getBytes ( CDM . utf8Charset ) ) , out ) ; } catch ( IOException e ) { log . error ( \" IOException sending string: \" , e ) ; res . sendError ( HttpServletResponse . SC_NOT_FOUND , \"Problem sending string: \" + e . getMessage ( ) ) ; } }", "nl": "Send given content string as the HTTP response ."}}
{"translation": {"code": "public static String getRequestPath ( HttpServletRequest req ) { StringBuilder buff = new StringBuilder ( ) ; if ( req . getServletPath ( ) != null ) buff . append ( req . getServletPath ( ) ) ; if ( req . getPathInfo ( ) != null ) buff . append ( req . getPathInfo ( ) ) ; return buff . toString ( ) ; }", "nl": "servletPath + pathInfo"}}
{"translation": {"code": "public static void returnFile ( HttpServlet servlet , String contentPath , String path , HttpServletRequest req , HttpServletResponse res , String contentType ) throws IOException { String filename = ServletUtil . formFilename ( contentPath , path ) ; log . debug ( \"returnFile(): returning file <\" + filename + \">.\" ) ; // No file, nothing to view\r if ( filename == null ) { res . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } // dontallow ..\r if ( filename . contains ( \"..\" ) ) { res . sendError ( HttpServletResponse . SC_FORBIDDEN ) ; return ; } // dont allow access to WEB-INF or META-INF\r String upper = filename . toUpperCase ( ) ; if ( upper . contains ( \"WEB-INF\" ) || upper . contains ( \"META-INF\" ) ) { res . sendError ( HttpServletResponse . SC_FORBIDDEN ) ; return ; } returnFile ( servlet , req , res , new File ( filename ) , contentType ) ; }", "nl": "Write a file to the response stream ."}}
{"translation": {"code": "protected boolean identifyEncodingStation ( NetcdfDataset ds , EncodingInfo info , CF . FeatureType ftype , Formatter errlog ) { // find the obs dimension\r Dimension obsDim = null ; if ( info . time . getRank ( ) > 0 ) obsDim = info . time . getDimension ( info . time . getRank ( ) - 1 ) ; // may be time(time) or time(stn, obs)\r else if ( info . time . getParentStructure ( ) != null ) { Structure parent = info . time . getParentStructure ( ) ; // if time axis is a structure member, try pulling dimension out of parent structure\r obsDim = parent . getDimension ( parent . getRank ( ) - 1 ) ; } if ( obsDim == null ) { errlog . format ( \"CFpointObs: must have a non-scalar Time coordinate%n\" ) ; return false ; } // find the station dimension\r if ( info . lat . getRank ( ) == 0 ) { // scalar means single\r info . set ( Encoding . single , null , obsDim ) ; return true ; } Dimension stnDim = info . lat . getDimension ( 0 ) ; if ( obsDim == stnDim ) { info . set ( Encoding . flat , null , obsDim ) ; // not used ?\r return true ; } // the raggeds\r if ( identifyRaggeds ( ds , info , stnDim , obsDim , errlog ) ) return true ; // heres whats left\r if ( info . lat . getRank ( ) == 1 ) { //Encoding e = (info.time.getParentStructure() != null) ? Encoding.multiStructure : Encoding.multidim;\r info . set ( Encoding . multidim , stnDim , obsDim ) ; return true ; } errlog . format ( \"CFpointObs: %s Must have Lat/Lon coordinates of rank 0 or 1%n\" , ftype ) ; return false ; }", "nl": "for stations figure out the encoding"}}
{"translation": {"code": "protected String matchAxisTypeAndDimension ( NetcdfDataset ds , AxisType type , final Dimension outer ) { Variable var = CoordSysEvaluator . findCoordByType ( ds , type , new CoordSysEvaluator . Predicate ( ) { public boolean match ( CoordinateAxis axis ) { if ( ( outer == null ) && ( axis . getRank ( ) == 0 ) ) return true ; if ( ( outer != null ) && ( axis . getRank ( ) == 1 ) && ( outer . equals ( axis . getDimension ( 0 ) ) ) ) return true ; // if axis is structure member, try pulling dimension out of parent structure\r if ( axis . getParentStructure ( ) != null ) { Structure parent = axis . getParentStructure ( ) ; if ( ( outer != null ) && ( parent . getRank ( ) == 1 ) && ( outer . equals ( parent . getDimension ( 0 ) ) ) ) return true ; } return false ; } } ) ; if ( var == null ) return null ; return var . getFullName ( ) ; }", "nl": "class I don t understand enough of the code base to anticipate implementation artifacts ."}}
{"translation": {"code": "public double makeValue ( Date date ) { double secs = date . getTime ( ) / 1000.0 ; double origin_secs = getDateOrigin ( ) . getTime ( ) / 1000.0 ; double diff = secs - origin_secs ; try { timeUnit . setValueInSeconds ( diff ) ; } catch ( Exception e ) { throw new RuntimeException ( e . getMessage ( ) ) ; } return timeUnit . getValue ( ) ; }", "nl": "Create the equivalent value from this base unit and the given Date . Inverse of makeDate ."}}
{"translation": {"code": "public Date makeDate ( double val ) { if ( Double . isNaN ( val ) ) return null ; double secs = timeUnit . getValueInSeconds ( val ) ; //\r return new Date ( getDateOrigin ( ) . getTime ( ) + ( long ) ( 1000 * secs ) ) ; }", "nl": "Create a Date from this base unit and the given value ."}}
{"translation": {"code": "public Date getDate ( ) { double secs = timeUnit . getValueInSeconds ( value ) ; return new Date ( getDateOrigin ( ) . getTime ( ) + ( long ) ( 1000 * secs ) ) ; }", "nl": "Get the equivalent java . util . Date ."}}
{"translation": {"code": "public Date getDateOrigin ( ) { if ( ! ( uu instanceof TimeScaleUnit ) ) return null ; TimeScaleUnit tu = ( TimeScaleUnit ) uu ; return tu . getOrigin ( ) ; }", "nl": "Get the origin Date ."}}
{"translation": {"code": "static public Date getStandardOrISO ( String text ) { Date result = getStandardDate ( text ) ; if ( result == null ) { DateFormatter formatter = new DateFormatter ( ) ; result = formatter . getISODate ( text ) ; } return result ; }", "nl": "Create a java . util . Date from a udunit or ISO String ."}}
{"translation": {"code": "static public Date getStandardDate ( String text ) { double value ; String udunitString ; text = text . trim ( ) ; StringTokenizer stoker = new StringTokenizer ( text ) ; String firstToke = stoker . nextToken ( ) ; try { value = Double . parseDouble ( firstToke ) ; udunitString = text . substring ( firstToke . length ( ) ) ; } catch ( NumberFormatException e ) { // stupid way to test if it starts with a number\r value = 0.0 ; udunitString = text ; } DateUnit du ; try { du = new DateUnit ( udunitString ) ; } catch ( Exception e ) { return null ; } return du . makeDate ( value ) ; }", "nl": "Create a java . util . Date from this udunits String ."}}
{"translation": {"code": "public String makeStandardDateString ( double value ) { Date date = makeDate ( value ) ; if ( date == null ) return null ; DateFormatter formatter = new DateFormatter ( ) ; return formatter . toDateTimeStringISO ( date ) ; }", "nl": "Make a standard GMT string representation from this unit and given value ."}}
{"translation": {"code": "public DAPNode cloneDAG ( CloneMap map ) throws CloneNotSupportedException { DAPNode node = ( DAPNode ) super . clone ( ) ; // Object.clone\r map . nodes . put ( this , node ) ; DAPNode tmp = map . nodes . get ( _myParent ) ; if ( tmp != node ) _myParent = tmp ; return node ; }", "nl": "This procedure does the actual recursive clone ."}}
{"translation": {"code": "private void openURL ( String urlString , Command command ) { try { //Open the URLConnection for reading\r URL u = new URL ( urlString ) ; currentConnection = ( HttpURLConnection ) u . openConnection ( ) ; currentConnection . setRequestMethod ( command . toString ( ) ) ; // GET or HEAD\r currentConnection . setAllowUserInteraction ( true ) ; clear ( ) ; appendLine ( command + \" request for \" + urlString ) ; // request headers\r Map < String , List < String > > reqs = currentConnection . getRequestProperties ( ) ; for ( Map . Entry < String , List < String > > ent : reqs . entrySet ( ) ) { append ( \" \" + ent . getKey ( ) + \": \" ) ; for ( String v : ent . getValue ( ) ) append ( v + \" \" ) ; appendLine ( \"\" ) ; } appendLine ( \"\" ) ; appendLine ( \"getFollowRedirects=\" + HttpURLConnection . getFollowRedirects ( ) ) ; appendLine ( \"getInstanceFollowRedirects=\" + currentConnection . getInstanceFollowRedirects ( ) ) ; appendLine ( \"AllowUserInteraction=\" + currentConnection . getAllowUserInteraction ( ) ) ; appendLine ( \"\" ) ; int code = currentConnection . getResponseCode ( ) ; String response = currentConnection . getResponseMessage ( ) ; // response headers\r appendLine ( \" HTTP/1.x \" + code + \" \" + response ) ; appendLine ( \" content-length: \" + currentConnection . getContentLength ( ) ) ; appendLine ( \" content-encoding: \" + currentConnection . getContentEncoding ( ) ) ; appendLine ( \" content-type: \" + currentConnection . getContentType ( ) ) ; appendLine ( \"\\nHeaders: \" ) ; for ( int j = 1 ; true ; j ++ ) { String header = currentConnection . getHeaderField ( j ) ; String key = currentConnection . getHeaderFieldKey ( j ) ; if ( header == null || key == null ) break ; appendLine ( \" \" + key + \": \" + header ) ; } appendLine ( \"\" ) ; appendLine ( \"contents:\" ) ; // read it\r java . io . InputStream is = currentConnection . getInputStream ( ) ; ByteArrayOutputStream bout = new ByteArrayOutputStream ( 200000 ) ; IO . copy ( is , bout ) ; is . close ( ) ; append ( new String ( bout . toByteArray ( ) , CDM . utf8Charset ) ) ; appendLine ( \"end contents\" ) ; } catch ( MalformedURLException e ) { append ( urlString + \" is not a parseable URL\" ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } }", "nl": "Uses java . net"}}
{"translation": {"code": "public int projectedComponents ( boolean constrained ) { int comp ; if ( constrained ) { comp = ( ( DArray ) arrayVar ) . isProject ( ) ? 1 : 0 ; Enumeration e = mapVars . elements ( ) ; while ( e . hasMoreElements ( ) ) { if ( ( ( DArray ) e . nextElement ( ) ) . isProject ( ) ) comp ++ ; } } else { comp = 1 + mapVars . size ( ) ; } return comp ; }", "nl": "How many prohected components of this Grid object?"}}
{"translation": {"code": "public double getParameter ( String name ) { Double val = ( Double ) parameters . get ( name . toLowerCase ( ) ) ; if ( val == null ) { throw new IllegalArgumentException ( \"no parameter called \" + name ) ; } return val . doubleValue ( ) ; }", "nl": "Get the value of the projection parameter . An IllegalArgument exception is thrown if the parameter is not found ."}}
{"translation": {"code": "public static void addParameterTable ( int center , int subcenter , int tableVersion , String tableFilename ) { Grib1ParamTableReader table = new Grib1ParamTableReader ( center , subcenter , tableVersion , tableFilename ) ; synchronized ( lock ) { standardLookup . tables . add ( standardTablesStart , table ) ; standardTablesStart ++ ; } }", "nl": "Add table to standard tables for a specific center subcenter and version ."}}
{"translation": {"code": "public static boolean addParameterTableLookup ( String lookupFilename ) throws IOException { Lookup lookup = new Lookup ( ) ; if ( ! lookup . readLookupTable ( lookupFilename ) ) return false ; synchronized ( lock ) { standardLookup . tables . addAll ( standardTablesStart , lookup . tables ) ; standardTablesStart += lookup . tables . size ( ) ; } return true ; }", "nl": "Add all tables in list to standard tables"}}
{"translation": {"code": "public static Grib1ParamTables factory ( String paramTablePath , String lookupTablePath ) throws IOException { if ( paramTablePath == null && lookupTablePath == null ) return new Grib1ParamTables ( ) ; Lookup lookup = null ; Grib1ParamTableReader override = null ; Grib1ParamTableReader table ; if ( paramTablePath != null ) { table = localTableHash . get ( paramTablePath ) ; if ( table == null ) { table = new Grib1ParamTableReader ( paramTablePath ) ; localTableHash . put ( paramTablePath , table ) ; override = table ; } } if ( lookupTablePath != null ) { lookup = new Lookup ( ) ; if ( ! lookup . readLookupTable ( lookupTablePath ) ) throw new FileNotFoundException ( \"cant read lookup table=\" + lookupTablePath ) ; } return new Grib1ParamTables ( lookup , override ) ; }", "nl": "Get a Grib1ParamTables object optionally specifying a parameter table or lookup table specific to this dataset ."}}
{"translation": {"code": "static public String collapseWhitespace ( String s ) { int len = s . length ( ) ; StringBuilder b = new StringBuilder ( len ) ; for ( int i = 0 ; i < len ; i ++ ) { char c = s . charAt ( i ) ; if ( ! Character . isWhitespace ( c ) ) { b . append ( c ) ; } else { b . append ( ' ' ) ; while ( ( i + 1 < len ) && Character . isWhitespace ( s . charAt ( i + 1 ) ) ) { i ++ ; /// skip further whitespace\r } } } return b . toString ( ) ; }", "nl": "Collapse continuous whitespace into one single ."}}
{"translation": {"code": "public boolean load ( String abspath ) { abspath = abspath . replace ( ' ' , ' ' ) ; File rcFile = new File ( abspath ) ; if ( ! rcFile . exists ( ) || ! rcFile . canRead ( ) ) { return false ; } if ( showlog ) log . debug ( \"Loading rc file: \" + abspath ) ; try ( BufferedReader rdr = new BufferedReader ( new InputStreamReader ( new FileInputStream ( rcFile ) , CDM . UTF8 ) ) ) { for ( int lineno = 1 ; ; lineno ++ ) { URL url = null ; String line = rdr . readLine ( ) ; if ( line == null ) break ; // trim leading blanks line = line . trim ( ) ; if ( line . length ( ) == 0 ) continue ; // empty line if ( line . charAt ( 0 ) == ' ' ) continue ; // check for comment // parse the line if ( line . charAt ( 0 ) == LTAG ) { int rindex = line . indexOf ( RTAG ) ; if ( rindex < 0 ) return false ; if ( showlog ) log . error ( \"Malformed [url] at \" + abspath + \".\" + lineno ) ; String surl = line . substring ( 1 , rindex ) ; try { url = new URL ( surl ) ; } catch ( MalformedURLException mue ) { if ( showlog ) log . error ( \"Malformed [url] at \" + abspath + \".\" + lineno ) ; } line = line . substring ( rindex + 1 ) ; // trim again line = line . trim ( ) ; } // Get the key,value part String [ ] pieces = line . split ( \"\\\\s*=\\\\s*\" ) ; assert ( pieces . length == 1 || pieces . length == 2 ) ; // Create the triple String value = \"1\" ; if ( pieces . length == 2 ) value = pieces [ 1 ] . trim ( ) ; Triple triple = new Triple ( pieces [ 0 ] . trim ( ) , value , url ) ; List < Triple > list = triplestore . get ( triple . key ) ; if ( list == null ) list = new ArrayList < Triple > ( ) ; Triple prev = addtriple ( list , triple ) ; triplestore . put ( triple . key , list ) ; } } catch ( FileNotFoundException fe ) { if ( showlog ) log . debug ( \"Loading rc file: \" + abspath ) ; return false ; } catch ( IOException ioe ) { if ( showlog ) log . error ( \"File \" + abspath + \": IO exception: \" + ioe . getMessage ( ) ) ; return false ; } return true ; }", "nl": "overwrite existing entries"}}
{"translation": {"code": "static boolean urlMatch ( URL pattern , URL url ) { int relation ; if ( pattern == null ) return ( url == null ) ; if ( ! ( url . getHost ( ) . endsWith ( pattern . getHost ( ) ) ) ) return false ; // e.g. pattern=x.y.org url=y.org if ( ! ( url . getPath ( ) . startsWith ( pattern . getPath ( ) ) ) ) return false ; // e.g. pattern=y.org/a/b url=y.org/a if ( pattern . getPort ( ) > 0 && pattern . getPort ( ) != url . getPort ( ) ) return false ; // note: all other fields are ignored return true ; }", "nl": "Match has different semantics than urlCompare"}}
{"translation": {"code": "private String convertDDSAliasFieldsToDASAliasFields ( String attribute ) throws MalformedAliasException { String prefix = \"\" ; Vector aNames = tokenizeAliasField ( attribute ) ; // We know that the first token should be a dot, we look at the // second token to see if it references a variable in the DDS. String topName = ( String ) aNames . get ( 1 ) ; boolean foundIt = false ; Enumeration e = getVariables ( ) ; while ( e . hasMoreElements ( ) ) { BaseType bt = ( BaseType ) e . nextElement ( ) ; String normName = normalize ( bt . getEncodedName ( ) ) ; if ( topName . equals ( normName ) ) foundIt = true ; } if ( ! foundIt ) { // The Attribute referenced is at the top level of the DDS itself. // The Attributes at the top level of the DDS get repackaged into // a special AttributeTable, this makes the Aliases that point to // any of these Attribute resolve correctly. prefix = \".\" + getLooseEndsTableName ( ) ; } return ( prefix + attribute ) ; }", "nl": "This method just makes sure that the attribute field in each Aliases resolves correctly if there ends up being a looseEnds Attribute Table at the top level ."}}
{"translation": {"code": "public BaseType getVariable ( String name ) throws NoSuchVariableException { Stack s = new Stack ( ) ; s = search ( name , s ) ; return ( BaseType ) s . pop ( ) ; }", "nl": "Returns a reference to the named variable ."}}
{"translation": {"code": "public void printDAS ( PrintWriter pw ) { DAS myDAS = null ; try { myDAS = this . getDAS ( ) ; myDAS . print ( pw ) ; } catch ( DASException dasE ) { pw . println ( \"\\n\\nCould not get a DAS object to print!\\n\" + \"DDS.getDAS() threw an Exception. Message: \\n\" + dasE . getMessage ( ) ) ; } }", "nl": "Print a DAS constructed from this DDS and it s BaseType variables ."}}
{"translation": {"code": "public Triple insert ( Triple t ) { if ( t . key == null ) return null ; List < Triple > list = triplestore . get ( t . key ) ; if ( list == null ) list = new ArrayList < Triple > ( ) ; Triple prev = addtriple ( list , t ) ; triplestore . put ( t . key , list ) ; return prev ; }", "nl": "Allow for external loading"}}
{"translation": {"code": "static synchronized public void add ( String key , String value , String url ) { if ( key == null ) return ; if ( ! initialized ) RC . initialize ( ) ; Triple t = new Triple ( key , value , url ) ; dfaltRC . insert ( t ) ; // recompute well-knowns setWellKnown ( ) ; }", "nl": "Allow users to add to the default rc"}}
{"translation": {"code": "public FileCacheable acquire ( FileFactory factory , DatasetUrl durl , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { return acquire ( factory , durl . trueurl , durl , - 1 , cancelTask , null ) ; }", "nl": "Acquire a FileCacheable and lock it so no one else can use it . call FileCacheable . close when done ."}}
{"translation": {"code": "@ Override public boolean release ( FileCacheable ncfile ) throws IOException { if ( ncfile == null ) return false ; if ( disabled . get ( ) ) { ncfile . setFileCache ( null ) ; // prevent infinite loops\r ncfile . close ( ) ; return false ; } // find it in the file cache\r CacheElement . CacheFile file = files . get ( ncfile ) ; // using hashCode of the FileCacheable\r if ( file != null ) { if ( ! file . isLocked . get ( ) ) { cacheLog . warn ( \"FileCache \" + name + \" release \" + ncfile . getLocation ( ) + \" not locked; hash= \" + ncfile . hashCode ( ) ) ; } file . lastAccessed = System . currentTimeMillis ( ) ; file . countAccessed ++ ; file . isLocked . set ( false ) ; file . ncfile . release ( ) ; if ( cacheLog . isDebugEnabled ( ) ) cacheLog . debug ( \"FileCache \" + name + \" release \" + ncfile . getLocation ( ) + \"; hash= \" + ncfile . hashCode ( ) ) ; if ( debugPrint ) System . out . printf ( \"  FileCache %s release %s lock=%s count=%d%n\" , name , ncfile . getLocation ( ) , file . isLocked . get ( ) , countLocked ( ) ) ; return true ; } return false ; // throw new IOException(\"FileCache \" + name + \" release does not have file in cache = \" + ncfile.getLocation());\r }", "nl": "Release the file . This unlocks it updates its lastAccessed date . Normally applications need not call this just close the file as usual . The FileCacheable has to do tricky stuff ."}}
{"translation": {"code": "int pcode_5 ( int [ ] pos , int hoff , int len , boolean isZ ) { ArrayList dims = new ArrayList ( ) ; //int vlen =len;\r Dimension sDim = new Dimension ( \"windBarbSize\" , len ) ; ncfile . addDimension ( null , sDim ) ; dims . add ( sDim ) ; Structure dist = new Structure ( ncfile , null , null , \"vectorArrow\" ) ; dist . setDimensions ( dims ) ; ncfile . addVariable ( null , dist ) ; dist . addAttribute ( new Attribute ( CDM . LONG_NAME , \"Vector Arrow Data\" ) ) ; Variable i0 = new Variable ( ncfile , null , dist , \"x_start\" ) ; i0 . setDimensions ( ( String ) null ) ; i0 . setDataType ( DataType . SHORT ) ; i0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( i0 ) ; Variable j0 = new Variable ( ncfile , null , dist , \"y_start\" ) ; j0 . setDimensions ( ( String ) null ) ; j0 . setDataType ( DataType . SHORT ) ; j0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( j0 ) ; Variable direct = new Variable ( ncfile , null , dist , \"direction\" ) ; direct . setDimensions ( ( String ) null ) ; direct . setDataType ( DataType . SHORT ) ; direct . addAttribute ( new Attribute ( CDM . UNITS , \"degree\" ) ) ; dist . addMemberVariable ( direct ) ; Variable speed = new Variable ( ncfile , null , dist , \"arrowLength\" ) ; speed . setDimensions ( ( String ) null ) ; speed . setDataType ( DataType . SHORT ) ; speed . addAttribute ( new Attribute ( CDM . UNITS , \"pixels\" ) ) ; dist . addMemberVariable ( speed ) ; Variable speed1 = new Variable ( ncfile , null , dist , \"arrowHeadLength\" ) ; speed1 . setDimensions ( ( String ) null ) ; speed1 . setDataType ( DataType . SHORT ) ; speed1 . addAttribute ( new Attribute ( CDM . UNITS , \"pixels\" ) ) ; dist . addMemberVariable ( speed1 ) ; int [ ] pos1 = new int [ len ] ; System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , null , 4 , 0 ) ) ; return 1 ; }", "nl": "construct a dataset for vector arrow data packet with code 5"}}
{"translation": {"code": "int pcode_25 ( int [ ] pos , int hoff , int len , boolean isZ ) { ArrayList dims = new ArrayList ( ) ; Dimension sDim = new Dimension ( \"circleSize\" , len ) ; ncfile . addDimension ( null , sDim ) ; dims . add ( sDim ) ; Structure dist = new Structure ( ncfile , null , null , \"circleStruct\" ) ; dist . setDimensions ( dims ) ; ncfile . addVariable ( null , dist ) ; dist . addAttribute ( new Attribute ( CDM . LONG_NAME , \"Circle Packet\" ) ) ; Variable ii0 = new Variable ( ncfile , null , dist , \"x_center\" ) ; ii0 . setDimensions ( ( String ) null ) ; ii0 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( ii0 ) ; Variable ii1 = new Variable ( ncfile , null , dist , \"y_center\" ) ; ii1 . setDimensions ( ( String ) null ) ; ii1 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( ii1 ) ; Variable jj0 = new Variable ( ncfile , null , dist , \"radius\" ) ; jj0 . setDimensions ( ( String ) null ) ; jj0 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( jj0 ) ; int [ ] pos1 = new int [ len ] ; System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , null , 25 , 0 ) ) ; return 1 ; }", "nl": "construct a dataset for special symbol packet with code 25"}}
{"translation": {"code": "int checkMsgHeader ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { int rc ; long actualSize ; int readLen ; actualSize = raf . length ( ) ; int pos = 0 ; raf . seek ( pos ) ; // Read in the whole contents of the NEXRAD Level III product since\r // some product require to go through the whole file to build the  struct of file.\r readLen = ( int ) actualSize ; byte [ ] b = new byte [ readLen ] ; rc = raf . read ( b ) ; if ( rc != readLen ) { log . warn ( \" error reading nids product header \" + raf . getLocation ( ) ) ; } ByteBuffer bos = ByteBuffer . wrap ( b ) ; return read_msghead ( bos , 0 ) ; }", "nl": "check level III file header"}}
{"translation": {"code": "public byte [ ] getUncompData ( int offset , int len ) { if ( len == 0 ) len = uncompdata . length - offset ; byte [ ] data = new byte [ len ] ; System . arraycopy ( uncompdata , offset , data , 0 , len ) ; return data ; }", "nl": "read the compressed data"}}
{"translation": {"code": "int pcode_12n13n14 ( int [ ] pos , int [ ] dlen , int hoff , int len , boolean isZ , String structName , int code ) { //int vlen = len;\r int vlen = 0 ; for ( int i = 0 ; i < len ; i ++ ) { vlen = vlen + dlen [ i ] ; } ArrayList dims = new ArrayList ( ) ; Dimension sDim = new Dimension ( \"graphicSymbolSize\" , vlen ) ; ncfile . addDimension ( null , sDim ) ; dims . add ( sDim ) ; Structure dist = new Structure ( ncfile , null , null , structName ) ; dist . setDimensions ( dims ) ; ncfile . addVariable ( null , dist ) ; dist . addAttribute ( new Attribute ( CDM . LONG_NAME , \"special graphic symbol for code \" + code ) ) ; Variable i0 = new Variable ( ncfile , null , dist , \"x_start\" ) ; i0 . setDimensions ( ( String ) null ) ; i0 . setDataType ( DataType . FLOAT ) ; i0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( i0 ) ; Variable j0 = new Variable ( ncfile , null , dist , \"y_start\" ) ; j0 . setDimensions ( ( String ) null ) ; j0 . setDataType ( DataType . FLOAT ) ; j0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( j0 ) ; int [ ] pos1 = new int [ len ] ; int [ ] dlen1 = new int [ len ] ; System . arraycopy ( dlen , 0 , dlen1 , 0 , len ) ; System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , dlen1 , code , 0 ) ) ; return 1 ; }", "nl": "construct a dataset for special graphic symbol packet with code 12 13 and 14"}}
{"translation": {"code": "protected boolean addParameter2 ( CoordinateTransform rs , String paramName , NetcdfFile ds , AttributeContainer v , String attName , boolean readData ) { String varName ; if ( null == ( varName = v . findAttValueIgnoreCase ( attName , null ) ) ) { parseInfo . format ( \"CSMConvention No Attribute named %s%n\" , attName ) ; return false ; } varName = varName . trim ( ) ; Variable dataVar ; if ( null == ( dataVar = ds . findVariable ( varName ) ) ) { parseInfo . format ( \"CSMConvention No Variable named %s%n\" , varName ) ; return false ; } if ( readData ) { Array data ; try { data = dataVar . read ( ) ; } catch ( IOException e ) { parseInfo . format ( \"CSMConvention failed on read of %s err= %s%n\" , varName , e . getMessage ( ) ) ; return false ; } double [ ] vals = ( double [ ] ) data . get1DJavaArray ( DataType . DOUBLE ) ; rs . addParameter ( new Parameter ( paramName , vals ) ) ; } else rs . addParameter ( new Parameter ( paramName , varName ) ) ; return true ; }", "nl": "Add a Parameter to a CoordinateTransform . The variable attribute points to a another variable that has the data in it . Make sure that atrribute and variable exist . Id readData is true read the data and use it as the value of the parameter otherwise use the name as the value of the parameter ."}}
{"translation": {"code": "int pcode_128 ( int [ ] pos , int [ ] size , int code , int hoff , int len , String structName , String abbre , boolean isZ ) { //int vlen = len;\r ArrayList dims = new ArrayList ( ) ; Dimension sDim = new Dimension ( \"textStringSize\" + abbre + code , len ) ; ncfile . addDimension ( null , sDim ) ; dims . add ( sDim ) ; Structure dist = new Structure ( ncfile , null , null , structName + abbre ) ; dist . setDimensions ( dims ) ; ncfile . addVariable ( null , dist ) ; dist . addAttribute ( new Attribute ( CDM . LONG_NAME , \"text and special symbol for code \" + code ) ) ; if ( code == 8 ) { Variable strVal = new Variable ( ncfile , null , dist , \"strValue\" ) ; strVal . setDimensions ( ( String ) null ) ; strVal . setDataType ( DataType . SHORT ) ; strVal . addAttribute ( new Attribute ( CDM . UNITS , \"\" ) ) ; dist . addMemberVariable ( strVal ) ; } Variable i0 = new Variable ( ncfile , null , dist , \"x_start\" ) ; i0 . setDimensions ( ( String ) null ) ; i0 . setDataType ( DataType . SHORT ) ; i0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( i0 ) ; Variable j0 = new Variable ( ncfile , null , dist , \"y_start\" ) ; j0 . setDimensions ( ( String ) null ) ; j0 . setDataType ( DataType . SHORT ) ; j0 . addAttribute ( new Attribute ( CDM . UNITS , \"KM\" ) ) ; dist . addMemberVariable ( j0 ) ; Variable tstr = new Variable ( ncfile , null , dist , \"textString\" ) ; tstr . setDimensions ( ( String ) null ) ; tstr . setDataType ( DataType . STRING ) ; tstr . addAttribute ( new Attribute ( CDM . UNITS , \"\" ) ) ; dist . addMemberVariable ( tstr ) ; int [ ] pos1 = new int [ len ] ; System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , size , code , 0 ) ) ; return 1 ; }", "nl": "construct a dataset for text and special symbol packets with code 1 2 and 8"}}
{"translation": {"code": "private DataType getAttributeDataType ( Attribute attribute ) { DataType dataType = attribute . getDataType ( ) ; if ( signedness == Signedness . UNSIGNED ) { // If variable is unsigned, make its integral attributes unsigned too.\r dataType = dataType . withSignedness ( signedness ) ; } return dataType ; }", "nl": "Get the data type of an attribute . Make it unsigned if the variable is unsigned ."}}
{"translation": {"code": "protected Sequence makeSequence ( Structure parent , String partName , boolean includeMissing ) { List < GempakParameter > params = gemreader . getParameters ( partName ) ; if ( params == null ) { return null ; } Sequence sVar = new Sequence ( ncfile , null , parent , partName ) ; sVar . setDimensions ( \"\" ) ; for ( GempakParameter param : params ) { Variable v = makeParamVariable ( param , null ) ; addVerticalCoordAttribute ( v ) ; sVar . addMemberVariable ( v ) ; } if ( includeMissing ) { sVar . addMemberVariable ( makeMissingVariable ( ) ) ; } return sVar ; }", "nl": "Make a Sequence for the part"}}
{"translation": {"code": "static public ArrayStructureMA factoryMA ( ArrayStructure from ) throws IOException { if ( from instanceof ArrayStructureMA ) return ( ArrayStructureMA ) from ; // To create an ArrayStructureMA that we can iterate over later, we need to know the shape of \"from\".\r if ( from . getSize ( ) > 0 ) { ArrayStructureMA to = new ArrayStructureMA ( new StructureMembers ( from . getStructureMembers ( ) ) , from . getShape ( ) ) ; for ( StructureMembers . Member m : from . getMembers ( ) ) { to . setMemberArray ( m . getName ( ) , from . extractMemberArray ( m ) ) ; } return to ; } // from.getSize() <= 0. This usually means that \"from\" is an ArraySequence, and that we won't know its size until\r // we iterate over it. extractMemberArray() will do that iteration for us, and then we can use the size of the\r // array it returns to determine the shape of \"from\".\r int numRecords = - 1 ; Map < String , Array > memberArrayMap = new LinkedHashMap <> ( ) ; for ( StructureMembers . Member m : from . getMembers ( ) ) { Array array = from . extractMemberArray ( m ) ; assert array . getSize ( ) > 0 : \"array's size should have been computed in extractMemberArray().\" ; int firstDimLen = array . getShape ( ) [ 0 ] ; if ( numRecords == - 1 ) { numRecords = firstDimLen ; } else { assert numRecords == firstDimLen : String . format ( \"Expected all structure members to have the same first\" + \"dimension length, but %d != %d.\" , numRecords , firstDimLen ) ; } memberArrayMap . put ( m . getName ( ) , array ) ; } int [ ] shape ; if ( numRecords == - 1 ) { shape = new int [ ] { 0 } ; // \"from\" really was empty.\r } else { shape = new int [ ] { numRecords } ; } ArrayStructureMA to = new ArrayStructureMA ( new StructureMembers ( from . getStructureMembers ( ) ) , shape ) ; for ( Map . Entry < String , Array > entry : memberArrayMap . entrySet ( ) ) { to . setMemberArray ( entry . getKey ( ) , entry . getValue ( ) ) ; } return to ; }", "nl": "Turn any ArrayStructure into a ArrayStructureMA"}}
{"translation": {"code": "public void setMemberArray ( String memberName , Array data ) { StructureMembers . Member m = members . findMember ( memberName ) ; m . setDataArray ( data ) ; }", "nl": "Set the data array for this member ."}}
{"translation": {"code": "int readWMO ( ucar . unidata . io . RandomAccessFile raf ) throws IOException { int pos = 0 ; //long     actualSize = 0;\r raf . seek ( pos ) ; int readLen = 35 ; // Read in the contents of the NEXRAD Level III product head\r byte [ ] b = new byte [ readLen ] ; int rc = raf . read ( b ) ; if ( rc != readLen ) { // out.println(\" error reading nids product header\");\r return 0 ; } // new check\r int iarr2_1 = bytesToInt ( b [ 0 ] , b [ 1 ] , false ) ; int iarr2_16 = bytesToInt ( b [ 30 ] , b [ 31 ] , false ) ; int iarr2_10 = bytesToInt ( b [ 18 ] , b [ 19 ] , false ) ; int iarr2_7 = bytesToInt ( b [ 12 ] , b [ 13 ] , false ) ; if ( ( iarr2_1 == iarr2_16 ) && ( ( iarr2_1 >= 16 ) && ( iarr2_1 <= 299 ) ) && ( iarr2_10 == - 1 ) && ( iarr2_7 < 10000 ) ) { noHeader = true ; return 1 ; } //Get product message header into a string for processing\r String pib = new String ( b , CDM . utf8Charset ) ; if ( pib . indexOf ( \"SDUS\" ) != - 1 ) { noHeader = false ; return 1 ; } else if ( raf . getLocation ( ) . indexOf ( \".nids\" ) != - 1 ) { noHeader = true ; return 1 ; // } else if(checkMsgHeader(raf) == 1) {\r //    noHeader = true;\r //     return 1;\r } else return 0 ; }", "nl": "read the header of input file and parsing the WMO part"}}
{"translation": {"code": "int pcode_10n9 ( int [ ] pos , int [ ] dlen , int hoff , int len , boolean isZ ) { ArrayList dims = new ArrayList ( ) ; Variable v ; int vlen = 0 ; for ( int i = 0 ; i < len ; i ++ ) { vlen = vlen + dlen [ i ] ; } Dimension sDim = new Dimension ( \"unlinkedVectorSize\" , vlen ) ; ncfile . addDimension ( null , sDim ) ; dims . add ( sDim ) ; Structure dist = new Structure ( ncfile , null , null , \"unlinkedVectorStruct\" ) ; dist . setDimensions ( dims ) ; ncfile . addVariable ( null , dist ) ; dist . addAttribute ( new Attribute ( CDM . LONG_NAME , \"Unlinked Vector Packet\" ) ) ; v = new Variable ( ncfile , null , null , \"iValue\" ) ; v . setDataType ( DataType . SHORT ) ; v . setDimensions ( ( String ) null ) ; dist . addMemberVariable ( v ) ; Variable ii0 = new Variable ( ncfile , null , dist , \"x_start\" ) ; ii0 . setDimensions ( ( String ) null ) ; ii0 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( ii0 ) ; Variable ii1 = new Variable ( ncfile , null , dist , \"y_start\" ) ; ii1 . setDimensions ( ( String ) null ) ; ii1 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( ii1 ) ; Variable jj0 = new Variable ( ncfile , null , dist , \"x_end\" ) ; jj0 . setDimensions ( ( String ) null ) ; jj0 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( jj0 ) ; Variable jj1 = new Variable ( ncfile , null , dist , \"y_end\" ) ; jj1 . setDimensions ( ( String ) null ) ; jj1 . setDataType ( DataType . SHORT ) ; dist . addMemberVariable ( jj1 ) ; int [ ] pos1 = new int [ len ] ; int [ ] dlen1 = new int [ len ] ; System . arraycopy ( pos , 0 , pos1 , 0 , len ) ; System . arraycopy ( dlen , 0 , dlen1 , 0 , len ) ; dist . setSPobject ( new Vinfo ( 0 , 0 , 0 , 0 , hoff , 0 , isR , isZ , pos1 , dlen1 , 10 , 0 ) ) ; return 1 ; }", "nl": "construct a dataset for linked vector packet and unlinked vector packet"}}
{"translation": {"code": "static public void findCoords ( TableConfig nt , NetcdfDataset ds , Predicate p ) { nt . lat = findCoordShortNameByType ( ds , AxisType . Lat , p ) ; nt . lon = findCoordShortNameByType ( ds , AxisType . Lon , p ) ; nt . time = findCoordShortNameByType ( ds , AxisType . Time , p ) ; nt . elev = findCoordShortNameByType ( ds , AxisType . Height , p ) ; if ( nt . elev == null ) nt . elev = findCoordShortNameByType ( ds , AxisType . Pressure , p ) ; }", "nl": "search for Axis by Type assign to TableConfig if found . search for Lat Lon Time Height ."}}
{"translation": {"code": "protected AxisType getAxisType ( NetcdfDataset ncDataset , VariableEnhanced v ) { String unit = v . getUnitsString ( ) ; if ( unit == null ) return null ; unit = unit . trim ( ) ; if ( unit . equalsIgnoreCase ( \"degrees_east\" ) || unit . equalsIgnoreCase ( \"degrees_E\" ) || unit . equalsIgnoreCase ( \"degreesE\" ) || unit . equalsIgnoreCase ( \"degree_east\" ) || unit . equalsIgnoreCase ( \"degree_E\" ) || unit . equalsIgnoreCase ( \"degreeE\" ) ) return AxisType . Lon ; if ( unit . equalsIgnoreCase ( \"degrees_north\" ) || unit . equalsIgnoreCase ( \"degrees_N\" ) || unit . equalsIgnoreCase ( \"degreesN\" ) || unit . equalsIgnoreCase ( \"degree_north\" ) || unit . equalsIgnoreCase ( \"degree_N\" ) || unit . equalsIgnoreCase ( \"degreeN\" ) ) return AxisType . Lat ; if ( SimpleUnit . isDateUnit ( unit ) ) { return AxisType . Time ; } // look for other z coordinate\r if ( SimpleUnit . isCompatible ( \"mbar\" , unit ) ) return AxisType . Pressure ; if ( unit . equalsIgnoreCase ( \"level\" ) || unit . equalsIgnoreCase ( \"layer\" ) || unit . equalsIgnoreCase ( \"sigma_level\" ) ) return AxisType . GeoZ ; String positive = ncDataset . findAttValueIgnoreCase ( ( Variable ) v , CF . POSITIVE , null ) ; if ( positive != null ) { if ( SimpleUnit . isCompatible ( \"m\" , unit ) ) return AxisType . Height ; else return AxisType . GeoZ ; } // a bad idea, but CDC SST relies on it :\r // :Source = \"NOAA/National Climatic Data Center\";\r // :Contact = \"Dick Reynolds, email: Richard.W.Reynolds@noaa.gov & Chunying Liu, email: Chunying.liu@noaa.gov\";\r //:netcdf_Convention = \"COARDS\";\r // if (checkForMeter && SimpleUnit.isCompatible(\"m\", unit))\r //   return AxisType.Height;\r return null ; }", "nl": "we assume that coordinate axes get identified by being coordinate variables"}}
{"translation": {"code": "private String normalize ( String units ) { switch ( units ) { case \"fraction\" : units = \"\" ; break ; case \"dimensionless\" : units = \"\" ; break ; case \"NA\" : units = \"\" ; break ; case \"-\" : units = \"\" ; break ; default : units = StringUtil2 . substitute ( units , \"**\" , \"^\" ) ; units = StringUtil2 . remove ( units , ' ' ) ; units = StringUtil2 . remove ( units , ' ' ) ; break ; } return units ; }", "nl": "pretty much WRF specific"}}
{"translation": {"code": "static public VarAtt findVariableWithAttribute ( NetcdfDataset ds , String attName ) { for ( Variable v : ds . getVariables ( ) ) { Attribute att = v . findAttributeIgnoreCase ( attName ) ; if ( att != null ) return new VarAtt ( v , att ) ; } // descend into structures\r for ( Variable v : ds . getVariables ( ) ) { if ( v instanceof Structure ) { Structure s = ( Structure ) v ; for ( Variable vs : s . getVariables ( ) ) { Attribute att = vs . findAttributeIgnoreCase ( attName ) ; if ( att != null ) return new VarAtt ( vs , att ) ; } } } return null ; }", "nl": "Find first variable with given attribute name"}}
{"translation": {"code": "static public Variable findVariableWithAttributeValue ( NetcdfDataset ds , String attName , String attValue ) { for ( Variable v : ds . getVariables ( ) ) { String haveValue = ds . findAttValueIgnoreCase ( v , attName , null ) ; if ( ( haveValue != null ) && haveValue . equals ( attValue ) ) return v ; } // descend into structures\r for ( Variable v : ds . getVariables ( ) ) { if ( v instanceof Structure ) { Variable vn = findVariableWithAttributeValue ( ( Structure ) v , attName , attValue ) ; if ( null != vn ) return vn ; } } return null ; }", "nl": "Find first variable with given attribute name and value . If not found search one level into structures ."}}
{"translation": {"code": "static public String findNameOfVariableWithAttributeValue ( NetcdfDataset ds , String attName , String attValue ) { Variable v = findVariableWithAttributeValue ( ds , attName , attValue ) ; return ( v == null ) ? null : v . getShortName ( ) ; }", "nl": "Find first variable with given attribute name and value"}}
{"translation": {"code": "static public Variable findVariableWithAttributeValue ( Structure struct , String attName , String attValue ) { for ( Variable v : struct . getVariables ( ) ) { Attribute att = v . findAttributeIgnoreCase ( attName ) ; if ( ( att != null ) && att . getStringValue ( ) . equals ( attValue ) ) return v ; } return null ; }", "nl": "Find first member variable in this struct with given attribute name and value"}}
{"translation": {"code": "static public Structure findNestedStructure ( Structure s ) { for ( Variable v : s . getVariables ( ) ) { if ( ( v instanceof Structure ) ) return ( Structure ) v ; } return null ; }", "nl": "Find first nested structure"}}
{"translation": {"code": "static public boolean hasNetcdf3RecordStructure ( NetcdfDataset ds ) { Variable v = ds . findVariable ( \"record\" ) ; return ( v != null ) && ( v . getDataType ( ) == DataType . STRUCTURE ) ; }", "nl": "Does this dataset have a record structure? netcdf - 3 specific"}}
{"translation": {"code": "static public String getLiteral ( NetcdfDataset ds , String key , Formatter errlog ) { if ( key . startsWith ( \":\" ) ) { String val = ds . findAttValueIgnoreCase ( null , key . substring ( 1 ) , null ) ; if ( ( val == null ) && ( errlog != null ) ) errlog . format ( \" Cant find global attribute %s%n\" , key ) ; return val ; } return key ; }", "nl": "Translate key to value"}}
{"translation": {"code": "public Element makeDimensionElement ( Dimension dim ) throws IllegalArgumentException { if ( ! dim . isShared ( ) ) { throw new IllegalArgumentException ( \"Cannot create private dimension: \" + \"in NcML, <dimension> elements are always shared.\" ) ; } Element dimElem = new Element ( \"dimension\" , namespace ) ; dimElem . setAttribute ( \"name\" , dim . getShortName ( ) ) ; dimElem . setAttribute ( \"length\" , Integer . toString ( dim . getLength ( ) ) ) ; if ( dim . isUnlimited ( ) ) dimElem . setAttribute ( \"isUnlimited\" , \"true\" ) ; return dimElem ; }", "nl": "Only for shared dimensions ."}}
{"translation": {"code": "static public String getVariableName ( NetcdfDataset ds , String key , Formatter errlog ) { Variable v = null ; String vs = getLiteral ( ds , key , errlog ) ; if ( vs != null ) { v = ds . findVariable ( vs ) ; if ( ( v == null ) && ( errlog != null ) ) errlog . format ( \" Cant find Variable %s from %s%n\" , vs , key ) ; } return v == null ? null : v . getShortName ( ) ; }", "nl": "Find the variable pointed to by key"}}
{"translation": {"code": "protected boolean accept ( StringBuffer buff ) { if ( ! validate ( buff ) ) { validate ( buff ) ; return false ; } if ( acceptIfDifferent ( getEditValue ( ) ) ) { setStoreValue ( validValue ) ; sendEvent ( ) ; } return true ; }", "nl": "Get current value from editComponent save to store . If different from old value fire PropertyChangeEvent . Return false if invalid format add error message to buff if not null ."}}
{"translation": {"code": "static private void showFormatInfo ( JFormattedTextField tf ) { JFormattedTextField . AbstractFormatter ff = tf . getFormatter ( ) ; System . out . println ( \"AbstractFormatter  \" + ff . getClass ( ) . getName ( ) ) ; if ( ff instanceof NumberFormatter ) { NumberFormatter nf = ( NumberFormatter ) ff ; Format f = nf . getFormat ( ) ; System . out . println ( \" Format  = \" + f . getClass ( ) . getName ( ) ) ; if ( f instanceof NumberFormat ) { NumberFormat nfat = ( NumberFormat ) f ; System . out . println ( \" getMinimumIntegerDigits=\" + nfat . getMinimumIntegerDigits ( ) ) ; System . out . println ( \" getMaximumIntegerDigits=\" + nfat . getMaximumIntegerDigits ( ) ) ; System . out . println ( \" getMinimumFractionDigits=\" + nfat . getMinimumFractionDigits ( ) ) ; System . out . println ( \" getMaximumFractionDigits=\" + nfat . getMaximumFractionDigits ( ) ) ; } if ( f instanceof DecimalFormat ) { DecimalFormat df = ( DecimalFormat ) f ; System . out . println ( \" Pattern  = \" + df . toPattern ( ) ) ; } } }", "nl": "An integer input field with an associated CDM . UNITS label ."}}
{"translation": {"code": "static public boolean amendFromODL ( NetcdfFile ncfile , Group eosGroup ) throws IOException { String smeta = getStructMetadata ( eosGroup ) ; if ( smeta == null ) { return false ; } HdfEos fixer = new HdfEos ( ) ; fixer . fixAttributes ( ncfile . getRootGroup ( ) ) ; fixer . amendFromODL ( ncfile , smeta ) ; return true ; }", "nl": "Amend the given NetcdfFile with metadata from HDF - EOS structMetadata . All Variables named StructMetadata . n where n = 1 2 3 ... are read in and their contents concatenated to make the structMetadata String ."}}
{"translation": {"code": "private void setSharedDimensions ( Variable v , List < Element > values , List < Dimension > unknownDims , String location ) { if ( values . size ( ) == 0 ) { return ; } // remove the \"scalar\" dumbension\r Iterator < Element > iter = values . iterator ( ) ; while ( iter . hasNext ( ) ) { Element value = iter . next ( ) ; String dimName = value . getText ( ) . trim ( ) ; if ( dimName . equalsIgnoreCase ( \"scalar\" ) ) { iter . remove ( ) ; } } // gotta have same number of dimensions\r List < Dimension > oldDims = v . getDimensions ( ) ; if ( oldDims . size ( ) != values . size ( ) ) { log . error ( \"Different number of dimensions for {} {}\" , v , location ) ; return ; } List < Dimension > newDims = new ArrayList <> ( ) ; Group group = v . getParentGroup ( ) ; for ( int i = 0 ; i < values . size ( ) ; i ++ ) { Element value = values . get ( i ) ; String dimName = value . getText ( ) . trim ( ) ; dimName = NetcdfFile . makeValidCdmObjectName ( dimName ) ; Dimension dim = group . findDimension ( dimName ) ; Dimension oldDim = oldDims . get ( i ) ; if ( dim == null ) { dim = checkUnknownDims ( dimName , unknownDims , oldDim , location ) ; } if ( dim == null ) { log . error ( \"Unknown Dimension= {} for variable = {} {} \" , dimName , v . getFullName ( ) , location ) ; return ; } if ( dim . getLength ( ) != oldDim . getLength ( ) ) { log . error ( \"Shared dimension ({}) has different length than data dimension ({}) shared={} org={} for {} {}\" , dim . getShortName ( ) , oldDim . getShortName ( ) , dim . getLength ( ) , oldDim . getLength ( ) , v , location ) ; return ; } newDims . add ( dim ) ; } v . setDimensions ( newDims ) ; if ( showWork ) { log . debug ( \" set shared dimensions for {}\" , v . getNameAndDimensions ( ) ) ; } }", "nl": "convert to shared dimensions"}}
{"translation": {"code": "private Dimension checkUnknownDims ( String wantDim , List < Dimension > unknownDims , Dimension oldDim , String location ) { for ( Dimension dim : unknownDims ) { if ( dim . getShortName ( ) . equals ( wantDim ) ) { int len = oldDim . getLength ( ) ; if ( len == 0 ) { dim . setUnlimited ( true ) ; // allow zero length dimension !!\r } dim . setLength ( len ) ; // use existing (anon) dimension\r Group parent = dim . getGroup ( ) ; parent . addDimensionIfNotExists ( dim ) ; // add to the parent\r unknownDims . remove ( dim ) ; // remove from list LOOK is this ok?\r log . warn ( \"unknownDim {} length set to {}{}\" , wantDim , oldDim . getLength ( ) , location ) ; return dim ; } } return null ; }", "nl": "look if the wanted dimension is in the unknownDims list ."}}
{"translation": {"code": "private Group findGroupNested ( Group parent , String name ) { for ( Group g : parent . getGroups ( ) ) { if ( g . getShortName ( ) . equals ( name ) ) { return g ; } } for ( Group g : parent . getGroups ( ) ) { Group result = findGroupNested ( g , name ) ; if ( result != null ) { return result ; } } return null ; }", "nl": "look for a group with the given name . recurse into subgroups if needed . breadth first"}}
{"translation": {"code": "static public ArrayStructureMA factoryMA ( Structure from , int [ ] shape ) throws IOException { StructureMembers sm = from . makeStructureMembers ( ) ; for ( Variable v : from . getVariables ( ) ) { Array data ; if ( v instanceof Sequence ) { data = Array . factory ( DataType . SEQUENCE , shape ) ; // an array sequence - one for each parent element\r //Structure s = (Structure) v;\r //StructureMembers smn = s.makeStructureMembers();\r // data = new ArraySequenceNested(smn, (int) Index.computeSize(v.getShapeAll())); // ??\r } else if ( v instanceof Structure ) data = ArrayStructureMA . factoryMA ( ( Structure ) v , combine ( shape , v . getShape ( ) ) ) ; else data = Array . factory ( v . getDataType ( ) , combine ( shape , v . getShape ( ) ) ) ; StructureMembers . Member m = sm . findMember ( v . getShortName ( ) ) ; m . setDataArray ( data ) ; } return new ArrayStructureMA ( sm , shape ) ; }", "nl": "Create an ArrayStructure for a Structure . Allow nested Structures . Create the data arrays and an iterator ."}}
{"translation": {"code": "protected void addLightningGlobalAttributes ( NetcdfFile ncfile ) { ncfile . addAttribute ( null , new Attribute ( CF . FEATURE_TYPE , CF . FeatureType . point . toString ( ) ) ) ; ncfile . addAttribute ( null , new Attribute ( CDM . HISTORY , \"Read directly by Netcdf Java IOSP\" ) ) ; }", "nl": "Add the global attributes . Specific implementations should call super and then add their own ."}}
{"translation": {"code": "public Document makeStationCollectionDocument ( LatLonRect bb , String [ ] names ) throws IOException { List < DsgFeatureCollection > list = fdp . getPointFeatureCollectionList ( ) ; DsgFeatureCollection fc = list . get ( 0 ) ; // LOOK maybe should pass in the dsg?\r if ( ! ( fc instanceof StationTimeSeriesFeatureCollection ) ) { throw new UnsupportedOperationException ( fc . getClass ( ) . getName ( ) + \" not a StationTimeSeriesFeatureCollection\" ) ; } StationTimeSeriesFeatureCollection sobs = ( StationTimeSeriesFeatureCollection ) fc ; Element rootElem = new Element ( \"stationCollection\" ) ; Document doc = new Document ( rootElem ) ; List < StationFeature > stations ; if ( bb != null ) stations = sobs . getStationFeatures ( bb ) ; else if ( names != null ) stations = sobs . getStationFeatures ( Arrays . asList ( names ) ) ; else stations = sobs . getStationFeatures ( ) ; for ( Station s : stations ) { Element sElem = new Element ( \"station\" ) ; sElem . setAttribute ( \"name\" , s . getName ( ) ) ; if ( s . getWmoId ( ) != null ) sElem . setAttribute ( \"wmo_id\" , s . getWmoId ( ) ) ; if ( ( s . getDescription ( ) != null ) && ( s . getDescription ( ) . length ( ) > 0 ) ) sElem . addContent ( new Element ( \"description\" ) . addContent ( s . getDescription ( ) ) ) ; sElem . addContent ( new Element ( \"longitude\" ) . addContent ( Double . toString ( s . getLongitude ( ) ) ) ) ; sElem . addContent ( new Element ( \"latitide\" ) . addContent ( Double . toString ( s . getLatitude ( ) ) ) ) ; if ( ! Double . isNaN ( s . getAltitude ( ) ) ) sElem . addContent ( new Element ( \"altitude\" ) . addContent ( Double . toString ( s . getAltitude ( ) ) ) ) ; rootElem . addContent ( sElem ) ; } return doc ; }", "nl": "Create an XML document for the stations in this dataset possible subsetted by bb . Must be a station dataset ."}}
{"translation": {"code": "public Document getCapabilitiesDocument ( ) { Element rootElem = new Element ( \"capabilities\" ) ; Document doc = new Document ( rootElem ) ; if ( null != path ) { rootElem . setAttribute ( \"location\" , path ) ; Element elem = new Element ( \"featureDataset\" ) ; FeatureType ft = fdp . getFeatureType ( ) ; elem . setAttribute ( \"type\" , ft . toString ( ) . toLowerCase ( ) ) ; String url = path . replace ( \"dataset.xml\" , ft . toString ( ) . toLowerCase ( ) + \".xml\" ) ; elem . setAttribute ( \"url\" , url ) ; rootElem . addContent ( elem ) ; } List < DsgFeatureCollection > list = fdp . getPointFeatureCollectionList ( ) ; DsgFeatureCollection fc = list . get ( 0 ) ; // LOOK maybe should pass in the dsg?\r rootElem . addContent ( writeTimeUnit ( fc . getTimeUnit ( ) ) ) ; rootElem . addContent ( new Element ( \"AltitudeUnits\" ) . addContent ( fc . getAltUnits ( ) ) ) ; // data variables\r List < ? extends VariableSimpleIF > vars = fdp . getDataVariables ( ) ; Collections . sort ( vars ) ; for ( VariableSimpleIF v : vars ) { rootElem . addContent ( writeVariable ( v ) ) ; } /* CollectionInfo info;\r\n    try {\r\n      info = new DsgCollectionHelper(fc).calcBounds();\r\n    } catch (IOException e) {\r\n      throw new RuntimeException(e);\r\n    } */ LatLonRect bb = fc . getBoundingBox ( ) ; if ( bb != null ) rootElem . addContent ( writeBoundingBox ( bb ) ) ; // add date range\r CalendarDateRange dateRange = fc . getCalendarDateRange ( ) ; if ( dateRange != null ) { Element drElem = new Element ( \"TimeSpan\" ) ; // from KML\r drElem . addContent ( new Element ( \"begin\" ) . addContent ( dateRange . getStart ( ) . toString ( ) ) ) ; drElem . addContent ( new Element ( \"end\" ) . addContent ( dateRange . getEnd ( ) . toString ( ) ) ) ; if ( dateRange . getResolution ( ) != null ) drElem . addContent ( new Element ( \"resolution\" ) . addContent ( dateRange . getResolution ( ) . toString ( ) ) ) ; rootElem . addContent ( drElem ) ; } /* add accept list\r\n    Element elem = new Element(\"AcceptList\");\r\n    //elem.addContent(new Element(\"accept\").addContent(\"raw\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"csv\").setAttribute(\"displayName\", \"csv\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/csv\").setAttribute(\"displayName\", \"csv (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"xml\").setAttribute(\"displayName\", \"xml\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"text/xml\").setAttribute(\"displayName\", \"xml (file)\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"waterml2\").setAttribute(\"displayName\", \"WaterML 2.0\"));\r\n    elem.addContent(new Element(\"accept\").addContent(\"netcdf\").setAttribute(\"displayName\", \"CF/NetCDF-3\"));\r\n    //elem.addContent(new Element(\"accept\").addContent(\"ncstream\"));\r\n    rootElem.addContent(elem); */ return doc ; }", "nl": "Create the capabilities XML document for this dataset"}}
{"translation": {"code": "protected Structure makeStructure ( String partName , List < Dimension > dimensions , boolean includeMissing ) { List < GempakParameter > params = gemreader . getParameters ( partName ) ; if ( params == null ) { return null ; } Structure sVar = new Structure ( ncfile , null , null , partName ) ; sVar . setDimensions ( dimensions ) ; for ( GempakParameter param : params ) { sVar . addMemberVariable ( makeParamVariable ( param , null ) ) ; } if ( includeMissing ) { sVar . addMemberVariable ( makeMissingVariable ( ) ) ; } return sVar ; }", "nl": "Make a structure for the part"}}
{"translation": {"code": "protected Variable makeParamVariable ( GempakParameter param , List < Dimension > dims ) { Variable var = new Variable ( ncfile , null , null , param . getName ( ) ) ; var . setDataType ( DataType . FLOAT ) ; var . setDimensions ( dims ) ; var . addAttribute ( new Attribute ( CDM . LONG_NAME , param . getDescription ( ) ) ) ; String units = param . getUnit ( ) ; if ( ( units != null ) && ! units . equals ( \"\" ) ) { var . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; } var . addAttribute ( new Attribute ( CDM . MISSING_VALUE , RMISS ) ) ; return var ; }", "nl": "Make a variable from a GempakParmaeter"}}
{"translation": {"code": "protected int getStnVarSize ( String name ) { int size = - 1 ; for ( int i = 0 ; i < stnVarNames . length ; i ++ ) { if ( name . equals ( stnVarNames [ i ] ) ) { size = stnVarSizes [ i ] ; break ; } } return size ; }", "nl": "Get the size of a particular station variable"}}
{"translation": {"code": "private Array get1DArray ( DataType type , int len ) { Array varArray = null ; if ( type . equals ( DataType . FLOAT ) ) { varArray = new ArrayFloat . D1 ( len ) ; } else if ( type . equals ( DataType . DOUBLE ) ) { varArray = new ArrayDouble . D1 ( len ) ; } else if ( type . equals ( DataType . INT ) ) { varArray = new ArrayInt . D1 ( len , false ) ; } return varArray ; }", "nl": "Get a 1DArray for the type and length"}}
{"translation": {"code": "DataType getDataType ( int format ) { DataType p ; switch ( format ) { case 1 : // 8-bit signed integer format.\r p = DataType . SHORT ; break ; case 2 : // 16-bit signed integer format.\r p = DataType . FLOAT ; break ; case 3 : // 32-bit signed integer format.\r p = DataType . LONG ; break ; case 4 : // 32-bit IEEE float format.\r p = DataType . FLOAT ; break ; case 5 : //  16-bit IEEE float format.\r p = DataType . DOUBLE ; break ; default : p = null ; break ; } //end of switch\r return p ; }", "nl": "Return the string of entity ID for the Dorade image file"}}
{"translation": {"code": "public static boolean isMine ( NetcdfFile ncfile ) { String cs = ncfile . findAttValueIgnoreCase ( null , CDM . CONVENTIONS , null ) ; if ( cs != null ) return false ; String s = ncfile . findAttValueIgnoreCase ( null , \"DataType\" , null ) ; if ( ( s == null ) || ! ( s . equalsIgnoreCase ( \"LatLonGrid\" ) || s . equalsIgnoreCase ( \"LatLonHeightGrid\" ) ) ) return false ; if ( ( null == ncfile . findGlobalAttribute ( \"Latitude\" ) ) || ( null == ncfile . findGlobalAttribute ( \"Longitude\" ) ) || ( null == ncfile . findGlobalAttribute ( \"LatGridSpacing\" ) ) || ( null == ncfile . findGlobalAttribute ( \"LonGridSpacing\" ) ) || ( null == ncfile . findGlobalAttribute ( \"Time\" ) ) ) return false ; return ! ( null == ncfile . findDimension ( \"Lat\" ) || null == ncfile . findDimension ( \"Lon\" ) ) ; }", "nl": "Is this my file?"}}
{"translation": {"code": "public List < ucar . nc2 . dt . GridDataset . Gridset > getGridsets ( ) { return new ArrayList < ucar . nc2 . dt . GridDataset . Gridset > ( gridsetHash . values ( ) ) ; }", "nl": "Return GridDatatype objects grouped by GridCoordSys . All GridDatatype in a Gridset have the same GridCoordSystem ."}}
{"translation": {"code": "static public FeatureType getFeatureType ( NetcdfDataset ds , String key , Formatter errlog ) { FeatureType ft = null ; String fts = getLiteral ( ds , key , errlog ) ; if ( fts != null ) { ft = FeatureType . valueOf ( fts . toUpperCase ( ) ) ; if ( ( ft == null ) && ( errlog != null ) ) errlog . format ( \" Cant find Feature type %s from %s%n\" , fts , key ) ; } return ft ; }", "nl": "Turn the key into a String and return the corresponding featureType if any ."}}
{"translation": {"code": "static public String findCoordNameByType ( NetcdfDataset ds , AxisType atype ) { CoordinateAxis coordAxis = findCoordByType ( ds , atype ) ; return coordAxis == null ? null : coordAxis . getFullName ( ) ; }", "nl": "search for Axis by Type ."}}
{"translation": {"code": "int getUInt ( byte [ ] b , int num ) { int base = 1 ; int i ; int word = 0 ; int bv [ ] = new int [ num ] ; for ( i = 0 ; i < num ; i ++ ) { bv [ i ] = convertunsignedByte2Short ( b [ i ] ) ; } /*\r\n        ** Calculate the integer value of the byte sequence\r\n        */ for ( i = num - 1 ; i >= 0 ; i -- ) { word += base * bv [ i ] ; base *= 256 ; } return word ; }", "nl": "get unsigned integer from byte array"}}
{"translation": {"code": "protected void findCoordinateAxes ( NetcdfDataset ds ) { // coordinates is an alias for _CoordinateAxes\r for ( VarProcess vp : varList ) { if ( vp . coordAxes == null ) { // dont override if already set\r String coordsString = ds . findAttValueIgnoreCase ( vp . v , CF . COORDINATES , null ) ; if ( coordsString != null ) { vp . coordinates = coordsString ; } } } super . findCoordinateAxes ( ds ) ; }", "nl": "The attribute coordinates is an alias for _CoordinateAxes ."}}
{"translation": {"code": "byte [ ] uncompressed ( ByteBuffer buf , int offset , int uncomplen ) throws IOException { byte [ ] header = new byte [ offset ] ; buf . position ( 0 ) ; buf . get ( header ) ; byte [ ] out = new byte [ offset + uncomplen ] ; System . arraycopy ( header , 0 , out , 0 , offset ) ; CBZip2InputStream cbzip2 = new CBZip2InputStream ( ) ; int numCompBytes = buf . remaining ( ) ; byte [ ] bufc = new byte [ numCompBytes ] ; buf . get ( bufc , 0 , numCompBytes ) ; ByteArrayInputStream bis = new ByteArrayInputStream ( bufc , 2 , numCompBytes - 2 ) ; //CBZip2InputStream cbzip2 = new CBZip2InputStream(bis);\r cbzip2 . setStream ( bis ) ; int total = 0 ; int nread ; byte [ ] ubuff = new byte [ 40000 ] ; byte [ ] obuff = new byte [ 40000 ] ; try { while ( ( nread = cbzip2 . read ( ubuff ) ) != - 1 ) { if ( total + nread > obuff . length ) { byte [ ] temp = obuff ; obuff = new byte [ temp . length * 2 ] ; System . arraycopy ( temp , 0 , obuff , 0 , temp . length ) ; } System . arraycopy ( ubuff , 0 , obuff , total , nread ) ; total += nread ; } if ( obuff . length >= 0 ) System . arraycopy ( obuff , 0 , out , offset , total ) ; } catch ( BZip2ReadException ioe ) { log . warn ( \"Nexrad2IOSP.uncompress \" + raf . getLocation ( ) , ioe ) ; } return out ; }", "nl": "uncompress the TDWR products"}}
{"translation": {"code": "void addParameter ( String pName , String longName , NetcdfFile nc , ArrayList dims , Attribute att , DataType dtype , String ut , long hoff , long doff , boolean isZ , int y0 ) { String vName = pName ; Variable vVar = new Variable ( nc , null , null , vName ) ; vVar . setDataType ( dtype ) ; if ( dims != null ) vVar . setDimensions ( dims ) ; else vVar . setDimensions ( \"\" ) ; if ( att != null ) vVar . addAttribute ( att ) ; vVar . addAttribute ( new Attribute ( CDM . UNITS , ut ) ) ; vVar . addAttribute ( new Attribute ( CDM . LONG_NAME , longName ) ) ; nc . addVariable ( null , vVar ) ; vVar . setSPobject ( new Vinfo ( numX , numX0 , numY , y0 , hoff , doff , isR , isZ , null , null , 0 , 0 ) ) ; }", "nl": "adding new parameter to the netcdf file"}}
{"translation": {"code": "public void addCoordinateSystem ( CoordinateSystem cs ) { if ( cs == null ) throw new RuntimeException ( \"Attempted to add null CoordinateSystem to var \" + forVar . getFullName ( ) ) ; if ( coordSys == null ) coordSys = new ArrayList <> ( 5 ) ; coordSys . add ( cs ) ; }", "nl": "Add a CoordinateSystem to the dataset ."}}
{"translation": {"code": "public void setUnitsString ( String units ) { this . units = units ; forVar . addAttribute ( new Attribute ( CDM . UNITS , units ) ) ; }", "nl": "Set the Unit String for this Variable . Default is to use the CDM . UNITS attribute ."}}
{"translation": {"code": "int getInt ( byte [ ] b , int num ) { int base = 1 ; int i ; int word = 0 ; int bv [ ] = new int [ num ] ; for ( i = 0 ; i < num ; i ++ ) { bv [ i ] = convertunsignedByte2Short ( b [ i ] ) ; } if ( bv [ 0 ] > 127 ) { bv [ 0 ] -= 128 ; base = - 1 ; } /*\r\n        ** Calculate the integer value of the byte sequence\r\n        */ for ( i = num - 1 ; i >= 0 ; i -- ) { word += base * bv [ i ] ; base *= 256 ; } return word ; }", "nl": "get signed integer from bytes"}}
{"translation": {"code": "public String getUnitsString ( ) { String result = units ; if ( ( result == null ) && ( forVar != null ) ) { Attribute att = forVar . findAttribute ( CDM . UNITS ) ; if ( att == null ) att = forVar . findAttributeIgnoreCase ( CDM . UNITS ) ; if ( ( att != null ) && att . isString ( ) ) result = att . getStringValue ( ) ; } return ( result == null ) ? null : result . trim ( ) ; }", "nl": "Get the Unit String for the Variable . May be set explicitly else look for attribute CDM . UNITS ."}}
{"translation": {"code": "public int [ ] getDualpolLevels ( short [ ] th ) { int inc = th . length ; int [ ] levels = new int [ inc ] ; //th[2] ];\r for ( int i = 0 ; i < inc ; i ++ ) { /* calibrated data values        */ levels [ i ] = th [ i ] ; } return levels ; }", "nl": "get the calibrate data values for dualpol data"}}
{"translation": {"code": "void addVariable ( String pName , String longName , NetcdfFile nc , ArrayList dims , String coordinates , DataType dtype , String ut , long hoff , long hedsiz , boolean isZ , int nlevel , int [ ] levels , int iscale ) { Variable v = new Variable ( nc , null , null , pName ) ; v . setDataType ( dtype ) ; v . setDimensions ( dims ) ; ncfile . addVariable ( null , v ) ; v . addAttribute ( new Attribute ( CDM . LONG_NAME , longName ) ) ; v . addAttribute ( new Attribute ( CDM . UNITS , ut ) ) ; v . addAttribute ( new Attribute ( _Coordinate . Axes , coordinates ) ) ; v . setSPobject ( new Vinfo ( numX , numX0 , numY , numY0 , hoff , hedsiz , isR , isZ , null , levels , iscale , nlevel ) ) ; }", "nl": "adding new variable to the netcdf file"}}
{"translation": {"code": "private List < Dimension > breakupLevels ( NetcdfDataset ds , Variable levelVar ) throws IOException { if ( debugBreakup ) parseInfo . format ( \"breakupLevels = %s%n\" , levelVar . getShortName ( ) ) ; List < Dimension > dimList = new ArrayList <> ( ) ; ArrayChar levelVarData ; try { levelVarData = ( ArrayChar ) levelVar . read ( ) ; } catch ( IOException ioe ) { return dimList ; } List < String > values = null ; String currentUnits = null ; ArrayChar . StringIterator iter = levelVarData . getStringIterator ( ) ; while ( iter . hasNext ( ) ) { String s = iter . next ( ) ; if ( debugBreakup ) parseInfo . format ( \"   %s%n\" , s ) ; StringTokenizer stoke = new StringTokenizer ( s ) ; /* problem with blank string:\r\n   char pvvLevels(levels_35=35, charsPerLevel=10);\r\n\"MB 1000   \", \"MB 975    \", \"MB 950    \", \"MB 925    \", \"MB 900    \", \"MB 875    \", \"MB 850    \", \"MB 825    \", \"MB 800    \", \"MB 775    \", \"MB 750    \",\r\n\"MB 725    \", \"MB 700    \", \"MB 675    \", \"MB 650    \", \"MB 625    \", \"MB 600    \", \"MB 575    \", \"MB 550    \", \"MB 525    \", \"MB 500    \", \"MB 450    \",\r\n\"MB 400    \", \"MB 350    \", \"MB 300    \", \"MB 250    \", \"MB 200    \", \"MB 150    \", \"MB 100    \", \"BL 0 30   \", \"BL 60 90  \", \"BL 90 120 \", \"BL 120 150\",\r\n\"BL 150 180\", \"\"\r\n*/ if ( ! stoke . hasMoreTokens ( ) ) continue ; // skip it\r // first token is the unit\r String units = stoke . nextToken ( ) . trim ( ) ; if ( ! units . equals ( currentUnits ) ) { if ( values != null ) dimList . add ( makeZCoordAxis ( ds , values , currentUnits ) ) ; values = new ArrayList <> ( ) ; currentUnits = units ; } // next token is the value\r if ( stoke . hasMoreTokens ( ) ) values . add ( stoke . nextToken ( ) ) ; else values . add ( \"0\" ) ; } if ( values != null ) dimList . add ( makeZCoordAxis ( ds , values , currentUnits ) ) ; if ( debugBreakup ) parseInfo . format ( \"  done breakup%n\" ) ; return dimList ; }", "nl": "return the list of Dimensions that were created"}}
{"translation": {"code": "static public CoordinateAxis findCoordByType ( NetcdfDataset ds , AxisType atype ) { return findCoordByType ( ds , atype , null ) ; }", "nl": "Search for Axis by Type ."}}
{"translation": {"code": "static public CoordinateAxis findCoordByType ( NetcdfDataset ds , AxisType atype , Predicate p ) { // try the \"best\" coordinate system\r CoordinateSystem use = findBestCoordinateSystem ( ds ) ; if ( use == null ) return null ; CoordinateAxis result = findCoordByType ( use . getCoordinateAxes ( ) , atype , p ) ; if ( result != null ) return result ; // try all the axes\r return findCoordByType ( ds . getCoordinateAxes ( ) , atype , p ) ; }", "nl": "search for Axis by Type and test against a predicate"}}
{"translation": {"code": "public int [ ] getLevels ( int nlevel , short [ ] th ) { int [ ] levels = new int [ nlevel ] ; int ival ; int isign ; for ( int i = 0 ; i < nlevel ; i ++ ) { /* calibrated data values        */ ival = convertShort2unsignedInt ( th [ i ] ) ; if ( ( ival & 0x00008000 ) == 0 ) { isign = - 1 ; if ( ( ival & 0x00000100 ) == 0 ) isign = 1 ; levels [ i ] = isign * ( ival & 0x000000FF ) ; } else { levels [ i ] = - 9999 + ( ival & 0x000000FF ) ; } } return levels ; }", "nl": "get the table to calibrate data value"}}
{"translation": {"code": "static public Dimension findDimensionByType ( NetcdfDataset ds , AxisType atype ) { CoordinateAxis axis = findCoordByType ( ds , atype ) ; if ( axis == null ) return null ; if ( axis . isScalar ( ) ) return null ; return axis . getDimension ( 0 ) ; }", "nl": "search for Dimension used by axis of given by Type ."}}
{"translation": {"code": "public boolean isValidFile ( RandomAccessFile raf ) throws IOException { raf . seek ( 0 ) ; String test = raf . readString ( MAGIC . length ( ) ) ; return test . equals ( MAGIC ) ; }", "nl": "Check if this is a valid file for this IOServiceProvider . You must make this method thread safe ie dont keep any state ."}}
{"translation": {"code": "protected Object convert ( byte [ ] barray , DataType dataType , int nelems , int byteOrder ) { if ( dataType == DataType . BYTE ) { return barray ; } if ( dataType == DataType . CHAR ) { return IospHelper . convertByteToChar ( barray ) ; } ByteBuffer bbuff = ByteBuffer . wrap ( barray ) ; if ( byteOrder >= 0 ) bbuff . order ( byteOrder == ucar . unidata . io . RandomAccessFile . LITTLE_ENDIAN ? ByteOrder . LITTLE_ENDIAN : ByteOrder . BIG_ENDIAN ) ; if ( dataType == DataType . SHORT ) { ShortBuffer tbuff = bbuff . asShortBuffer ( ) ; short [ ] pa = new short [ nelems ] ; tbuff . get ( pa ) ; return pa ; } else if ( dataType == DataType . INT ) { IntBuffer tbuff = bbuff . asIntBuffer ( ) ; int [ ] pa = new int [ nelems ] ; tbuff . get ( pa ) ; return pa ; } else if ( dataType == DataType . FLOAT ) { FloatBuffer tbuff = bbuff . asFloatBuffer ( ) ; float [ ] pa = new float [ nelems ] ; tbuff . get ( pa ) ; return pa ; } else if ( dataType == DataType . DOUBLE ) { DoubleBuffer tbuff = bbuff . asDoubleBuffer ( ) ; double [ ] pa = new double [ nelems ] ; tbuff . get ( pa ) ; return pa ; } throw new IllegalStateException ( ) ; }", "nl": "this converts a byte array to another primitive array"}}
{"translation": {"code": "static private CoordinateSystem findBestCoordinateSystem ( NetcdfDataset ds ) { // find coordinate system with highest rank (largest number of axes)\r CoordinateSystem use = null ; for ( CoordinateSystem cs : ds . getCoordinateSystems ( ) ) { if ( use == null ) use = cs ; else if ( cs . getCoordinateAxes ( ) . size ( ) > use . getCoordinateAxes ( ) . size ( ) ) use = cs ; } return use ; }", "nl": "Find the CoordinateSystem with the most number of CoordinateAxes"}}
{"translation": {"code": "private CoordinateAxis makeTimeCoordAxisFromReference ( NetcdfDataset ds , Variable timeVar , Array vals ) { Variable refVar = ds . findVariable ( \"reftime\" ) ; if ( refVar == null ) return null ; double refValue ; try { Array refArray = refVar . read ( ) ; refValue = refArray . getDouble ( refArray . getIndex ( ) ) ; // get the first value\r } catch ( IOException ioe ) { return null ; } if ( refValue == N3iosp . NC_FILL_DOUBLE ) return null ; // construct the values array - make it a double to be safe\r Array dvals = Array . factory ( DataType . DOUBLE , vals . getShape ( ) ) ; IndexIterator diter = dvals . getIndexIterator ( ) ; IndexIterator iiter = vals . getIndexIterator ( ) ; while ( iiter . hasNext ( ) ) diter . setDoubleNext ( iiter . getDoubleNext ( ) + refValue ) ; // add reftime to each of the values\r String units = ds . findAttValueIgnoreCase ( refVar , CDM . UNITS , \"seconds since 1970-1-1 00:00:00\" ) ; units = normalize ( units ) ; String desc = \"synthesized time coordinate from reftime, valtimeMINUSreftime\" ; CoordinateAxis1D timeCoord = new CoordinateAxis1D ( ds , null , \"timeCoord\" , DataType . DOUBLE , \"record\" , units , desc ) ; timeCoord . setCachedData ( dvals , true ) ; parseInfo . format ( \"Created Time Coordinate Axis From Reference = \" ) ; timeCoord . getNameAndDimensions ( parseInfo , true , false ) ; parseInfo . format ( \"%n\" ) ; return timeCoord ; }", "nl": "construct time coordinate from reftime variable"}}
{"translation": {"code": "private void createNewVariables ( NetcdfDataset ds , Variable ncVar , List < Dimension > newDims , Dimension levelDim ) throws InvalidRangeException { List < Dimension > dims = ncVar . getDimensions ( ) ; int newDimIndex = dims . indexOf ( levelDim ) ; //String shapeS = ncVar.getShapeS();\r int [ ] origin = new int [ ncVar . getRank ( ) ] ; int [ ] shape = ncVar . getShape ( ) ; int count = 0 ; for ( Dimension dim : newDims ) { String name = ncVar . getShortName ( ) + \"-\" + dim . getShortName ( ) ; origin [ newDimIndex ] = count ; shape [ newDimIndex ] = dim . getLength ( ) ; Variable varNew = ncVar . section ( new Section ( origin , shape ) ) ; varNew . setName ( name ) ; varNew . setDimension ( newDimIndex , dim ) ; // synthesize long name\r String long_name = ds . findAttValueIgnoreCase ( ncVar , CDM . LONG_NAME , ncVar . getShortName ( ) ) ; long_name = long_name + \"-\" + dim . getShortName ( ) ; ds . addVariableAttribute ( varNew , new Attribute ( CDM . LONG_NAME , long_name ) ) ; ds . addVariable ( null , varNew ) ; parseInfo . format ( \"Created New Variable as section = \" ) ; varNew . getNameAndDimensions ( parseInfo , true , false ) ; parseInfo . format ( \"%n\" ) ; count += dim . getLength ( ) ; } }", "nl": "create new variables as sections of ncVar"}}
{"translation": {"code": "private Dimension makeZCoordAxis ( NetcdfDataset ds , List < String > values , String units ) throws IOException { int len = values . size ( ) ; String name = makeZCoordName ( units ) ; if ( len > 1 ) name = name + Integer . toString ( len ) ; else name = name + values . get ( 0 ) ; StringUtil2 . replace ( name , ' ' , \"-\" ) ; Dimension dim ; if ( null != ( dim = ds . getRootGroup ( ) . findDimension ( name ) ) ) { if ( dim . getLength ( ) == len ) { // check against actual values\r Variable coord = ds . getRootGroup ( ) . findVariable ( name ) ; Array coordData = coord . read ( ) ; Array newData = Array . makeArray ( coord . getDataType ( ) , values ) ; if ( MAMath . nearlyEquals ( coordData , newData ) ) { if ( debugBreakup ) parseInfo . format ( \"  use existing coord %s%n\" , dim ) ; return dim ; } } } String orgName = name ; int count = 1 ; while ( ds . getRootGroup ( ) . findDimension ( name ) != null ) { name = orgName + \"-\" + count ; count ++ ; } // create new one\r dim = new Dimension ( name , len ) ; ds . addDimension ( null , dim ) ; if ( debugBreakup ) parseInfo . format ( \"  make Dimension = %s length = %d%n\" , name , len ) ; // if (len < 2) return dim; // skip 1D\r if ( debugBreakup ) { parseInfo . format ( \"  make ZCoordAxis = = %s length = %d%n\" , name , len ) ; } CoordinateAxis v = new CoordinateAxis1D ( ds , null , name , DataType . DOUBLE , name , makeUnitsName ( units ) , makeLongName ( name ) ) ; String positive = getZisPositive ( ds , v ) ; if ( null != positive ) v . addAttribute ( new Attribute ( _Coordinate . ZisPositive , positive ) ) ; v . setValues ( values ) ; ds . addCoordinateAxis ( v ) ; parseInfo . format ( \"Created Z Coordinate Axis = \" ) ; v . getNameAndDimensions ( parseInfo , true , false ) ; parseInfo . format ( \"%n\" ) ; return dim ; }", "nl": "make a new variable out of the list in values"}}
{"translation": {"code": "public void addDatasetScan ( Element crawlableDatasetElement , String dirName , String suffix , String regexpPatternString , String dateFormatMark , Set < NetcdfDataset . Enhance > enhanceMode , String subdirs , String olderThan ) { datasetManager . addDirectoryScan ( dirName , suffix , regexpPatternString , subdirs , olderThan , enhanceMode ) ; this . dateFormatMark = dateFormatMark ; if ( dateFormatMark != null ) { isDate = true ; if ( type == Type . joinExisting ) type = Type . joinExistingOne ; // tricky\r DateExtractor dateExtractor = new DateExtractorFromName ( dateFormatMark , true ) ; datasetManager . setDateExtractor ( dateExtractor ) ; } }", "nl": "Add a dataset scan"}}
{"translation": {"code": "protected void makeDatasets ( CancelTask cancelTask ) throws IOException { // heres where the results will go\r datasets = new ArrayList <> ( ) ; for ( MFile cd : datasetManager . getFilesSorted ( ) ) { datasets . add ( makeDataset ( cd ) ) ; } // sort using Aggregation.Dataset as Comparator.\r // Sort by date if it exists, else filename.\r Collections . sort ( datasets ) ; /* optionally extract the date\r\n      String dateCoordS = null;\r\n      if (null != dateFormatMark) {\r\n        String filename = myf.getName(); // LOOK operates on name, not path\r\n        Date dateCoord = DateFromString.getDateUsingDemarkatedCount(filename, dateFormatMark, '#');\r\n        dateCoordS = formatter.toDateTimeStringISO(dateCoord);\r\n        if (debugDateParse) System.out.println(\"  adding \" + myf.getPath() + \" date= \" + dateCoordS);\r\n      } else {\r\n        if (debugDateParse) System.out.println(\"  adding \" + myf.getPath());\r\n      }\r\n\r\n      String location = myf.getPath();\r\n      Aggregation.Dataset ds = makeDataset(location, location, null, null, dateCoordS, null, enhance, null);\r\n      datasets.add(ds);\r\n    }\r\n\r\n    // Sort by date if it exists, else filename.\r\n    Collections.sort(datasets, new Comparator<Aggregation.Dataset>() {\r\n      public int compare(Aggregation.Dataset ds1, Aggregation.Dataset ds2) {\r\n        if(ds1.cd == null)\r\n           return ds1.getLocation().compareTo(ds2.getLocation()) ;\r\n        if (ds1.cd.dateCoord != null) // LOOK can we generalize\r\n          return ds1.cd.dateCoord.compareTo(ds2.cd.dateCoord);\r\n        else\r\n          return ds1.cd.file.getName().compareTo(ds2.cd.file.getName());\r\n      }\r\n    });  */ // add the explicit datasets - these need to be kept in order\r // LOOK - should they be before or after scanned? Does it make sense to mix scan and explicit?\r // AggFmrcSingle sets explicit datasets - the scan is empty\r for ( Aggregation . Dataset dataset : explicitDatasets ) { datasets . add ( dataset ) ; } // Remove unreadable files (i.e. due to permissions) from the aggregation.\r // LOOK: Is this logic we should install \"upstream\", perhaps in MFileCollectionManager?\r // It would affect other collections than just NcML aggregation in that case.\r for ( Iterator < Dataset > datasetsIter = datasets . iterator ( ) ; datasetsIter . hasNext ( ) ; ) { Dataset dataset = datasetsIter . next ( ) ; Path datasetPath ; if ( dataset . getMFile ( ) instanceof MFileOS ) { datasetPath = ( ( MFileOS ) dataset . getMFile ( ) ) . getFile ( ) . toPath ( ) ; } else if ( dataset . getMFile ( ) instanceof MFileOS7 ) { datasetPath = ( ( MFileOS7 ) dataset . getMFile ( ) ) . getNioPath ( ) ; } else { continue ; } if ( ! Files . isReadable ( datasetPath ) ) { // File.canRead() is broken on Windows, but the JDK7 methods work.\r logger . warn ( \"Aggregation member isn't readable (permissions issue?). Skipping: \" + datasetPath ) ; datasetsIter . remove ( ) ; } } // check for duplicate location\r Set < String > dset = new HashSet <> ( 2 * datasets . size ( ) ) ; for ( Aggregation . Dataset dataset : datasets ) { if ( dset . contains ( dataset . cacheLocation ) ) logger . warn ( \"Duplicate dataset in aggregation = \" + dataset . cacheLocation ) ; dset . add ( dataset . cacheLocation ) ; } if ( datasets . size ( ) == 0 ) { throw new IllegalStateException ( \"There are no datasets in the aggregation \" + datasetManager ) ; } }", "nl": "Make the list of Datasets from explicit and scans ."}}
{"translation": {"code": "protected Dataset getTypicalDataset ( ) throws IOException { List < Dataset > nestedDatasets = getDatasets ( ) ; int n = nestedDatasets . size ( ) ; if ( n == 0 ) throw new FileNotFoundException ( \"No datasets in this aggregation\" ) ; int select ; if ( typicalDatasetMode == TypicalDataset . LATEST ) select = n - 1 ; else if ( typicalDatasetMode == TypicalDataset . PENULTIMATE ) select = ( n < 2 ) ? 0 : n - 2 ; else if ( typicalDatasetMode == TypicalDataset . FIRST ) select = 0 ; else { // random is default\r if ( r == null ) r = new Random ( ) ; select = ( n < 2 ) ? 0 : r . nextInt ( n ) ; } return nestedDatasets . get ( select ) ; }", "nl": "Open one of the nested datasets as a template for the aggregation dataset ."}}
{"translation": {"code": "protected Dataset makeDataset ( String cacheName , String location , String id , String ncoordS , String coordValueS , String sectionSpec , EnumSet < NetcdfDataset . Enhance > enhance , ucar . nc2 . util . cache . FileFactory reader ) { return new Dataset ( cacheName , location , id , enhance , reader ) ; // overridden in OuterDim, tiled\r }", "nl": "Dataset factory so subclasses can override"}}
{"translation": {"code": "public void addExplicitDataset ( String cacheName , String location , String id , String ncoordS , String coordValueS , String sectionSpec , ucar . nc2 . util . cache . FileFactory reader ) { Dataset nested = makeDataset ( cacheName , location , id , ncoordS , coordValueS , sectionSpec , null , reader ) ; explicitDatasets . add ( nested ) ; }", "nl": "Add a nested dataset specified by an explicit netcdf element . enhance is handled by the reader so its always false here ."}}
{"translation": {"code": "public void finish ( CancelTask cancelTask ) throws IOException { datasetManager . scan ( true ) ; // Make the list of Datasets, by scanning if needed.\r cacheDirty = true ; makeDatasets ( cancelTask ) ; //ucar.unidata.io.RandomAccessFile.setDebugAccess( true);\r buildNetcdfDataset ( cancelTask ) ; //ucar.unidata.io.RandomAccessFile.setDebugAccess( false);\r }", "nl": "all elements are processed finish construction"}}
{"translation": {"code": "public double getConvertFactor ( CalendarPeriod from ) { if ( field == CalendarPeriod . Field . Month || field == CalendarPeriod . Field . Year ) { log . warn ( \" CalendarDate.convert on Month or Year\" ) ; } return ( double ) from . millisecs ( ) / millisecs ( ) ; }", "nl": "Get the conversion factor of the other CalendarPeriod to this one"}}
{"translation": {"code": "static public File getCacheFile ( String fileLocation ) { File f = new File ( makeCachePath ( fileLocation ) ) ; if ( f . exists ( ) ) { if ( ! f . setLastModified ( System . currentTimeMillis ( ) ) ) logger . warn ( \"Failed to setLastModified on \" + f . getPath ( ) ) ; } if ( ! checkExist ) { File dir = f . getParentFile ( ) ; if ( ! dir . exists ( ) && ! dir . mkdirs ( ) ) logger . warn ( \"Failed to mkdirs on \" + dir . getPath ( ) ) ; checkExist = true ; } return f ; }", "nl": "Get a file in the cache . File may or may not exist . We assume its always writeable . If it does exist set its LastModifiedDate to current time ."}}
{"translation": {"code": "static public void cleanCache ( Date cutoff , StringBuilder sbuff ) { if ( sbuff != null ) sbuff . append ( \"CleanCache files before \" ) . append ( cutoff ) . append ( \"\\n\" ) ; File dir = new File ( root ) ; File [ ] children = dir . listFiles ( ) ; if ( children == null ) return ; for ( File file : children ) { Date lastMod = new Date ( file . lastModified ( ) ) ; if ( lastMod . before ( cutoff ) ) { boolean ret = file . delete ( ) ; if ( sbuff != null ) { sbuff . append ( \" delete \" ) . append ( file ) . append ( \" (\" ) . append ( lastMod ) . append ( \")\\n\" ) ; if ( ! ret ) sbuff . append ( \"Error deleting \" ) . append ( file ) . append ( \"\\n\" ) ; } } } }", "nl": "Remove all files with date < cutoff ."}}
{"translation": {"code": "static public void setRootDirectory ( String cacheDir ) { if ( ! cacheDir . endsWith ( \"/\" ) ) cacheDir = cacheDir + \"/\" ; root = StringUtil2 . replace ( cacheDir , ' ' , \"/\" ) ; // no nasty backslash\r makeRootDirectory ( ) ; }", "nl": "Set the cache root directory . Create it if it doesnt exist ."}}
{"translation": {"code": "static public void cleanCache ( long maxBytes , Comparator < File > fileComparator , StringBuilder sbuff ) { if ( sbuff != null ) sbuff . append ( \"DiskCache clean maxBytes= \" ) . append ( maxBytes ) . append ( \"on dir \" ) . append ( root ) . append ( \"\\n\" ) ; File dir = new File ( root ) ; long total = 0 , total_delete = 0 ; File [ ] files = dir . listFiles ( ) ; if ( files != null ) { List < File > fileList = Arrays . asList ( files ) ; Collections . sort ( fileList , fileComparator ) ; for ( File file : fileList ) { if ( file . length ( ) + total > maxBytes ) { total_delete += file . length ( ) ; if ( sbuff != null ) sbuff . append ( \" delete \" ) . append ( file ) . append ( \" (\" ) . append ( file . length ( ) ) . append ( \")\\n\" ) ; if ( ! file . delete ( ) && sbuff != null ) sbuff . append ( \"Error deleting \" ) . append ( file ) . append ( \"\\n\" ) ; } else { total += file . length ( ) ; } } } if ( sbuff != null ) { sbuff . append ( \"Total bytes deleted= \" ) . append ( total_delete ) . append ( \"\\n\" ) ; sbuff . append ( \"Total bytes left in cache= \" ) . append ( total ) . append ( \"\\n\" ) ; } }", "nl": "Remove files if needed to make cache have less than maxBytes bytes file sizes . This will remove files in sort order defined by fileComparator . The first files in the sort order are kept until the max bytes is exceeded then they are deleted ."}}
{"translation": {"code": "static public void makeRootDirectory ( ) { File dir = new File ( root ) ; if ( ! dir . exists ( ) ) if ( ! dir . mkdirs ( ) ) throw new IllegalStateException ( \"DiskCache.setRootDirectory(): could not create root directory <\" + root + \">.\" ) ; checkExist = true ; }", "nl": "Make sure that the current root directory exists ."}}
{"translation": {"code": "public double getForecastTimeIntervalSizeInHours ( Grib2Pds pds ) { Grib2Pds . PdsInterval pdsIntv = ( Grib2Pds . PdsInterval ) pds ; int timeUnitOrg = pds . getTimeUnit ( ) ; // calculate total \"range\" in units of timeUnit\r int range = 0 ; for ( Grib2Pds . TimeInterval ti : pdsIntv . getTimeIntervals ( ) ) { if ( ti . timeRangeUnit == 255 ) continue ; if ( ( ti . timeRangeUnit != timeUnitOrg ) || ( ti . timeIncrementUnit != timeUnitOrg && ti . timeIncrementUnit != 255 && ti . timeIncrement != 0 ) ) { logger . warn ( \"TimeInterval(2) has different units timeUnit org=\" + timeUnitOrg + \" TimeInterval=\" + ti . timeIncrementUnit ) ; throw new RuntimeException ( \"TimeInterval(2) has different units\" ) ; } range += ti . timeRangeLength ; if ( ti . timeIncrementUnit != 255 ) range += ti . timeIncrement ; } // now convert that range to units of the requested period.\r CalendarPeriod timeUnitPeriod = Grib2Utils . getCalendarPeriod ( convertTimeUnit ( timeUnitOrg ) ) ; if ( timeUnitPeriod == null ) return GribNumbers . UNDEFINEDD ; if ( timeUnitPeriod . equals ( CalendarPeriod . Hour ) ) return range ; double fac ; if ( timeUnitPeriod . getField ( ) == CalendarPeriod . Field . Month ) { fac = 30.0 * 24.0 ; // nominal hours in a month\r } else if ( timeUnitPeriod . getField ( ) == CalendarPeriod . Field . Year ) { fac = 365.0 * 24.0 ; // nominal hours in a year\r } else { fac = CalendarPeriod . Hour . getConvertFactor ( timeUnitPeriod ) ; } return fac * range ; }", "nl": "Get interval size in units of hours . Only use in GribVariable to decide on variable identity when intvMerge = false ."}}
{"translation": {"code": "@ Nullable public static GribStatType getStatType ( int timeRangeIndicator ) { switch ( timeRangeIndicator ) { case 3 : case 6 : case 7 : case 51 : case 113 : case 115 : case 117 : case 120 : case 123 : return GribStatType . Average ; case 4 : case 114 : case 116 : case 124 : return GribStatType . Accumulation ; case 5 : return GribStatType . DifferenceFromEnd ; case 118 : return GribStatType . Covariance ; case 119 : case 125 : return GribStatType . StandardDeviation ; default : return null ; } }", "nl": "The time unit statistical type derived from code table 5 )"}}
{"translation": {"code": "public int indexOf ( byte [ ] data , int start , int max ) { int j = 0 ; if ( data . length == 0 ) return - 1 ; if ( start + max > data . length ) System . out . println ( \"HEY KMPMatch\" ) ; for ( int i = start ; i < start + max ; i ++ ) { while ( j > 0 && match [ j ] != data [ i ] ) j = failure [ j - 1 ] ; if ( match [ j ] == data [ i ] ) j ++ ; if ( j == match . length ) return i - match . length + 1 ; } return - 1 ; }", "nl": "Finds the first occurrence of match in data ."}}
{"translation": {"code": "@ Nullable public static Map < Integer , String > getNcepGenProcess ( ) { if ( genProcessMap != null ) return genProcessMap ; String path = \"resources/grib1/ncep/ncepTableA.xml\" ; try ( InputStream is = GribResourceReader . getInputStream ( path ) ) { SAXBuilder builder = new SAXBuilder ( ) ; org . jdom2 . Document doc = builder . build ( is ) ; Element root = doc . getRootElement ( ) ; HashMap < Integer , String > result = new HashMap <> ( 200 ) ; List < Element > params = root . getChildren ( \"parameter\" ) ; for ( Element elem1 : params ) { int code = Integer . parseInt ( elem1 . getAttributeValue ( \"code\" ) ) ; String desc = elem1 . getChildText ( \"description\" ) ; result . put ( code , desc ) ; } return Collections . unmodifiableMap ( result ) ; // all at once - thread safe\r } catch ( IOException | JDOMException ioe ) { logger . error ( \"Cant read NCEP Table 1 = \" + path , ioe ) ; return null ; } }", "nl": "public so can be called from Grib2"}}
{"translation": {"code": "public void setObject ( int index , Object value ) { if ( sdata == null ) sdata = new StructureData [ nelems ] ; sdata [ index ] = ( StructureData ) value ; }", "nl": "Set the index - th StructureData of this ArrayStructure ."}}
{"translation": {"code": "public StructureData getStructureData ( int index ) { if ( sdata == null ) sdata = new StructureData [ nelems ] ; if ( index >= sdata . length ) throw new IllegalArgumentException ( index + \" > \" + sdata . length ) ; if ( sdata [ index ] == null ) sdata [ index ] = makeStructureData ( this , index ) ; return sdata [ index ] ; }", "nl": "Get the index - th StructureData of this ArrayStructure ."}}
{"translation": {"code": "protected void copyStructures ( int recnum , StructureMembers . Member m , IndexIterator result ) { Array data = getArray ( recnum , m ) ; IndexIterator dataIter = data . getIndexIterator ( ) ; while ( dataIter . hasNext ( ) ) result . setObjectNext ( dataIter . getObjectNext ( ) ) ; }", "nl": "member data is itself a structure and may be an array of structures ."}}
{"translation": {"code": "public String getScalarString ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) == DataType . CHAR ) { ArrayChar data = ( ArrayChar ) m . getDataArray ( ) ; return data . getString ( recnum ) ; } if ( m . getDataType ( ) == DataType . STRING ) { Array data = m . getDataArray ( ) ; return ( String ) data . getObject ( recnum ) ; } throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be String or char\" ) ; }", "nl": "Get member data of type String or char ."}}
{"translation": {"code": "public ArrayObject getArrayObject ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) != DataType . OPAQUE ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be Sequence\" ) ; ArrayObject array = ( ArrayObject ) m . getDataArray ( ) ; return ( ArrayObject ) array . getObject ( recnum ) ; // LOOK ??\r }", "nl": "Get member data of type ArrayObject"}}
{"translation": {"code": "public Object getScalarObject ( int recno , StructureMembers . Member m ) { DataType dataType = m . getDataType ( ) ; if ( dataType == DataType . DOUBLE ) { return getScalarDouble ( recno , m ) ; } else if ( dataType == DataType . FLOAT ) { return getScalarFloat ( recno , m ) ; } else if ( dataType . getPrimitiveClassType ( ) == byte . class ) { return getScalarByte ( recno , m ) ; } else if ( dataType . getPrimitiveClassType ( ) == short . class ) { return getScalarShort ( recno , m ) ; } else if ( dataType . getPrimitiveClassType ( ) == int . class ) { return getScalarInt ( recno , m ) ; } else if ( dataType . getPrimitiveClassType ( ) == long . class ) { return getScalarLong ( recno , m ) ; } else if ( dataType == DataType . CHAR ) { return getScalarString ( recno , m ) ; } else if ( dataType == DataType . STRING ) { return getScalarString ( recno , m ) ; } else if ( dataType == DataType . STRUCTURE ) { return getScalarStructure ( recno , m ) ; } else if ( dataType == DataType . OPAQUE ) { ArrayObject data = ( ArrayObject ) m . getDataArray ( ) ; return data . getObject ( recno * m . getSize ( ) ) ; // LOOK ?? \r } throw new RuntimeException ( \"Dont have implementation for \" + dataType ) ; }", "nl": "Get member data array of any type as an Object eg Float Double String StructureData etc ."}}
{"translation": {"code": "public double convertScalarDouble ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) == DataType . DOUBLE ) return getScalarDouble ( recnum , m ) ; if ( m . getDataType ( ) == DataType . FLOAT ) return ( double ) getScalarFloat ( recnum , m ) ; Object o = getScalarObject ( recnum , m ) ; if ( o instanceof Number ) return ( ( Number ) o ) . doubleValue ( ) ; throw new ForbiddenConversionException ( \"Type is \" + m . getDataType ( ) + \", not convertible to double\" ) ; }", "nl": "Get scalar value as a double with conversion as needed . Underlying type must be convertible to double ."}}
{"translation": {"code": "public int convertScalarInt ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) == DataType . INT || m . getDataType ( ) == DataType . UINT ) return getScalarInt ( recnum , m ) ; if ( m . getDataType ( ) == DataType . SHORT ) return ( int ) getScalarShort ( recnum , m ) ; if ( m . getDataType ( ) == DataType . USHORT ) return DataType . unsignedShortToInt ( getScalarShort ( recnum , m ) ) ; if ( m . getDataType ( ) == DataType . BYTE ) return ( int ) getScalarByte ( recnum , m ) ; if ( m . getDataType ( ) == DataType . UBYTE ) return ( int ) DataType . unsignedByteToShort ( getScalarByte ( recnum , m ) ) ; if ( m . getDataType ( ) == DataType . LONG || m . getDataType ( ) == DataType . ULONG ) return ( int ) getScalarLong ( recnum , m ) ; Object o = getScalarObject ( recnum , m ) ; if ( o instanceof Number ) return ( ( Number ) o ) . intValue ( ) ; throw new ForbiddenConversionException ( \"Type is \" + m . getDataType ( ) + \", not convertible to int\" ) ; }", "nl": "Get scalar value as an int with conversion as needed . Underlying type must be convertible to int ."}}
{"translation": {"code": "public float getScalarFloat ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) != DataType . FLOAT ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be float\" ) ; Array data = m . getDataArray ( ) ; return data . getFloat ( recnum * m . getSize ( ) ) ; // gets first one in the array\r }", "nl": "Get scalar member data of type float ."}}
{"translation": {"code": "public byte getScalarByte ( int recnum , StructureMembers . Member m ) { if ( ! ( m . getDataType ( ) . getPrimitiveClassType ( ) == byte . class ) ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be byte\" ) ; Array data = m . getDataArray ( ) ; return data . getByte ( recnum * m . getSize ( ) ) ; // gets first one in the array\r }", "nl": "Get scalar member data of type byte ."}}
{"translation": {"code": "public short getScalarShort ( int recnum , StructureMembers . Member m ) { if ( ! ( m . getDataType ( ) . getPrimitiveClassType ( ) == short . class ) ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be short\" ) ; Array data = m . getDataArray ( ) ; return data . getShort ( recnum * m . getSize ( ) ) ; // gets first one in the array\r }", "nl": "Get scalar member data of type short ."}}
{"translation": {"code": "public char getScalarChar ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) != DataType . CHAR ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be char\" ) ; Array data = m . getDataArray ( ) ; return data . getChar ( recnum * m . getSize ( ) ) ; // gets first one in the array\r }", "nl": "Get scalar member data of type char ."}}
{"translation": {"code": "public ArrayStructure getArrayStructure ( int recnum , StructureMembers . Member m ) { if ( ( m . getDataType ( ) != DataType . STRUCTURE ) && ( m . getDataType ( ) != DataType . SEQUENCE ) ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be Structure or Sequence\" ) ; if ( m . getDataType ( ) == DataType . SEQUENCE ) return getArraySequence ( recnum , m ) ; ArrayStructure array = ( ArrayStructure ) m . getDataArray ( ) ; int count = m . getSize ( ) ; StructureData [ ] this_sdata = new StructureData [ count ] ; for ( int i = 0 ; i < count ; i ++ ) this_sdata [ i ] = array . getStructureData ( recnum * count + i ) ; // make a copy of the members, but remove the data arrays, since the structureData must be used instead\r StructureMembers membersw = new StructureMembers ( array . getStructureMembers ( ) ) ; return new ArrayStructureW ( membersw , m . getShape ( ) , this_sdata ) ; }", "nl": "Get member data of type array of Structure ."}}
{"translation": {"code": "public ArraySequence getArraySequence ( int recnum , StructureMembers . Member m ) { if ( m . getDataType ( ) != DataType . SEQUENCE ) throw new IllegalArgumentException ( \"Type is \" + m . getDataType ( ) + \", must be Sequence\" ) ; // should store sequences as ArrayObject of ArraySequence objects\r ArrayObject array = ( ArrayObject ) m . getDataArray ( ) ; return ( ArraySequence ) array . getObject ( recnum ) ; }", "nl": "Get member data of type ArraySequence"}}
{"translation": {"code": "@ Override public ByteBuffer getDataAsByteBuffer ( ) { ByteBuffer bb = ByteBuffer . allocate ( ( int ) getSize ( ) ) ; resetLocalIterator ( ) ; while ( hasNext ( ) ) bb . put ( nextByte ( ) ) ; return bb ; }", "nl": "Trasfer data to a ByteBuffer . Note we cast char to byte discarding top byte if any . This is because CDM char is really a byte not a java char ."}}
{"translation": {"code": "public static ArrayChar makeFromStringArray ( ArrayObject values , int strlen ) { // create shape for equivilent charArray\r try { Section section = new Section ( values . getShape ( ) ) ; section . appendRange ( strlen ) ; int [ ] shape = section . getShape ( ) ; long size = section . computeSize ( ) ; // populate char array\r char [ ] cdata = new char [ ( int ) size ] ; int start = 0 ; IndexIterator ii = values . getIndexIterator ( ) ; while ( ii . hasNext ( ) ) { String s = ( String ) ii . next ( ) ; for ( int k = 0 ; k < s . length ( ) && k < strlen ; k ++ ) cdata [ start + k ] = s . charAt ( k ) ; start += strlen ; } // ready to create the char Array\r Array carr = Array . factory ( DataType . CHAR , shape , cdata ) ; return ( ArrayChar ) carr ; } catch ( InvalidRangeException e ) { e . printStackTrace ( ) ; // cant happen.\r return null ; } }", "nl": "Create an ArrayChar from an ArrayObject of Strings . Inverse of make1DStringArray . Copies the data ."}}
{"translation": {"code": "public void setString ( String val ) { int rank = getRank ( ) ; if ( rank != 1 ) throw new IllegalArgumentException ( \"ArayChar.setString rank must be 1\" ) ; int arrayLen = indexCalc . getShape ( 0 ) ; int strLen = Math . min ( val . length ( ) , arrayLen ) ; for ( int k = 0 ; k < strLen ; k ++ ) storage [ k ] = val . charAt ( k ) ; char c = 0 ; for ( int k = strLen ; k < arrayLen ; k ++ ) storage [ k ] = ; }", "nl": "Set the ArrayChar values from the characters in the String . Rank must be 1 . If String longer than ArrayChar ignore extra chars ; if shorter fill with 0 ."}}
{"translation": {"code": "public ArrayObject make1DStringArray ( ) { int nelems = ( getRank ( ) == 0 ) ? 1 : ( int ) getSize ( ) / indexCalc . getShape ( getRank ( ) - 1 ) ; Array sarr = Array . factory ( DataType . STRING , new int [ ] { nelems } ) ; IndexIterator newsiter = sarr . getIndexIterator ( ) ; ArrayChar . StringIterator siter = getStringIterator ( ) ; while ( siter . hasNext ( ) ) { newsiter . setObjectNext ( siter . next ( ) ) ; } return ( ArrayObject ) sarr ; }", "nl": "Make this into the equivilent 1D ArrayObject of Strings ."}}
{"translation": {"code": "public static ArrayChar makeFromStringArray ( ArrayObject values ) { // find longest string\r IndexIterator ii = values . getIndexIterator ( ) ; int strlen = 0 ; while ( ii . hasNext ( ) ) { String s = ( String ) ii . next ( ) ; strlen = Math . max ( s . length ( ) , strlen ) ; } return makeFromStringArray ( values , strlen ) ; }", "nl": "Create an ArrayChar from an ArrayObject of Strings ."}}
{"translation": {"code": "public static ArrayChar makeFromString ( String s , int max ) { ArrayChar result = new ArrayChar . D1 ( max ) ; for ( int i = 0 ; i < max && i < s . length ( ) ; i ++ ) result . setChar ( i , s . charAt ( i ) ) ; return result ; }", "nl": "Create an ArrayChar from a String"}}
{"translation": {"code": "public static Grib1ParamTables factory ( org . jdom2 . Element paramTableElem ) { if ( paramTableElem == null ) return new Grib1ParamTables ( ) ; return new Grib1ParamTables ( null , new Grib1ParamTableReader ( paramTableElem ) ) ; }", "nl": "Get a Grib1Tables object optionally specifiying a parameter table in XML specific to this dataset ."}}
{"translation": {"code": "@ Nullable public int [ ] getForecastTimeIntervalOffset ( Grib2Record gr ) { TimeCoordIntvDateValue tinvd = getForecastTimeInterval ( gr ) ; if ( tinvd == null ) return null ; Grib2Pds pds = gr . getPDS ( ) ; int unit = convertTimeUnit ( pds . getTimeUnit ( ) ) ; TimeCoordIntvValue tinv = tinvd . convertReferenceDate ( gr . getReferenceDate ( ) , Grib2Utils . getCalendarPeriod ( unit ) ) ; if ( tinv == null ) return null ; int [ ] result = new int [ 2 ] ; result [ 0 ] = tinv . getBounds1 ( ) ; result [ 1 ] = tinv . getBounds2 ( ) ; return result ; }", "nl": "If this has a time interval coordinate get time interval"}}
{"translation": {"code": "public static Grib2Tables factory ( int center , int subCenter , int masterVersion , int localVersion , int genProcessId ) { Grib2TablesId id = new Grib2TablesId ( center , subCenter , masterVersion , localVersion , genProcessId ) ; Grib2Tables cust = tables . get ( id ) ; if ( cust != null ) return cust ; // note that we match on id, so same Grib2Customizer may be mapped to multiple id's (eg match on -1)\r Grib2TableConfig config = Grib2TableConfig . matchTable ( id ) ; cust = build ( config ) ; tables . put ( id , cust ) ; return cust ; }", "nl": "Lazy instantiation ."}}
{"translation": {"code": "public int getOffset ( CalendarDate start , CalendarDate end ) { if ( start . equals ( end ) ) return 0 ; long start_millis = start . getDateTime ( ) . getMillis ( ) ; long end_millis = end . getDateTime ( ) . getMillis ( ) ; // 5 second slop\r Period p ; if ( start_millis < end_millis ) p = new Period ( start_millis , end_millis + 5000 , getPeriodType ( ) ) ; else p = new Period ( start_millis + 5000 , end_millis , getPeriodType ( ) ) ; return p . get ( getDurationFieldType ( ) ) ; }", "nl": "start + offset = end"}}
{"translation": {"code": "@ Override public String getSubCenterName ( int center , int subcenter ) { switch ( subcenter ) { case 0 : return null ; case 1 : return \"FSL/FRD Regional Analysis and Prediction Branch\" ; case 2 : return \"FSL/FRD Local Analysis and Prediction Branch\" ; } return super . getSubCenterName ( center , subcenter ) ; }", "nl": "LOOK maybe combine grib1 grib2 and bufr ??"}}
{"translation": {"code": "private ucar . ma2 . ArrayStructure readStructureData ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException , InvalidRangeException { H4header . Vinfo vinfo = ( H4header . Vinfo ) s . getSPobject ( ) ; vinfo . setLayoutInfo ( ) ; // make sure needed info is present\r int recsize = vinfo . elemSize ; // create the ArrayStructure\r StructureMembers members = s . makeStructureMembers ( ) ; for ( StructureMembers . Member m : members . getMembers ( ) ) { Variable v2 = s . findVariable ( m . getName ( ) ) ; H4header . Minfo minfo = ( H4header . Minfo ) v2 . getSPobject ( ) ; m . setDataParam ( minfo . offset ) ; } members . setStructureSize ( recsize ) ; ArrayStructureBB structureArray = new ArrayStructureBB ( members , section . getShape ( ) ) ; // LOOK subset\r // loop over records\r byte [ ] result = structureArray . getByteBuffer ( ) . array ( ) ; /*if (vinfo.isChunked) {\r\n      InputStream is = getChunkedInputStream(vinfo);\r\n      PositioningDataInputStream dataSource = new PositioningDataInputStream(is);\r\n      Layout layout = new LayoutRegular(vinfo.start, recsize, s.getShape(), section);\r\n      IospHelper.readData(dataSource, layout, DataType.STRUCTURE, result);  */ if ( ! vinfo . isLinked && ! vinfo . isCompressed ) { Layout layout = new LayoutRegular ( vinfo . start , recsize , s . getShape ( ) , section ) ; IospHelper . readData ( raf , layout , DataType . STRUCTURE , result , - 1 , true ) ; /* option 1\r\n    } else if (vinfo.isLinked && !vinfo.isCompressed) {\r\n      Layout layout = new LayoutSegmented(vinfo.segPos, vinfo.segSize, recsize, s.getShape(), section);\r\n      IospHelper.readData(raf, layout, DataType.STRUCTURE, result, -1);  */ // option 2\r } else if ( vinfo . isLinked && ! vinfo . isCompressed ) { InputStream is = new LinkedInputStream ( vinfo ) ; PositioningDataInputStream dataSource = new PositioningDataInputStream ( is ) ; Layout layout = new LayoutRegular ( 0 , recsize , s . getShape ( ) , section ) ; IospHelper . readData ( dataSource , layout , DataType . STRUCTURE , result ) ; } else if ( ! vinfo . isLinked && vinfo . isCompressed ) { InputStream is = getCompressedInputStream ( vinfo ) ; PositioningDataInputStream dataSource = new PositioningDataInputStream ( is ) ; Layout layout = new LayoutRegular ( 0 , recsize , s . getShape ( ) , section ) ; IospHelper . readData ( dataSource , layout , DataType . STRUCTURE , result ) ; } else if ( vinfo . isLinked && vinfo . isCompressed ) { InputStream is = getLinkedCompressedInputStream ( vinfo ) ; PositioningDataInputStream dataSource = new PositioningDataInputStream ( is ) ; Layout layout = new LayoutRegular ( 0 , recsize , s . getShape ( ) , section ) ; IospHelper . readData ( dataSource , layout , DataType . STRUCTURE , result ) ; } else { throw new IllegalStateException ( ) ; } return structureArray ; }", "nl": "Structures must be fixed sized"}}
{"translation": {"code": "@ Override public long readToByteChannel ( ucar . nc2 . Variable v2 , Section section , WritableByteChannel channel ) throws java . io . IOException , ucar . ma2 . InvalidRangeException { Array data = readData ( v2 , section ) ; return IospHelper . copyToByteChannel ( data , channel ) ; }", "nl": "LOOK DataOutputStream uses big - endian"}}
{"translation": {"code": "protected int getItem ( int pixel ) { if ( nitems < 2 ) return 0 ; int eff_width = b . width - 2 * arrow_size ; // effective width\r double fitem = ( ( double ) ( pixel - arrow_size ) * ( nitems - 1 ) ) / eff_width ; int item = ( int ) ( fitem + .5 ) ; item = Math . max ( Math . min ( item , nitems - 1 ) , 0 ) ; return item ; }", "nl": "return item selected by this pixel position"}}
{"translation": {"code": "public void addMapBean ( MapBean mb ) { mapBeanMenu . addAction ( mb . getActionDesc ( ) , mb . getIcon ( ) , mb . getAction ( ) ) ; // first one is the \"default\"\r if ( mapBeanCount == 0 ) { setMapRenderer ( mb . getRenderer ( ) ) ; } mapBeanCount ++ ; mb . addPropertyChangeListener ( new PropertyChangeListener ( ) { public void propertyChange ( java . beans . PropertyChangeEvent e ) { if ( e . getPropertyName ( ) . equals ( \"Renderer\" ) ) { setMapRenderer ( ( Renderer ) e . getNewValue ( ) ) ; } } } ) ; }", "nl": "add a MapBean to the User Interface"}}
{"translation": {"code": "public void setNumColors ( int n ) { if ( n != ncolors ) { colors = new Color [ n ] ; int prevn = Math . min ( ncolors , n ) ; System . arraycopy ( useColors , 0 , colors , 0 , prevn ) ; for ( int i = ncolors ; i < n ; i ++ ) colors [ i ] = Color . white ; useColors = colors ; ncolors = n ; edge = new double [ ncolors ] ; hist = new int [ ncolors + 1 ] ; } }", "nl": "Set the number of colors in the colorscale ."}}
{"translation": {"code": "protected int getItemPos ( ) { if ( nitems < 1 ) return - arrow_size ; // dont show indicator\r else if ( nitems == 1 ) return b . width / 2 ; // indicator in center\r int item = table . getSelectedRowIndex ( ) ; // selected item\r int eff_width = b . width - 2 * arrow_size ; // effective width\r int pixel = ( item * eff_width ) / ( nitems - 1 ) ; // divided into n-1 intervals\r return pixel + arrow_size ; }", "nl": "return slider indicator position for currently selected item"}}
{"translation": {"code": "public double getCoordValue ( int j , int i ) { if ( coords == null ) doRead ( ) ; return coords . get ( j , i ) ; }", "nl": "Get the coordinate value at the i j index ."}}
{"translation": {"code": "public double [ ] getCoordValues ( ) { if ( coords == null ) doRead ( ) ; if ( ! isNumeric ( ) ) throw new UnsupportedOperationException ( \"CoordinateAxis2D.getCoordValues() on non-numeric\" ) ; return ( double [ ] ) coords . get1DJavaArray ( DataType . DOUBLE ) ; }", "nl": "Get the coordinate values as a 1D double array in canonical order ."}}
{"translation": {"code": "public CoordinateAxis2D section ( Range r1 , Range r2 ) throws InvalidRangeException { List < Range > section = new ArrayList <> ( ) ; section . add ( r1 ) ; section . add ( r2 ) ; return ( CoordinateAxis2D ) section ( section ) ; }", "nl": "Create a new CoordinateAxis2D as a section of this CoordinateAxis2D ."}}
{"translation": {"code": "static public Date isoStringToDate ( String iso ) throws IllegalArgumentException { CalendarDate dt = isoStringToCalendarDate ( null , iso ) ; return dt . toDate ( ) ; }", "nl": "Does not handle non - standard Calendars"}}
{"translation": {"code": "static public MFileOS getExistingFile ( String filename ) { if ( filename == null ) return null ; File file = new File ( filename ) ; if ( file . exists ( ) ) return new MFileOS ( file ) ; return null ; }", "nl": "Make MFileOS if file exists otherwise return null"}}
{"translation": {"code": "private static int sumArray ( int [ ] arr ) { if ( arr == null ) throw new NullPointerException ( \"null array\" ) ; if ( arr . length == 0 ) throw new IllegalArgumentException ( \"Zero-length array\" ) ; int sum = 0 ; for ( int i = 0 ; i < arr . length ; i ++ ) { if ( arr [ i ] <= 0 ) { throw new IllegalArgumentException ( \"All array values must be > 0\" ) ; } sum += arr [ i ] ; } return sum ; }", "nl": "Calculates the sum of the values in the given array ."}}
{"translation": {"code": "@ Override public final Chronology withZone ( DateTimeZone zone ) { if ( zone . equals ( DateTimeZone . UTC ) ) return this . withUTC ( ) ; throw new UnsupportedOperationException ( \"Not supported yet.\" ) ; }", "nl": "Throws UnsupportedOperationException unless the time zone is UTC"}}
{"translation": {"code": "private int loadData ( ) { if ( ! headerLoaded ) return - 1 ; if ( dataLoaded ) return 0 ; InputStream s = stream ; if ( s == null ) return - 1 ; try { /* read in the data */ for ( int i = 0 ; i < nrecords ; i ++ ) { /* read the data record indicator */ byte recbyte = ds . readByte ( ) ; if ( recbyte == 0x20 ) { for ( int j = 0 ; j < nfields ; j ++ ) { data [ j ] . readRowN ( ds , i ) ; } } else { /* a deleted record */ nrecords -- ; i -- ; } } dataLoaded = true ; } catch ( java . io . IOException e ) { close ( s ) ; return - 1 ; } finally { close ( s ) ; } return 0 ; }", "nl": "Load the dbase file data ."}}
{"translation": {"code": "private int loadHeader ( ) { if ( headerLoaded ) return 0 ; InputStream s = stream ; if ( s == null ) return - 1 ; try { BufferedInputStream bs = new BufferedInputStream ( s ) ; ds = new DataInputStream ( bs ) ; /* read the header as one block of bytes*/ Header = new byte [ 32 ] ; ds . readFully ( Header ) ; //System.out.println(\"dbase header is \" + Header);\r if ( Header [ 0 ] == ' ' ) { //looks like html coming back to us!\r close ( ds ) ; return - 1 ; } filetype = Header [ 0 ] ; /* 4 bytes for number of records is in little endian */ nrecords = Swap . swapInt ( Header , 4 ) ; nbytesheader = Swap . swapShort ( Header , 8 ) ; /* read in the Field Descriptors */ /* have to figure how many there are from\r\n      * the header size.  Should be nbytesheader/32 -1\r\n      */ nfields = ( nbytesheader / 32 ) - 1 ; if ( nfields < 1 ) { System . out . println ( \"nfields = \" + nfields ) ; System . out . println ( \"nbytesheader = \" + nbytesheader ) ; return - 1 ; } FieldDesc = new DbaseFieldDesc [ nfields ] ; data = new DbaseData [ nfields ] ; for ( int i = 0 ; i < nfields ; i ++ ) { FieldDesc [ i ] = new DbaseFieldDesc ( ds , filetype ) ; data [ i ] = new DbaseData ( FieldDesc [ i ] , nrecords ) ; } /* read the last byte of the header (0x0d) */ ds . readByte ( ) ; headerLoaded = true ; } catch ( java . io . IOException e ) { close ( s ) ; return - 1 ; } return 0 ; }", "nl": "Load the dbase file header ."}}
{"translation": {"code": "static public byte [ ] intToBytes ( int v ) { byte [ ] b = new byte [ 4 ] ; int allbits = 255 ; for ( int i = 0 ; i < 4 ; i ++ ) { b [ 3 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) >> i * 8 ) ; } return b ; }", "nl": "Convert an int to an array of 4 bytes ."}}
{"translation": {"code": "private void addChsub ( Chsub sub ) { if ( chsubs == null ) { chsubs = new ArrayList <> ( ) ; } chsubs . add ( sub ) ; }", "nl": "Add a Chsub"}}
{"translation": {"code": "static public byte [ ] shortToBytes ( short v ) { byte [ ] b = new byte [ 2 ] ; int allbits = 255 ; for ( int i = 0 ; i < 2 ; i ++ ) { b [ 1 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) >> i * 8 ) ; } return b ; }", "nl": "Convert a short to an array of 2 bytes ."}}
{"translation": {"code": "private String getFullPath ( String filename ) { String file ; String ddfPath = getDDFPath ( ) ; if ( filename . startsWith ( \"^\" ) ) { file = filename . replace ( \"^\" , \"\" ) ; file = ddfPath + file ; } else { File f = new File ( filename ) ; if ( ! f . isAbsolute ( ) ) { file = ddfPath + filename ; } else { file = filename ; } } return file ; }", "nl": "Get the full path for a given filename"}}
{"translation": {"code": "private String getDDFPath ( ) { if ( pathToDDF == null ) { int lastSlash = ddFile . lastIndexOf ( \"/\" ) ; if ( lastSlash < 0 ) { lastSlash = ddFile . lastIndexOf ( File . separator ) ; } pathToDDF = ( lastSlash < 0 ) ? \"\" : ddFile . substring ( 0 , lastSlash + 1 ) ; } return pathToDDF ; }", "nl": "Get the path to the Data Descriptor File"}}
{"translation": {"code": "private List < String > getFileNames ( ) throws IOException { if ( fileNames == null ) { fileNames = new ArrayList <> ( ) ; timeStepsPerFile = tDim . getSize ( ) ; if ( ! isTemplate ( ) ) { // single file\r fileNames . add ( getFullPath ( getDataFile ( ) ) ) ; } else { // figure out template type\r long start = System . currentTimeMillis ( ) ; List < String > fileSet = new ArrayList <> ( ) ; String template = getDataFile ( ) ; if ( GradsTimeDimension . hasTimeTemplate ( template ) ) { if ( template . contains ( GradsEnsembleDimension . ENS_TEMPLATE_ID ) ) { templateType = ENS_TIME_TEMPLATE ; } else { templateType = TIME_TEMPLATE ; } } else { // not time - either ens or chsub\r if ( template . contains ( GradsEnsembleDimension . ENS_TEMPLATE_ID ) ) { templateType = ENS_TEMPLATE ; } else { templateType = TIME_TEMPLATE ; } } if ( templateType == ENS_TEMPLATE ) { for ( int e = 0 ; e < eDim . getSize ( ) ; e ++ ) { fileSet . add ( getFullPath ( eDim . replaceFileTemplate ( template , e ) ) ) ; } } else if ( ( templateType == TIME_TEMPLATE ) || ( templateType == ENS_TIME_TEMPLATE ) ) { int numens = ( templateType == TIME_TEMPLATE ) ? 1 : eDim . getSize ( ) ; for ( int t = 0 ; t < tDim . getSize ( ) ; t ++ ) { for ( int e = 0 ; e < numens ; e ++ ) { String file = getFileName ( e , t ) ; if ( ! fileSet . contains ( file ) ) { fileSet . add ( file ) ; } } } // this'll be a bogus number if chsub was used\r timeStepsPerFile = tDim . getSize ( ) / ( fileSet . size ( ) / numens ) ; } //System.out.println(\"Time to generate file list = \"\r //                   + (System.currentTimeMillis() - start));\r fileNames . addAll ( fileSet ) ; } //long start2 = System.currentTimeMillis();\r // now make sure they exist\r for ( String file : fileNames ) { File f = new File ( file ) ; if ( ! f . exists ( ) ) { log . error ( \"File: \" + f + \" does not exist\" ) ; throw new IOException ( \"File: \" + f + \" does not exist\" ) ; } } //System.out.println(\"Time to check file list = \"\r //                   + (System.currentTimeMillis() - start2));\r } return fileNames ; }", "nl": "Get the list of filenames"}}
{"translation": {"code": "public String getFileName ( int eIndex , int tIndex ) { String dataFilePath = dataFile ; if ( ( getTemplateType ( ) == ENS_TEMPLATE ) || ( getTemplateType ( ) == ENS_TIME_TEMPLATE ) ) { dataFilePath = getEnsembleDimension ( ) . replaceFileTemplate ( dataFilePath , eIndex ) ; } dataFilePath = getTimeDimension ( ) . replaceFileTemplate ( dataFilePath , tIndex ) ; if ( ( chsubs != null ) && ( dataFilePath . contains ( CHSUB_TEMPLATE_ID ) ) ) { for ( Chsub ch : chsubs ) { if ( ( tIndex >= ch . startTimeIndex ) && ( tIndex <= ch . endTimeIndex ) ) { dataFilePath = dataFilePath . replace ( CHSUB_TEMPLATE_ID , ch . subString ) ; break ; } } } return getFullPath ( dataFilePath ) ; }", "nl": "Get the file name for the particular time and ensemble index"}}
{"translation": {"code": "public int [ ] getTimeStepsPerFile ( String filename ) { if ( chsubs != null ) { for ( Chsub ch : chsubs ) { if ( filename . contains ( ch . subString ) ) { return new int [ ] { ch . numTimes , ch . startTimeIndex } ; } } } return new int [ ] { timeStepsPerFile , 0 } ; }", "nl": "Get the number of timesteps per file and the starting offset"}}
{"translation": {"code": "static public double swapDouble ( double v ) { long l = swapLong ( Double . doubleToLongBits ( v ) ) ; return ( Double . longBitsToDouble ( l ) ) ; }", "nl": "Returns the double resulting from reversing 8 bytes of a specified double ."}}
{"translation": {"code": "private void swapByteOrder ( ) { // NB: we are setting bigEndian to be opposite the system arch\r String arch = System . getProperty ( \"os.arch\" ) ; if ( arch . equals ( \"x86\" ) || // Windows, Linux\r arch . equals ( \"arm\" ) || // Window CE\r arch . equals ( \"x86_64\" ) || // Windows64, Mac OS-X\r arch . equals ( \"amd64\" ) || // Linux64?\r arch . equals ( \"alpha\" ) ) { // Utrix, VAX, DECOS\r bigEndian = true ; } else { bigEndian = false ; } }", "nl": "Swap the byte order from the system default"}}
{"translation": {"code": "static public short swapShort ( byte [ ] b , int offset ) { // 2 bytes\r int low = b [ offset ] & 0xff ; int high = b [ offset + 1 ] & 0xff ; return ( short ) ( high << 8 | low ) ; }", "nl": "Returns the short resulting from swapping 2 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "static public int swapInt ( byte [ ] b , int offset ) { // 4 bytes\r int accum = 0 ; for ( int shiftBy = 0 , i = offset ; shiftBy < 32 ; shiftBy += 8 , i ++ ) { accum |= ( b [ i ] & 0xff ) << shiftBy ; } return accum ; }", "nl": "Returns the int resulting from reversing 4 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "static public double swapDouble ( byte [ ] b , int offset ) { long accum = 0 ; long shiftedval ; for ( int shiftBy = 0 , i = offset ; shiftBy < 64 ; shiftBy += 8 , i ++ ) { shiftedval = ( ( long ) ( b [ i ] & 0xff ) ) << shiftBy ; accum |= shiftedval ; } return Double . longBitsToDouble ( accum ) ; }", "nl": "Returns the double resulting from reversing 8 bytes at a specified offset in a byte array ."}}
{"translation": {"code": "static public float swapFloat ( float v ) { int l = swapInt ( Float . floatToIntBits ( v ) ) ; return ( Float . intBitsToFloat ( l ) ) ; }", "nl": "Returns the float resulting from reversing 4 bytes of a specified float ."}}
{"translation": {"code": "public double [ ] getDoublesByName ( String Name ) { DbaseData d ; if ( ( d = getField ( Name ) ) == null ) return null ; if ( d . getType ( ) == DbaseData . TYPE_CHAR ) { String [ ] s = d . getStrings ( ) ; double [ ] dd = new double [ s . length ] ; for ( int i = 0 ; i < s . length ; i ++ ) { dd [ i ] = Double . valueOf ( s [ i ] ) ; } return dd ; } if ( d . getType ( ) == DbaseData . TYPE_BOOLEAN ) { boolean [ ] b = d . getBooleans ( ) ; double [ ] dd = new double [ b . length ] ; for ( int i = 0 ; i < b . length ; i ++ ) { if ( b [ i ] ) { dd [ i ] = 1 ; } else { dd [ i ] = 0 ; } } return dd ; } return d . getDoubles ( ) ; }", "nl": "Extract the double array of data for a field by Name ."}}
{"translation": {"code": "static public byte [ ] longToBytes ( long v ) { byte [ ] b = new byte [ 8 ] ; long allbits = 255 ; for ( int i = 0 ; i < 8 ; i ++ ) { b [ 7 - i ] = ( byte ) ( ( v & ( allbits << i * 8 ) ) >> i * 8 ) ; } return b ; }", "nl": "Convert a long to an array of 8 bytes ."}}
{"translation": {"code": "public DbaseData getField ( String Name ) { for ( int i = 0 ; i < nfields ; i ++ ) { if ( FieldDesc [ i ] . Name . equals ( Name ) ) return data [ i ] ; } return null ; }", "nl": "Extract the data for a given field by name ."}}
{"translation": {"code": "public static void main ( String [ ] args ) { if ( args . length < 1 ) { System . out . println ( \"filename or URL required\" ) ; System . exit ( - 1 ) ; } for ( String s : args ) { System . out . println ( \"*** Dump of Dbase \" + s + \":\" ) ; try { DbaseFile dbf = new DbaseFile ( s ) ; // load() method reads all data at once\r if ( dbf . loadHeader ( ) != 0 ) { System . out . println ( \"Error loading header\" + s ) ; System . exit ( - 1 ) ; } // output schema as [type0 field0, type1 field1, ...]\r String [ ] fieldNames = dbf . getFieldNames ( ) ; System . out . print ( \"[\" ) ; int nf = dbf . getNumFields ( ) ; DbaseData [ ] dbd = new DbaseData [ nf ] ; for ( int field = 0 ; field < nf ; field ++ ) { dbd [ field ] = dbf . getField ( field ) ; switch ( dbd [ field ] . getType ( ) ) { case DbaseData . TYPE_BOOLEAN : System . out . print ( \"boolean \" ) ; break ; case DbaseData . TYPE_CHAR : System . out . print ( \"String \" ) ; break ; case DbaseData . TYPE_NUMERIC : System . out . print ( \"double \" ) ; break ; } System . out . print ( fieldNames [ field ] ) ; if ( field < nf - 1 ) System . out . print ( \", \" ) ; } System . out . println ( \"]\" ) ; if ( dbf . loadData ( ) != 0 ) { System . out . println ( \"Error loading data\" + s ) ; System . exit ( - 1 ) ; } // output data\r for ( int rec = 0 ; rec < dbf . getNumRecords ( ) ; rec ++ ) { for ( int field = 0 ; field < nf ; field ++ ) { System . out . print ( dbd [ field ] . getData ( rec ) ) ; if ( field < nf - 1 ) System . out . print ( \", \" ) ; else System . out . println ( ) ; } } } catch ( IOException e ) { e . printStackTrace ( ) ; break ; } } }", "nl": "Test program dumps a Dbase file to stdout ."}}
{"translation": {"code": "private Date dateOnlyFormat ( String text ) throws java . text . ParseException { text = ( text == null ) ? \"\" : text . trim ( ) ; dateOnlyFormat ( ) ; return dateOnlyFormat . parse ( text ) ; }", "nl": "Parse text in the format yyyy - MM - dd"}}
{"translation": {"code": "public String getFieldName ( int i ) { if ( i >= nfields || i < 0 ) { return null ; } return ( FieldDesc [ i ] . Name ) ; }", "nl": "Get the name of a field by column number ."}}
{"translation": {"code": "void markStackedVariables ( Stack s ) { // Reverse the stack.\r Stack bts = new Stack ( ) ; // LogStream.err.println(\"Variables to be marked:\");\r while ( ! s . empty ( ) ) { // LogStream.err.println(((BaseType)s.peek()).getName());\r bts . push ( s . pop ( ) ) ; } // For each but the last stack element, set the projection.\r // setProject(true, false) for a ctor type sets the projection for\r // the ctor itself but *does not* set the projection for all its\r // children. Thus, if a user wants the variable S.X, and S contains Y\r // and Z too, S's projection will be set (so serialize will descend\r // into S) but X, Y and Z's projection remain clear. In this example,\r // X's projection is set by the code that follows the while loop.\r // 1/28/2000 jhrg\r while ( bts . size ( ) > 1 ) { ServerMethods ct = ( ServerMethods ) bts . pop ( ) ; ct . setProject ( true , false ) ; } // For the last element, project the entire variable.\r ServerMethods bt = ( ServerMethods ) bts . pop ( ) ; bt . setProject ( true , true ) ; }", "nl": "Given a stack of BaseType variables mark these as part of the current projection . This function assumes that if the TOS contains a Ctor type variable all of its members are to be projected . Also assume all variables under the TOS are Ctor variables and only the ctor itself is to be projected ; the member within the Ctor that is part of the projection will be on the stack too ."}}
{"translation": {"code": "String removeQuotes ( String s ) { if ( s . startsWith ( \"\\\"\" ) && s . endsWith ( \"\\\"\" ) ) return s . substring ( 1 , s . length ( ) - 1 ) ; else return s ; }", "nl": "Remove double quotes from around a string . If there s not both start and ending quotes does nothing ."}}
{"translation": {"code": "public String [ ] getFieldNames ( ) { String [ ] s = new String [ nfields ] ; for ( int i = 0 ; i < nfields ; i ++ ) { s [ i ] = getFieldName ( i ) ; } return s ; }", "nl": "Get a list of all the field names in the dbase file"}}
{"translation": {"code": "LayoutTiled . DataChunkIterator getDataChunkIteratorNoFilter ( Section want , int nChunkDim ) throws IOException { /*\r\n    if (if (debugChunkOrder) ) {\r\n    DataChunkIteratorNoFilter iter = new DataChunkIteratorNoFilter(null, nChunkDim);\r\n    int count = 0;\r\n    int last = -1;\r\n    while (iter.hasNext()) {\r\n      LayoutTiled.DataChunk chunk = iter.next();\r\n      System.out.printf(\"%d : %d%n\", count++, tiling.order(chunk.offset));\r\n      if (tiling.order(chunk.offset) <= last)\r\n        System.out.println(\"HEY\");\r\n      last = tiling.order(chunk.offset);\r\n    }\r\n    }*/ return new DataChunkIteratorNoFilter ( want , nChunkDim ) ; }", "nl": "used by H5tiledLayout"}}
{"translation": {"code": "static public ucar . ma2 . Array readSection ( ParsedSectionSpec cer ) throws IOException , InvalidRangeException { Variable inner = null ; List < Range > totalRanges = new ArrayList <> ( ) ; ParsedSectionSpec current = cer ; while ( current != null ) { totalRanges . addAll ( current . section . getRanges ( ) ) ; inner = current . v ; current = current . child ; } assert inner != null ; Section total = new Section ( totalRanges ) ; Array result = Array . factory ( inner . getDataType ( ) , total . getShape ( ) ) ; // must be a Structure\r Structure outer = ( Structure ) cer . v ; Structure outerSubset = outer . select ( cer . child . v . getShortName ( ) ) ; // allows IOSPs to optimize for  this case\r ArrayStructure outerData = ( ArrayStructure ) outerSubset . read ( cer . section ) ; extractSection ( cer . child , outerData , result . getIndexIterator ( ) ) ; return result ; }", "nl": "section reading for member data"}}
{"translation": {"code": "public void setDim ( int dim , int value ) { if ( value < 0 || value >= shape [ dim ] ) // check index here\r throw new ArrayIndexOutOfBoundsException ( ) ; if ( shape [ dim ] >= 0 ) //!vlen\r current [ dim ] = value ; }", "nl": "set current element at dimension dim to v"}}
{"translation": {"code": "public Index set ( int v0 , int v1 , int v2 ) { setDim ( 0 , v0 ) ; setDim ( 1 , v1 ) ; setDim ( 2 , v2 ) ; return this ; }", "nl": "set current element at dimension 0 1 2 to v0 v1 v2"}}
{"translation": {"code": "public Index set ( int [ ] index ) { if ( index . length != rank ) throw new ArrayIndexOutOfBoundsException ( ) ; if ( rank == 0 ) return this ; int prefixrank = ( hasvlen ? rank : rank - 1 ) ; System . arraycopy ( index , 0 , current , 0 , prefixrank ) ; if ( hasvlen ) current [ prefixrank ] = - 1 ; return this ; }", "nl": "Set the current element s index . General - rank case ."}}
{"translation": {"code": "public int currentElement ( ) { int value = offset ; // NB: dont have to check each index again\r for ( int ii = 0 ; ii < rank ; ii ++ ) { // general rank\r if ( shape [ ii ] < 0 ) break ; //vlen\r value += current [ ii ] * stride [ ii ] ; } return value ; }", "nl": "Get the current element s index into the 1D backing array . VLEN stops processing ."}}
{"translation": {"code": "IndexIterator getIndexIterator ( Array maa ) { if ( fastIterator ) return new IteratorFast ( size , maa ) ; else return new IteratorImpl ( maa ) ; }", "nl": "Get an index iterator for traversing the array in canonical order ."}}
{"translation": {"code": "Index permute ( int [ ] dims ) { if ( dims . length != shape . length ) throw new IllegalArgumentException ( ) ; for ( int dim : dims ) if ( ( dim < 0 ) || ( dim >= rank ) ) throw new IllegalArgumentException ( ) ; boolean isPermuted = false ; Index newIndex = ( Index ) this . clone ( ) ; for ( int i = 0 ; i < dims . length ; i ++ ) { newIndex . stride [ i ] = stride [ dims [ i ] ] ; newIndex . shape [ i ] = shape [ dims [ i ] ] ; //if (name != null) newIndex.name[i] = name[dims[i]];\r if ( i != dims [ i ] ) isPermuted = true ; } newIndex . fastIterator = fastIterator && ! isPermuted ; // useful optimization\r newIndex . precalc ( ) ; // any subclass-specific optimizations\r return newIndex ; }", "nl": "create a new Index based on a permutation of the current indices ; vlen fails ."}}
{"translation": {"code": "Index transpose ( int index1 , int index2 ) { if ( ( index1 < 0 ) || ( index1 >= rank ) ) throw new IllegalArgumentException ( ) ; if ( ( index2 < 0 ) || ( index2 >= rank ) ) throw new IllegalArgumentException ( ) ; Index newIndex = ( Index ) this . clone ( ) ; newIndex . stride [ index1 ] = stride [ index2 ] ; newIndex . stride [ index2 ] = stride [ index1 ] ; newIndex . shape [ index1 ] = shape [ index2 ] ; newIndex . shape [ index2 ] = shape [ index1 ] ; /* if (name != null) {\r\n      newIndex.name[index1] = name[index2];\r\n      newIndex.name[index2] = name[index1];\r\n    } */ newIndex . fastIterator = false ; newIndex . precalc ( ) ; // any subclass-specific optimizations\r return newIndex ; }", "nl": "create a new Index based on current one except transpose two of the indices ."}}
{"translation": {"code": "Index reduce ( int dim ) { if ( ( dim < 0 ) || ( dim >= rank ) ) throw new IllegalArgumentException ( \"illegal reduce dim \" + dim ) ; if ( shape [ dim ] != 1 ) throw new IllegalArgumentException ( \"illegal reduce dim \" + dim + \" : length != 1\" ) ; Index newindex = Index . factory ( rank - 1 ) ; newindex . offset = offset ; int count = 0 ; for ( int ii = 0 ; ii < rank ; ii ++ ) { if ( ii != dim ) { newindex . shape [ count ] = shape [ ii ] ; newindex . stride [ count ] = stride [ ii ] ; //if (name != null) newindex.name[count] = name[ii];\r count ++ ; } } newindex . size = computeSize ( newindex . shape ) ; newindex . fastIterator = fastIterator ; newindex . precalc ( ) ; // any subclass-specific optimizations\r return newindex ; }", "nl": "Create a new Index based on current one by eliminating the specified dimension ;"}}
{"translation": {"code": "Index reduce ( ) { Index c = this ; for ( int ii = 0 ; ii < rank ; ii ++ ) if ( shape [ ii ] == 1 ) { // do this on the first one you find\r Index newc = c . reduce ( ii ) ; return newc . reduce ( ) ; // any more to do?\r } return c ; }", "nl": "Create a new Index based on current one by eliminating any dimensions with length one ."}}
{"translation": {"code": "static public char [ ] convertByteToChar ( byte [ ] byteArray ) { int size = byteArray . length ; char [ ] cbuff = new char [ size ] ; for ( int i = 0 ; i < size ; i ++ ) cbuff [ i ] = ( char ) DataType . unsignedByteToShort ( byteArray [ i ] ) ; // NOTE: not Unicode !\r return cbuff ; } // convert char array to byte array\r static public byte [ ] convertCharToByte ( char [ ] from ) { byte [ ] to = null ; if ( from != null ) { int size = from . length ; to = new byte [ size ] ; for ( int i = 0 ; i < size ; i ++ ) to [ i ] = ( byte ) from [ i ] ; // LOOK wrong, convert back to unsigned byte ???\r } return to ; }", "nl": "convert byte array to char array"}}
{"translation": {"code": "static private long computeStrides ( int [ ] shape , int [ ] stride ) { long product = 1 ; for ( int ii = shape . length - 1 ; ii >= 0 ; ii -- ) { final int thisDim = shape [ ii ] ; if ( thisDim < 0 ) continue ; // ignore vlen\r stride [ ii ] = ( int ) product ; product *= thisDim ; } return product ; }", "nl": "Compute standard strides based on array s shape . Ignore vlen"}}
{"translation": {"code": "static public Object readDataFill ( RandomAccessFile raf , Layout index , DataType dataType , Object fillValue , int byteOrder ) throws java . io . IOException { Object arr = ( fillValue == null ) ? makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType ) : makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType , fillValue ) ; return readData ( raf , index , dataType , arr , byteOrder , true ) ; }", "nl": "Read data subset from RandomAccessFile create primitive array of size Layout . getTotalNelems . Reading is controlled by the Layout object ."}}
{"translation": {"code": "static public Index factory ( int [ ] shape ) { int rank = shape . length ; switch ( rank ) { case 0 : return new Index0D ( ) ; case 1 : return new Index1D ( shape ) ; case 2 : return new Index2D ( shape ) ; case 3 : return new Index3D ( shape ) ; case 4 : return new Index4D ( shape ) ; case 5 : return new Index5D ( shape ) ; case 6 : return new Index6D ( shape ) ; case 7 : return new Index7D ( shape ) ; default : return new Index ( shape ) ; } }", "nl": "Generate a subclass of Index optimized for this array s rank"}}
{"translation": {"code": "public void setSelected ( VariableIF v ) { if ( v == null ) { return ; } // construct chain of variables\r final List < VariableIF > vchain = new ArrayList <> ( ) ; vchain . add ( v ) ; VariableIF vp = v ; while ( vp . isMemberOfStructure ( ) ) { vp = vp . getParentStructure ( ) ; vchain . add ( 0 , vp ) ; // reverse\r } // construct chain of groups\r final List < Group > gchain = new ArrayList <> ( ) ; Group gp = vp . getParentGroup ( ) ; gchain . add ( gp ) ; while ( gp . getParentGroup ( ) != null ) { gp = gp . getParentGroup ( ) ; gchain . add ( 0 , gp ) ; // reverse\r } final List < Object > pathList = new ArrayList <> ( ) ; // start at root, work down through the nested groups, if any\r GroupNode gnode = ( GroupNode ) model . getRoot ( ) ; pathList . add ( gnode ) ; Group parentGroup = gchain . get ( 0 ) ; // always the root group\r for ( int i = 1 ; i < gchain . size ( ) ; i ++ ) { parentGroup = gchain . get ( i ) ; gnode = gnode . findNestedGroup ( parentGroup ) ; assert gnode != null ; pathList . add ( gnode ) ; } vp = vchain . get ( 0 ) ; VariableNode vnode = gnode . findNestedVariable ( vp ) ; if ( vnode == null ) { return ; } // not found\r pathList . add ( vnode ) ; // now work down through the structure members, if any\r for ( int i = 1 ; i < vchain . size ( ) ; i ++ ) { vp = vchain . get ( i ) ; vnode = vnode . findNestedVariable ( vp ) ; if ( vnode == null ) { return ; } // not found\r pathList . add ( vnode ) ; } // convert to TreePath, and select it\r final Object [ ] paths = pathList . toArray ( ) ; final TreePath treePath = new TreePath ( paths ) ; tree . setSelectionPath ( treePath ) ; tree . scrollPathToVisible ( treePath ) ; }", "nl": "Set the currently selected Variable ."}}
{"translation": {"code": "static public Object readDataFill ( PositioningDataInputStream is , Layout index , DataType dataType , Object fillValue ) throws java . io . IOException { Object arr = ( fillValue == null ) ? makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType ) : makePrimitiveArray ( ( int ) index . getTotalNelems ( ) , dataType , fillValue ) ; return readData ( is , index , dataType , arr ) ; }", "nl": "Read data subset from PositioningDataInputStream create primitive array of size Layout . getTotalNelems . Reading is controlled by the Layout object ."}}
{"translation": {"code": "private Array readVlenData ( Variable v , Section section , DataStorage dataStorage ) throws IOException , InvalidRangeException { raf . seek ( dataStorage . filePos ) ; int nelems = readVInt ( raf ) ; Array [ ] result = new Array [ nelems ] ; for ( int elem = 0 ; elem < nelems ; elem ++ ) { int dsize = readVInt ( raf ) ; byte [ ] data = new byte [ dsize ] ; raf . readFully ( data ) ; Array dataArray = Array . factory ( v . getDataType ( ) , ( int [ ] ) null , ByteBuffer . wrap ( data ) ) ; result [ elem ] = dataArray ; } // return Array.makeObjectArray(v.getDataType(), result[0].getClass(), new int[]{nelems}, result);\r return Array . makeVlenArray ( new int [ ] { nelems } , result ) ; //return dataArray.section(section.getRanges());\r }", "nl": "lOOK probably desnt work"}}
{"translation": {"code": "static public Object readDataFill ( LayoutBB layout , DataType dataType , Object fillValue ) throws java . io . IOException { long size = layout . getTotalNelems ( ) ; if ( dataType == DataType . STRUCTURE ) size *= layout . getElemSize ( ) ; Object arr = ( fillValue == null ) ? makePrimitiveArray ( ( int ) size , dataType ) : makePrimitiveArray ( ( int ) size , dataType , fillValue ) ; return readData ( layout , dataType , arr ) ; }", "nl": "Read data subset from ByteBuffer create primitive array of size Layout . getTotalNelems . Reading is controlled by the Layout object ."}}
{"translation": {"code": "static public Object makePrimitiveArray ( int size , DataType dataType ) { Object arr = null ; if ( ( dataType . getPrimitiveClassType ( ) == byte . class ) || ( dataType == DataType . CHAR ) || ( dataType == DataType . OPAQUE ) || ( dataType == DataType . STRUCTURE ) ) { arr = new byte [ size ] ; } else if ( dataType . getPrimitiveClassType ( ) == short . class ) { arr = new short [ size ] ; } else if ( dataType . getPrimitiveClassType ( ) == int . class ) { arr = new int [ size ] ; } else if ( dataType . getPrimitiveClassType ( ) == long . class ) { arr = new long [ size ] ; } else if ( dataType == DataType . FLOAT ) { arr = new float [ size ] ; } else if ( dataType == DataType . DOUBLE ) { arr = new double [ size ] ; } else if ( dataType == DataType . STRING ) { arr = new String [ size ] ; } return arr ; }", "nl": "Create 1D primitive array of the given size and type"}}
{"translation": {"code": "static private ArrayStructure sectionArrayStructure ( ParsedSectionSpec child , ArrayStructure innerData , StructureMembers . Member m ) throws IOException , InvalidRangeException { StructureMembers membersw = new StructureMembers ( m . getStructureMembers ( ) ) ; // no data arrays get propagated\r ArrayStructureW result = new ArrayStructureW ( membersw , child . section . getShape ( ) ) ; int count = 0 ; Section . Iterator iter = child . section . getIterator ( child . v . getShape ( ) ) ; while ( iter . hasNext ( ) ) { int recno = iter . next ( null ) ; StructureData sd = innerData . getStructureData ( recno ) ; result . setStructureData ( sd , count ++ ) ; } return result ; }", "nl": "LOOK could be used in createView ??"}}
{"translation": {"code": "Index section ( List < Range > ranges ) throws InvalidRangeException { // check ranges are valid\r if ( ranges . size ( ) != rank ) throw new InvalidRangeException ( \"Bad ranges [] length\" ) ; for ( int ii = 0 ; ii < rank ; ii ++ ) { Range r = ranges . get ( ii ) ; if ( r == null ) continue ; if ( r == Range . VLEN ) continue ; if ( ( r . first ( ) < 0 ) || ( r . first ( ) >= shape [ ii ] ) ) throw new InvalidRangeException ( \"Bad range starting value at index \" + ii + \" == \" + r . first ( ) ) ; if ( ( r . last ( ) < 0 ) || ( r . last ( ) >= shape [ ii ] ) ) throw new InvalidRangeException ( \"Bad range ending value at index \" + ii + \" == \" + r . last ( ) ) ; } int reducedRank = rank ; for ( Range r : ranges ) { if ( ( r != null ) && ( r . length ( ) == 1 ) ) reducedRank -- ; } Index newindex = Index . factory ( reducedRank ) ; newindex . offset = offset ; // calc shape, size, and index transformations\r // calc strides into original (backing) store\r int newDim = 0 ; for ( int ii = 0 ; ii < rank ; ii ++ ) { Range r = ranges . get ( ii ) ; if ( r == null ) { // null range means use the whole original dimension\r newindex . shape [ newDim ] = shape [ ii ] ; newindex . stride [ newDim ] = stride [ ii ] ; //if (name != null) newindex.name[newDim] = name[ii];\r newDim ++ ; } else if ( r . length ( ) != 1 ) { newindex . shape [ newDim ] = r . length ( ) ; newindex . stride [ newDim ] = stride [ ii ] * r . stride ( ) ; newindex . offset += stride [ ii ] * r . first ( ) ; //if (name != null) newindex.name[newDim] = name[ii];\r newDim ++ ; } else { newindex . offset += stride [ ii ] * r . first ( ) ; // constant due to rank reduction\r } } newindex . size = computeSize ( newindex . shape ) ; newindex . fastIterator = fastIterator && ( newindex . size == size ) ; // if equal, then its not a real subset, so can still use fastIterator\r newindex . precalc ( ) ; // any subclass-specific optimizations\r return newindex ; }", "nl": "create a new Index based on a subsection of this one with rank reduction if dimension length == 1 ."}}
{"translation": {"code": "public DataResult readData ( InputStream is , NetcdfFile ncfile , String location ) throws IOException { byte [ ] b = new byte [ 4 ] ; int bytesRead = NcStream . readFully ( is , b ) ; if ( bytesRead < b . length ) throw new EOFException ( location ) ; if ( NcStream . test ( b , NcStream . MAGIC_DATA ) ) return readData1 ( is , ncfile ) ; if ( NcStream . test ( b , NcStream . MAGIC_DATA2 ) ) return readData2 ( is ) ; throw new IOException ( \"Data transfer corrupted on \" + location ) ; }", "nl": "Read the result of a data request . Only one variable at a time ."}}
{"translation": {"code": "public Attribute deleteGroupAttribute ( Group g , String attName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; if ( g == null ) g = ncfile . getRootGroup ( ) ; Attribute att = g . findAttribute ( attName ) ; if ( null == att ) return null ; g . remove ( att ) ; return att ; }", "nl": "Delete a group Attribute . Must be in define mode ."}}
{"translation": {"code": "public Group addGroup ( Group parent , String name ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; if ( parent == null ) return ncfile . getRootGroup ( ) ; Group result = new Group ( ncfile , parent , name ) ; parent . addGroup ( result ) ; return result ; }", "nl": "Add a Group to the file . Must be in define mode . If pass in null as the parent then the root group is returned and the name is ignored . This is how you get the root group . Note this is different from other uses of parent group ."}}
{"translation": {"code": "static public NetcdfFileWriter createNew ( Version version , String location , Nc4Chunking chunker ) throws IOException { return new NetcdfFileWriter ( version , location , false , chunker ) ; }", "nl": "Create a new Netcdf file with fill mode true ."}}
{"translation": {"code": "public EnumTypedef addTypedef ( Group g , EnumTypedef td ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; if ( ! version . isExtendedModel ( ) ) throw new IllegalArgumentException ( \"Enum type only supported in extended model, this version is=\" + version ) ; g . addEnumeration ( td ) ; return td ; }", "nl": "Add a EnumTypedef to the file . Must be in define mode ."}}
{"translation": {"code": "public Attribute renameGroupAttribute ( Group g , String oldName , String newName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; if ( ! isValidObjectName ( newName ) ) { String newnewName = createValidObjectName ( newName ) ; log . warn ( \"illegal attribute name= \" + newName + \" change to \" + newnewName ) ; newName = newnewName ; } if ( g == null ) g = ncfile . getRootGroup ( ) ; Attribute att = g . findAttribute ( oldName ) ; if ( null == att ) return null ; g . remove ( att ) ; att = new Attribute ( newName , att . getValues ( ) ) ; g . addAttribute ( att ) ; return att ; }", "nl": "Rename a group Attribute . Must be in define mode ."}}
{"translation": {"code": "public NetcdfFile write ( CancelTask cancel ) throws IOException { try { if ( version . isExtendedModel ( ) ) addGroupExtended ( null , fileIn . getRootGroup ( ) ) ; else addGroupClassic ( ) ; if ( cancel != null && cancel . isCancel ( ) ) return null ; // create the file\r writer . create ( ) ; if ( cancel != null && cancel . isCancel ( ) ) return null ; double total = copyVarData ( varList , null , cancel ) ; if ( cancel != null && cancel . isCancel ( ) ) return null ; writer . flush ( ) ; if ( debug ) System . out . println ( \"FileWriter done total bytes = \" + total ) ; } catch ( IOException ioe ) { ioe . printStackTrace ( ) ; writer . abort ( ) ; // clean up\r throw ioe ; } return writer . getNetcdfFile ( ) ; }", "nl": "Write the input file to the output file ."}}
{"translation": {"code": "public static void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlags ) { debug = debugFlags . isSet ( \"ncfileWriter2/debug\" ) ; debugWrite = debugFlags . isSet ( \"ncfileWriter2/debugWrite\" ) ; debugChunk = debugFlags . isSet ( \"ncfileWriter2/debugChunk\" ) ; }", "nl": "Set debugging flags"}}
{"translation": {"code": "public Structure addRecordStructure ( ) { if ( version != Version . netcdf3 ) return null ; boolean ok = ( Boolean ) ncfile . sendIospMessage ( NetcdfFile . IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; if ( ! ok ) throw new IllegalStateException ( \"can't add record variable\" ) ; return ( Structure ) ncfile . findVariable ( \"record\" ) ; }", "nl": "For netcdf3 only take all unlimited variables and make them into a structure ."}}
{"translation": {"code": "public Variable addVariable ( Variable oldVar ) { List < Dimension > newDims = getNewDimensions ( oldVar ) ; Variable newVar ; if ( ( oldVar . getDataType ( ) . equals ( DataType . STRING ) ) && ( ! version . isExtendedModel ( ) ) ) { newVar = writer . addStringVariable ( null , oldVar , newDims ) ; } else { newVar = writer . addVariable ( null , oldVar . getShortName ( ) , oldVar . getDataType ( ) , newDims ) ; } varMap . put ( oldVar , newVar ) ; varList . add ( oldVar ) ; for ( Attribute orgAtt : oldVar . getAttributes ( ) ) writer . addVariableAttribute ( newVar , convertAttribute ( orgAtt ) ) ; return newVar ; }", "nl": "Specify which variable will get written"}}
{"translation": {"code": "static public byte [ ] convertCharToByteUTF ( char [ ] from ) { Charset c = CDM . utf8Charset ; ByteBuffer output = c . encode ( CharBuffer . wrap ( from ) ) ; return output . array ( ) ; }", "nl": "convert char array to byte array assuming UTF - 8 encoding"}}
{"translation": {"code": "static public char [ ] convertByteToCharUTF ( byte [ ] byteArray ) { Charset c = CDM . utf8Charset ; CharBuffer output = c . decode ( ByteBuffer . wrap ( byteArray ) ) ; return output . array ( ) ; }", "nl": "convert byte array to char array assuming UTF - 8 encoding"}}
{"translation": {"code": "@ Override public boolean isGlobalLon ( ) { if ( ! isLatLon ) return false ; if ( ! ( horizXaxis instanceof CoordinateAxis1D ) ) return false ; CoordinateAxis1D lon = ( CoordinateAxis1D ) horizXaxis ; double first = lon . getCoordEdge ( 0 ) ; double last = lon . getCoordEdge ( ( int ) lon . getSize ( ) ) ; double min = Math . min ( first , last ) ; double max = Math . max ( first , last ) ; return ( max - min ) >= 360 ; }", "nl": "Is this a global coverage over longitude ?"}}
{"translation": {"code": "@ Override public void close ( ) throws IOException { if ( closed ) return ; /* Allow multiple close calls */ closed = true ; try { consume ( ) ; } finally { super . close ( ) ; } if ( method != null ) method . close ( ) ; }", "nl": "Closes this input stream and releases any system resources associated with the stream ; closes the method also ."}}
{"translation": {"code": "public static void main ( String [ ] args ) { ProjectionManager d = new ProjectionManager ( null , null ) ; d . setVisible ( ) ; }", "nl": "testing 1 - 2 - 3"}}
{"translation": {"code": "public void setProjection ( ProjectionManager . ProjectionClass pc ) { // clear out any fields\r removeAll ( ) ; for ( ProjectionManager . ProjectionParam pp : pc . paramList ) { // construct the label\r JPanel thisPanel = new JPanel ( ) ; thisPanel . add ( new JLabel ( pp . name + \": \" ) ) ; // text input field\r JTextField tf = new JTextField ( ) ; pp . setTextField ( tf ) ; tf . setColumns ( 12 ) ; thisPanel . add ( tf ) ; add ( thisPanel ) ; } revalidate ( ) ; }", "nl": "construct input fields based on Projection Class"}}
{"translation": {"code": "public Object getData ( int i ) { switch ( type ) { case TYPE_CHAR : return character [ i ] ; case TYPE_NUMERIC : return numeric [ i ] ; case TYPE_BOOLEAN : return logical [ i ] ; } return null ; }", "nl": "Method to retrieve data for this field"}}
{"translation": {"code": "int readRowN ( DataInputStream ds , int n ) { if ( n > nrec ) return - 1 ; /* the assumption here is that the DataInputStream (ds)\r\n    * is already pointing at the right spot!\r\n    */ try { ds . readFully ( field , 0 , desc . FieldLength ) ; } catch ( java . io . IOException e ) { return - 1 ; } switch ( desc . Type ) { case ' ' : case ' ' : character [ n ] = new String ( field , CDM . utf8Charset ) ; break ; case ' ' : numeric [ n ] = Double . valueOf ( new String ( field , CDM . utf8Charset ) ) ; break ; case ' ' : /* binary floating point */ if ( desc . FieldLength == 4 ) { numeric [ n ] = ( double ) Swap . swapFloat ( field , 0 ) ; } else { numeric [ n ] = Swap . swapDouble ( field , 0 ) ; } break ; case ' ' : switch ( field [ 0 ] ) { case ' ' : case ' ' : case ' ' : case ' ' : logical [ n ] = true ; break ; default : logical [ n ] = false ; break ; } default : return - 1 ; } return 0 ; }", "nl": "Method to read an entry from the data stream . The stream is assumed to be in the right spot for reading . This method should be called from something controlling the reading of the entire file ."}}
{"translation": {"code": "public String [ ] getStringsByName ( String Name ) { DbaseData d ; if ( ( d = getField ( Name ) ) == null ) return null ; if ( d . getType ( ) != DbaseData . TYPE_CHAR ) return null ; return d . getStrings ( ) ; }", "nl": "Extract the string array of data for a field by Name ."}}
{"translation": {"code": "public boolean [ ] getBooleansByName ( String Name ) { DbaseData d ; if ( ( d = getField ( Name ) ) == null ) return null ; if ( d . getType ( ) != DbaseData . TYPE_BOOLEAN ) return null ; return d . getBooleans ( ) ; }", "nl": "Extract the boolean array of data for a field by Name ."}}
{"translation": {"code": "public List < EsriFeature > getFeatures ( Rectangle2D bBox ) { if ( bBox == null ) return features ; List < EsriFeature > list = new ArrayList <> ( ) ; for ( EsriFeature gf : features ) { if ( gf . getBounds2D ( ) . intersects ( bBox ) ) list . add ( gf ) ; } return list ; }", "nl": "Get a List of all the features in the shapefile that intersect the specified bounding box . This requires testing every feature in the List created at construction so it s faster to just give a bounding box o the constructor if you will only do this once ."}}
{"translation": {"code": "private void discretize ( double [ ] d , int n ) { if ( coarseness == 0.0 ) return ; for ( int i = 0 ; i < n ; i ++ ) { d [ i ] = ( Math . rint ( resolution * d [ i ] ) / resolution ) ; } }", "nl": "Discretize elements of array to a lower resolution . For example if resolution = 100 . the value 3 . 14159265358979 will be changed to 3 . 14 ."}}
{"translation": {"code": "public static CalendarDate of ( Calendar cal , long msecs ) { Chronology base = Calendar . getChronology ( cal ) ; DateTime dt = new DateTime ( msecs , base ) ; return new CalendarDate ( cal , dt ) ; }", "nl": "Create CalendarDate from msecs since epoch Uses the given Calendar ."}}
{"translation": {"code": "DataDDS readDataDDSfromServer ( String CE ) throws IOException , opendap . dap . DAP2Exception { if ( debugServerCall ) System . out . println ( \"DODSNetcdfFile.readDataDDSfromServer = <\" + CE + \">\" ) ; long start = 0 ; if ( debugTime ) start = System . currentTimeMillis ( ) ; if ( ! CE . startsWith ( \"?\" ) ) CE = \"?\" + CE ; DataDDS data ; synchronized ( this ) { data = dodsConnection . getData ( CE , null ) ; } if ( debugTime ) System . out . println ( \"DODSNetcdfFile.readDataDDSfromServer took = \" + ( System . currentTimeMillis ( ) - start ) / 1000.0 ) ; if ( debugDataResult ) { System . out . println ( \" dataDDS return:\" ) ; data . print ( System . out ) ; } return data ; }", "nl": "This does the actual connection to the opendap server and reading of the data . All data calls go through here so we can add debugging ."}}
{"translation": {"code": "List < Dimension > constructDimensions ( Group group , opendap . dap . DArray dodsArray ) { if ( group == null ) group = rootGroup ; List < Dimension > dims = new ArrayList < Dimension > ( ) ; Enumeration enumerate = dodsArray . getDimensions ( ) ; while ( enumerate . hasMoreElements ( ) ) { opendap . dap . DArrayDimension dad = ( opendap . dap . DArrayDimension ) enumerate . nextElement ( ) ; String name = dad . getEncodedName ( ) ; if ( name != null ) name = StringUtil2 . unescape ( name ) ; Dimension myd ; if ( name == null ) { // if no name, make an anonymous dimension myd = new Dimension ( null , dad . getSize ( ) , false ) ; } else { // see if shared if ( RC . getUseGroups ( ) ) { if ( name . indexOf ( ' ' ) >= 0 ) { // place dimension in proper group group = group . makeRelativeGroup ( this , name , true ) ; // change our name name = name . substring ( name . lastIndexOf ( ' ' ) + 1 ) ; } } myd = group . findDimension ( name ) ; if ( myd == null ) { // add as shared myd = new Dimension ( name , dad . getSize ( ) ) ; group . addDimension ( myd ) ; } else if ( myd . getLength ( ) != dad . getSize ( ) ) { // make a non-shared dimension myd = new Dimension ( name , dad . getSize ( ) , false ) ; } // else use existing, shared dimension } dims . add ( myd ) ; // add it to the list } return dims ; }", "nl": "construct list of dimensions to use"}}
{"translation": {"code": "Dimension getNetcdfStrlenDim ( DODSVariable v ) { AttributeTable table = das . getAttributeTableN ( v . getFullName ( ) ) ; // LOOK this probably doesnt work for nested variables if ( table == null ) return null ; opendap . dap . Attribute dodsAtt = table . getAttribute ( \"DODS\" ) ; if ( dodsAtt == null ) return null ; AttributeTable dodsTable = dodsAtt . getContainerN ( ) ; if ( dodsTable == null ) return null ; opendap . dap . Attribute att = dodsTable . getAttribute ( \"strlen\" ) ; if ( att == null ) return null ; String strlen = att . getValueAtN ( 0 ) ; opendap . dap . Attribute att2 = dodsTable . getAttribute ( \"dimName\" ) ; String dimName = ( att2 == null ) ? null : att2 . getValueAtN ( 0 ) ; if ( debugCharArray ) System . out . println ( v . getFullName ( ) + \" has strlen= \" + strlen + \" dimName= \" + dimName ) ; int dimLength ; try { dimLength = Integer . parseInt ( strlen ) ; } catch ( NumberFormatException e ) { logger . warn ( \"DODSNetcdfFile \" + location + \" var = \" + v . getFullName ( ) + \" error on strlen attribute = \" + strlen ) ; return null ; } if ( dimLength <= 0 ) return null ; // LOOK what about unlimited ?? return new Dimension ( dimName , dimLength , dimName != null ) ; }", "nl": "Checks to see if this is netcdf char array ."}}
{"translation": {"code": "NamePieces parseName ( String name ) { NamePieces pieces = new NamePieces ( ) ; int dotpos = name . lastIndexOf ( ' ' ) ; int slashpos = name . lastIndexOf ( ' ' ) ; if ( slashpos < 0 && dotpos < 0 ) { pieces . name = name ; } else if ( slashpos >= 0 && dotpos < 0 ) { pieces . prefix = name . substring ( 0 , slashpos ) ; pieces . name = name . substring ( slashpos + 1 , name . length ( ) ) ; } else if ( slashpos < 0 && dotpos >= 0 ) { pieces . var = name . substring ( 0 , dotpos ) ; pieces . name = name . substring ( dotpos + 1 , name . length ( ) ) ; } else { //slashpos >= 0 && dotpos >= 0) if ( slashpos > dotpos ) { pieces . prefix = name . substring ( 0 , slashpos ) ; pieces . name = name . substring ( slashpos + 1 , name . length ( ) ) ; } else { //slashpos < dotpos) pieces . prefix = name . substring ( 0 , slashpos ) ; pieces . var = name . substring ( slashpos + 1 , dotpos ) ; pieces . name = name . substring ( dotpos + 1 , name . length ( ) ) ; } } // fixup if ( pieces . prefix != null && pieces . prefix . length ( ) == 0 ) pieces . prefix = null ; if ( pieces . var != null && pieces . var . length ( ) == 0 ) pieces . var = null ; if ( pieces . name . length ( ) == 0 ) pieces . name = null ; return pieces ; }", "nl": "Utility to decompose a name"}}
{"translation": {"code": "public static int getVersion ( String hasConvName ) { int result = extractVersion ( hasConvName ) ; if ( result >= 0 ) return result ; List < String > names = breakupConventionNames ( hasConvName ) ; for ( String name : names ) { result = extractVersion ( name ) ; if ( result >= 0 ) return result ; } return - 1 ; }", "nl": "Get which CF version this is ie CF - 1 . x"}}
{"translation": {"code": "public String getScaledSizeString ( ) { if ( scaledPicture != null ) return Integer . toString ( scaledPicture . getWidth ( ) ) + \" x \" + Integer . toString ( scaledPicture . getHeight ( ) ) ; else return \"0 x 0\" ; }", "nl": "return the size of the scaled image as a neatly formatted text or Zero if there is none"}}
{"translation": {"code": "public void createScaledPictureInThread ( int priority ) { setStatus ( SCALING , \"Scaling picture.\" ) ; ScaleThread t = new ScaleThread ( this ) ; t . setPriority ( priority ) ; t . start ( ) ; }", "nl": "method that creates the scaled image in the background in it s own thread ."}}
{"translation": {"code": "public void sourceLoadProgressNotification ( int statusCode , int percentage ) { Enumeration e = scalablePictureStatusListeners . elements ( ) ; while ( e . hasMoreElements ( ) ) { ( ( ScalablePictureListener ) e . nextElement ( ) ) . sourceLoadProgressNotification ( statusCode , percentage ) ; } }", "nl": "pass on the update on the loading Progress to the listening objects"}}
{"translation": {"code": "public Dimension getScaledSize ( ) { if ( scaledPicture != null ) return new Dimension ( scaledPicture . getWidth ( ) , scaledPicture . getHeight ( ) ) ; else return new Dimension ( 0 , 0 ) ; }", "nl": "return the size of the scaled image or Zero if there is none"}}
{"translation": {"code": "public void stopLoadingExcept ( URL url ) { if ( sourcePicture != null ) { boolean isCurrentlyLoading = sourcePicture . stopLoadingExcept ( url ) ; if ( ! isCurrentlyLoading ) { // sourcePicture.removeListener( this );\r } PictureCache . stopBackgroundLoadingExcept ( url ) ; } }", "nl": "stops all picture loading except if the Url we desire is being loaded"}}
{"translation": {"code": "public void loadPictureImd ( URL imageUrl , double rotation ) { Tools . log ( \"loadPictureImd invoked with URL: \" + imageUrl . toString ( ) ) ; if ( sourcePicture != null ) sourcePicture . removeListener ( this ) ; sourcePicture = new SourcePicture ( ) ; sourcePicture . addListener ( this ) ; setStatus ( LOADING , \"Loading: \" + imageUrl . toString ( ) ) ; scaleAfterLoad = true ; sourcePicture . loadPicture ( imageUrl , rotation ) ; }", "nl": "Synchroneous method to load the image . It should only be called by something which is a thread itself such as the HtmlDistillerThread . Since this intended for large batch operations this bypasses the cache ."}}
{"translation": {"code": "public void show ( ) { setState ( Frame . NORMAL ) ; // deiconify if needed\r super . toFront ( ) ; // need to put on event thread\r SwingUtilities . invokeLater ( new Runnable ( ) { public void run ( ) { IndependentWindow . super . show ( ) ; } } ) ; }", "nl": "show the window ."}}
{"translation": {"code": "public void showIfNotIconified ( ) { if ( getState ( ) == Frame . ICONIFIED ) return ; // need to put on event thread\r SwingUtilities . invokeLater ( new Runnable ( ) { public void run ( ) { IndependentWindow . super . show ( ) ; } } ) ; }", "nl": "show if not iconified"}}
{"translation": {"code": "public void sourceStatusChange ( int statusCode , String statusMessage , SourcePicture sp ) { //Tools.log(\"ScalablePicture.sourceStatusChange: status received from SourceImage: \" + statusMessage);\r switch ( statusCode ) { case SourcePicture . UNINITIALISED : Tools . log ( \"ScalablePicture.sourceStatusChange: pictureStatus was: UNINITIALISED message: \" + statusMessage ) ; setStatus ( UNINITIALISED , statusMessage ) ; break ; case SourcePicture . ERROR : Tools . log ( \"ScalablePicture.sourceStatusChange: pictureStatus was: ERROR message: \" + statusMessage ) ; setStatus ( ERROR , statusMessage ) ; sourcePicture . removeListener ( this ) ; break ; case SourcePicture . LOADING : Tools . log ( \"ScalablePicture.sourceStatusChange: pictureStatus was: LOADING message: \" + statusMessage ) ; setStatus ( LOADING , statusMessage ) ; break ; case SourcePicture . ROTATING : Tools . log ( \"ScalablePicture.sourceStatusChange: pictureStatus was: ROTATING message: \" + statusMessage ) ; setStatus ( LOADING , statusMessage ) ; break ; case SourcePicture . READY : Tools . log ( \"ScalablePicture.sourceStatusChange: pictureStatus was: READY message: \" + statusMessage ) ; setStatus ( LOADED , statusMessage ) ; sourcePicture . removeListener ( this ) ; if ( scaleAfterLoad ) { createScaledPictureInThread ( Thread . MAX_PRIORITY ) ; scaleAfterLoad = false ; } break ; default : Tools . log ( \"ScalablePicture.sourceStatusChange: Don't recognize this status: \" + statusMessage ) ; break ; } }", "nl": "method that is invoked by the SourcePictureListener interface . Usually this will be called by the SourcePicture telling the ScalablePicture that it has completed loading . The ScalablePicture should then change it s own status and tell the ScalableListeners what s up ."}}
{"translation": {"code": "public File getFile ( String fileLocation ) { if ( ! alwaysUseCache ) { File f = new File ( fileLocation ) ; if ( f . exists ( ) ) return f ; if ( canWrite ( f ) ) return f ; } if ( neverUseCache ) { throw new IllegalStateException ( \"neverUseCache=true, but file does not exist and directory is not writeable =\" + fileLocation ) ; } File f = new File ( makeCachePath ( fileLocation ) ) ; if ( cachePathPolicy == CachePathPolicy . NestedDirectory ) { File dir = f . getParentFile ( ) ; if ( ! dir . exists ( ) && ! dir . mkdirs ( ) ) cacheLog . warn ( \"Cant create directories for file \" + dir . getPath ( ) ) ; } return f ; }", "nl": "Get the named File . If exists or isWritable return it . Otherwise get corresponding file in the cache directory ."}}
{"translation": {"code": "public Group makeRelativeGroup ( NetcdfFile ncf , String path , boolean ignorelast ) { path = path . trim ( ) ; path = path . replace ( \"//\" , \"/\" ) ; boolean isabsolute = ( path . charAt ( 0 ) == ' ' ) ; if ( isabsolute ) path = path . substring ( 1 ) ; // iteratively create path String pieces [ ] = path . split ( \"/\" ) ; if ( ignorelast ) pieces [ pieces . length - 1 ] = null ; Group current = ( isabsolute ? ncfile . getRootGroup ( ) : this ) ; for ( String name : pieces ) { if ( name == null ) continue ; String clearname = NetcdfFile . makeNameUnescaped ( name ) ; //?? Group next = current . findGroup ( clearname ) ; if ( next == null ) { next = new Group ( ncf , current , clearname ) ; current . addGroup ( next ) ; } current = next ; } return current ; }", "nl": "Create groups to ensure path is defined"}}
{"translation": {"code": "public boolean removeDimension ( String dimName ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; for ( int i = 0 ; i < dimensions . size ( ) ; i ++ ) { Dimension d = dimensions . get ( i ) ; if ( dimName . equals ( d . getShortName ( ) ) ) { dimensions . remove ( d ) ; return true ; } } return false ; }", "nl": "remove a Dimension using its name in this group only"}}
{"translation": {"code": "boolean isChildOf ( H5Group that ) { if ( parent == null ) return false ; if ( parent == that ) return true ; return parent . isChildOf ( that ) ; }", "nl": "is this a child of that ?"}}
{"translation": {"code": "public void setCachedData ( Array cacheData , boolean isMetadata ) { if ( ( cacheData != null ) && ( cacheData . getElementType ( ) != getDataType ( ) . getPrimitiveClassType ( ) ) ) throw new IllegalArgumentException ( \"setCachedData type=\" + cacheData . getElementType ( ) + \" incompatible with variable type=\" + getDataType ( ) ) ; this . cache . data = cacheData ; this . isMetadata = isMetadata ; this . cache . cachingSet = true ; this . cache . isCaching = true ; }", "nl": "Set the data cache"}}
{"translation": {"code": "public static MessageType getType ( String name ) { if ( name == null ) return null ; return hash . get ( name ) ; }", "nl": "Find the MessageType that matches this name ."}}
{"translation": {"code": "public List < Dimension > getDimensionsAll ( ) { List < Dimension > dimsAll = new ArrayList <> ( ) ; addDimensionsAll ( dimsAll , this ) ; return dimsAll ; }", "nl": "Get list of Dimensions including parents if any ."}}
{"translation": {"code": "public void addVariable ( Variable v ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( v == null ) return ; if ( findVariable ( v . getShortName ( ) ) != null ) { //Variable other = findVariable(v.getShortName()); // debug throw new IllegalArgumentException ( \"Variable name (\" + v . getShortName ( ) + \") must be unique within Group \" + getShortName ( ) ) ; } variables . add ( v ) ; v . setParentGroup ( this ) ; // variable can only be in one group }", "nl": "Add a Variable"}}
{"translation": {"code": "public CoordinateAxis1D section ( Range r ) throws InvalidRangeException { Section section = new Section ( ) . appendRange ( r ) ; CoordinateAxis1D result = ( CoordinateAxis1D ) section ( section ) ; int len = r . length ( ) ; // deal with the midpoints, bounds if ( isNumeric ( ) ) { double [ ] new_mids = new double [ len ] ; for ( int idx = 0 ; idx < len ; idx ++ ) { int old_idx = r . element ( idx ) ; new_mids [ idx ] = coords [ old_idx ] ; } result . coords = new_mids ; if ( isInterval ) { double [ ] new_bound1 = new double [ len ] ; double [ ] new_bound2 = new double [ len ] ; double [ ] new_edge = new double [ len + 1 ] ; for ( int idx = 0 ; idx < len ; idx ++ ) { int old_idx = r . element ( idx ) ; new_bound1 [ idx ] = bound1 [ old_idx ] ; new_bound2 [ idx ] = bound2 [ old_idx ] ; new_edge [ idx ] = bound1 [ old_idx ] ; new_edge [ idx + 1 ] = bound2 [ old_idx ] ; // all but last are overwritten } result . bound1 = new_bound1 ; result . bound2 = new_bound2 ; result . edge = new_edge ; } else { double [ ] new_edge = new double [ len + 1 ] ; for ( int idx = 0 ; idx < len ; idx ++ ) { int old_idx = r . element ( idx ) ; new_edge [ idx ] = edge [ old_idx ] ; new_edge [ idx + 1 ] = edge [ old_idx + 1 ] ; // all but last are overwritten } result . edge = new_edge ; } } if ( names != null ) { String [ ] new_names = new String [ len ] ; for ( int idx = 0 ; idx < len ; idx ++ ) { int old_idx = r . element ( idx ) ; new_names [ idx ] = names [ old_idx ] ; } result . names = new_names ; } result . wasCalcRegular = false ; result . calcIsRegular ( ) ; return result ; }", "nl": "Create a new CoordinateAxis1D as a section of this CoordinateAxis1D ."}}
{"translation": {"code": "public void addEnumeration ( EnumTypedef e ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( e == null ) return ; e . setParentGroup ( this ) ; enumTypedefs . add ( e ) ; }", "nl": "Add an Enumeration"}}
{"translation": {"code": "protected Array _read ( Section section ) throws IOException , InvalidRangeException { // check if its really a full read if ( ( null == section ) || section . computeSize ( ) == getSize ( ) ) return _read ( ) ; // full read was cached if ( isCaching ( ) ) { if ( cache . data == null ) { setCachedData ( _read ( ) ) ; // read and cache entire array if ( debugCaching ) System . out . println ( \"cache \" + getFullName ( ) ) ; } if ( debugCaching ) System . out . println ( \"got data from cache \" + getFullName ( ) ) ; return cache . data . sectionNoReduce ( section . getRanges ( ) ) . copy ( ) ; // subset it, return copy } return proxyReader . reallyRead ( this , section , null ) ; }", "nl": "assume filled validated Section"}}
{"translation": {"code": "public void addGroup ( Group g ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( findGroup ( g . getShortName ( ) ) != null ) throw new IllegalArgumentException ( \"Group name (\" + g . getShortName ( ) + \") must be unique within Group \" + getShortName ( ) ) ; groups . add ( g ) ; g . setParentGroup ( this ) ; // groups are a tree - only one parent }", "nl": "Add a nested Group"}}
{"translation": {"code": "public void setParentGroup ( Group parent ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; super . setParentGroup ( parent == null ? ncfile . getRootGroup ( ) : parent ) ; }", "nl": "Set the Group s parent Group"}}
{"translation": {"code": "public boolean isParent ( Group other ) { while ( ( other != this ) && ( other . getParentGroup ( ) != null ) ) other = other . getParentGroup ( ) ; return ( other == this ) ; }", "nl": "Is this a parent of the other Group?"}}
{"translation": {"code": "public String writeCDL ( boolean useFullName , boolean strict ) { Formatter buf = new Formatter ( ) ; writeCDL ( buf , new Indent ( 2 ) , useFullName , strict ) ; return buf . toString ( ) ; }", "nl": "CDL representation of a Variable ."}}
{"translation": {"code": "public Section getShapeAsSection ( ) { if ( shapeAsSection == null ) { try { List < Range > list = new ArrayList <> ( ) ; for ( Dimension d : dimensions ) { int len = d . getLength ( ) ; if ( len > 0 ) list . add ( new Range ( d . getShortName ( ) , 0 , len - 1 ) ) ; else if ( len == 0 ) list . add ( Range . EMPTY ) ; // LOOK empty not named else { assert d . isVariableLength ( ) ; list . add ( Range . VLEN ) ; // LOOK vlen not named } } shapeAsSection = new Section ( list ) . makeImmutable ( ) ; } catch ( InvalidRangeException e ) { log . error ( \"Bad shape in variable \" + getFullName ( ) , e ) ; throw new IllegalStateException ( e . getMessage ( ) ) ; } } return shapeAsSection ; }", "nl": "Get shape as a Section object ."}}
{"translation": {"code": "public void setDataType ( DataType dataType ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; this . dataType = dataType ; this . elementSize = getDataType ( ) . getSize ( ) ; /* why is this needed ??\n    EnumTypedef etd = getEnumTypedef();\n    if (etd != null) {\n      DataType etdtype = etd.getBaseType();\n      if (dataType != etdtype)\n        log.error(\"Variable.setDataType: enum basetype mismatch: {} != {}\", etdtype, dataType);\n\n      /* DataType basetype = null;\n      if (dataType == DataType.ENUM1) basetype = DataType.BYTE;\n      else if (dataType == DataType.ENUM2) basetype = DataType.SHORT;\n      else if (dataType == DataType.ENUM4) basetype = DataType.INT;\n      else basetype = etdtype;\n\n      if (etdtype != null && dataType != etdtype)\n      else\n        etd.setBaseType(basetype);\n    }  */ }", "nl": "Set the data type"}}
{"translation": {"code": "public Variable slice ( int dim , int value ) throws InvalidRangeException { if ( ( dim < 0 ) || ( dim >= shape . length ) ) throw new InvalidRangeException ( \"Slice dim invalid= \" + dim ) ; // ok to make slice of record dimension with length 0 boolean recordSliceOk = false ; if ( ( dim == 0 ) && ( value == 0 ) ) { Dimension d = getDimension ( 0 ) ; recordSliceOk = d . isUnlimited ( ) ; } // otherwise check slice in range if ( ! recordSliceOk ) { if ( ( value < 0 ) || ( value >= shape [ dim ] ) ) throw new InvalidRangeException ( \"Slice value invalid= \" + value + \" for dimension \" + dim ) ; } // create a copy of this variable with a proxy reader Variable sliceV = copy ( ) ; // subclasses must override Section slice = new Section ( getShapeAsSection ( ) ) ; slice . replaceRange ( dim , new Range ( value , value ) ) . makeImmutable ( ) ; sliceV . setProxyReader ( new SliceReader ( this , dim , slice ) ) ; sliceV . createNewCache ( ) ; // dont share the cache sliceV . setCaching ( false ) ; // dont cache // remove that dimension - reduce rank sliceV . dimensions . remove ( dim ) ; sliceV . resetShape ( ) ; return sliceV ; }", "nl": "Create a new Variable that is a logical slice of this Variable by fixing the specified dimension at the specified index value . This reduces rank by 1 . No data is read until a read method is called on it ."}}
{"translation": {"code": "public Group commonParent ( Group other ) { if ( isParent ( other ) ) return this ; if ( other . isParent ( this ) ) return other ; while ( ! other . isParent ( this ) ) other = other . getParentGroup ( ) ; return other ; }", "nl": "Get the common parent of this and the other group . Cant fail since the root group is always a parent of any 2 groups ."}}
{"translation": {"code": "public void setDimensions ( List < Dimension > dims ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; this . dimensions = ( dims == null ) ? new ArrayList <> ( ) : new ArrayList <> ( dims ) ; resetShape ( ) ; }", "nl": "Set the shape with a list of Dimensions . The Dimensions may be shared or not . Dimensions are in order slowest varying first . Send a null for a scalar . Technically you can use Dimensions from any group ; pragmatically you should only use Dimensions contained in the Variable s parent groups ."}}
{"translation": {"code": "public Dimension getDimension ( int i ) { if ( ( i < 0 ) || ( i >= getRank ( ) ) ) return null ; return dimensions . get ( i ) ; }", "nl": "Get the ith dimension ."}}
{"translation": {"code": "public void addDimension ( Dimension dim ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( ! dim . isShared ( ) ) { throw new IllegalArgumentException ( \"Dimensions added to a group must be shared.\" ) ; } if ( findDimensionLocal ( dim . getShortName ( ) ) != null ) throw new IllegalArgumentException ( \"Dimension name (\" + dim . getShortName ( ) + \") must be unique within Group \" + getShortName ( ) ) ; dimensions . add ( dim ) ; dim . setGroup ( this ) ; }", "nl": "Adds the specified shared dimension to this group ."}}
{"translation": {"code": "public int findDimensionIndex ( String name ) { for ( int i = 0 ; i < dimensions . size ( ) ; i ++ ) { Dimension d = dimensions . get ( i ) ; if ( name . equals ( d . getShortName ( ) ) ) return i ; } return - 1 ; }", "nl": "Find the index of the named Dimension in this Variable ."}}
{"translation": {"code": "public void resetShape ( ) { // if (immutable) throw new IllegalStateException(\"Cant modify\");  LOOK allow this for unlimited dimension updating this . shape = new int [ dimensions . size ( ) ] ; for ( int i = 0 ; i < dimensions . size ( ) ; i ++ ) { Dimension dim = dimensions . get ( i ) ; shape [ i ] = dim . getLength ( ) ; //shape[i] = Math.max(dim.getLength(), 0); // LOOK // if (dim.isUnlimited() && (i != 0)) // LOOK only true for Netcdf-3 //   throw new IllegalArgumentException(\"Unlimited dimension must be outermost\"); if ( dim . isVariableLength ( ) ) { //if (dimensions.size() != 1) //  throw new IllegalArgumentException(\"Unknown dimension can only be used in 1 dim array\"); //else isVariableLength = true ; } } this . shapeAsSection = null ; // recalc next time its asked for }", "nl": "Use when dimensions have changed to recalculate the shape ."}}
{"translation": {"code": "public String getUnitsString ( ) { String units = null ; Attribute att = findAttribute ( CDM . UNITS ) ; if ( att == null ) att = findAttributeIgnoreCase ( CDM . UNITS ) ; if ( ( att != null ) && att . isString ( ) ) { units = att . getStringValue ( ) ; if ( units != null ) units = units . trim ( ) ; } return units ; }", "nl": "Get the Unit String for the Variable . Looks for the CDM . UNITS attribute value"}}
{"translation": {"code": "public void setDimensions ( String dimString ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; try { setDimensions ( Dimension . makeDimensionsList ( getParentGroup ( ) , dimString ) ) ; //this.dimensions = Dimension.makeDimensionsList(getParentGroup(), dimString); resetShape ( ) ; } catch ( IllegalStateException e ) { throw new IllegalArgumentException ( \"Variable \" + getFullName ( ) + \" setDimensions = '\" + dimString + \"' FAILED: \" + e . getMessage ( ) + \" file = \" + getDatasetLocation ( ) ) ; } }", "nl": "Set the dimensions using the dimensions names . The dimension is searched for recursively in the parent groups ."}}
{"translation": {"code": "public void setEnumTypedef ( EnumTypedef enumTypedef ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( ! dataType . isEnum ( ) ) throw new UnsupportedOperationException ( \"Can only call Variable.setEnumTypedef() on enum types\" ) ; this . enumTypedef = enumTypedef ; }", "nl": "Public by accident ."}}
{"translation": {"code": "public Array read ( List < Range > ranges ) throws IOException , InvalidRangeException { if ( null == ranges ) return _read ( ) ; return read ( new Section ( ranges ) ) ; }", "nl": "Read a section of the data for this Variable from the netcdf file and return a memory resident Array ."}}
{"translation": {"code": "public void resetDimensions ( ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; ArrayList < Dimension > newDimensions = new ArrayList <> ( ) ; for ( Dimension dim : dimensions ) { if ( dim . isShared ( ) ) { Dimension newD = getParentGroup ( ) . findDimension ( dim . getShortName ( ) ) ; if ( newD == null ) throw new IllegalArgumentException ( \"Variable \" + getFullName ( ) + \" resetDimensions  FAILED, dim doesnt exist in parent group=\" + dim ) ; newDimensions . add ( newD ) ; } else { newDimensions . add ( dim ) ; } } this . dimensions = newDimensions ; resetShape ( ) ; }", "nl": "Reset the dimension array . Anonymous dimensions are left alone . Shared dimensions are searched for recursively in the parent groups ."}}
{"translation": {"code": "public void setDimension ( int idx , Dimension dim ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; dimensions . set ( idx , dim ) ; resetShape ( ) ; }", "nl": "Replace a dimension with an equivalent one ."}}
{"translation": {"code": "public String readScalarString ( ) throws IOException { Array data = getScalarData ( ) ; if ( dataType == DataType . STRING ) return ( String ) data . getObject ( Index . scalarIndexImmutable ) ; else if ( dataType == DataType . CHAR ) { ArrayChar dataC = ( ArrayChar ) data ; return dataC . getString ( ) ; } else throw new IllegalArgumentException ( \"readScalarString not STRING or CHAR \" + getFullName ( ) ) ; }", "nl": "Get the value as a String for a scalar Variable . May also be one - dimensional of length 1 . May also be one - dimensional of type CHAR which wil be turned into a scalar String ."}}
{"translation": {"code": "protected Array _read ( ) throws IOException { // caching overrides the proxyReader // check if already cached if ( cache . data != null ) { if ( debugCaching ) System . out . println ( \"got data from cache \" + getFullName ( ) ) ; return cache . data . copy ( ) ; } Array data = proxyReader . reallyRead ( this , null ) ; // optionally cache it if ( isCaching ( ) ) { setCachedData ( data ) ; if ( debugCaching ) System . out . println ( \"cache \" + getFullName ( ) ) ; return cache . data . copy ( ) ; // dont let users get their nasty hands on cached data } else { return data ; } }", "nl": "non - structure - member Variables ."}}
{"translation": {"code": "public String toStringDebug ( ) { Formatter f = new Formatter ( ) ; f . format ( \"Variable %s\" , getFullName ( ) ) ; if ( ncfile != null ) { f . format ( \" in file %s\" , getDatasetLocation ( ) ) ; String extra = ncfile . toStringDebug ( this ) ; if ( extra != null ) f . format ( \" %s\" , extra ) ; } return f . toString ( ) ; }", "nl": "String representation of Variable and its attributes ."}}
{"translation": {"code": "public boolean addDimensionIfNotExists ( Dimension dim ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( ! dim . isShared ( ) ) { throw new IllegalArgumentException ( \"Dimensions added to a group must be shared.\" ) ; } if ( findDimensionLocal ( dim . getShortName ( ) ) != null ) return false ; dimensions . add ( dim ) ; dim . setGroup ( this ) ; return true ; }", "nl": "Adds the specified shared dimension to this group but only if another dimension with the same name doesn t already exist ."}}
{"translation": {"code": "static float calcStep ( float range_first , float range_last , short num_bins ) { float step = ( range_last - range_first ) / ( num_bins - 1 ) ; BigDecimal bd = new BigDecimal ( step ) ; BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; return result . floatValue ( ) ; }", "nl": "Calculate distance between sequential bins in a ray"}}
{"translation": {"code": "static float calcElev ( short angle ) { final double maxval = 65536.0 ; double ang = ( double ) angle ; if ( angle < 0 ) ang = ( ~ angle ) + 1 ; double temp = ( ang / maxval ) * 360.0 ; BigDecimal bd = new BigDecimal ( temp ) ; BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; return result . floatValue ( ) ; }", "nl": "Calculate radial elevation of each ray"}}
{"translation": {"code": "public java . util . Map < String , String > readStnNames ( ucar . unidata . io . RandomAccessFile raf ) { java . util . Map < String , String > hdrNames = new java . util . HashMap < String , String > ( ) ; try { raf . seek ( 6288 ) ; String stnName = raf . readString ( 16 ) ; //System.out.println(\" stnName=\"+stnName.trim());\r raf . seek ( 6306 ) ; String stnName_util = raf . readString ( 16 ) ; hdrNames . put ( \"StationName\" , stnName . trim ( ) ) ; hdrNames . put ( \"StationName_SetupUtility\" , stnName_util . trim ( ) ) ; } catch ( Exception e ) { System . out . println ( e . toString ( ) ) ; e . printStackTrace ( ) ; } return hdrNames ; }", "nl": "Read StationName strings"}}
{"translation": {"code": "static float calcNyquist ( int prf , int wave ) { double tmp = ( prf * wave * 0.01 ) * 0.25 ; tmp = tmp * 0.01 ; //Make it m/sec\r BigDecimal bd = new BigDecimal ( tmp ) ; BigDecimal result = bd . setScale ( 2 , RoundingMode . HALF_DOWN ) ; return result . floatValue ( ) ; }", "nl": "Calculate of Nyquist velocity"}}
{"translation": {"code": "public static MAMath . MinMax getMinMax ( Array a ) { IndexIterator iter = a . getIndexIterator ( ) ; double max = - Double . MAX_VALUE ; double min = Double . MAX_VALUE ; while ( iter . hasNext ( ) ) { double val = iter . getDoubleNext ( ) ; if ( Double . isNaN ( val ) ) continue ; if ( val > max ) max = val ; if ( val < min ) min = val ; } return new MinMax ( min , max ) ; }", "nl": "Find min and max value in this array getting values as doubles . Skip Double . NaN ."}}
{"translation": {"code": "public static void copyObject ( Array result , Array a ) throws IllegalArgumentException { if ( ! conformable ( a , result ) ) throw new IllegalArgumentException ( \"copy arrays are not conformable\" ) ; IndexIterator iterA = a . getIndexIterator ( ) ; IndexIterator iterR = result . getIndexIterator ( ) ; while ( iterA . hasNext ( ) ) { iterR . setObjectNext ( iterA . getObjectNext ( ) ) ; } }", "nl": "copy array a to array result as an Object The array a and result must be type object"}}
{"translation": {"code": "public static void setDouble ( Array result , double val ) { IndexIterator iter = result . getIndexIterator ( ) ; while ( iter . hasNext ( ) ) { iter . setDoubleNext ( val ) ; } }", "nl": "Set all the elements of this array to the given double value . The value is converted to the element type of the array if needed ."}}
{"translation": {"code": "public static void copy ( Array result , Array a ) throws IllegalArgumentException { Class classType = a . getElementType ( ) ; if ( classType == double . class ) { copyDouble ( result , a ) ; } else if ( classType == float . class ) { copyFloat ( result , a ) ; } else if ( classType == long . class ) { copyLong ( result , a ) ; } else if ( classType == int . class ) { copyInt ( result , a ) ; } else if ( classType == short . class ) { copyShort ( result , a ) ; } else if ( classType == char . class ) { copyChar ( result , a ) ; } else if ( classType == byte . class ) { copyByte ( result , a ) ; } else if ( classType == boolean . class ) { copyBoolean ( result , a ) ; } else copyObject ( result , a ) ; }", "nl": "Copy array a to array result the result array will be in canonical order The operation type is taken from the type of a ."}}
{"translation": {"code": "public static Array convert ( Array org , DataType wantType ) { if ( org == null ) return null ; Class wantClass = wantType . getPrimitiveClassType ( ) ; if ( org . getElementType ( ) . equals ( wantClass ) ) return org ; Array result = Array . factory ( wantType , org . getShape ( ) ) ; copy ( wantType , org . getIndexIterator ( ) , result . getIndexIterator ( ) ) ; return result ; }", "nl": "Convert original array to desired type"}}
{"translation": {"code": "public static boolean conformable ( int [ ] shapeA , int [ ] shapeB ) { if ( reducedRank ( shapeA ) != reducedRank ( shapeB ) ) return false ; int rankB = shapeB . length ; int dimB = 0 ; for ( int aShapeA : shapeA ) { //System.out.println(dimA + \" \"+ dimB);\r //skip length 1 dimensions\r if ( aShapeA == 1 ) continue ; while ( dimB < rankB ) if ( shapeB [ dimB ] == 1 ) dimB ++ ; else break ; // test same shape (NB dimB cant be > rankB due to first test)\r if ( aShapeA != shapeB [ dimB ] ) return false ; dimB ++ ; } return true ; }", "nl": "Check that two array shapes are conformable . The shapes must match exactly except that dimensions of length 1 are ignored ."}}
{"translation": {"code": "public static boolean conformable ( Array a , Array b ) { return conformable ( a . getShape ( ) , b . getShape ( ) ) ; }", "nl": "Check that two arrays are conformable ."}}
{"translation": {"code": "public static Array add ( Array a , Array b ) throws IllegalArgumentException { Array result = Array . factory ( a . getDataType ( ) , a . getShape ( ) ) ; if ( a . getElementType ( ) == double . class ) { addDouble ( result , a , b ) ; } else throw new UnsupportedOperationException ( ) ; return result ; }", "nl": "Add elements of two arrays together allocating the result array . The result type and the operation type are taken from the type of a ."}}
{"translation": {"code": "public static void copyBoolean ( Array result , Array a ) throws IllegalArgumentException { if ( ! conformable ( a , result ) ) throw new IllegalArgumentException ( \"copy arrays are not conformable\" ) ; IndexIterator iterA = a . getIndexIterator ( ) ; IndexIterator iterR = result . getIndexIterator ( ) ; while ( iterA . hasNext ( ) ) iterR . setBooleanNext ( iterA . getBooleanNext ( ) ) ; }", "nl": "copy array a to array result as bytes The array a and result must be type boolean"}}
{"translation": {"code": "static public String backslashEscape ( String x , String reservedChars ) { if ( x == null ) { return null ; } else if ( reservedChars == null ) { return x ; } boolean ok = true ; for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { char c = x . charAt ( pos ) ; if ( reservedChars . indexOf ( c ) >= 0 ) { ok = false ; break ; } } if ( ok ) return x ; // gotta do it StringBuilder sb = new StringBuilder ( x ) ; for ( int pos = 0 ; pos < sb . length ( ) ; pos ++ ) { char c = sb . charAt ( pos ) ; if ( reservedChars . indexOf ( c ) < 0 ) { continue ; } sb . setCharAt ( pos , ' ' ) ; pos ++ ; sb . insert ( pos , c ) ; pos ++ ; } return sb . toString ( ) ; }", "nl": "backslash escape a string"}}
{"translation": {"code": "static public String backslashUnescape ( String x ) { if ( ! x . contains ( \"\\\\\" ) ) return x ; // gotta do it StringBuilder sb = new StringBuilder ( x . length ( ) ) ; for ( int pos = 0 ; pos < x . length ( ) ; pos ++ ) { char c = x . charAt ( pos ) ; if ( c == ' ' ) { c = x . charAt ( ++ pos ) ; // skip backslash, get next cha } sb . append ( c ) ; } return sb . toString ( ) ; }", "nl": "backslash unescape a string"}}
{"translation": {"code": "static public void registerIOProvider ( String className ) throws IllegalAccessException , InstantiationException , ClassNotFoundException { Class ioClass = NetcdfFile . class . getClassLoader ( ) . loadClass ( className ) ; registerIOProvider ( ioClass ) ; }", "nl": "Register an IOServiceProvider using its class string name ."}}
{"translation": {"code": "public static String urlDecode ( String s ) { try { //s = unescapeString(s, _URIEscape, \"\", false); s = URLDecoder . decode ( s , \"UTF-8\" ) ; } catch ( Exception e ) { s = null ; } return s ; }", "nl": "Define the DEFINITIVE URL unescape function ."}}
{"translation": {"code": "public static String unescapeDAPIdentifier ( String id ) { String s ; try { s = unescapeString ( id ) ; } catch ( Exception e ) { s = null ; } return s ; }", "nl": "Define the DEFINITIVE opendap identifier unescape function ."}}
{"translation": {"code": "public Attribute findGlobalAttributeIgnoreCase ( String name ) { for ( Attribute a : gattributes ) { if ( name . equalsIgnoreCase ( a . getShortName ( ) ) ) return a ; } return null ; }", "nl": "Look up global Attribute by name ignore case ."}}
{"translation": {"code": "public static NetcdfFile openInMemory ( URI uri ) throws IOException { URL url = uri . toURL ( ) ; byte [ ] contents = IO . readContentsToByteArray ( url . openStream ( ) ) ; return openInMemory ( uri . toString ( ) , contents ) ; }", "nl": "Read a remote CDM file into memory . All reads are then done from memory ."}}
{"translation": {"code": "public static List < String > tokenizeEscapedName ( String escapedName ) { List < String > result = new ArrayList <> ( ) ; int pos = 0 ; int start = 0 ; while ( true ) { pos = escapedName . indexOf ( sep , pos + 1 ) ; if ( pos <= 0 ) break ; if ( ( pos > 0 ) && escapedName . charAt ( pos - 1 ) != ' ' ) { result . add ( escapedName . substring ( start , pos ) ) ; start = pos + 1 ; } } result . add ( escapedName . substring ( start , escapedName . length ( ) ) ) ; // remaining return result ; }", "nl": "Tokenize an escaped name using . as delimiter skipping \\ ."}}
{"translation": {"code": "public void writeCDL ( OutputStream out , boolean strict ) { PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( out , CDM . utf8Charset ) ) ; toStringStart ( pw , strict ) ; toStringEnd ( pw ) ; pw . flush ( ) ; }", "nl": "Write CDL representation to OutputStream ."}}
{"translation": {"code": "public static int indexOf ( String escapedName , char c ) { int pos = 0 ; while ( true ) { pos = escapedName . indexOf ( c , pos + 1 ) ; if ( pos <= 0 ) return pos ; if ( ( pos > 0 ) && escapedName . charAt ( pos - 1 ) != ' ' ) return pos ; } }", "nl": "Find first occurence of char c in escapedName excluding escaped c ."}}
{"translation": {"code": "public Array read ( String variableSection , boolean flatten ) throws IOException , InvalidRangeException { if ( ! flatten ) throw new UnsupportedOperationException ( \"NetdfFile.read(String variableSection, boolean flatten=false)\" ) ; return readSection ( variableSection ) ; }", "nl": "Read a variable using the given section specification ."}}
{"translation": {"code": "public void writeCDL ( PrintWriter pw , boolean strict ) { toStringStart ( pw , strict ) ; toStringEnd ( pw ) ; pw . flush ( ) ; }", "nl": "Write CDL representation to PrintWriter ."}}
{"translation": {"code": "static public void registerIOProvider ( Class iospClass , boolean last ) throws IllegalAccessException , InstantiationException { IOServiceProvider spi ; spi = ( IOServiceProvider ) iospClass . newInstance ( ) ; // fail fast if ( userLoads && ! last ) registeredProviders . add ( 0 , spi ) ; // put user stuff first else registeredProviders . add ( spi ) ; }", "nl": "Register an IOServiceProvider . A new instance will be created when one of its files is opened ."}}
{"translation": {"code": "public boolean removeDimension ( Group g , String dimName ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( g == null ) g = rootGroup ; return g . removeDimension ( dimName ) ; }", "nl": "Remove a shared Dimension from a Group by name ."}}
{"translation": {"code": "public Variable addVariable ( Group g , Variable v ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( g == null ) g = rootGroup ; if ( v != null ) g . addVariable ( v ) ; return v ; }", "nl": "Add a Variable to the given group ."}}
{"translation": {"code": "public Dimension addDimension ( Group parent , Dimension d ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( parent == null ) parent = rootGroup ; parent . addDimension ( d ) ; return d ; }", "nl": "Add a shared Dimension to a Group ."}}
{"translation": {"code": "public Variable addVariable ( Group g , String shortName , DataType dtype , String dims ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( g == null ) g = rootGroup ; Variable v = new Variable ( this , g , null , shortName ) ; v . setDataType ( dtype ) ; v . setDimensions ( dims ) ; g . addVariable ( v ) ; return v ; }", "nl": "Create a new Variable and add to the given group ."}}
{"translation": {"code": "public Variable addStringVariable ( Group g , String shortName , String dims , int strlen ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( g == null ) g = rootGroup ; String dimName = shortName + \"_strlen\" ; addDimension ( g , new Dimension ( dimName , strlen ) ) ; Variable v = new Variable ( this , g , null , shortName ) ; v . setDataType ( DataType . CHAR ) ; v . setDimensions ( dims + \" \" + dimName ) ; g . addVariable ( v ) ; return v ; }", "nl": "Create a new Variable of type Datatype . CHAR and add to the given group ."}}
{"translation": {"code": "public Object sendIospMessage ( Object message ) { if ( null == message ) return null ; if ( message == IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) { Variable v = rootGroup . findVariable ( \"record\" ) ; boolean gotit = ( v != null ) && ( v instanceof Structure ) ; return gotit || makeRecordStructure ( ) ; } else if ( message == IOSP_MESSAGE_REMOVE_RECORD_STRUCTURE ) { Variable v = rootGroup . findVariable ( \"record\" ) ; boolean gotit = ( v != null ) && ( v instanceof Structure ) ; if ( gotit ) { rootGroup . remove ( v ) ; variables . remove ( v ) ; removeRecordStructure ( ) ; } return ( gotit ) ; } if ( spi != null ) return spi . sendIospMessage ( message ) ; return null ; }", "nl": "Generic way to send a message to the underlying IOSP . This message is sent after the file is open . To affect the creation of the file you must send into the factory method ."}}
{"translation": {"code": "protected Boolean makeRecordStructure ( ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; Boolean didit = false ; if ( ( spi != null ) && ( spi instanceof N3iosp ) && hasUnlimitedDimension ( ) ) { didit = ( Boolean ) spi . sendIospMessage ( IOSP_MESSAGE_ADD_RECORD_STRUCTURE ) ; } return didit ; }", "nl": "If there is an unlimited dimension make all variables that use it into a Structure . A Variable called record is added . You can then access these through the record structure ."}}
{"translation": {"code": "public static String backslashToDAP ( String bs ) { StringBuilder buf = new StringBuilder ( ) ; int len = bs . length ( ) ; for ( int i = 0 ; i < len ; i ++ ) { char c = bs . charAt ( i ) ; if ( i < ( len - 1 ) && c == ' ' ) { c = bs . charAt ( ++ i ) ; } if ( _allowableInDAP . indexOf ( c ) < 0 ) { buf . append ( _URIEscape ) ; // convert the char to hex String ashex = Integer . toHexString ( ( int ) c ) ; if ( ashex . length ( ) < 2 ) buf . append ( ' ' ) ; buf . append ( ashex ) ; } else buf . append ( c ) ; } return buf . toString ( ) ; }", "nl": "Given a backslash escaped name convert to a DAP escaped name"}}
{"translation": {"code": "public Array readSection ( String variableSection ) throws IOException , InvalidRangeException { /* if (unlocked)\n      throw new IllegalStateException(\"File is unlocked - cannot use\"); */ ParsedSectionSpec cer = ParsedSectionSpec . parseVariableSection ( this , variableSection ) ; if ( cer . child == null ) { return cer . v . read ( cer . section ) ; } if ( spi == null ) return IospHelper . readSection ( cer ) ; else // allow iosp to optimize return spi . readSection ( cer ) ; }", "nl": "Read a variable using the given section specification . The result is always an array of the type of the innermost variable . Its shape is the accumulation of all the shapes of its parent structures ."}}
{"translation": {"code": "protected long readToByteChannel ( ucar . nc2 . Variable v , Section section , WritableByteChannel wbc ) throws java . io . IOException , ucar . ma2 . InvalidRangeException { //if (unlocked) //  throw new IllegalStateException(\"File is unlocked - cannot use\"); if ( ( spi == null ) || v . hasCachedData ( ) ) return IospHelper . copyToByteChannel ( v . read ( section ) , wbc ) ; return spi . readToByteChannel ( v , section , wbc ) ; }", "nl": "Read data from a top level Variable and send data to a WritableByteChannel . Experimental ."}}
{"translation": {"code": "public void finish ( ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; variables = new ArrayList <> ( ) ; dimensions = new ArrayList <> ( ) ; gattributes = new ArrayList <> ( ) ; finishGroup ( rootGroup ) ; }", "nl": "Finish constructing the object model . This construsts the global variables attributes and dimensions . It also looks for coordinate variables ."}}
{"translation": {"code": "static public boolean canOpen ( String location ) throws IOException { ucar . unidata . io . RandomAccessFile raf = null ; try { raf = getRaf ( location , - 1 ) ; return ( raf != null ) && canOpen ( raf ) ; } finally { if ( raf != null ) raf . close ( ) ; } }", "nl": "Find out if the file can be opened but dont actually open it . Experimental ."}}
{"translation": {"code": "public static NetcdfFile openInMemory ( String name , byte [ ] data , String iospClassName ) throws IOException , ClassNotFoundException , IllegalAccessException , InstantiationException { ucar . unidata . io . InMemoryRandomAccessFile raf = new ucar . unidata . io . InMemoryRandomAccessFile ( name , data ) ; Class iospClass = NetcdfFile . class . getClassLoader ( ) . loadClass ( iospClassName ) ; IOServiceProvider spi = ( IOServiceProvider ) iospClass . newInstance ( ) ; return new NetcdfFile ( spi , raf , name , null ) ; }", "nl": "Open an in - memory netcdf file with a specific iosp ."}}
{"translation": {"code": "public static NetcdfFile openInMemory ( String name , byte [ ] data ) throws IOException { ucar . unidata . io . InMemoryRandomAccessFile raf = new ucar . unidata . io . InMemoryRandomAccessFile ( name , data ) ; return open ( raf , name , null , null ) ; }", "nl": "Open an in - memory netcdf file ."}}
{"translation": {"code": "public static NetcdfFile openInMemory ( String filename ) throws IOException { File file = new File ( filename ) ; ByteArrayOutputStream bos = new ByteArrayOutputStream ( ( int ) file . length ( ) ) ; try ( InputStream in = new BufferedInputStream ( new FileInputStream ( filename ) ) ) { IO . copy ( in , bos ) ; } return openInMemory ( filename , bos . toByteArray ( ) ) ; }", "nl": "Read a local CDM file into memory . All reads are then done from memory ."}}
{"translation": {"code": "static protected String makeFullName ( CDMNode node , String reservedChars ) { Group parent = node . getParentGroup ( ) ; if ( ( ( parent == null ) || parent . isRoot ( ) ) && ! node . isMemberOfStructure ( ) ) // common case? return EscapeStrings . backslashEscape ( node . getShortName ( ) , reservedChars ) ; StringBuilder sbuff = new StringBuilder ( ) ; appendGroupName ( sbuff , parent , reservedChars ) ; appendStructureName ( sbuff , node , reservedChars ) ; return sbuff . toString ( ) ; }", "nl": "Given a CDMNode create its full name with appropriate backslash escaping of the specified characters ."}}
{"translation": {"code": "public Group addGroup ( Group parent , Group g ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( parent == null ) parent = rootGroup ; parent . addGroup ( g ) ; return g ; }", "nl": "Add a group to the parent group ."}}
{"translation": {"code": "protected String makeFullNameWithString ( Group parent , String name ) { name = makeValidPathName ( name ) ; // escape for use in full name   StringBuilder sbuff = new StringBuilder ( ) ; appendGroupName ( sbuff , parent , null ) ; sbuff . append ( name ) ; return sbuff . toString ( ) ; }", "nl": "Create a synthetic full name from a group plus a string"}}
{"translation": {"code": "public Attribute addAttribute ( Group parent , Attribute att ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( parent == null ) parent = rootGroup ; parent . addAttribute ( att ) ; return att ; }", "nl": "Add an attribute to a group ."}}
{"translation": {"code": "protected void writeCDL ( Formatter f , Indent indent , boolean strict ) { toStringStart ( f , indent , strict ) ; f . format ( \"%s}%n\" , indent ) ; }", "nl": "the actual work is here"}}
{"translation": {"code": "public java . util . List < Array > readArrays ( java . util . List < Variable > variables ) throws IOException { java . util . List < Array > result = new java . util . ArrayList <> ( ) ; for ( Variable variable : variables ) result . ( variable . read ( ) ) ; return result ; }", "nl": "Do a bulk read on a list of Variables and return a corresponding list of Array that contains the results of a full read on each Variable . This is mostly here so DODSNetcdf can override it with one call to the server ."}}
{"translation": {"code": "public boolean removeVariable ( Group g , String varName ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( g == null ) g = rootGroup ; return g . removeVariable ( varName ) ; }", "nl": "Remove a Variable from the given group by name ."}}
{"translation": {"code": "private String getShapeString ( int [ ] shape ) { StringBuilder buf = new StringBuilder ( ) ; for ( int i = 0 ; i < shape . length ; i ++ ) { if ( i != 0 ) buf . append ( \" \" ) ; buf . append ( shape [ i ] ) ; } return buf . toString ( ) ; }", "nl": "display name plus the dimensions"}}
{"translation": {"code": "public String getDetailInfo ( ) { Formatter ff = new Formatter ( ) ; ff . format ( \"%s\" , super . getDetailInfo ( ) ) ; ff . format ( \"%s\" , parseInfo ) ; return ff . toString ( ) ; }", "nl": "Get the detail information"}}
{"translation": {"code": "protected Variable makeMissingVariable ( ) { Variable var = new Variable ( ncfile , null , null , MISSING_VAR ) ; var . setDataType ( DataType . BYTE ) ; var . setDimensions ( ( List < Dimension > ) null ) ; var . addAttribute ( new Attribute ( \"description\" , \"missing flag - 1 means all params are missing\" ) ) ; var . addAttribute ( new Attribute ( CDM . MISSING_VALUE , ( byte ) 1 ) ) ; return var ; }", "nl": "Make the missing variable"}}
{"translation": {"code": "protected void addGlobalAttributes ( ) { // global stuff\r ncfile . addAttribute ( null , new Attribute ( CDM . CONVENTIONS , getConventions ( ) ) ) ; String fileType = \"GEMPAK \" + gemreader . getFileType ( ) ; ncfile . addAttribute ( null , new Attribute ( \"file_format\" , fileType ) ) ; ncfile . addAttribute ( null , new Attribute ( \"history\" , \"Direct read of \" + fileType + \" into NetCDF-Java API\" ) ) ; ncfile . addAttribute ( null , new Attribute ( CF . FEATURE_TYPE , getCFFeatureType ( ) ) ) ; }", "nl": "Add on global attributes for all types"}}
{"translation": {"code": "public static String cleanUnit ( String unit ) { if ( unit == null ) return null ; // These specific words become dimensionless\r if ( unit . equalsIgnoreCase ( \"Proportion\" ) || unit . equalsIgnoreCase ( \"Numeric\" ) ) unit = \"\" ; // So does '-'\r else if ( unit . equalsIgnoreCase ( \"-\" ) ) { unit = \"\" ; // Make sure degree(s) true gets concatenated with '_'\r } else if ( unit . startsWith ( \"degree\" ) && unit . endsWith ( \"true\" ) ) { unit = unit . replace ( ' ' , ' ' ) ; // And only do the rest of the conversion if it's not a \"* table *\" entry\r } else if ( ! unit . contains ( \" table \" ) ) { if ( unit . startsWith ( \"/\" ) ) unit = \"1\" + unit ; unit = unit . trim ( ) ; unit = StringUtil2 . remove ( unit , \"**\" ) ; StringBuilder sb = new StringBuilder ( unit ) ; StringUtil2 . remove ( sb , \"^[]\" ) ; StringUtil2 . replace ( sb , ' ' , \".\" ) ; StringUtil2 . replace ( sb , ' ' , \".\" ) ; unit = sb . toString ( ) ; } return unit ; }", "nl": "Clean up strings to be used for unit string"}}
{"translation": {"code": "public static String cleanName ( String name ) { if ( name == null ) return null ; int pos = name . indexOf ( \"(see\" ) ; if ( pos < 0 ) pos = name . indexOf ( \"(See\" ) ; if ( pos > 0 ) name = name . substring ( 0 , pos ) ; name = StringUtil2 . replace ( name , ' ' , \"-\" ) ; StringBuilder sb = new StringBuilder ( name ) ; StringUtil2 . replace ( sb , ' ' , \"plus\" ) ; StringUtil2 . remove ( sb , \".;,=[]()/*\\\"\" ) ; return StringUtil2 . collapseWhitespace ( sb . toString ( ) . trim ( ) ) ; }", "nl": "Clean up strings to be used in Netcdf Object names"}}
{"translation": {"code": "public void setOriginalVariable ( ucar . nc2 . Variable orgVar ) { if ( ! ( orgVar instanceof Structure ) ) throw new IllegalArgumentException ( \"StructureDS must wrap a Structure; name=\" + orgVar . getFullName ( ) ) ; this . orgVar = ( Structure ) orgVar ; }", "nl": "Set the Structure to wrap ."}}
{"translation": {"code": "@ Override public Array reallyRead ( Variable client , CancelTask cancelTask ) throws IOException { Array result ; if ( hasCachedData ( ) ) result = super . reallyRead ( client , cancelTask ) ; else if ( orgVar != null ) result = orgVar . read ( ) ; else { throw new IllegalStateException ( \"StructureDS has no way to get data\" ) ; //Object data = smProxy.getFillValue(getDataType());\r //return Array.factoryConstant(dataType.getPrimitiveClassType(), getShape(), data);\r } return convert ( result , null ) ; }", "nl": "regular Variables ."}}
{"translation": {"code": "@ Override public Array reallyRead ( Variable client , Section section , CancelTask cancelTask ) throws IOException , InvalidRangeException { if ( section . computeSize ( ) == getSize ( ) ) return _read ( ) ; Array result ; if ( hasCachedData ( ) ) result = super . reallyRead ( client , section , cancelTask ) ; else if ( orgVar != null ) result = orgVar . read ( section ) ; else { throw new IllegalStateException ( \"StructureDS has no way to get data\" ) ; //Object data = smProxy.getFillValue(getDataType());\r //return Array.factoryConstant(dataType.getPrimitiveClassType(), section.getShape(), data);\r } // do any needed conversions (enum/scale/offset/missing/unsigned, etc)\r return convert ( result , section ) ; }", "nl": "section of regular Variable"}}
{"translation": {"code": "private boolean convertNeeded ( StructureMembers smData ) { for ( Variable v : getVariables ( ) ) { if ( v instanceof VariableDS ) { VariableDS vds = ( VariableDS ) v ; if ( vds . needConvert ( ) ) return true ; } else if ( v instanceof StructureDS ) { StructureDS nested = ( StructureDS ) v ; if ( nested . convertNeeded ( null ) ) return true ; } // a variable with no data in the underlying smData\r if ( ( smData != null ) && ! varHasData ( v , smData ) ) return true ; } return false ; }", "nl": "is conversion needed?"}}
{"translation": {"code": "protected ArrayStructure convert ( Array data , Section section ) throws IOException { ArrayStructure orgAS = ( ArrayStructure ) data ; if ( ! convertNeeded ( orgAS . getStructureMembers ( ) ) ) { // name, info change only\r convertMemberInfo ( orgAS . getStructureMembers ( ) ) ; return orgAS ; } // LOOK! converting to ArrayStructureMA\r // do any enum/scale/offset/missing/unsigned conversions\r ArrayStructure newAS = ArrayStructureMA . factoryMA ( orgAS ) ; for ( StructureMembers . Member m : newAS . getMembers ( ) ) { VariableEnhanced v2 = ( VariableEnhanced ) findVariable ( m . getName ( ) ) ; if ( ( v2 == null ) && ( orgVar != null ) ) // these are from orgVar - may have been renamed\r v2 = findVariableFromOrgName ( m . getName ( ) ) ; if ( v2 == null ) continue ; if ( v2 instanceof VariableDS ) { VariableDS vds = ( VariableDS ) v2 ; if ( vds . needConvert ( ) ) { Array mdata = newAS . extractMemberArray ( m ) ; // mdata has not yet been enhanced, but vds would *think* that it has been if we used the 1-arg version of\r // VariableDS.convert(). So, we use the 2-arg version to explicitly request enhancement.\r mdata = vds . convert ( mdata , vds . getEnhanceMode ( ) ) ; newAS . setMemberArray ( m , mdata ) ; } } else if ( v2 instanceof StructureDS ) { StructureDS innerStruct = ( StructureDS ) v2 ; if ( innerStruct . convertNeeded ( null ) ) { if ( innerStruct . getDataType ( ) == DataType . SEQUENCE ) { ArrayObject . D1 seqArray = ( ArrayObject . D1 ) newAS . extractMemberArray ( m ) ; ArrayObject . D1 newSeq = ( ArrayObject . D1 ) Array . factory ( DataType . SEQUENCE , new int [ ] { ( int ) seqArray . getSize ( ) } ) ; m . setDataArray ( newSeq ) ; // put back into member array\r // wrap each Sequence\r for ( int i = 0 ; i < seqArray . getSize ( ) ; i ++ ) { ArraySequence innerSeq = ( ArraySequence ) seqArray . get ( i ) ; // get old ArraySequence\r newSeq . set ( i , new SequenceConverter ( innerStruct , innerSeq ) ) ; // wrap in converter\r } // non-Sequence Structures\r } else { Array mdata = newAS . extractMemberArray ( m ) ; mdata = innerStruct . convert ( mdata , null ) ; newAS . setMemberArray ( m , mdata ) ; } } // always convert the inner StructureMembers\r innerStruct . convertMemberInfo ( m . getStructureMembers ( ) ) ; } } StructureMembers sm = newAS . getStructureMembers ( ) ; convertMemberInfo ( sm ) ; // check for variables that have been added by NcML\r for ( Variable v : getVariables ( ) ) { if ( ! varHasData ( v , sm ) ) { try { Variable completeVar = getParentGroup ( ) . findVariable ( v . getShortName ( ) ) ; // LOOK BAD\r Array mdata = completeVar . read ( section ) ; StructureMembers . Member m = sm . addMember ( v . getShortName ( ) , v . getDescription ( ) , v . getUnitsString ( ) , v . getDataType ( ) , v . getShape ( ) ) ; newAS . setMemberArray ( m , mdata ) ; } catch ( InvalidRangeException e ) { throw new IOException ( e . getMessage ( ) ) ; } } } return newAS ; }", "nl": "3 ) variable with cached data added to StructureDS through NcML"}}
{"translation": {"code": "static private double connectLon ( double connect , double val ) { if ( Double . isNaN ( connect ) ) return val ; if ( Double . isNaN ( val ) ) return val ; double diff = val - connect ; if ( Math . abs ( diff ) < MAX_JUMP ) return val ; // common case fast\r // we have to add or subtract 360\r double result = diff > 0 ? val - 360 : val + 360 ; double diff2 = connect - result ; if ( ( Math . abs ( diff2 ) ) < Math . abs ( diff ) ) val = result ; return val ; }", "nl": "larger than you would ever expect"}}
{"translation": {"code": "private VariableEnhanced findVariableFromOrgName ( String orgName ) { for ( Variable vTop : getVariables ( ) ) { Variable v = vTop ; while ( v instanceof VariableEnhanced ) { VariableEnhanced ve = ( VariableEnhanced ) v ; if ( ( ve . getOriginalName ( ) != null ) && ( ve . getOriginalName ( ) . equals ( orgName ) ) ) return ( VariableEnhanced ) vTop ; v = ve . getOriginalVariable ( ) ; } } return null ; }", "nl": "look for the top variable that has an orgVar with the wanted orgName"}}
{"translation": {"code": "private boolean varHasData ( Variable v , StructureMembers sm ) { if ( sm . findMember ( v . getShortName ( ) ) != null ) return true ; while ( v instanceof VariableEnhanced ) { VariableEnhanced ve = ( VariableEnhanced ) v ; if ( sm . findMember ( ve . getOriginalName ( ) ) != null ) return true ; v = ve . getOriginalVariable ( ) ; } return false ; }", "nl": "verify that the variable has data in the data array"}}
{"translation": {"code": "public void enhance ( Set < NetcdfDataset . Enhance > mode ) { for ( Variable v : getVariables ( ) ) { VariableEnhanced ve = ( VariableEnhanced ) v ; ve . enhance ( mode ) ; } }", "nl": "DO NOT USE DIRECTLY . public by accident . recalc any enhancement info"}}
{"translation": {"code": "private void convertMemberInfo ( StructureMembers wrapperSm ) { for ( StructureMembers . Member m : wrapperSm . getMembers ( ) ) { Variable v = findVariable ( m . getName ( ) ) ; if ( ( v == null ) && ( orgVar != null ) ) // may have been renamed\r v = ( Variable ) findVariableFromOrgName ( m . getName ( ) ) ; if ( v != null ) { // a section will have missing variables LOOK wrapperSm probably wrong in that case\r //  log.error(\"Cant find \" + m.getName());\r //else\r m . setVariableInfo ( v . getShortName ( ) , v . getDescription ( ) , v . getUnitsString ( ) , v . getDataType ( ) ) ; } // nested structures\r if ( v instanceof StructureDS ) { StructureDS innerStruct = ( StructureDS ) v ; innerStruct . convertMemberInfo ( m . getStructureMembers ( ) ) ; } } }", "nl": "the wrapper StructureMembers must be converted to correspond to the wrapper Structure"}}
{"translation": {"code": "private void swapGridHeader ( int [ ] gh ) { McIDASUtil . flip ( gh , 0 , 5 ) ; McIDASUtil . flip ( gh , 7 , 7 ) ; McIDASUtil . flip ( gh , 9 , 10 ) ; McIDASUtil . flip ( gh , 12 , 14 ) ; McIDASUtil . flip ( gh , 32 , 51 ) ; }", "nl": "Swap the grid header avoiding strings"}}
{"translation": {"code": "public int getByteOrder ( int kmachn ) { if ( ( kmachn == MTVAX ) || ( kmachn == MTULTX ) || ( kmachn == MTALPH ) || ( kmachn == MTLNUX ) || ( kmachn == MTIGPH ) ) { return RandomAccessFile . LITTLE_ENDIAN ; } return RandomAccessFile . BIG_ENDIAN ; }", "nl": "Get the byte order for the machine type ."}}
{"translation": {"code": "void setByteOrder ( ) { String arch = System . getProperty ( \"os.arch\" ) ; if ( arch . equals ( \"x86\" ) || // Windows, Linux arch . equals ( \"arm\" ) || // Window CE arch . equals ( \"x86_64\" ) || // Windows64, Mac OS-X arch . equals ( \"amd64\" ) || // Linux64? arch . equals ( \"alpha\" ) ) { // Utrix, VAX, DECOS MTMACH = RandomAccessFile . LITTLE_ENDIAN ; } else { MTMACH = RandomAccessFile . BIG_ENDIAN ; } }", "nl": "LOOK WTF ?? Set the machine type for this system ."}}
{"translation": {"code": "public DMFileHeaderInfo findFileHeader ( String name ) { if ( ( fileHeaderInfo == null ) || fileHeaderInfo . isEmpty ( ) ) { return null ; } for ( DMFileHeaderInfo fhi : fileHeaderInfo ) { if ( name . equals ( fhi . kfhnam ) ) { return fhi ; } } return null ; }", "nl": "Find the file header with this name"}}
{"translation": {"code": "public void printParts ( ) { if ( parts == null ) { return ; } for ( int i = 0 ; i < parts . size ( ) ; i ++ ) { System . out . println ( \"\\nParts[\" + i + \"]:\" ) ; System . out . println ( parts . get ( i ) ) ; } }", "nl": "Print the part information"}}
{"translation": {"code": "public int getDataPointer ( int irow , int icol , String partName ) { int ipoint = - 1 ; if ( ( irow < 1 ) || ( irow > dmLabel . krow ) || ( icol < 1 ) || ( icol > dmLabel . kcol ) ) { System . out . println ( \"bad row or column number: \" + irow + \"/\" + icol ) ; return ipoint ; } int iprt = getPartNumber ( partName ) ; if ( iprt == 0 ) { System . out . println ( \"couldn't find part\" ) ; return ipoint ; } // gotta subtract 1 because parts are 1 but List is 0 based DMPart part = parts . get ( iprt - 1 ) ; // check for valid data type if ( ( part . ktyprt != MDREAL ) && ( part . ktyprt != MDGRID ) && ( part . ktyprt != MDRPCK ) ) { System . out . println ( \"Not a valid type\" ) ; return ipoint ; } int ilenhd = part . klnhdr ; ipoint = dmLabel . kpdata + ( irow - 1 ) * dmLabel . kcol * dmLabel . kprt + ( icol - 1 ) * dmLabel . kprt + ( iprt - 1 ) ; return ipoint ; }", "nl": "Get the pointer to the data . Taken from DM_RDTR"}}
{"translation": {"code": "public float DM_RFLT ( int word ) throws IOException { if ( rf == null ) { throw new IOException ( \"DM_RFLT: no file to read from\" ) ; } if ( dmLabel == null ) { throw new IOException ( \"DM_RFLT: reader not initialized\" ) ; } rf . seek ( getOffset ( word ) ) ; if ( needToSwap ) { // set the order //if ((dmLabel.kmachn != MTMACH) && //   ((dmLabel.kvmst && ! mvmst) || //   (mvmst && !dmLabel.kvmst))) { rf . order ( RandomAccessFile . LITTLE_ENDIAN ) ; // swap } else { rf . order ( RandomAccessFile . BIG_ENDIAN ) ; } float rdata = rf . readFloat ( ) ; if ( RMISSD != dmLabel . smissd ) { if ( Math . abs ( rdata - dmLabel . smissd ) < RDIFFD ) { rdata = RMISSD ; } } // reset to read normally rf . order ( RandomAccessFile . BIG_ENDIAN ) ; return rdata ; }", "nl": "Read a float"}}
{"translation": {"code": "public String DM_RSTR ( int isword , int nchar ) throws IOException { if ( rf == null ) { throw new IOException ( \"DM_RSTR: no file to read from\" ) ; } rf . seek ( getOffset ( isword ) ) ; return rf . readString ( nchar ) ; }", "nl": "Read a String"}}
{"translation": {"code": "public float [ ] getFileHeader ( String name ) throws IOException { DMFileHeaderInfo fh = findFileHeader ( name ) ; if ( ( fh == null ) || ( fh . kfhtyp != MDREAL ) ) { return null ; } int knt = fileHeaderInfo . indexOf ( fh ) ; // 0 based int iread = dmLabel . kpfile + 3 * dmLabel . kfhdrs ; for ( int i = 0 ; i < knt ; i ++ ) { DMFileHeaderInfo fhi = fileHeaderInfo . get ( i ) ; iread = iread + fhi . kfhlen + 1 ; } int nword = DM_RINT ( iread ) ; if ( nword <= 0 ) { logError ( \"Invalid header length for \" + name ) ; return null ; } iread ++ ; float [ ] rheader = new float [ nword ] ; if ( name . equals ( \"NAVB\" ) && needToSwap ) { DM_RFLT ( iread , 1 , rheader , 0 ) ; needToSwap = false ; iread ++ ; DM_RFLT ( iread , 1 , rheader , 1 ) ; needToSwap = true ; iread ++ ; DM_RFLT ( iread , nword - 2 , rheader , 2 ) ; } else { DM_RFLT ( iread , rheader ) ; } return rheader ; }", "nl": "Read in the values for the file header"}}
{"translation": {"code": "boolean writeNcml ( String location ) { boolean err = false ; closeOpenFiles ( ) ; try { final String result ; ds = openDataset ( location , addCoords , null ) ; if ( ds == null ) { editor . setText ( \"Failed to open <\" + location + \">\" ) ; } else { final NcMLWriter ncmlWriter = new NcMLWriter ( ) ; final Element netcdfElem = ncmlWriter . makeNetcdfElement ( ds , null ) ; result = ncmlWriter . writeToString ( netcdfElem ) ; editor . setText ( result ) ; editor . setCaretPosition ( 0 ) ; } } catch ( Exception e ) { final StringWriter sw = new StringWriter ( 10000 ) ; e . printStackTrace ( ) ; e . printStackTrace ( new PrintWriter ( sw ) ) ; editor . setText ( sw . toString ( ) ) ; err = true ; } return ! err ; }", "nl": "write ncml from given dataset"}}
{"translation": {"code": "public static CalendarPeriod of ( String udunit ) { int value ; String units ; String [ ] split = StringUtil2 . splitString ( udunit ) ; if ( split . length == 1 ) { value = 1 ; units = split [ 0 ] ; } else if ( split . length == 2 ) { try { value = Integer . parseInt ( split [ 0 ] ) ; } catch ( Throwable t ) { return null ; } units = split [ 1 ] ; } else return null ; CalendarPeriod . Field unit = CalendarPeriod . fromUnitString ( units ) ; return CalendarPeriod . of ( value , unit ) ; }", "nl": "Convert a udunit period string into a CalendarPeriod"}}
{"translation": {"code": "static public NetcdfDataset wrap ( NetcdfFile ncfile , Set < Enhance > mode ) throws IOException { if ( ncfile instanceof NetcdfDataset ) { NetcdfDataset ncd = ( NetcdfDataset ) ncfile ; if ( ! ncd . enhanceNeeded ( mode ) ) return ( NetcdfDataset ) ncfile ; } // enhancement requires wrappping, to not modify underlying dataset, eg if cached // perhaps need a method variant that allows the ncfile to be modified return new NetcdfDataset ( ncfile , mode ) ; }", "nl": "Make NetcdfFile into NetcdfDataset with given enhance mode"}}
{"translation": {"code": "public void setValues ( Variable v , List < String > values ) throws IllegalArgumentException { Array data = Array . makeArray ( v . getDataType ( ) , values ) ; if ( data . getSize ( ) != v . getSize ( ) ) throw new IllegalArgumentException ( \"Incorrect number of values specified for the Variable \" + v . getFullName ( ) + \" needed= \" + v . getSize ( ) + \" given=\" + data . getSize ( ) ) ; if ( v . getRank ( ) != 1 ) // dont have to reshape for rank 1 data = data . reshape ( v . getShape ( ) ) ; v . setCachedData ( data , true ) ; }", "nl": "Set the data values from a list of Strings ."}}
{"translation": {"code": "public void setValues ( Variable v , int npts , double start , double incr ) { if ( npts != v . getSize ( ) ) throw new IllegalArgumentException ( \"bad npts = \" + npts + \" should be \" + v . getSize ( ) ) ; Array data = Array . makeArray ( v . getDataType ( ) , npts , start , incr ) ; if ( v . getRank ( ) != 1 ) data = data . reshape ( v . getShape ( ) ) ; v . setCachedData ( data , true ) ; }", "nl": "Generate the list of values from a starting value and an increment . Will reshape to variable if needed ."}}
{"translation": {"code": "public boolean enhanceNeeded ( Set < Enhance > want ) throws IOException { if ( want == null ) return false ; for ( Enhance mode : want ) { if ( ! this . enhanceMode . contains ( mode ) ) return true ; } return false ; }", "nl": "is this enhancement already done ?"}}
{"translation": {"code": "public CoordinateTransform findCoordinateTransform ( String name ) { if ( name == null ) return null ; for ( CoordinateTransform v : coordTransforms ) { if ( name . equals ( v . getName ( ) ) ) return v ; } return null ; }", "nl": "Retrieve the CoordinateTransform with the specified name ."}}
{"translation": {"code": "public static NetcdfFile openFile ( String location , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { DatasetUrl durl = DatasetUrl . findDatasetUrl ( location ) ; return openOrAcquireFile ( null , null , null , durl , - 1 , cancelTask , null ) ; }", "nl": "Factory method for opening a NetcdfFile through the netCDF API ."}}
{"translation": {"code": "public CoordinateSystem findCoordinateSystem ( String name ) { if ( name == null ) return null ; for ( CoordinateSystem v : coordSys ) { if ( name . equals ( v . getName ( ) ) ) return v ; } return null ; }", "nl": "Retrieve the CoordinateSystem with the specified name ."}}
{"translation": {"code": "static public Array makeArray ( DataType dtype , List < String > stringValues ) throws NumberFormatException { return Array . makeArray ( dtype , stringValues ) ; }", "nl": "Make a 1D array from a list of strings ."}}
{"translation": {"code": "public void clearCoordinateSystems ( ) { coordSys = new ArrayList <> ( ) ; coordAxes = new ArrayList <> ( ) ; coordTransforms = new ArrayList <> ( ) ; for ( Variable v : getVariables ( ) ) { VariableEnhanced ve = ( VariableEnhanced ) v ; ve . clearCoordinateSystems ( ) ; // ?? } enhanceMode . remove ( Enhance . CoordSystems ) ; }", "nl": "Clear Coordinate System metadata to allow them to be redone"}}
{"translation": {"code": "public CoordinateAxis findCoordinateAxis ( AxisType type ) { if ( type == null ) return null ; for ( CoordinateAxis v : coordAxes ) { if ( type == v . getAxisType ( ) ) return v ; } return null ; }", "nl": "Retrieve the CoordinateAxis with the specified Axis Type ."}}
{"translation": {"code": "public CoordinateAxis findCoordinateAxis ( String fullName ) { if ( fullName == null ) return null ; for ( CoordinateAxis v : coordAxes ) { if ( fullName . equals ( v . getFullName ( ) ) ) return v ; } return null ; }", "nl": "Retrieve the CoordinateAxis with the specified type ."}}
{"translation": {"code": "static public void printArrayPlain ( Array ma , PrintWriter out ) { ma . resetLocalIterator ( ) ; while ( ma . hasNext ( ) ) { out . print ( ma . next ( ) ) ; out . print ( ' ' ) ; } }", "nl": "Print array as undifferentiated sequence of values ."}}
{"translation": {"code": "static public void writeNcML ( NetcdfFile ncfile , Writer writer , WantValues showValues , String url ) throws IOException { Preconditions . checkNotNull ( ncfile ) ; Preconditions . checkNotNull ( writer ) ; Preconditions . checkNotNull ( showValues ) ; Predicate < Variable > writeVarsPred ; switch ( showValues ) { case none : writeVarsPred = NcMLWriter . writeNoVariablesPredicate ; break ; case coordsOnly : writeVarsPred = NcMLWriter . writeCoordinateVariablesPredicate ; break ; case all : writeVarsPred = NcMLWriter . writeAllVariablesPredicate ; break ; default : String message = String . format ( \"CAN'T HAPPEN: showValues (%s) != null and checked all possible enum values.\" , showValues ) ; throw new AssertionError ( message ) ; } NcMLWriter ncmlWriter = new NcMLWriter ( ) ; ncmlWriter . setWriteVariablesPredicate ( writeVarsPred ) ; Element netcdfElement = ncmlWriter . makeNetcdfElement ( ncfile , url ) ; ncmlWriter . writeToWriter ( netcdfElement , writer ) ; }", "nl": "Write the NcML representation for a file . Note that ucar . nc2 . dataset . NcMLWriter has a JDOM implementation for complete NcML . This method implements only the core NcML for plain ole netcdf files ."}}
{"translation": {"code": "public static boolean print ( String command , Writer out , ucar . nc2 . util . CancelTask ct ) throws IOException { // pull out the filename from the command String filename ; StringTokenizer stoke = new StringTokenizer ( command ) ; if ( stoke . hasMoreTokens ( ) ) filename = stoke . nextToken ( ) ; else { out . write ( usage ) ; return false ; } try ( NetcdfFile nc = NetcdfDataset . openFile ( filename , ct ) ) { // the rest of the command int pos = command . indexOf ( filename ) ; command = command . substring ( pos + filename . length ( ) ) ; return print ( nc , command , out , ct ) ; } catch ( java . io . FileNotFoundException e ) { out . write ( \"file not found= \" ) ; out . write ( filename ) ; return false ; } finally { out . close ( ) ; } }", "nl": "ncdump that parses a command string ."}}
{"translation": {"code": "public static boolean print ( NetcdfFile nc , String command , Writer out , ucar . nc2 . util . CancelTask ct ) throws IOException { WantValues showValues = WantValues . none ; boolean ncml = false ; boolean strict = false ; String varNames = null ; String trueDataset = null ; String fakeDataset = null ; if ( command != null ) { StringTokenizer stoke = new StringTokenizer ( command ) ; while ( stoke . hasMoreTokens ( ) ) { String toke = stoke . nextToken ( ) ; if ( toke . equalsIgnoreCase ( \"-help\" ) ) { out . write ( usage ) ; out . write ( ' ' ) ; return true ; } if ( toke . equalsIgnoreCase ( \"-vall\" ) ) showValues = WantValues . all ; if ( toke . equalsIgnoreCase ( \"-c\" ) && ( showValues == WantValues . none ) ) showValues = WantValues . coordsOnly ; if ( toke . equalsIgnoreCase ( \"-ncml\" ) ) ncml = true ; if ( toke . equalsIgnoreCase ( \"-cdl\" ) || toke . equalsIgnoreCase ( \"-strict\" ) ) strict = true ; if ( toke . equalsIgnoreCase ( \"-v\" ) && stoke . hasMoreTokens ( ) ) varNames = stoke . nextToken ( ) ; if ( toke . equalsIgnoreCase ( \"-datasetname\" ) && stoke . hasMoreTokens ( ) ) { fakeDataset = stoke . nextToken ( ) ; if ( fakeDataset . length ( ) == 0 ) fakeDataset = null ; if ( fakeDataset != null ) { trueDataset = nc . getLocation ( ) ; nc . setLocation ( fakeDataset ) ; } } } } boolean ok = print ( nc , out , showValues , ncml , strict , varNames , ct ) ; if ( trueDataset != null && fakeDataset != null ) nc . setLocation ( trueDataset ) ; return ok ; }", "nl": "ncdump parsing command string file already open ."}}
{"translation": {"code": "static public String printVariableData ( VariableIF v , ucar . nc2 . util . CancelTask ct ) throws IOException { Array data = v . read ( ) ; /* try {\n      data = v.isMemberOfStructure() ? v.readAllStructures(null, true) : v.read();\n    }\n    catch (InvalidRangeException ex) {\n      return ex.getMessage();\n    } */ StringWriter writer = new StringWriter ( 10000 ) ; printArray ( data , v . getFullName ( ) , new PrintWriter ( writer ) , new Indent ( 2 ) , ct ) ; return writer . toString ( ) ; }", "nl": "Print all the data of the given Variable ."}}
{"translation": {"code": "static public void printStructureData ( PrintWriter out , StructureData sdata ) throws IOException { printStructureData ( out , sdata , new Indent ( 2 ) , null ) ; out . flush ( ) ; }", "nl": "Print contents of a StructureData ."}}
{"translation": {"code": "static public String printVariableDataSection ( Variable v , String sectionSpec , ucar . nc2 . util . CancelTask ct ) throws IOException , InvalidRangeException { Array data = v . read ( sectionSpec ) ; StringWriter writer = new StringWriter ( 20000 ) ; printArray ( data , v . getFullName ( ) , new PrintWriter ( writer ) , new Indent ( 2 ) , ct ) ; return writer . toString ( ) ; }", "nl": "Print a section of the data of the given Variable ."}}
{"translation": {"code": "public HTTPSession setUseSessions ( boolean tf ) { localsettings . put ( Prop . USESESSIONS , ( Boolean ) tf ) ; this . cachevalid = false ; return this ; }", "nl": "Should we use sessionid s?"}}
{"translation": {"code": "public synchronized void close ( ) { if ( closed ) return ; // recursive calls ok closed = true ; // mark as closed to prevent recursive calls if ( methodstream != null ) { try { this . methodstream . close ( ) ; // May recursr } catch ( IOException ioe ) { /*failure is ok*/ } this . methodstream = null ; } // Force release underlying connection back to the connection manager if ( this . lastresponse != null ) { if ( false ) { try { try { // Attempt to keep connection alive by consuming its remaining content EntityUtils . consume ( this . lastresponse . getEntity ( ) ) ; } finally { HttpClientUtils . closeQuietly ( this . lastresponse ) ; // Paranoia } } catch ( IOException ignore ) { /*ignore*/ } } else HttpClientUtils . closeQuietly ( this . lastresponse ) ; this . lastresponse = null ; } if ( session != null ) { session . removeMethod ( this ) ; if ( localsession ) { session . close ( ) ; session = null ; } } this . lastrequest = null ; }", "nl": "Calling close will force the method to close and will force any open stream to terminate . If the session is local Then that too will be closed ."}}
{"translation": {"code": "static protected synchronized void track ( HTTPSession session ) { if ( ! TESTING ) throw new UnsupportedOperationException ( ) ; if ( sessionList == null ) sessionList = new ConcurrentSkipListSet < HTTPSession > ( ) ; sessionList . add ( session ) ; }", "nl": "If we are testing then track the sessions for kill"}}
{"translation": {"code": "synchronized public void close ( ) { if ( this . closed ) return ; // multiple calls ok closed = true ; for ( HTTPMethod m : this . methods ) { m . close ( ) ; // forcibly close; will invoke removemethod(). } methods . clear ( ) ; }", "nl": "Close the session . This implies closing any open methods ."}}
{"translation": {"code": "public HTTPSession setMaxRedirects ( int n ) { if ( n < 0 ) //validate throw new IllegalArgumentException ( \"setMaxRedirects\" ) ; localsettings . put ( Prop . MAX_REDIRECTS , n ) ; this . cachevalid = false ; return this ; }", "nl": "Set the max number of redirects to follow"}}
{"translation": {"code": "public boolean isValidFile ( ucar . unidata . io . RandomAccessFile raf ) { NOWRadheader localHeader = new NOWRadheader ( ) ; return ( localHeader . isValidFile ( raf ) ) ; }", "nl": "checking the file"}}
{"translation": {"code": "public void open ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile file , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { super . open ( raf , ncfile , cancelTask ) ; headerParser = new NOWRadheader ( ) ; try { headerParser . read ( this . raf , ncfile ) ; } catch ( Exception e ) { } // myInfo = headerParser.getVarInfo();\r pcode = 0 ; ncfile . finish ( ) ; }", "nl": "Open the file and read the header part"}}
{"translation": {"code": "public Array readData ( Variable v2 , Section section ) throws IOException , InvalidRangeException { // subset\r Object data ; Array outputData ; byte [ ] vdata = null ; NOWRadheader . Vinfo vinfo ; ByteBuffer bos ; List < Range > ranges = section . getRanges ( ) ; vinfo = ( NOWRadheader . Vinfo ) v2 . getSPobject ( ) ; vdata = headerParser . getData ( ( int ) vinfo . hoff ) ; bos = ByteBuffer . wrap ( vdata ) ; data = readOneScanData ( bos , vinfo , v2 . getShortName ( ) ) ; outputData = Array . factory ( v2 . getDataType ( ) , v2 . getShape ( ) , data ) ; outputData = outputData . flip ( 1 ) ; // outputData = outputData.flip(2);\r return ( outputData . sectionNoReduce ( ranges ) . copy ( ) ) ; // return outputData;\r }", "nl": "Read the data for each variable passed in"}}
{"translation": {"code": "public byte [ ] readOneRowData ( byte [ ] ddata , int rLen , int xt ) throws IOException , InvalidRangeException { int run ; byte [ ] bdata = new byte [ xt ] ; int nbin = 0 ; int total = 0 ; for ( run = 0 ; run < rLen ; run ++ ) { int drun = DataType . unsignedByteToShort ( ddata [ run ] ) >> 4 ; byte dcode1 = ( byte ) ( DataType . unsignedByteToShort ( ddata [ run ] ) & 0Xf ) ; for ( int i = 0 ; i < drun ; i ++ ) { bdata [ nbin ++ ] = dcode1 ; total ++ ; } } if ( total < xt ) { for ( run = total ; run < xt ; run ++ ) { bdata [ run ] = 0 ; } } return bdata ; }", "nl": "Read data from encoded values and run len into regular data array"}}
{"translation": {"code": "static public boolean iospRegistered ( Class iospClass ) { for ( IOServiceProvider spi : registeredProviders ) { if ( spi . getClass ( ) == iospClass ) return true ; } return false ; }", "nl": "See if a specific IOServiceProvider is registered"}}
{"translation": {"code": "@ Override public void eject ( Object hashKey ) { if ( disabled . get ( ) ) return ; // see if its in the cache\r CacheElement wantCacheElem = cache . get ( hashKey ) ; if ( wantCacheElem == null ) return ; synchronized ( wantCacheElem ) { // synch in order to traverse the list\r for ( CacheElement . CacheFile want : wantCacheElem . list ) { // LOOK can we use remove(want);  ??\r files . remove ( want . ncfile ) ; try { want . ncfile . setFileCache ( null ) ; // unhook the caching\r want . ncfile . close ( ) ; // really close the file\r log . debug ( \"close \" + want . ncfile . getLocation ( ) ) ; } catch ( IOException e ) { log . error ( \"close failed on \" + want . ncfile . getLocation ( ) , e ) ; } want . ncfile = null ; if ( debugPrint ) System . out . println ( \"  FileCache \" + name + \" eject \" + hashKey ) ; } wantCacheElem . list . clear ( ) ; } cache . remove ( hashKey ) ; }", "nl": "Remove all instances of object from the cache"}}
{"translation": {"code": "private boolean readBuffer ( InputStream is , byte [ ] dest , int start , int want ) throws IOException { int done = 0 ; while ( done < want ) { int got = is . read ( dest , start + done , want - done ) ; if ( got < 0 ) return false ; done += got ; } if ( showRead ) System . out . println ( \"Read buffer at \" + bytesRead + \" len=\" + done ) ; bytesRead += done ; return true ; }", "nl": "read into dest byte array until buffer is full or end of stream"}}
{"translation": {"code": "public void processStream ( InputStream is ) throws IOException { int pos = - 1 ; Buffer b = null ; while ( true ) { b = ( pos < 0 ) ? readBuffer ( is ) : readBuffer ( is , b , pos ) ; pos = processBuffer ( b , is ) ; if ( b . done ) break ; } }", "nl": "process all the bytes in the stream"}}
{"translation": {"code": "public void scanLogFile ( File file , Closure closure , LogFilter logf , Stats stat ) throws IOException { try ( InputStream ios = new FileInputStream ( file ) ) { System . out . printf ( \"-----Reading %s %n\" , file . getPath ( ) ) ; BufferedReader dataIS = new BufferedReader ( new InputStreamReader ( ios , CDM . utf8Charset ) , 40 * 1000 ) ; int total = 0 ; int count = 0 ; while ( ( maxLines < 0 ) || ( count < maxLines ) ) { Log log = parser . nextLog ( dataIS ) ; if ( log == null ) break ; total ++ ; if ( ( logf != null ) && ! logf . pass ( log ) ) continue ; closure . process ( log ) ; count ++ ; } if ( stat != null ) { stat . total += total ; stat . passed += count ; } System . out . printf ( \"----- %s total requests=%d passed=%d %n\" , file . getPath ( ) , total , count ) ; } }", "nl": "Read a log file ."}}
{"translation": {"code": "static public String getServiceSpecial ( String path ) { String ss = null ; if ( path . startsWith ( \"/dqcServlet\" ) ) ss = \"dqcServlet\" ; else if ( path . startsWith ( \"/cdmvalidator\" ) ) ss = \"cdmvalidator\" ; return ss ; }", "nl": "the ones that dont start with thredds"}}
{"translation": {"code": "public void readAll ( File dir , FileFilter ff , Closure closure , LogFilter logf , Stats stat ) throws IOException { File [ ] files = dir . listFiles ( ) ; if ( files == null ) { System . out . printf ( \"Dir has no files= %s%n\" , dir ) ; return ; } List < File > list = Arrays . asList ( files ) ; Collections . sort ( list ) ; for ( File f : list ) { if ( ( ff != null ) && ! ff . accept ( f ) ) continue ; if ( f . isDirectory ( ) ) readAll ( f , ff , closure , logf , stat ) ; else scanLogFile ( f , closure , logf , stat ) ; } }", "nl": "Read all the files in a directory and process them . Files are sorted by filename ."}}
{"translation": {"code": "public static void main ( String [ ] args ) throws IOException { AccessLogParser p = new AccessLogParser ( ) ; String line = \"24.18.236.132 - - [04/Feb/2011:17:49:03 -0700] \\\"GET /thredds/fileServer//nexrad/level3/N0R/YUX/20110205/Level3_YUX_N0R_20110205_0011.nids \\\" 200 10409 \\\"-\\\" \\\"-\\\" 17\" ; Matcher m = regPattern . matcher ( line ) ; System . out . printf ( \"%s %s%n\" , m . matches ( ) , m ) ; for ( int i = 0 ; i < m . groupCount ( ) ; i ++ ) { System . out . println ( \" \" + i + \" \" + m . group ( i ) ) ; } LogReader . Log log = p . parseLog ( line ) ; System . out . printf ( \"%s%n\" , log ) ; }", "nl": "try problem logs"}}
{"translation": {"code": "public void abort ( ) throws java . io . IOException { if ( spiw != null ) { spiw . close ( ) ; spiw = null ; } }", "nl": "Abort writing to this file . The file is closed ."}}
{"translation": {"code": "static synchronized public void closeAll ( ) { List < MetadataManager > closeDatabases = new ArrayList <> ( openDatabases ) ; for ( MetadataManager mm : closeDatabases ) { if ( debug ) System . out . println ( \"  close database \" + mm . collectionName ) ; mm . close ( ) ; } openDatabases = new ArrayList <> ( ) ; // empty if ( myEnv != null ) { try { // Finally, close the store and environment. myEnv . close ( ) ; myEnv = null ; logger . info ( \"closed bdb caching\" ) ; } catch ( DatabaseException dbe ) { logger . error ( \"Error closing bdb: \" , dbe ) ; } } }", "nl": "this is called on TDS shutdown and reinit"}}
{"translation": {"code": "private synchronized void openDatabase ( ) { if ( database != null ) return ; DatabaseConfig dbConfig = new DatabaseConfig ( ) ; dbConfig . setReadOnly ( readOnly ) ; dbConfig . setAllowCreate ( ! readOnly ) ; if ( ! readOnly ) dbConfig . setDeferredWrite ( true ) ; database = myEnv . openDatabase ( null , collectionName , dbConfig ) ; openDatabases . add ( this ) ; }", "nl": "assumes only one open at a time ; could have MetadataManagers share open databases"}}
{"translation": {"code": "boolean readPIB ( RandomAccessFile raf ) throws IOException { this . firstHeader = new AwxFileFirstHeader ( ) ; int pos = 0 ; raf . seek ( pos ) ; // gini header process byte [ ] buf = new byte [ FY_AWX_PIB_LEN ] ; int count = raf . read ( buf ) ; EndianByteBuffer byteBuffer ; if ( count == FY_AWX_PIB_LEN ) { byteBuffer = new EndianByteBuffer ( buf , this . firstHeader . byteOrder ) ; this . firstHeader . fillHeader ( byteBuffer ) ; } else { return false ; } if ( ! ( ( this . firstHeader . fileName . endsWith ( \".AWX\" ) || this . firstHeader . fileName . endsWith ( \".awx\" ) ) && this . firstHeader . firstHeaderLength == FY_AWX_PIB_LEN ) ) { return false ; } // skip the fills of the first record //  raf.seek(FY_AWX_PIB_LEN + this.firstHeader.fillSectionLength); buf = new byte [ this . firstHeader . secondHeaderLength ] ; raf . readFully ( buf ) ; byteBuffer = new EndianByteBuffer ( buf , this . firstHeader . byteOrder ) ; switch ( this . firstHeader . typeOfProduct ) { case AwxFileFirstHeader . AWX_PRODUCT_TYPE_UNDEFINED : throw new UnsupportedDatasetException ( ) ; case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GEOSAT_IMAGE : secondHeader = new AwxFileGeoSatelliteSecondHeader ( ) ; secondHeader . fillHeader ( byteBuffer ) ; break ; case AwxFileFirstHeader . AWX_PRODUCT_TYPE_POLARSAT_IMAGE : throw new UnsupportedDatasetException ( ) ; case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GRID : secondHeader = new AwxFileGridProductSecondHeader ( ) ; secondHeader . fillHeader ( byteBuffer ) ; break ; case AwxFileFirstHeader . AWX_PRODUCT_TYPE_DISCREET : throw new UnsupportedDatasetException ( ) ; case AwxFileFirstHeader . AWX_PRODUCT_TYPE_GRAPH_ANALIYSIS : throw new UnsupportedDatasetException ( ) ; } return true ; }", "nl": "Read the header and populate the ncfile"}}
{"translation": {"code": "static public XMLStore createFromInputStream ( InputStream is1 , InputStream is2 , XMLStore storedDefaults ) throws java . io . IOException { if ( debugWhichStore ) System . out . println ( \"XMLStore read from input stream \" + is1 ) ; return new XMLStore ( is1 , is2 , storedDefaults ) ; }", "nl": "Create an XMLStore reading from an input stream . Because of some peculiariteis you must open the input stream wtice and pass both in ."}}
{"translation": {"code": "static public XMLStore createFromResource ( String resourceName , XMLStore storedDefaults ) throws java . io . IOException { // open files if exist Class c = XMLStore . class ; InputStream primIS = c . getResourceAsStream ( resourceName ) ; InputStream objIS = c . getResourceAsStream ( resourceName ) ; // debug //    InputStream debugIS = c.getResourceAsStream(fileName); //  System.out.println(\"Resource stream= \"+fileName); //thredds.util.IO.copy(debugIS, System.out); if ( primIS == null ) { //System.out.println(\"classLoader=\"+new XMLStore().getClass().getClassLoader()); throw new java . io . IOException ( \"XMLStore.createFromResource cant find <\" + resourceName + \">\" ) ; } if ( debugWhichStore ) System . out . println ( \"XMLStore read from resource \" + resourceName ) ; return new XMLStore ( primIS , objIS , storedDefaults ) ; }", "nl": "Create a read - only XMLStore reading from the specified resource opened as a Resource stream using the XMLStore ClassLoader . This allows you to find files that are in jar files on the application CLASSPATH ."}}
{"translation": {"code": "public void save ( ) throws java . io . IOException { if ( prefsFile == null ) throw new UnsupportedOperationException ( \"XMLStore is read-only\" ) ; // get temporary file to write to File prefTemp ; String parentFilename = prefsFile . getParent ( ) ; if ( parentFilename == null ) { prefTemp = File . createTempFile ( \"pref\" , \".xml\" ) ; } else { File parentFile = new File ( parentFilename ) ; prefTemp = File . createTempFile ( \"pref\" , \".xml\" , parentFile ) ; } prefTemp . deleteOnExit ( ) ; // save to the temp file FileOutputStream fos = new FileOutputStream ( prefTemp , false ) ; save ( fos ) ; fos . close ( ) ; // success - rename files Path xmlBackup = Paths . get ( prefsFile . getAbsolutePath ( ) + \".bak\" ) ; Path prefsPath = prefsFile . toPath ( ) ; if ( Files . exists ( prefsPath ) ) Files . move ( prefsPath , xmlBackup , StandardCopyOption . REPLACE_EXISTING ) ; Files . move ( prefTemp . toPath ( ) , prefsFile . toPath ( ) , StandardCopyOption . REPLACE_EXISTING ) ; }", "nl": "Save the current state of the Preferences tree to disk using the original filename . The XMLStore must have been constructed from a writeable XML file ."}}
{"translation": {"code": "public void save ( OutputStream out ) throws java . io . IOException { outputExceptionMessage = null ; // the OutputMunger strips off the XMLEncoder header OutputMunger bos = new OutputMunger ( out ) ; PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( bos , CDM . utf8Charset ) ) ; XMLEncoder beanEncoder = new XMLEncoder ( bos ) ; beanEncoder . setExceptionListener ( new ExceptionListener ( ) { public void exceptionThrown ( Exception exception ) { System . out . println ( \"XMLStore.save() got Exception: abort saving the preferences!\" ) ; exception . printStackTrace ( ) ; outputExceptionMessage = exception . getMessage ( ) ; } } ) ; pw . printf ( \"<?xml version='1.0' encoding='UTF-8'?>%n\" ) ; pw . printf ( \"<preferences EXTERNAL_XML_VERSION='1.0'>%n\" ) ; if ( ! rootPrefs . isUserNode ( ) ) pw . printf ( \"  <root type='system'>%n\" ) ; else pw . printf ( \"  <root type='user'>%n\" ) ; Indent indent = new Indent ( 2 ) ; indent . incr ( ) ; writeXmlNode ( bos , pw , rootPrefs , beanEncoder , indent ) ; if ( outputExceptionMessage != null ) throw new IOException ( outputExceptionMessage ) ; pw . printf ( \"  </root>%n\" ) ; pw . printf ( \"</preferences>%n\" ) ; pw . flush ( ) ; }", "nl": "Save the current state of the Preferences tree to the given OutputStream ."}}
{"translation": {"code": "public void putBeanCollection ( String key , Collection newValue ) { // if matches a stored Default, dont store Object oldValue = getBean ( key , null ) ; if ( ( oldValue == null ) || ! oldValue . equals ( newValue ) ) keyValues . put ( key , new Bean . Collection ( newValue ) ) ; }", "nl": "Stores a Collection of beans . The beans are stored using simple bean properties . The collection of beans must all be of the same class ."}}
{"translation": {"code": "private Object _getObject ( String keyName ) { Object result = null ; try { result = keyValues . get ( keyName ) ; if ( result == null ) { // if failed, check the stored Defaults PreferencesExt sd = getStoredDefaults ( ) ; if ( sd != null ) result = sd . getObjectFromNode ( absolutePath ( ) , keyName ) ; } } catch ( Exception e ) { // Ignoring exception causes default to be returned } return result ; }", "nl": "assume key non - null locked node"}}
{"translation": {"code": "public List getList ( String key , List def ) { try { Object bean = getBean ( key , def ) ; return ( List ) bean ; } catch ( Exception e ) { e . printStackTrace ( ) ; return null ; } }", "nl": "Get an arrayList . This returns a copy of the stored list ."}}
{"translation": {"code": "static public XMLStore createFromFile ( String fileName , XMLStore storedDefaults ) throws java . io . IOException { File prefsFile = new File ( fileName ) ; // open file if it exists InputStream primIS = null , objIS = null ; if ( prefsFile . exists ( ) && prefsFile . length ( ) > 0 ) { primIS = new BufferedInputStream ( new FileInputStream ( prefsFile ) ) ; objIS = new BufferedInputStream ( new FileInputStream ( prefsFile ) ) ; } if ( debugWhichStore ) System . out . println ( \"XMLStore read from file \" + fileName ) ; XMLStore store = new XMLStore ( primIS , objIS , storedDefaults ) ; store . prefsFile = prefsFile ; return store ; }", "nl": "Create an XMLStore reading from the specified filename ."}}
{"translation": {"code": "static public String makeStandardFilename ( String appName , String storeName ) { // the directory String userHome = null ; try { userHome = System . getProperty ( \"user.home\" ) ; } catch ( Exception e ) { System . out . println ( \"XMLStore.makeStandardFilename: error System.getProperty(user.home) \" + e ) ; } if ( null == userHome ) userHome = \".\" ; String dirFilename = userHome + \"/\" + appName ; File f = new File ( dirFilename ) ; if ( ! f . exists ( ) ) { boolean ok = f . mkdirs ( ) ; // now ready for file creation in writeXML if ( ! ok ) System . out . println ( \"Error creating directories: \" + f . getAbsolutePath ( ) ) ; } return dirFilename + \"/\" + storeName ; }", "nl": "Convenience routine for creating an XMLStore file in a standard place ."}}
{"translation": {"code": "public void writeProperties ( PrintWriter out ) throws IOException { if ( p == null ) p = BeanParser . getParser ( o . getClass ( ) ) ; p . writeProperties ( o , out ) ; }", "nl": "write XML using the bean properties of the contained object"}}
{"translation": {"code": "private double readScaledInt ( ByteBuffer buf ) { // Get the first two bytes short s1 = buf . getShort ( ) ; // And the last one as unsigned short s2 = DataType . unsignedByteToShort ( buf . get ( ) ) ; // Get the sign bit, converting from 0 or 2 to +/- 1. int posneg = 1 - ( ( s1 & 0x8000 ) >> 14 ) ; // Combine the first two bytes (without sign bit) with the last byte. // Multiply by proper factor for +/- int nn = ( ( ( s1 & 0x7FFF ) << 8 ) | s2 ) * posneg ; return ( double ) nn / 10000.0 ; }", "nl": "Read a scaled 3 - byte integer from file and convert to double"}}
{"translation": {"code": "String gini_GetSectorID ( int ent_id ) { String name ; switch ( ent_id ) { case 0 : name = \"Northern Hemisphere Composite\" ; break ; case 1 : name = \"East CONUS\" ; break ; case 2 : name = \"West CONUS\" ; break ; case 3 : name = \"Alaska Regional\" ; break ; case 4 : name = \"Alaska National\" ; break ; case 5 : name = \"Hawaii Regional\" ; break ; case 6 : name = \"Hawaii National\" ; break ; case 7 : name = \"Puerto Rico Regional\" ; break ; case 8 : name = \"Puerto Rico National\" ; break ; case 9 : name = \"Supernational\" ; break ; case 10 : name = \"NH Composite - Meteosat/GOES E/ GOES W/GMS\" ; break ; case 11 : name = \"Central CONUS\" ; break ; case 12 : name = \"East Floater\" ; break ; case 13 : name = \"West Floater\" ; break ; case 14 : name = \"Central Floater\" ; break ; case 15 : name = \"Polar Floater\" ; break ; default : name = \"Unknown-ID\" ; } return name ; }", "nl": "Return the string of Sector for the GINI image file"}}
{"translation": {"code": "private double [ ] addCoordAxis ( NetcdfFile ncfile , String name , int n , double start , double incr , String units , String desc , String standard_name , AxisType axis ) { // ncfile.addDimension(g, new Dimension(name, n, true)); Variable v = new Variable ( ncfile , g , null , name ) ; v . setDataType ( DataType . DOUBLE ) ; v . setDimensions ( name ) ; // create the data double [ ] data = new double [ n ] ; for ( int i = 0 ; i < n ; i ++ ) { data [ i ] = start + incr * i ; } Array dataArray = Array . factory ( DataType . DOUBLE , new int [ ] { n } , data ) ; v . setCachedData ( dataArray , false ) ; v . addAttribute ( new Attribute ( \"units\" , units ) ) ; v . addAttribute ( new Attribute ( \"long_name\" , desc ) ) ; v . addAttribute ( new Attribute ( \"standard_name\" , standard_name ) ) ; v . addAttribute ( new Attribute ( \"grid_spacing\" , incr + \" \" + units ) ) ; v . addAttribute ( new Attribute ( _Coordinate . AxisType , axis . toString ( ) ) ) ; ncfile . addVariable ( g , v ) ; return data ; }", "nl": "Add a coordinate axis"}}
{"translation": {"code": "private boolean makeProjection ( NetcdfFile ncfile , int projType ) { switch ( projType ) { case GridTableLookup . RotatedLatLon : makeRotatedLatLon ( ncfile ) ; break ; case GridTableLookup . PolarStereographic : makePS ( ) ; break ; case GridTableLookup . LambertConformal : makeLC ( ) ; break ; case GridTableLookup . Mercator : makeMercator ( ) ; break ; case GridTableLookup . Orthographic : //makeSpaceViewOrOthographic(); makeMSGgeostationary ( ) ; break ; case GridTableLookup . Curvilinear : makeCurvilinearAxis ( ncfile ) ; break ; default : throw new UnsupportedOperationException ( \"unknown projection = \" + gds . getInt ( GridDefRecord . GRID_TYPE ) ) ; } // dummy coordsys variable Variable v = new Variable ( ncfile , g , null , grid_name ) ; v . setDataType ( DataType . CHAR ) ; v . setDimensions ( \"\" ) ; // scalar char [ ] data = new char [ ] { ' ' } ; Array dataArray = Array . factory ( DataType . CHAR , new int [ 0 ] , data ) ; v . setCachedData ( dataArray , false ) ; for ( Attribute att : attributes ) v . addAttribute ( att ) ; // add CF Conventions attributes v . addAttribute ( new Attribute ( GridCF . EARTH_SHAPE , shape_name ) ) ; // LOOK - spherical earth ?? double radius_spherical_earth = gds . getDouble ( GridDefRecord . RADIUS_SPHERICAL_EARTH ) ; // have to check both because Grib1 and Grib2 used different names if ( Double . isNaN ( radius_spherical_earth ) ) radius_spherical_earth = gds . getDouble ( \"radius_spherical_earth\" ) ; if ( ! Double . isNaN ( radius_spherical_earth ) ) { //inconsistent - sometimes in km, sometimes in m. if ( radius_spherical_earth < 10000.00 ) // then its in km radius_spherical_earth *= 1000.0 ; // convert to meters v . addAttribute ( new Attribute ( GridCF . EARTH_RADIUS , radius_spherical_earth ) ) ; //this attribute needs to be meters } else { // oblate earth double major_axis = gds . getDouble ( GridDefRecord . MAJOR_AXIS_EARTH ) ; if ( Double . isNaN ( major_axis ) ) major_axis = gds . getDouble ( \"major_axis_earth\" ) ; double minor_axis = gds . getDouble ( GridDefRecord . MINOR_AXIS_EARTH ) ; if ( Double . isNaN ( minor_axis ) ) minor_axis = gds . getDouble ( \"minor_axis_earth\" ) ; if ( ! Double . isNaN ( major_axis ) && ! Double . isNaN ( minor_axis ) ) { v . addAttribute ( new Attribute ( GridCF . SEMI_MAJOR_AXIS , major_axis ) ) ; v . addAttribute ( new Attribute ( GridCF . SEMI_MINOR_AXIS , minor_axis ) ) ; } } addGDSparams ( v ) ; ncfile . addVariable ( g , v ) ; return true ; }", "nl": "Make a projection and add it to the netCDF file"}}
{"translation": {"code": "private void addGDSparams ( Variable v ) { // add all the gds parameters List < String > keyList = new ArrayList <> ( gds . getKeys ( ) ) ; Collections . sort ( keyList ) ; String pre = getGDSprefix ( ) ; for ( String key : keyList ) { String name = pre + \"_param_\" + key ; String vals = gds . getParam ( key ) ; try { int vali = Integer . parseInt ( vals ) ; if ( key . equals ( GridDefRecord . VECTOR_COMPONENT_FLAG ) ) { String cf = GridCF . VectorComponentFlag . of ( vali ) ; v . addAttribute ( new Attribute ( name , cf ) ) ; } else { v . addAttribute ( new Attribute ( name , vali ) ) ; } } catch ( Exception e ) { try { double vald = Double . parseDouble ( vals ) ; v . addAttribute ( new Attribute ( name , vald ) ) ; } catch ( Exception e2 ) { v . addAttribute ( new Attribute ( name , vals ) ) ; } } } }", "nl": "Add the GDS params to the variable as attributes"}}
{"translation": {"code": "private void makeLC ( ) { // we have to project in order to find the origin proj = new LambertConformal ( gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LOV ) , gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LATIN2 ) ) ; LatLonPointImpl startLL = new LatLonPointImpl ( gds . getDouble ( GridDefRecord . LA1 ) , gds . getDouble ( GridDefRecord . LO1 ) ) ; ProjectionPointImpl start = ( ProjectionPointImpl ) proj . latLonToProj ( startLL ) ; startx = start . getX ( ) ; starty = start . getY ( ) ; if ( Double . isNaN ( getDxInKm ( ) ) ) { setDxDy ( startx , starty , proj ) ; } if ( GridServiceProvider . debugProj ) { System . out . println ( \"GridHorizCoordSys.makeLC start at latlon \" + startLL ) ; double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) ; double La2 = gds . getDouble ( GridDefRecord . LA2 ) ; LatLonPointImpl endLL = new LatLonPointImpl ( La2 , Lo2 ) ; System . out . println ( \"GridHorizCoordSys.makeLC end at latlon \" + endLL ) ; ProjectionPointImpl endPP = ( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; System . out . println ( \"   end at proj coord \" + endPP ) ; double endx = startx + getNx ( ) * getDxInKm ( ) ; double endy = starty + getNy ( ) * getDyInKm ( ) ; System . out . println ( \"   should be x=\" + endx + \" y=\" + endy ) ; } attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , \"lambert_conformal_conic\" ) ) ; if ( gds . getDouble ( GridDefRecord . LATIN1 ) == gds . getDouble ( GridDefRecord . LATIN2 ) ) { attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , gds . getDouble ( GridDefRecord . LATIN1 ) ) ) ; } else { double [ ] data = new double [ ] { gds . getDouble ( GridDefRecord . LATIN1 ) , gds . getDouble ( GridDefRecord . LATIN2 ) } ; attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , Array . factory ( DataType . DOUBLE , new int [ ] { 2 } , data ) ) ) ; } //attributes.add(new Attribute(\"longitude_of_central_meridian\", attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_CENTRAL_MERIDIAN , gds . getDouble ( GridDefRecord . LOV ) ) ) ; //attributes.add(new Attribute(\"latitude_of_projection_origin\", attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , gds . getDouble ( GridDefRecord . LATIN1 ) ) ) ; }", "nl": "Make a LambertConformalConic projection"}}
{"translation": {"code": "private void makePS ( ) { String nproj = gds . getParam ( GridDefRecord . NPPROJ ) ; double latOrigin = ( nproj == null || nproj . equalsIgnoreCase ( \"true\" ) ) ? 90.0 : - 90.0 ; // Why the scale factor?. according to GRIB docs: // \"Grid lengths are in units of meters, at the 60 degree latitude circle nearest to the pole\" // since the scale factor at 60 degrees = k = 2*k0/(1+sin(60))  [Snyder,Working Manual p157] // then to make scale = 1 at 60 degrees, k0 = (1+sin(60))/2 = .933 double scale ; double lad = gds . getDouble ( GridDefRecord . LAD ) ; if ( Double . isNaN ( lad ) ) { scale = .933 ; } else { scale = ( 1.0 + Math . sin ( Math . toRadians ( Math . abs ( lad ) ) ) ) / 2 ; } proj = new Stereographic ( latOrigin , gds . getDouble ( GridDefRecord . LOV ) , scale ) ; // we have to project in order to find the origin ProjectionPointImpl start = ( ProjectionPointImpl ) proj . latLonToProj ( new LatLonPointImpl ( gds . getDouble ( GridDefRecord . LA1 ) , gds . getDouble ( GridDefRecord . LO1 ) ) ) ; startx = start . getX ( ) ; starty = start . getY ( ) ; if ( Double . isNaN ( getDxInKm ( ) ) ) setDxDy ( startx , starty , proj ) ; if ( GridServiceProvider . debugProj ) { System . out . printf ( \"starting proj coord %s lat/lon %s%n\" , start , proj . projToLatLon ( start ) ) ; System . out . println ( \"   should be LA1=\" + gds . getDouble ( GridDefRecord . LA1 ) + \" l)1=\" + gds . getDouble ( GridDefRecord . LO1 ) ) ; } attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , \"polar_stereographic\" ) ) ; //attributes.add(new Attribute(\"longitude_of_projection_origin\", attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , gds . getDouble ( GridDefRecord . LOV ) ) ) ; //attributes.add(new Attribute(\"straight_vertical_longitude_from_pole\", attributes . add ( new Attribute ( GridCF . STRAIGHT_VERTICAL_LONGITUDE_FROM_POLE , gds . getDouble ( GridDefRecord . LOV ) ) ) ; //attributes.add(new Attribute(\"scale_factor_at_projection_origin\", attributes . add ( new Attribute ( GridCF . SCALE_FACTOR_AT_PROJECTION_ORIGIN , scale ) ) ; attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , latOrigin ) ) ; }", "nl": "Make a PolarStereographic projection"}}
{"translation": {"code": "static public void setExtendIndex ( boolean b ) { indexFileModeOnOpen = b ? IndexExtendMode . extendwrite : IndexExtendMode . readonly ; indexFileModeOnSync = b ? IndexExtendMode . extendwrite : IndexExtendMode . readonly ; }", "nl": "Set how indexes are used for both open and sync"}}
{"translation": {"code": "private void makeMSGgeostationary ( ) { double Lat0 = gds . getDouble ( GridDefRecord . LAP ) ; // sub-satellite point lat double Lon0 = gds . getDouble ( GridDefRecord . LOP ) ; // sub-satellite point lon //int nx = gds.getInt(GridDefRecord.NX); int ny = gds . getInt ( GridDefRecord . NY ) ; int x_off = gds . getInt ( GridDefRecord . XP ) ; // sub-satellite point in grid lengths int y_off = gds . getInt ( GridDefRecord . YP ) ; double dx ; // = gds.getDouble(GridDefRecord.DX);  // apparent diameter of earth in units of grid lengths double dy = gds . getDouble ( GridDefRecord . DY ) ; // per Simon Eliot 1/18/2010, there is a bug in Eumetsat grib files, // we need to \"correct for ellipsoidal earth\" // (Note we should check who the originating center is // \"Originating_center\" = \"EUMETSAT Operation Centre\" in the GRIB id (section 1)) // although AFAIK, eumetsat is only one using this projection. if ( dy < 2100 ) { dx = 1207 ; dy = 1203 ; } else { dx = 3622 ; dy = 3610 ; } // have to check both names because Grib1 and Grib2 used different names double major_axis = gds . getDouble ( GridDefRecord . MAJOR_AXIS_EARTH ) ; // m if ( Double . isNaN ( major_axis ) ) major_axis = gds . getDouble ( \"major_axis_earth\" ) ; double minor_axis = gds . getDouble ( GridDefRecord . MINOR_AXIS_EARTH ) ; // m if ( Double . isNaN ( minor_axis ) ) minor_axis = gds . getDouble ( \"minor_axis_earth\" ) ; // Nr = altitude of camera from center, in units of radius double nr = gds . getDouble ( GridDefRecord . NR ) * 1e-6 ; // altitude of the camera from the Earths centre, measured in units of the Earth (equatorial) radius // CFAC = 2^16 / {[2 * arcsine (10^6 / Nr)] / dx } double as = 2 * Math . asin ( 1.0 / nr ) ; double cfac = dx / as ; double lfac = dy / as ; // use km, so scale by the earth radius double scale_factor = ( nr - 1 ) * major_axis / 1000 ; // this sets the units of the projection x,y coords in km double scale_x = scale_factor ; // LOOK fake neg need scan value double scale_y = - scale_factor ; // LOOK fake neg need scan value startx = scale_factor * ( 1 - x_off ) / cfac ; starty = scale_factor * ( y_off - ny ) / lfac ; incrx = scale_factor / cfac ; incry = scale_factor / lfac ; attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , \"MSGnavigation\" ) ) ; attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , Lon0 ) ) ; attributes . add ( new Attribute ( GridCF . LATITUDE_OF_PROJECTION_ORIGIN , Lat0 ) ) ; //attributes.add(new Attribute(\"semi_major_axis\", new Double(major_axis))); //attributes.add(new Attribute(\"semi_minor_axis\", new Double(minor_axis))); attributes . add ( new Attribute ( \"height_from_earth_center\" , nr * major_axis ) ) ; attributes . add ( new Attribute ( \"scale_x\" , scale_x ) ) ; attributes . add ( new Attribute ( \"scale_y\" , scale_y ) ) ; proj = new MSGnavigation ( Lat0 , Lon0 , major_axis , minor_axis , nr * major_axis , scale_x , scale_y ) ; if ( GridServiceProvider . debugProj ) { double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) + 360.0 ; double La2 = gds . getDouble ( GridDefRecord . LA2 ) ; LatLonPointImpl endLL = new LatLonPointImpl ( La2 , Lo2 ) ; System . out . println ( \"GridHorizCoordSys.makeMSGgeostationary end at latlon \" + endLL ) ; ProjectionPointImpl endPP = ( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; System . out . println ( \"   end at proj coord \" + endPP ) ; double endx = 1 + getNx ( ) ; double endy = 1 + getNy ( ) ; System . out . println ( \"   should be x=\" + endx + \" y=\" + endy ) ; } }", "nl": "Make a Eumetsat MSG Normalized Geostationary Projection projection . Fake coordinates for now then see if this can be generalized ."}}
{"translation": {"code": "protected String makeLongName ( ) { Formatter f = new Formatter ( ) ; GridParameter param = lookup . getParameter ( firstRecord ) ; if ( param == null ) return null ; f . format ( \"%s\" , param . getDescription ( ) ) ; String levelName = makeLevelName ( firstRecord , lookup ) ; if ( levelName . length ( ) != 0 ) f . format ( \" @ %s\" , levelName ) ; return f . toString ( ) ; }", "nl": "Make a long name for the variable"}}
{"translation": {"code": "public String dump ( ) { DateFormatter formatter = new DateFormatter ( ) ; Formatter sbuff = new Formatter ( ) ; sbuff . format ( \"%s %d %n\" , name , records . size ( ) ) ; for ( GridRecord record : records ) { sbuff . format ( \" level = %d %f\" , record . getLevelType1 ( ) , record . getLevel1 ( ) ) ; if ( null != record . getValidTime ( ) ) sbuff . format ( \" time = %s\" , formatter . toDateTimeString ( record . getValidTime ( ) ) ) ; sbuff . format ( \"%n\" ) ; } return sbuff . toString ( ) ; }", "nl": "Dump this variable"}}
{"translation": {"code": "public GridRecord findRecord ( int ens , int time , int level ) { if ( hasEnsemble ( ) ) { return recordTracker [ ens * ( ntimes * nlevels ) + ( time * nlevels ) + level ] ; } else { return recordTracker [ time * nlevels + level ] ; } }", "nl": "Find the grid record for the time and level indices Canonical ordering is ens time level"}}
{"translation": {"code": "public int showMissingSummary ( Formatter f ) { int count = 0 ; int total = recordTracker . length ; for ( int i = 0 ; i < total ; i ++ ) { if ( recordTracker [ i ] == null ) count ++ ; } f . format ( \"  MISSING= %d / %d for %s%n\" , count , total , name ) ; return count ; }", "nl": "Dump out the missing data as a summary"}}
{"translation": {"code": "public void showMissing ( Formatter f ) { //System.out.println(\"  \" +name+\" ntimes (across)= \"+ ntimes+\" nlevs (down)= \"+ nlevels+\":\"); int count = 0 , total = 0 ; f . format ( \"  %s%n\" , name ) ; for ( int j = 0 ; j < nlevels ; j ++ ) { f . format ( \"   \" ) ; for ( int i = 0 ; i < ntimes ; i ++ ) { boolean missing = recordTracker [ i * nlevels + j ] == null ; f . format ( \"%s\" , missing ? \"-\" : \"X\" ) ; if ( missing ) count ++ ; total ++ ; } f . format ( \"%n\" ) ; } f . format ( \"  MISSING= %d / %d for %s%n\" , count , total , name ) ; }", "nl": "Dump out the missing data"}}
{"translation": {"code": "void addProduct ( GridRecord record ) { records . add ( record ) ; if ( firstRecord == null ) { firstRecord = record ; } }", "nl": "Add in a new product"}}
{"translation": {"code": "private void makeVerticalDimensions ( List < GridVertCoord > vertCoordList , NetcdfFile ncfile , Group group ) { // find biggest vert coord GridVertCoord gvcs0 = null ; int maxLevels = 0 ; for ( GridVertCoord gvcs : vertCoordList ) { if ( gvcs . getNLevels ( ) > maxLevels ) { gvcs0 = gvcs ; maxLevels = gvcs . getNLevels ( ) ; } } int seqno = 1 ; for ( GridVertCoord gvcs : vertCoordList ) { if ( gvcs != gvcs0 ) { gvcs . setSequence ( seqno ++ ) ; } gvcs . addDimensionsToNetcdfFile ( ncfile , group ) ; } }", "nl": "Make a vertical dimensions"}}
{"translation": {"code": "private void makeMercator ( ) { /**\n     * Construct a Mercator Projection.\n     * @param lon0 longitude of origin (degrees)\n     * @param par standard parallel (degrees). cylinder cuts earth at this latitude.\n     */ double Latin = gds . getDouble ( GridDefRecord . LAD ) ; // name depends on Grib version 1 or 2 if ( Double . isNaN ( Latin ) ) Latin = gds . getDouble ( GridDefRecord . LATIN ) ; double Lo1 = gds . getDouble ( GridDefRecord . LO1 ) ; //gds.Lo1; double La1 = gds . getDouble ( GridDefRecord . LA1 ) ; //gds.La1; // put longitude origin at first point - doesnt actually matter proj = new Mercator ( Lo1 , Latin ) ; // find out where ProjectionPoint startP = proj . latLonToProj ( new LatLonPointImpl ( La1 , Lo1 ) ) ; startx = startP . getX ( ) ; starty = startP . getY ( ) ; if ( Double . isNaN ( getDxInKm ( ) ) ) { setDxDy ( startx , starty , proj ) ; } attributes . add ( new Attribute ( GridCF . GRID_MAPPING_NAME , \"mercator\" ) ) ; attributes . add ( new Attribute ( GridCF . STANDARD_PARALLEL , Latin ) ) ; attributes . add ( new Attribute ( GridCF . LONGITUDE_OF_PROJECTION_ORIGIN , Lo1 ) ) ; if ( GridServiceProvider . debugProj ) { double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) ; if ( Lo2 < Lo1 ) Lo2 += 360 ; double La2 = gds . getDouble ( GridDefRecord . LA2 ) ; LatLonPointImpl endLL = new LatLonPointImpl ( La2 , Lo2 ) ; System . out . println ( \"GridHorizCoordSys.makeMercator: end at latlon= \" + endLL ) ; ProjectionPointImpl endPP = ( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; System . out . println ( \"   start at proj coord \" + new ProjectionPointImpl ( startx , starty ) ) ; System . out . println ( \"   end at proj coord \" + endPP ) ; double endx = startx + ( getNx ( ) - 1 ) * getDxInKm ( ) ; double endy = starty + ( getNy ( ) - 1 ) * getDyInKm ( ) ; System . out . println ( \"   should be x=\" + endx + \" y=\" + endy ) ; } }", "nl": "Make a Mercator projection"}}
{"translation": {"code": "private void addCoordSystemVariable ( NetcdfFile ncfile , String name , String dims ) { Variable v = new Variable ( ncfile , g , null , name ) ; v . setDataType ( DataType . CHAR ) ; v . setDimensions ( \"\" ) ; // scalar Array dataArray = Array . factory ( DataType . CHAR , new int [ 0 ] , new char [ ] { ' ' } ) ; v . setCachedData ( dataArray , false ) ; v . addAttribute ( new Attribute ( _Coordinate . Axes , dims ) ) ; if ( isLatLon ( ) ) v . addAttribute ( new Attribute ( _Coordinate . Transforms , \"\" ) ) ; // to make sure its identified as a Coordinate System Variable else v . addAttribute ( new Attribute ( _Coordinate . Transforms , getGridName ( ) ) ) ; addGDSparams ( v ) ; ncfile . addVariable ( g , v ) ; }", "nl": "Add coordinate system variable"}}
{"translation": {"code": "private void setDxDy ( double startx , double starty , ProjectionImpl proj ) { double Lo2 = gds . getDouble ( GridDefRecord . LO2 ) ; double La2 = gds . getDouble ( GridDefRecord . LA2 ) ; if ( Double . isNaN ( Lo2 ) || Double . isNaN ( La2 ) ) { return ; } LatLonPointImpl endLL = new LatLonPointImpl ( La2 , Lo2 ) ; ProjectionPointImpl end = ( ProjectionPointImpl ) proj . latLonToProj ( endLL ) ; double dx = Math . abs ( end . getX ( ) - startx ) / ( gds . getInt ( GridDefRecord . NX ) - 1 ) ; double dy = Math . abs ( end . getY ( ) - starty ) / ( gds . getInt ( GridDefRecord . NY ) - 1 ) ; gds . addParam ( GridDefRecord . DX , String . valueOf ( dx ) ) ; gds . addParam ( GridDefRecord . DY , String . valueOf ( dy ) ) ; gds . addParam ( GridDefRecord . GRID_UNITS , \"km\" ) ; }", "nl": "Calculate the dx and dy from startx starty and projection ."}}
{"translation": {"code": "private double getGridSpacingInKm ( String type ) { double value = gds . getDouble ( type ) ; if ( Double . isNaN ( value ) ) return value ; String gridUnit = gds . getParam ( GridDefRecord . GRID_UNITS ) ; SimpleUnit unit ; if ( gridUnit == null || gridUnit . length ( ) == 0 ) { unit = SimpleUnit . meterUnit ; } else { unit = SimpleUnit . factory ( gridUnit ) ; } if ( unit != null && SimpleUnit . isCompatible ( unit . getUnitString ( ) , \"km\" ) ) { value = unit . convertTo ( value , SimpleUnit . kmUnit ) ; } return value ; }", "nl": "Get the grid spacing in kilometers"}}
{"translation": {"code": "public boolean isMissingXY ( Variable v2 , int timeIdx , int ensIdx , int levIdx ) throws InvalidRangeException { GridVariable pv = ( GridVariable ) v2 . getSPobject ( ) ; if ( ( timeIdx < 0 ) || ( timeIdx >= pv . getNTimes ( ) ) ) { throw new InvalidRangeException ( \"timeIdx=\" + timeIdx ) ; } if ( ( levIdx < 0 ) || ( levIdx >= pv . getVertNlevels ( ) ) ) { throw new InvalidRangeException ( \"levIdx=\" + levIdx ) ; } if ( ( ensIdx < 0 ) || ( ensIdx >= pv . getNEnsembles ( ) ) ) { throw new InvalidRangeException ( \"ensIdx=\" + ensIdx ) ; } return ( null == pv . findRecord ( ensIdx , timeIdx , levIdx ) ) ; }", "nl": "Is this XY level missing?"}}
{"translation": {"code": "static public void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) { debugOpen = debugFlag . isSet ( \"Grid/open\" ) ; debugMissing = debugFlag . isSet ( \"Grid/missing\" ) ; debugMissingDetails = debugFlag . isSet ( \"Grid/missingDetails\" ) ; debugProj = debugFlag . isSet ( \"Grid/projection\" ) ; debugVert = debugFlag . isSet ( \"Grid/vertical\" ) ; debugTiming = debugFlag . isSet ( \"Grid/timing\" ) ; }", "nl": "Set the debug flags"}}
{"translation": {"code": "private void readXY ( Variable v2 , int ensIdx , int timeIdx , int levIdx , Range yRange , Range xRange , IndexIterator ii ) throws IOException , InvalidRangeException { GridVariable pv = ( GridVariable ) v2 . getSPobject ( ) ; GridHorizCoordSys hsys = pv . getHorizCoordSys ( ) ; int nx = hsys . getNx ( ) ; GridRecord record = pv . findRecord ( ensIdx , timeIdx , levIdx ) ; if ( record == null ) { Attribute att = v2 . findAttribute ( \"missing_value\" ) ; float missing_value = ( att == null ) ? - 9999.0f : att . getNumericValue ( ) . floatValue ( ) ; int xyCount = yRange . length ( ) * xRange . length ( ) ; for ( int j = 0 ; j < xyCount ; j ++ ) { ii . setFloatNext ( missing_value ) ; } return ; } // otherwise read it float [ ] data = _readData ( record ) ; if ( data == null ) { _readData ( record ) ; // debug return ; } // LOOK can improve with System.copy ?? for ( int y : yRange ) { for ( int x : xRange ) { int index = y * nx + x ; ii . setFloatNext ( data [ index ] ) ; } } }", "nl": "read one YX array"}}
{"translation": {"code": "void addDimensionsToNetcdfFile ( NetcdfFile ncfile ) { if ( isLatLon ) { ncfile . addDimension ( g , new Dimension ( \"lat\" , gds . getInt ( GridDefRecord . NY ) , true ) ) ; ncfile . addDimension ( g , new Dimension ( \"lon\" , gds . getInt ( GridDefRecord . NX ) , true ) ) ; } else { ncfile . addDimension ( g , new Dimension ( \"y\" , gds . getInt ( GridDefRecord . NY ) , true ) ) ; ncfile . addDimension ( g , new Dimension ( \"x\" , gds . getInt ( GridDefRecord . NX ) , true ) ) ; } }", "nl": "Add the dimensions associated with this coord sys to the netCDF file"}}
{"translation": {"code": "public boolean equals2 ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; DataDescriptor that = ( DataDescriptor ) o ; if ( fxy != that . fxy ) return false ; if ( replication != that . replication ) return false ; if ( type != that . type ) return false ; if ( subKeys != null ? ! subKeys . equals ( that . subKeys ) : that . subKeys != null ) return false ; return true ; }", "nl": "LOOK need different hashCode reader assumes using object id"}}
{"translation": {"code": "public Attribute addAttribute ( Group parent , String name , String value ) { if ( immutable ) throw new IllegalStateException ( \"Cant modify\" ) ; if ( value == null ) return null ; if ( parent == null ) parent = rootGroup ; Attribute att = new Attribute ( name , value ) ; parent . addAttribute ( att ) ; return att ; }", "nl": "Add optional String attribute to a group ."}}
{"translation": {"code": "private Variable makeVerticalVariable ( int vert_sys , int n_levels , float [ ] vert_args ) throws IOException { String vert_unit = null ; String vert_type ; ArrayFloat . D1 data = new ArrayFloat . D1 ( n_levels ) ; AxisType axisType = null ; switch ( vert_sys ) { case ( 0 ) : vert_unit = null ; vert_type = \"height\" ; break ; case ( 1 ) : case ( 2 ) : vert_unit = \"km\" ; vert_type = \"altitude\" ; axisType = AxisType . Height ; break ; case ( 3 ) : vert_unit = \"mbar\" ; vert_type = \"pressure\" ; axisType = AxisType . Pressure ; break ; default : throw new IOException ( \"vert_sys unknown\" ) ; } Variable vertVar = new Variable ( ncfile , null , null , vert_type ) ; vertVar . setDimensions ( LEVEL ) ; vertVar . setDataType ( DataType . FLOAT ) ; if ( vert_unit != null ) { vertVar . addAttribute ( new Attribute ( CDM . UNITS , vert_unit ) ) ; } if ( axisType != null ) { vertVar . addAttribute ( new Attribute ( _Coordinate . AxisType , axisType . toString ( ) ) ) ; } switch ( vert_sys ) { case ( 0 ) : case ( 1 ) : for ( int i = 0 ; i < n_levels ; i ++ ) { data . set ( i , vert_args [ 0 ] + vert_args [ 1 ] * i ) ; } break ; case ( 2 ) : // Altitude in km - non-linear for ( int i = 0 ; i < n_levels ; i ++ ) { data . set ( i , vert_args [ i ] ) ; } break ; case ( 3 ) : // heights of pressure surfaces in km - non-linear try { Vis5DVerticalSystem . Vis5DVerticalCoordinateSystem vert_cs = new Vis5DVerticalSystem . Vis5DVerticalCoordinateSystem ( ) ; float [ ] [ ] pressures = new float [ 1 ] [ n_levels ] ; System . arraycopy ( vert_args , 0 , pressures [ 0 ] , 0 , n_levels ) ; for ( int i = 0 ; i < n_levels ; i ++ ) { pressures [ 0 ] [ i ] *= 1000 ; // km->m } pressures = vert_cs . fromReference ( pressures ) ; // convert to pressures for ( int i = 0 ; i < n_levels ; i ++ ) { data . set ( i , pressures [ 0 ] [ i ] ) ; } } catch ( VisADException ve ) { throw new IOException ( \"unable to make vertical system\" ) ; } break ; } vertVar . setCachedData ( data , false ) ; return vertVar ; }", "nl": "Create a vertical dimension variable based on the info . Based on visad . data . vis5d . Vis5DVerticalSystem ."}}
{"translation": {"code": "static public Map < String , Attribute > makeMap ( List < Attribute > atts ) { int size = ( atts == null ) ? 1 : atts . size ( ) ; Map < String , Attribute > result = new HashMap <> ( size ) ; if ( atts == null ) return result ; for ( Attribute att : atts ) result . put ( att . getShortName ( ) , att ) ; return result ; }", "nl": "Turn a list into a map"}}
{"translation": {"code": "private boolean hasValidDateRange ( String time_start , String time_end , String time_duration ) { // no range if ( ( null == time_start ) && ( null == time_end ) && ( null == time_duration ) ) return false ; if ( ( null != time_start ) && ( null != time_end ) ) return true ; if ( ( null != time_start ) && ( null != time_duration ) ) return true ; if ( ( null != time_end ) && ( null != time_duration ) ) return true ; // misformed range // errs.append(\"Must have 2 of 3 parameters: time_start, time_end, time_duration\\n\"); return false ; }", "nl": "Determine if a valid date range was specified"}}
{"translation": {"code": "public Group getParentGroup ( ) { Group g = super . getParentGroup ( ) ; if ( g == null ) { g = ncfile . getRootGroup ( ) ; super . setParentGroup ( g ) ; } assert g != null ; return g ; }", "nl": "Get the parent group ."}}
{"translation": {"code": "private ArraySequence makeEmptySequence ( Sequence seq ) { StructureMembers members = seq . makeStructureMembers ( ) ; return new ArraySequence ( members , new EmptyStructureDataIterator ( ) , - 1 ) ; }", "nl": "Create an empty ArraySequence for missing data"}}
{"translation": {"code": "private String makeHeader ( GempakStation stn , String date ) { StringBuilder builder = new StringBuilder ( ) ; builder . append ( \"STID = \" ) ; builder . append ( StringUtil2 . padRight ( ( stn . getSTID ( ) . trim ( ) + stn . getSTD2 ( ) . trim ( ) ) , 8 ) ) ; builder . append ( \"\\t\" ) ; builder . append ( \"STNM = \" ) ; builder . append ( Format . i ( stn . getSTNM ( ) , 6 ) ) ; builder . append ( \"\\t\" ) ; builder . append ( \"TIME = \" ) ; builder . append ( date ) ; builder . append ( \"\\n\" ) ; builder . append ( \"SLAT = \" ) ; builder . append ( Format . d ( stn . getLatitude ( ) , 5 ) ) ; builder . append ( \"\\t\" ) ; builder . append ( \"SLON = \" ) ; builder . append ( Format . d ( stn . getLongitude ( ) , 5 ) ) ; builder . append ( \"\\t\" ) ; builder . append ( \"SELV = \" ) ; builder . append ( Format . d ( stn . getAltitude ( ) , 5 ) ) ; builder . append ( \"\\n\" ) ; return builder . toString ( ) ; }", "nl": "Make the header for the text report"}}
{"translation": {"code": "private void addVerticalCoordAttribute ( Variable v ) { GempakSoundingFileReader gsfr = ( GempakSoundingFileReader ) gemreader ; int vertType = gsfr . getVerticalCoordinate ( ) ; String pName = v . getFullName ( ) ; if ( gemreader . getFileSubType ( ) . equals ( GempakSoundingFileReader . MERGED ) ) { if ( ( vertType == GempakSoundingFileReader . PRES_COORD ) && pName . equals ( \"PRES\" ) ) { v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Pressure . name ( ) ) ) ; } else if ( ( vertType == GempakSoundingFileReader . HGHT_COORD ) && ( pName . equals ( \"HGHT\" ) || pName . equals ( \"MHGT\" ) || pName . equals ( \"DHGT\" ) ) ) { v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Height . name ( ) ) ) ; } } else if ( pName . equals ( \"PRES\" ) ) { v . addAttribute ( new Attribute ( _Coordinate . AxisType , AxisType . Pressure . name ( ) ) ) ; } }", "nl": "Add the vertical coordinate variables if necessary"}}
{"translation": {"code": "public List < String > getMergedParts ( ) { List < String > list = new ArrayList <> ( 1 ) ; list . add ( SNDT ) ; return list ; }", "nl": "Get the list of merged parts in this file"}}
{"translation": {"code": "private boolean checkForValidGroup ( String partToCheck , String [ ] params ) { DMPart part = getPart ( partToCheck ) ; if ( part == null ) { return false ; } int i = 0 ; for ( DMParam parm : part . params ) { if ( ! ( parm . kprmnm . equals ( params [ i ++ ] ) ) ) { return false ; } } return true ; }", "nl": "Check for valid groups"}}
{"translation": {"code": "private ArraySequence makeArraySequence ( Sequence seq , List < GempakParameter > params , float [ ] values ) { if ( values == null ) { return makeEmptySequence ( seq ) ; } int numLevels = values . length / params . size ( ) ; StructureMembers members = seq . makeStructureMembers ( ) ; int offset = ArrayStructureBB . setOffsets ( members ) ; int size = offset * numLevels ; byte [ ] bytes = new byte [ size ] ; ByteBuffer buf = ByteBuffer . wrap ( bytes ) ; ArrayStructureBB abb = new ArrayStructureBB ( members , new int [ ] { numLevels } , buf , 0 ) ; int var = 0 ; for ( int i = 0 ; i < numLevels ; i ++ ) { for ( GempakParameter param : params ) { if ( members . findMember ( param . getName ( ) ) != null ) { buf . putFloat ( values [ var ] ) ; } var ++ ; } } return new ArraySequence ( members , new SequenceIterator ( numLevels , abb ) , numLevels ) ; }", "nl": "Create an ArraySequence to hold the data"}}
{"translation": {"code": "public int findStationIndex ( String id ) { for ( GempakStation station : getStations ( ) ) { if ( station . getSTID ( ) . equals ( id ) ) { return station . getIndex ( ) ; } } return - 1 ; }", "nl": "Find the station index for the specified station id ."}}
{"translation": {"code": "private List < GempakParameter > makeParams ( DMPart part ) { List < GempakParameter > gemparms = new ArrayList <> ( part . kparms ) ; for ( DMParam param : part . params ) { String name = param . kprmnm ; GempakParameter parm = GempakParameters . getParameter ( name ) ; if ( parm == null ) { //System.out.println(\"couldn't find \" + name //                   + \" in params table\"); parm = new GempakParameter ( 1 , name , name , \"\" , 0 ) ; } gemparms . add ( parm ) ; } return gemparms ; }", "nl": "Make GempakParameters from the list of"}}
{"translation": {"code": "private List < GempakStation > getStationList ( ) { Key slat = findKey ( GempakStation . SLAT ) ; if ( slat == null ) { return null ; } List < int [ ] > toCheck ; if ( slat . type . equals ( ROW ) ) { toCheck = headers . rowHeaders ; } else { toCheck = headers . colHeaders ; } List < GempakStation > fileStations = new ArrayList <> ( ) ; int i = 0 ; for ( int [ ] header : toCheck ) { if ( header [ 0 ] != IMISSD ) { GempakStation station = makeStation ( header ) ; if ( station != null ) { station . setIndex ( i + 1 ) ; fileStations . add ( station ) ; } } i ++ ; } return fileStations ; }", "nl": "Get the station list"}}
{"translation": {"code": "public List < String > getStationKeyNames ( ) { List < String > keys = new ArrayList <> ( ) ; if ( ( stationKeys != null ) && ! stationKeys . isEmpty ( ) ) { for ( Key key : stationKeys ) { keys . add ( key . name ) ; } } return keys ; }", "nl": "Get the station key names"}}
{"translation": {"code": "public List < Date > getDates ( ) { if ( ( dates == null || dates . isEmpty ( ) ) && ! dateList . isEmpty ( ) ) { dates = new ArrayList <> ( dateList . size ( ) ) ; dateFmt . setTimeZone ( TimeZone . getTimeZone ( \"GMT\" ) ) ; for ( String dateString : dateList ) { Date d = dateFmt . parse ( dateString , new ParsePosition ( 0 ) ) ; //DateFromString.getDateUsingSimpleDateFormat(dateString, //    DATE_FORMAT); dates . add ( d ) ; } } return dates ; }", "nl": "Get the list of dates in this file ."}}
{"translation": {"code": "private GempakStation makeStation ( int [ ] header ) { if ( ( stationKeys == null ) || stationKeys . isEmpty ( ) ) { return null ; } GempakStation newStation = new GempakStation ( ) ; for ( Key key : stationKeys ) { int loc = key . loc + 1 ; switch ( key . name ) { case GempakStation . STID : newStation . setSTID ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; case GempakStation . STNM : newStation . setSTNM ( header [ loc ] ) ; break ; case GempakStation . SLAT : newStation . setSLAT ( header [ loc ] ) ; break ; case GempakStation . SLON : newStation . setSLON ( header [ loc ] ) ; break ; case GempakStation . SELV : newStation . setSELV ( header [ loc ] ) ; break ; case GempakStation . SPRI : newStation . setSPRI ( header [ loc ] ) ; break ; case GempakStation . STAT : newStation . setSTAT ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; case GempakStation . COUN : newStation . setCOUN ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; case GempakStation . SWFO : newStation . setSWFO ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; case GempakStation . WFO2 : newStation . setWFO2 ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; case GempakStation . STD2 : newStation . setSTD2 ( GempakUtil . ST_ITOC ( header [ loc ] ) . trim ( ) ) ; break ; } } return newStation ; }", "nl": "Make a station from the header info"}}
{"translation": {"code": "protected void makeFileSubType ( ) { // determine file type\r Key key = findKey ( GempakStation . SLAT ) ; if ( key == null ) throw new IllegalStateException ( \"File does not have key=\" + GempakStation . SLAT ) ; String latType = key . type ; Key dateKey = findKey ( DATE ) ; if ( dateKey != null && ! dateKey . type . equals ( latType ) ) { if ( latType . equals ( ROW ) ) { subType = CLIMATE ; } else { subType = STANDARD ; } } else { subType = SHIP ; } }", "nl": "Set the file subType ."}}
{"translation": {"code": "public String getWmoId ( ) { String wmoID = \"\" ; if ( ! ( stnm == GempakConstants . IMISSD ) ) { wmoID = String . valueOf ( ( int ) ( stnm / 10 ) ) ; } return wmoID ; }", "nl": "Get the WMO Station ID as a string"}}
{"translation": {"code": "public static int uint ( RandomAccessFile raf ) throws IOException { int a = raf . read ( ) ; return ( int ) DataType . unsignedByteToShort ( ( byte ) a ) ; }", "nl": "Convert unsigned bytes into an integer ."}}
{"translation": {"code": "public boolean findIndex ( ) throws IOException { Path indexPath = Paths . get ( dir . toString ( ) , partitionName + suffix ) ; if ( Files . exists ( indexPath ) ) { this . index = indexPath ; BasicFileAttributes attr = Files . readAttributes ( indexPath , BasicFileAttributes . class ) ; this . indexLastModified = attr . lastModifiedTime ( ) ; this . indexSize = attr . size ( ) ; return true ; } return false ; }", "nl": "Find the index file using its canonical name"}}
{"translation": {"code": "private void scanForChildren ( ) { if ( debug ) System . out . printf ( \"DirectoryBuilder.scanForChildren on %s \" , dir ) ; int count = 0 ; try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( dir ) ) { for ( Path p : ds ) { BasicFileAttributes attr = Files . readAttributes ( p , BasicFileAttributes . class ) ; if ( attr . isDirectory ( ) ) { children . add ( new DirectoryBuilder ( topCollectionName , p , attr , suffix ) ) ; if ( debug && ( ++ count % 10 == 0 ) ) System . out . printf ( \"%d \" , count ) ; } } } catch ( IOException e ) { e . printStackTrace ( ) ; } if ( debug ) System . out . printf ( \"done=%d%n\" , count ) ; childrenConstructed = true ; }", "nl": "Scan for subdirectories make each into a DirectoryBuilder and add as a child"}}
{"translation": {"code": "static public String filter7bits ( String s ) { if ( s == null ) return null ; char [ ] bo = new char [ s . length ( ) ] ; int count = 0 ; for ( int i = 0 ; i < s . length ( ) ; i ++ ) { char c = s . charAt ( i ) ; if ( ( c < 128 ) && ( c > 31 ) || ( ( c == ' ' ) || ( c == ' ' ) ) ) { bo [ count ++ ] = c ; } } return new String ( bo , 0 , count ) ; }", "nl": "Remove all but printable ascii"}}
{"translation": {"code": "public List < DirectoryBuilder > constructChildren ( IndexReader indexReader , CollectionUpdateType forceCollection ) throws IOException { if ( childrenConstructed ) return children ; if ( index != null && forceCollection == CollectionUpdateType . nocheck ) { // use index if it exists constructChildrenFromIndex ( indexReader , false ) ; } else { scanForChildren ( ) ; } //once we have found children, we know that this is a time partition partitionStatus = ( children . size ( ) > 0 ) ? PartitionStatus . isDirectoryPartition : PartitionStatus . isLeaf ; childrenConstructed = true ; // otherwise we are good return children ; }", "nl": "Find all children directories . Does not recurse . We separate this from the constructor so it can be done on demand Public for debugging ."}}
{"translation": {"code": "static public MFileOS7 getExistingFile ( String filename ) throws IOException { if ( filename == null ) return null ; Path path = Paths . get ( filename ) ; if ( Files . exists ( path ) ) return new MFileOS7 ( path ) ; return null ; }", "nl": "Make MFileOS7 if file exists otherwise return null"}}
{"translation": {"code": "public void iterateOverMFileCollection ( Visitor visit ) throws IOException { if ( debug ) System . out . printf ( \" iterateOverMFileCollection %s \" , collectionDir ) ; int count = 0 ; try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( collectionDir , new MyStreamFilter ( ) ) ) { for ( Path p : ds ) { try { BasicFileAttributes attr = Files . readAttributes ( p , BasicFileAttributes . class ) ; if ( ! attr . isDirectory ( ) ) visit . consume ( new MFileOS7 ( p ) ) ; if ( debug ) System . out . printf ( \"%d \" , count ++ ) ; } catch ( IOException ioe ) { // catch error and skip file logger . error ( \"Failed to read attributes from file found in Files.newDirectoryStream \" , ioe ) ; } } } if ( debug ) System . out . printf ( \"%d%n\" , count ) ; }", "nl": "this idiom keeps the iterator from escaping so that we can use try - with - resource and ensure DirectoryStream closes . like ++"}}
{"translation": {"code": "private boolean isLeaf ( IndexReader indexReader ) throws IOException { if ( partitionStatus == PartitionStatus . unknown ) { int countDir = 0 , countFile = 0 , count = 0 ; try ( DirectoryStream < Path > dirStream = Files . newDirectoryStream ( dir ) ) { Iterator < Path > iterator = dirStream . iterator ( ) ; while ( iterator . hasNext ( ) && count ++ < 100 ) { Path p = iterator . next ( ) ; BasicFileAttributes attr = Files . readAttributes ( p , BasicFileAttributes . class ) ; if ( attr . isDirectory ( ) ) countDir ++ ; else countFile ++ ; } } partitionStatus = ( countFile > countDir ) ? PartitionStatus . isLeaf : PartitionStatus . isDirectoryPartition ; } return partitionStatus == PartitionStatus . isLeaf ; }", "nl": "Scans first 100 files to decide if its a leaf . If so it becomes a DirectoryCollection else a PartitionCollection ."}}
{"translation": {"code": "@ Override public void getDataset ( Dataset ds , Object context ) { if ( ds . hasAccess ( ) ) { DataFactory tdataFactory = new DataFactory ( ) ; Access access = tdataFactory . chooseDatasetAccess ( ds . getAccess ( ) ) ; if ( access == null ) throw new IllegalStateException ( ) ; MFileRemote mfile = new MFileRemote ( access ) ; if ( mfile . getPath ( ) . endsWith ( \".xml\" ) ) return ; // eliminate latest.xml  LOOK kludge-o-rama mfiles . add ( mfile ) ; if ( debug ) System . out . format ( \"add %s %n\" , mfile . getPath ( ) ) ; } }", "nl": "CatalogCrawler . Listener"}}
{"translation": {"code": "static public MCollection factory ( FeatureCollectionConfig config , Path topDir , boolean isTop , IndexReader indexReader , String suffix , org . slf4j . Logger logger ) throws IOException { DirectoryBuilder builder = new DirectoryBuilder ( config . collectionName , topDir . toString ( ) , suffix ) ; DirectoryPartition dpart = new DirectoryPartition ( config , topDir , isTop , indexReader , suffix , logger ) ; if ( ! builder . isLeaf ( indexReader ) ) { // its a partition return dpart ; } // its a collection boolean hasIndex = builder . findIndex ( ) ; if ( hasIndex ) { return dpart . makeChildCollection ( builder ) ; } else { DirectoryCollection result = new DirectoryCollection ( config . collectionName , topDir , isTop , config . olderThan , logger ) ; // no index file return result ; } }", "nl": "returns a DirectoryPartition or DirectoryCollection"}}
{"translation": {"code": "public List < MFile > readFilesFromIndex ( IndexReader indexReader ) throws IOException { List < MFile > result = new ArrayList <> ( 100 ) ; if ( index == null ) return result ; indexReader . readMFiles ( index , result ) ; return result ; }", "nl": "read the list of files from the index"}}
{"translation": {"code": "@ Override public int getIndex ( T gr ) { Integer result = valMap . get ( extract ( gr ) ) ; return ( result == null ) ? 0 : result ; }", "nl": "Used by CoordinateND . makeSparseArray ; not used by CoordinateTime2D"}}
{"translation": {"code": "void setIndexRaf ( RandomAccessFile indexRaf ) { this . indexRaf = indexRaf ; if ( indexRaf != null ) { this . indexFilename = indexRaf . getLocation ( ) ; } }", "nl": "public by accident do not use"}}
{"translation": {"code": "private String getIndexFilepathInCache ( ) { File indexFile = GribCdmIndex . makeIndexFile ( name , directory ) ; return GribIndexCache . getFileOrCache ( indexFile . getPath ( ) ) . getPath ( ) ; }", "nl": "get index filename"}}
{"translation": {"code": "@ Override public boolean isValidFile ( RandomAccessFile raf ) throws IOException { if ( raf instanceof HTTPRandomAccessFile ) { // only do remote if memory resident if ( raf . length ( ) > raf . getBufferSize ( ) ) return false ; } else { // wont accept remote index GribCdmIndex . GribCollectionType type = GribCdmIndex . getType ( raf ) ; if ( type == GribCdmIndex . GribCollectionType . GRIB2 ) return true ; if ( type == GribCdmIndex . GribCollectionType . Partition2 ) return true ; } // check for GRIB2 data file return Grib2RecordScanner . isValidFile ( raf ) ; }", "nl": "accept grib2 or ncx files"}}
{"translation": {"code": "public List < String > getFilenames ( ) { List < String > result = new ArrayList <> ( ) ; for ( MFile file : fileMap . values ( ) ) result . ( file . getPath ( ) ) ; Collections . sort ( result ) ; return result ; }", "nl": "The files that comprise the collection . Actual paths including the grib cache if used ."}}
{"translation": {"code": "public void close ( ) throws java . io . IOException { if ( indexRaf != null ) { indexRaf . close ( ) ; indexRaf = null ; } }", "nl": "stuff for FileCacheable"}}
{"translation": {"code": "public List < Double > getOffsetsInTimeUnits ( ) { double start = firstDate . getMillis ( ) ; List < Double > result = new ArrayList <> ( runtimes . length ) ; for ( int idx = 0 ; idx < runtimes . length ; idx ++ ) { double runtime = ( double ) getRuntime ( idx ) ; double msecs = ( runtime - start ) ; result . add ( msecs / timeUnit . getValueInMillisecs ( ) ) ; } return result ; }", "nl": "Get offsets from firstDate in units of timeUnit"}}
{"translation": {"code": "public String getTimeIntervalName ( ) { // are they the same length ? int firstValue = - 1 ; for ( TimeCoordIntvValue tinv : timeIntervals ) { int value = ( tinv . getBounds2 ( ) - tinv . getBounds1 ( ) ) ; if ( firstValue < 0 ) firstValue = value ; else if ( value != firstValue ) return MIXED_INTERVALS ; } firstValue = ( firstValue * timeUnit . getValue ( ) ) ; return firstValue + \"_\" + timeUnit . getField ( ) . toString ( ) ; }", "nl": "Check if we all time intervals have the same length ."}}
{"translation": {"code": "@ Nullable public GribCollectionMutable makeGribCollection ( ) { GribCollectionMutable result = GribCdmIndex . openMutableGCFromIndex ( dcm . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) , config , false , true , logger ) ; if ( result == null ) { logger . error ( \"Failed on openMutableGCFromIndex {}\" , dcm . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) ) ; return null ; } lastModified = result . lastModified ; fileSize = result . fileSize ; if ( result . masterRuntime != null ) partitionDate = result . masterRuntime . getFirstDate ( ) ; return result ; }", "nl": "the children must already exist"}}
{"translation": {"code": "void addPartition ( int partno , int groupno , int varno , int ndups , int nrecords , int nmissing , GribCollectionMutable . VariableIndex vi ) { if ( partList == null ) partList = new ArrayList <> ( nparts ) ; partList . add ( new PartitionForVariable2D ( partno , groupno , varno ) ) ; this . ndups += ndups ; this . nrecords += nrecords ; this . nmissing += nmissing ; }", "nl": "only used by PartitionBuilder not PartitionBuilderFromIndex"}}
{"translation": {"code": "private static boolean updateLeafCollection ( boolean isGrib1 , FeatureCollectionConfig config , CollectionUpdateType updateType , boolean isTop , Logger logger , Path dirPath ) throws IOException { if ( config . ptype == FeatureCollectionConfig . PartitionType . file ) { return updateFilePartition ( isGrib1 , config , updateType , isTop , logger , dirPath ) ; } else { Formatter errlog = new Formatter ( ) ; CollectionSpecParser specp = config . getCollectionSpecParser ( errlog ) ; try ( DirectoryCollection dcm = new DirectoryCollection ( config . collectionName , dirPath , isTop , config . olderThan , logger ) ) { dcm . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; if ( specp . getFilter ( ) != null ) dcm . setStreamFilter ( new StreamFilter ( specp . getFilter ( ) , specp . getFilterOnName ( ) ) ) ; boolean changed = updateGribCollection ( isGrib1 , dcm , updateType , FeatureCollectionConfig . PartitionType . directory , logger , errlog ) ; logger . debug ( \"  GribCdmIndex.updateDirectoryPartition was updated=%s on %s%n\" , changed , dirPath ) ; return changed ; } } }", "nl": "Update all the gbx indices in one directory and the ncx index for that directory"}}
{"translation": {"code": "public static GribCollectionType getType ( RandomAccessFile raf ) throws IOException { String magic ; raf . seek ( 0 ) ; magic = raf . readString ( Grib2CollectionWriter . MAGIC_START . getBytes ( CDM . utf8Charset ) . length ) ; switch ( magic ) { case Grib2CollectionWriter . MAGIC_START : return GribCollectionType . GRIB2 ; case Grib1CollectionWriter . MAGIC_START : return GribCollectionType . GRIB1 ; case Grib2PartitionBuilder . MAGIC_START : return GribCollectionType . Partition2 ; case Grib1PartitionBuilder . MAGIC_START : return GribCollectionType . Partition1 ; } return GribCollectionType . none ; }", "nl": "Find out what kind of index this is"}}
{"translation": {"code": "public List < Integer > reindex ( List < Coordinate > coords ) { List < Integer > result = new ArrayList <> ( ) ; for ( Coordinate coord : coords ) { Coordinate sub = swap . get ( coord ) ; Coordinate use = ( sub == null ) ? coord : sub ; Integer idx = indexMap . get ( use ) ; // index into unionCoords if ( idx == null ) { throw new IllegalStateException ( ) ; } result . add ( idx ) ; } return result ; }", "nl": "redo the variables against the shared coordinates"}}
{"translation": {"code": "public void addCoords ( List < Coordinate > coords , PartitionCollectionMutable . Partition part ) { Coordinate runtime = null ; for ( Coordinate coord : coords ) { switch ( coord . getType ( ) ) { case runtime : CoordinateRuntime rtime = ( CoordinateRuntime ) coord ; if ( runtimeBuilder == null ) runtimeBuilder = new CoordinateRuntime . Builder2 ( rtime . getTimeUnits ( ) ) ; runtimeBuilder . addAll ( coord ) ; runtime = coord ; if ( debugPartitionErrors && ! duplicateRuntimeMessage && part != null ) testDuplicateRuntime ( rtime , part ) ; break ; case time : CoordinateTime time = ( CoordinateTime ) coord ; if ( timeBuilder == null ) timeBuilder = new CoordinateTime . Builder2 ( coord . getCode ( ) , time . getTimeUnit ( ) , time . getRefDate ( ) ) ; timeBuilder . addAll ( coord ) ; break ; case timeIntv : CoordinateTimeIntv timeIntv = ( CoordinateTimeIntv ) coord ; if ( timeIntvBuilder == null ) timeIntvBuilder = new CoordinateTimeIntv . Builder2 ( null , coord . getCode ( ) , timeIntv . getTimeUnit ( ) , timeIntv . getRefDate ( ) ) ; timeIntvBuilder . addAll ( intervalFilter ( ( CoordinateTimeIntv ) coord ) ) ; break ; case time2D : CoordinateTime2D time2D = ( CoordinateTime2D ) coord ; if ( time2DBuilder == null ) time2DBuilder = new CoordinateTime2DUnionizer ( time2D . isTimeInterval ( ) , time2D . getTimeUnit ( ) , coord . getCode ( ) , false , logger ) ; time2DBuilder . addAll ( time2D ) ; // debug CoordinateRuntime runtimeFrom2D = time2D . getRuntimeCoordinate ( ) ; if ( ! runtimeFrom2D . equals ( runtime ) ) logger . warn ( \"HEY CoordinateUnionizer runtimes not equal\" ) ; break ; case ens : if ( ensBuilder == null ) ensBuilder = new CoordinateEns . Builder2 ( coord . getCode ( ) ) ; ensBuilder . addAll ( coord ) ; break ; case vert : CoordinateVert vertCoord = ( CoordinateVert ) coord ; if ( vertBuilder == null ) vertBuilder = new CoordinateVert . Builder2 ( coord . getCode ( ) , vertCoord . getVertUnit ( ) ) ; vertBuilder . addAll ( coord ) ; break ; } } }", "nl": "only one message per CoordinatePartitionUnionizer instance"}}
{"translation": {"code": "void copyInfo ( GribCollectionMutable from ) { this . center = from . center ; this . subcenter = from . subcenter ; this . master = from . master ; this . local = from . local ; this . genProcessType = from . genProcessType ; this . genProcessId = from . genProcessId ; this . backProcessId = from . backProcessId ; }", "nl": "for making partition collection"}}
{"translation": {"code": "@ Override public CalendarDateRange makeCalendarDateRange ( ucar . nc2 . time . Calendar cal ) { CalendarDateUnit cdu = CalendarDateUnit . of ( cal , timeUnit . getField ( ) , refDate ) ; CalendarDate start = cdu . makeCalendarDate ( timeUnit . getValue ( ) * timeIntervals . get ( 0 ) . getBounds2 ( ) ) ; CalendarDate end = cdu . makeCalendarDate ( timeUnit . getValue ( ) * timeIntervals . get ( getSize ( ) - 1 ) . getBounds2 ( ) ) ; return CalendarDateRange . of ( start , end ) ; }", "nl": "Make calendar date range using the first and last ending bounds"}}
{"translation": {"code": "public static < T extends JComponent > Class getJClass ( T component ) { Class < ? > clazz = component . getClass ( ) ; while ( ! clazz . getName ( ) . matches ( \"javax.swing.J[^.]*$\" ) ) { clazz = clazz . getSuperclass ( ) ; } return clazz ; }", "nl": "Convenience method to obtain the Swing class from which this component was directly or indirectly derived ."}}
{"translation": {"code": "public static Object getUIDefaultOfClass ( Class clazz , String property ) { Object retVal = null ; UIDefaults defaults = getUIDefaultsOfClass ( clazz ) ; List < Object > listKeys = Collections . list ( defaults . keys ( ) ) ; for ( Object key : listKeys ) { if ( key . equals ( property ) ) { return defaults . get ( key ) ; } if ( key . toString ( ) . equalsIgnoreCase ( property ) ) { retVal = defaults . get ( key ) ; } } return retVal ; }", "nl": "Convenience method for retrieving the UIDefault for a single property of a particular class ."}}
{"translation": {"code": "private static GribCollectionImmutable openGribCollectionFromDataFile ( boolean isGrib1 , RandomAccessFile dataRaf , FeatureCollectionConfig config , CollectionUpdateType updateType , Formatter errlog , org . slf4j . Logger logger ) throws IOException { String filename = dataRaf . getLocation ( ) ; File dataFile = new File ( filename ) ; MFile mfile = new MFileOS ( dataFile ) ; return openGribCollectionFromDataFile ( isGrib1 , mfile , updateType , config , errlog , logger ) ; }", "nl": "Open a grib collection from a single grib1 or grib2 file . Create the gbx9 and ncx2 files if needed ."}}
{"translation": {"code": "@ Nullable public static GribCollectionImmutable openGribCollectionFromDataFile ( boolean isGrib1 , MFile mfile , CollectionUpdateType updateType , FeatureCollectionConfig config , Formatter errlog , org . slf4j . Logger logger ) throws IOException { MCollection dcm = new CollectionSingleFile ( mfile , logger ) ; dcm . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; if ( isGrib1 ) { Grib1CollectionBuilder builder = new Grib1CollectionBuilder ( dcm . getCollectionName ( ) , dcm , logger ) ; // LOOK ignoring partition type boolean changed = ( builder . updateNeeded ( updateType ) && builder . createIndex ( FeatureCollectionConfig . PartitionType . file , errlog ) ) ; } else { Grib2CollectionBuilder builder = new Grib2CollectionBuilder ( dcm . getCollectionName ( ) , dcm , logger ) ; boolean changed = ( builder . updateNeeded ( updateType ) && builder . createIndex ( FeatureCollectionConfig . PartitionType . file , errlog ) ) ; } // the index file should now exist, open it GribCollectionImmutable result = openCdmIndex ( dcm . getIndexFilename ( NCX_SUFFIX ) , config , true , logger ) ; if ( result != null ) return result ; // if open fails, force recreate the index if ( updateType == CollectionUpdateType . never ) return null ; // not allowed to write if ( updateType == CollectionUpdateType . always ) return null ; // already tried to force write, give up return openGribCollectionFromDataFile ( isGrib1 , mfile , CollectionUpdateType . always , config , errlog , logger ) ; }", "nl": "from a single file read in the index create if it doesnt exist ; return null on failure"}}
{"translation": {"code": "static synchronized protected void setDefaults ( Map < Prop , Object > props ) { if ( false ) { // turn off for now props . put ( Prop . HANDLE_AUTHENTICATION , Boolean . TRUE ) ; } props . put ( Prop . HANDLE_REDIRECTS , Boolean . TRUE ) ; props . put ( Prop . ALLOW_CIRCULAR_REDIRECTS , Boolean . TRUE ) ; props . put ( Prop . MAX_REDIRECTS , ( Integer ) DFALTREDIRECTS ) ; props . put ( Prop . SO_TIMEOUT , ( Integer ) DFALTSOTIMEOUT ) ; props . put ( Prop . CONN_TIMEOUT , ( Integer ) DFALTCONNTIMEOUT ) ; props . put ( Prop . CONN_REQ_TIMEOUT , ( Integer ) DFALTCONNREQTIMEOUT ) ; props . put ( Prop . USER_AGENT , DFALTUSERAGENT ) ; }", "nl": "Provide defaults for a settings map"}}
{"translation": {"code": "static protected HTTPMethod makemethod ( HTTPSession . Methods m , HTTPSession session , String url ) throws HTTPException { HTTPMethod meth = null ; if ( MOCKMETHODCLASS == null ) { // do the normal case meth = new HTTPMethod ( m , session , url ) ; } else { //(MOCKMETHODCLASS != null) java . lang . Class methodcl = MOCKMETHODCLASS ; Constructor < HTTPMethod > cons = null ; try { cons = methodcl . getConstructor ( HTTPSession . Methods . class , HTTPSession . class , String . class ) ; } catch ( Exception e ) { throw new HTTPException ( \"HTTPFactory: no proper HTTPMethod constructor available\" , e ) ; } try { meth = cons . newInstance ( m , session , url ) ; } catch ( Exception e ) { throw new HTTPException ( \"HTTPFactory: HTTPMethod constructor failed\" , e ) ; } } return meth ; }", "nl": "Common method creation code so we can isolate mocking"}}
{"translation": {"code": "private String getCompleteCE ( String CE ) { String localProjString = null ; String localSelString = null ; if ( CE == null ) return \"\" ; //remove any leading '?' if ( CE . startsWith ( \"?\" ) ) CE = CE . substring ( 1 ) ; int selIndex = CE . indexOf ( ' ' ) ; if ( selIndex == 0 ) { localProjString = \"\" ; localSelString = CE ; } else if ( selIndex > 0 ) { localSelString = CE . substring ( selIndex ) ; localProjString = CE . substring ( 0 , selIndex ) ; } else { // selIndex < 0 localProjString = CE ; localSelString = \"\" ; } String ce = projString ; if ( ! localProjString . equals ( \"\" ) ) { if ( ! ce . equals ( \"\" ) && localProjString . indexOf ( ' ' ) != 0 ) ce += \",\" ; ce += localProjString ; } if ( ! selString . equals ( \"\" ) ) { if ( selString . indexOf ( ' ' ) != 0 ) ce += \"&\" ; ce += selString ; } if ( ! localSelString . equals ( \"\" ) ) { if ( localSelString . indexOf ( ' ' ) != 0 ) ce += \"&\" ; ce += localSelString ; } if ( ce . length ( ) > 0 ) ce = \"?\" + ce ; if ( false ) { DAPNode . log . debug ( \"projString: '\" + projString + \"'\" ) ; DAPNode . log . debug ( \"localProjString: '\" + localProjString + \"'\" ) ; DAPNode . log . debug ( \"selString: '\" + selString + \"'\" ) ; DAPNode . log . debug ( \"localSelString: '\" + localSelString + \"'\" ) ; DAPNode . log . debug ( \"Complete CE: \" + ce ) ; } return ce ; // escaping will happen elsewhere }", "nl": "Use some sense when assembling the CE . Since this DConnect object may have constructed using a CE any new CE will have to be integrated into it for subsequent requests . Try to do this in a sensible manner!"}}
{"translation": {"code": "static public HTTPMethod Get ( HTTPSession session , String legalurl ) throws HTTPException { return makemethod ( HTTPSession . Methods . Get , session , legalurl ) ; }", "nl": "Static factory methods for creating HTTPMethod instances"}}
{"translation": {"code": "public DAS getDAS ( ) throws IOException , DAP2Exception { DASCommand command = new DASCommand ( ) ; if ( filePath != null ) { // url was file: File daspath = new File ( filePath + \".das\" ) ; // See if the das file exists if ( daspath . canRead ( ) ) { try ( FileInputStream is = new FileInputStream ( daspath ) ) { command . process ( is ) ; } } } else if ( stream != null ) { command . process ( stream ) ; } else { // assume url is remote try { openConnection ( urlString + \".das\" + getCompleteCE ( projString , selString ) , command ) ; } catch ( DAP2Exception de ) { //if(de.getErrorCode() != DAP2Exception.NO_SUCH_FILE) //throw de;  // rethrow } } return command . das ; }", "nl": "Returns the DAS object from the dataset referenced by this object s URL . The DAS object is referred to by appending . das to the end of a DODS URL ."}}
{"translation": {"code": "private void openConnection ( String urlString , Command command ) throws IOException , DAP2Exception { InputStream is = null ; try { try ( HTTPMethod method = HTTPFactory . Get ( _session , urlString ) ) { if ( acceptCompress ) method . setCompression ( \"deflate,gzip\" ) ; // enable sessions if ( allowSessions ) method . setUseSessions ( true ) ; int statusCode ; for ( ; ; ) { statusCode = method . execute ( ) ; if ( statusCode != HttpStatus . SC_SERVICE_UNAVAILABLE ) break ; Thread . sleep ( 5000 ) ; System . err . println ( \"Service Unavailable\" ) ; } // debug // if (debugHeaders) ucar.httpservices.HttpClientManager.showHttpRequestInfo(f, method); if ( statusCode == HttpStatus . SC_NOT_FOUND ) { throw new DAP2Exception ( DAP2Exception . NO_SUCH_FILE , method . getStatusText ( ) + \": \" + urlString ) ; } if ( statusCode == HttpStatus . SC_UNAUTHORIZED || statusCode == HttpStatus . SC_FORBIDDEN ) { throw new InvalidCredentialsException ( method . getStatusText ( ) ) ; } if ( statusCode != HttpStatus . SC_OK ) { throw new DAP2Exception ( \"Method failed:\" + method . getStatusText ( ) + \" on URL= \" + urlString ) ; } // Get the response body. is = method . getResponseAsStream ( ) ; // check if its an error Header header = method . getResponseHeader ( \"Content-Description\" ) ; if ( header != null && ( header . getValue ( ) . equals ( \"dods-error\" ) || header . getValue ( ) . equals ( \"dods_error\" ) ) ) { // create server exception object DAP2Exception ds = new DAP2Exception ( ) ; // parse the Error object from stream and throw it ds . parse ( is ) ; throw ds ; } ver = new ServerVersion ( method ) ; checkHeaders ( method ) ; // check for deflator Header h = method . getResponseHeader ( \"content-encoding\" ) ; String encoding = ( h == null ) ? null : h . getValue ( ) ; //if (encoding != null) LogStream.out.println(\"encoding= \" + encoding); if ( encoding != null && encoding . equals ( \"deflate\" ) ) { is = new BufferedInputStream ( new InflaterInputStream ( is ) , 1000 ) ; if ( showCompress ) System . out . printf ( \"deflate %s%n\" , urlString ) ; } else if ( encoding != null && encoding . equals ( \"gzip\" ) ) { is = new BufferedInputStream ( new GZIPInputStream ( is ) , 1000 ) ; if ( showCompress ) System . out . printf ( \"gzip %s%n\" , urlString ) ; } else { if ( showCompress ) System . out . printf ( \"none %s%n\" , urlString ) ; } command . process ( is ) ; } } catch ( IOException | DAP2Exception e ) { throw e ; } catch ( Exception e ) { Util . check ( e ) ; //e.printStackTrace(); throw new DAP2Exception ( e ) ; } }", "nl": "Open a connection to the DODS server ."}}
{"translation": {"code": "public static void installInAllColumns ( JTable table , int alignment ) { // We don't want to set up completely new cell renderers: rather, we want to use the existing ones but just // change their alignment. for ( int colViewIndex = 0 ; colViewIndex < table . getColumnCount ( ) ; ++ colViewIndex ) { installInOneColumn ( table , colViewIndex , alignment ) ; } }", "nl": "Installs alignment decorators in all of the table s columns ."}}
{"translation": {"code": "private void writeLookupTableFile ( List < String > tableNums , Path dir , String writeDate ) throws IOException { System . out . println ( \"Writing: lookupTables.txt\" ) ; Collections . sort ( tableNums ) ; Path lookupTableReg = dir . resolve ( \"lookupTables.txt\" ) ; Files . deleteIfExists ( lookupTableReg ) ; Files . createFile ( lookupTableReg ) ; try ( BufferedWriter writer = Files . newBufferedWriter ( lookupTableReg , ENCODING ) ) { writer . write ( \"# Generated by \" + this . getClass ( ) . getCanonicalName ( ) + \" on \" + writeDate ) ; writer . newLine ( ) ; for ( String tn : tableNums ) { String tableName = \"2.98.\" + tn + \".table\" ; String reg = \"98:\\t-1:\\t\" + tn + \":\\t\" + tableName ; writer . write ( reg ) ; writer . newLine ( ) ; } } }", "nl": "Write the lookupTables . txt file which basically registers all of the new grib1 tables with the CDM"}}
{"translation": {"code": "private void parseLocalConcept ( String filename , String conceptName ) throws IOException { try ( InputStream is = new FileInputStream ( filename ) ) { addLocalConcept ( is , conceptName ) ; } }", "nl": "Parse the localConcept files needed to create grib1 tables for use by the CDM ."}}
{"translation": {"code": "private void addLocalConcept ( InputStream is , String conceptName ) throws IOException { /*\n        example entry from name.def:\n\n        #Total precipitation of at least 5 mm\n        'Total precipitation of at least 5 mm' = {\n             table2Version = 131 ;\n             indicatorOfParameter = 61 ;\n            }\n         */ try ( BufferedReader br = new BufferedReader ( new InputStreamReader ( is , ENCODING ) ) ) { String line = br . readLine ( ) ; while ( ! line . startsWith ( \"#\" ) ) line = br . readLine ( ) ; // skip while ( true ) { HashMap < String , String > items = new HashMap <> ( ) ; line = br . readLine ( ) ; if ( line == null ) break ; // done with the file if ( ( line . length ( ) == 0 ) || line . startsWith ( \"#\" ) ) continue ; line = cleanLine ( line ) ; if ( line . contains ( \"{\" ) ) { String paramName = line . split ( \"=\" ) [ 0 ] . trim ( ) ; line = br . readLine ( ) ; if ( line == null ) break ; // done with the file line = cleanLine ( line ) ; while ( line . contains ( \"=\" ) ) { String [ ] kvp = line . split ( \"=\" ) ; items . put ( kvp [ 0 ] . trim ( ) , kvp [ 1 ] . trim ( ) ) ; line = br . readLine ( ) ; if ( line == null ) break ; // done with the file line = cleanLine ( line ) ; } String tableVersion = items . get ( TABLE_VERSION_ID ) ; String parameterNumber = items . get ( PARAM_NUM_ID ) ; storeConcept ( tableVersion , parameterNumber , conceptName , paramName ) ; } } } }", "nl": "Add the information from a localConcept file to super HashMap localConcepts"}}
{"translation": {"code": "private String cleanLine ( String lineIn ) { String lineOut ; lineOut = lineIn . replaceAll ( \"'\" , \"\" ) ; lineOut = lineOut . replaceAll ( \"\\t\" , \"\" ) ; lineOut = lineOut . replaceAll ( \";\" , \"\" ) ; return lineOut . trim ( ) ; }", "nl": "clean the string representation of a line in the localConcept file . Basic removal of tabs semicolons single quotes etc ."}}
{"translation": {"code": "private void storeConcept ( String tableVersion , String parameterNumber , String key , String value ) { HashMap < String , HashMap < String , String > > tmpTable ; if ( localConcepts . containsKey ( tableVersion ) ) { tmpTable = localConcepts . get ( tableVersion ) ; if ( tmpTable . containsKey ( parameterNumber ) ) { HashMap < String , String > tmpParam = tmpTable . get ( parameterNumber ) ; if ( ! tmpParam . containsKey ( key ) ) { tmpParam . put ( key , value ) ; } else { System . out . println ( \"already has key value pair: \" + key + \":\" + value ) ; } } else { HashMap < String , String > tmpParam = new HashMap <> ( 4 ) ; tmpParam . put ( key , value ) ; tmpTable . put ( parameterNumber , tmpParam ) ; } } else { tmpTable = new HashMap <> ( ) ; HashMap < String , String > tmpParam = new HashMap <> ( 4 ) ; tmpParam . put ( key , value ) ; tmpTable . put ( parameterNumber , tmpParam ) ; } localConcepts . put ( tableVersion , tmpTable ) ; }", "nl": "Store localConcept information in super HashMap localConcepts"}}
{"translation": {"code": "public static void main ( String [ ] args ) { EcmwfLocalConcepts ec = new EcmwfLocalConcepts ( ) ; try { ec . writeGrib1Tables ( ) ; System . out . println ( \"Finished!\" ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } }", "nl": "Generate grib1 tables for the CDM based on the localConcept files from ECMWF GRIB - API"}}
{"translation": {"code": "private void showLocalConcepts ( ) { for ( String tableNum : localConcepts . keySet ( ) ) { for ( String paramNum : localConcepts . get ( tableNum ) . keySet ( ) ) { for ( String key : localConcepts . get ( tableNum ) . get ( paramNum ) . keySet ( ) ) { System . out . println ( key + \":\" + localConcepts . get ( tableNum ) . get ( paramNum ) . get ( key ) ) ; } } } }", "nl": "Quick prinout to System . out of the different parameter metadata fields"}}
{"translation": {"code": "private void writeGrib1Tables ( ) throws IOException { SimpleDateFormat dateFormat = new SimpleDateFormat ( \"yyyy-MM-dd'T'HH:mm:ssz\" ) ; Calendar cal = Calendar . getInstance ( ) ; String writeDate = dateFormat . format ( cal . getTime ( ) ) ; String grib1Info ; List < String > tableNums = new ArrayList <> ( ) ; HashMap < String , String > paramInfo ; Path dir = Paths . get ( ecmwfLocalConceptsLoc . replace ( \"sources/\" , \"resources/resources/grib1/\" ) ) ; for ( String tableNum : localConcepts . keySet ( ) ) { tableNums . add ( tableNum ) ; String fileName = \"2.98.\" + tableNum + \".table\" ; System . out . println ( \"Writing: \" + fileName ) ; Path newFile = dir . resolve ( fileName ) ; Files . deleteIfExists ( newFile ) ; Files . createFile ( newFile ) ; try ( BufferedWriter writer = Files . newBufferedWriter ( newFile , ENCODING ) ) { writer . write ( \"# Generated by \" + this . getClass ( ) . getCanonicalName ( ) + \" on \" + writeDate ) ; writer . newLine ( ) ; for ( String paramNum : localConcepts . get ( tableNum ) . keySet ( ) ) { paramInfo = localConcepts . get ( tableNum ) . get ( paramNum ) ; String shortName = paramInfo . get ( SHORTNAME_ID ) ; String description = paramInfo . get ( DESCRIPTION_ID ) ; String units = paramInfo . get ( UNIT_ID ) ; grib1Info = paramNum + \" \" + shortName + \" [\" + description + \"] (\" + units + \")\" ; writer . write ( grib1Info ) ; writer . newLine ( ) ; } } } writeLookupTableFile ( tableNums , dir , writeDate ) ; }", "nl": "Write out grib1 tables based on localConcepts files - these are the tables that the CDM will read ."}}
{"translation": {"code": "public static boolean updateGribCollection ( FeatureCollectionConfig config , CollectionUpdateType updateType , Logger logger ) throws IOException { if ( logger == null ) logger = classLogger ; long start = System . currentTimeMillis ( ) ; Formatter errlog = new Formatter ( ) ; CollectionSpecParser specp = config . getCollectionSpecParser ( errlog ) ; Path rootPath = Paths . get ( specp . getRootDir ( ) ) ; boolean isGrib1 = config . type == FeatureCollectionType . GRIB1 ; boolean changed ; if ( config . ptype == FeatureCollectionConfig . PartitionType . none || config . ptype == FeatureCollectionConfig . PartitionType . all ) { try ( CollectionAbstract dcm = new CollectionPathMatcher ( config , specp , logger ) ) { changed = updateGribCollection ( isGrib1 , dcm , updateType , FeatureCollectionConfig . PartitionType . none , logger , errlog ) ; } } else if ( config . ptype == FeatureCollectionConfig . PartitionType . timePeriod ) { try ( TimePartition tp = new TimePartition ( config , specp , logger ) ) { changed = updateTimePartition ( isGrib1 , tp , updateType , logger ) ; } } else { // LOOK assume wantSubdirs makes it into a Partition. Isnt there something better ?? if ( specp . wantSubdirs ( ) ) { // its a partition try ( DirectoryPartition dpart = new DirectoryPartition ( config , rootPath , true , new GribCdmIndex ( logger ) , NCX_SUFFIX , logger ) ) { dpart . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , config ) ; changed = updateDirectoryCollectionRecurse ( isGrib1 , dpart , config , updateType , logger ) ; } } else { // otherwise its a leaf directory changed = updateLeafCollection ( isGrib1 , config , updateType , true , logger , rootPath ) ; } } long took = System . currentTimeMillis ( ) - start ; logger . info ( \"updateGribCollection {} changed {} took {} msecs\" , config . collectionName , changed , took ) ; return changed ; }", "nl": "Update Grib Collection if needed"}}
{"translation": {"code": "public static GribCollectionImmutable openGribCollectionFromRaf ( RandomAccessFile raf , FeatureCollectionConfig config , CollectionUpdateType updateType , org . slf4j . Logger logger ) throws IOException { GribCollectionImmutable result ; // check if its a plain ole GRIB1/2 data file boolean isGrib1 = false ; boolean isGrib2 = Grib2RecordScanner . isValidFile ( raf ) ; if ( ! isGrib2 ) isGrib1 = Grib1RecordScanner . isValidFile ( raf ) ; if ( isGrib1 || isGrib2 ) { result = openGribCollectionFromDataFile ( isGrib1 , raf , config , updateType , null , logger ) ; // close the data file, the ncx raf file is managed by gribCollection raf . close ( ) ; } else { // check its an ncx file result = openGribCollectionFromIndexFile ( raf , config , logger ) ; } return result ; }", "nl": "Used by IOSPs"}}
{"translation": {"code": "public static String unescapeURLQuery ( String ce ) { try { ce = unescapeString ( ce ) ; } catch ( Exception e ) { ce = null ; } return ce ; }", "nl": "Define the DEFINITIVE URL constraint expression unescape function ."}}
{"translation": {"code": "public static String escapeURLQuery ( String ce ) { try { ce = escapeString ( ce , _allowableInUrlQuery ) ; } catch ( Exception e ) { ce = null ; } return ce ; }", "nl": "Define the DEFINITIVE URL constraint expression escape function ."}}
{"translation": {"code": "private static String xunescapeString ( String in , char escape , boolean spaceplus ) { try { if ( in == null ) return null ; byte [ ] utf8 = in . getBytes ( utf8Charset ) ; byte escape8 = ( byte ) escape ; byte [ ] out = new byte [ utf8 . length ] ; // Should be max we need int index8 = 0 ; for ( int i = 0 ; i < utf8 . length ; ) { byte b = utf8 [ i ++ ] ; if ( b == plus && spaceplus ) { out [ index8 ++ ] = blank ; } else if ( b == escape8 ) { // check to see if there are enough characters left if ( i + 2 <= utf8 . length ) { b = ( byte ) ( fromHex ( utf8 [ i ] ) << 4 | fromHex ( utf8 [ i + 1 ] ) ) ; i += 2 ; } } out [ index8 ++ ] = b ; } return new String ( out , 0 , index8 , utf8Charset ) ; } catch ( Exception e ) { return in ; } }", "nl": "Given a string that contains WWW escape sequences translate those escape sequences back into ASCII characters . Return the modified string ."}}
{"translation": {"code": "public static int putContent ( String urlencoded , String content ) throws IOException { try ( HTTPMethod m = HTTPFactory . Put ( urlencoded ) ) { m . setRequestContent ( new StringEntity ( content , \"application/text\" , \"UTF-8\" ) ) ; m . execute ( ) ; int resultCode = m . getStatusCode ( ) ; // followRedirect wont work for PUT if ( resultCode == 302 ) { String redirectLocation ; Header locationHeader = m . getResponseHeader ( \"location\" ) ; if ( locationHeader != null ) { redirectLocation = locationHeader . getValue ( ) ; resultCode = putContent ( redirectLocation , content ) ; } } return resultCode ; } }", "nl": "Put content to a url using HTTP PUT . Handles one level of 302 redirection ."}}
{"translation": {"code": "@ Urlencoded @ Deprecated public static String getContentAsString ( HTTPSession session , String urlencoded ) throws IOException { HTTPSession useSession = session ; try { if ( useSession == null ) useSession = HTTPFactory . newSession ( urlencoded ) ; try ( HTTPMethod m = HTTPFactory . Get ( useSession , urlencoded ) ) { m . execute ( ) ; return m . getResponseAsString ( ) ; } } finally { if ( ( session == null ) && ( useSession != null ) ) useSession . close ( ) ; } }", "nl": "Get the content from a url . For large returns its better to use getResponseAsStream ."}}
{"translation": {"code": "private boolean needsUpdate ( CollectionUpdateType ff , File collectionIndexFile ) throws IOException { long collectionLastModified = collectionIndexFile . lastModified ( ) ; Set < String > newFileSet = new HashSet <> ( ) ; for ( MCollection dcm : partitionManager . makePartitions ( CollectionUpdateType . test ) ) { String partitionIndexFilename = StringUtil2 . replace ( dcm . getIndexFilename ( GribCdmIndex . NCX_SUFFIX ) , ' ' , \"/\" ) ; File partitionIndexFile = GribIndexCache . getExistingFileOrCache ( partitionIndexFilename ) ; if ( partitionIndexFile == null ) // make sure each partition has an index return true ; if ( collectionLastModified < partitionIndexFile . lastModified ( ) ) // and the partition index is earlier than the collection index return true ; newFileSet . add ( partitionIndexFilename ) ; } if ( ff == CollectionUpdateType . testIndexOnly ) return false ; // now see if any files were deleted GribCdmIndex reader = new GribCdmIndex ( logger ) ; List < MFile > oldFiles = new ArrayList <> ( ) ; reader . readMFiles ( collectionIndexFile . toPath ( ) , oldFiles ) ; Set < String > oldFileSet = new HashSet <> ( ) ; for ( MFile oldFile : oldFiles ) { if ( ! newFileSet . contains ( oldFile . getPath ( ) ) ) return true ; // got deleted - must recreate the index oldFileSet . add ( oldFile . getPath ( ) ) ; } // now see if any files were added for ( String newFilename : newFileSet ) { if ( ! oldFileSet . contains ( newFilename ) ) return true ; // got added - must recreate the index } return false ; }", "nl": "LOOK need an option to only scan latest last partition or something"}}
{"translation": {"code": "private boolean createAllRuntimeCollections ( Formatter errlog ) throws IOException { long start = System . currentTimeMillis ( ) ; this . type = GribCollectionImmutable . Type . SRC ; boolean ok = true ; List < MFile > files = new ArrayList <> ( ) ; List < ? extends Group > groups = makeGroups ( files , true , errlog ) ; List < MFile > allFiles = Collections . unmodifiableList ( files ) ; // gather into collections with a single runtime Map < Long , List < Group > > runGroups = new HashMap <> ( ) ; for ( Group g : groups ) { List < Group > runGroup = runGroups . computeIfAbsent ( g . getRuntime ( ) . getMillis ( ) , k -> new ArrayList <> ( ) ) ; runGroup . add ( g ) ; } // write each rungroup separately boolean multipleRuntimes = runGroups . values ( ) . size ( ) > 1 ; List < MFile > partitions = new ArrayList <> ( ) ; for ( List < Group > runGroupList : runGroups . values ( ) ) { Group g = runGroupList . get ( 0 ) ; // if multiple Runtimes, we will write a partition. otherwise, we need to use the standard name (without runtime) so we know the filename from the collection String gcname = multipleRuntimes ? GribCollectionMutable . makeName ( this . name , g . getRuntime ( ) ) : this . name ; MFile indexFileForRuntime = GribCollectionMutable . makeIndexMFile ( gcname , directory ) ; // not using disk cache LOOK why ? partitions . add ( indexFileForRuntime ) ; // create the master runtimes, consisting of the single runtime List < Long > runtimes = new ArrayList <> ( 1 ) ; runtimes . add ( g . getRuntime ( ) . getMillis ( ) ) ; CoordinateRuntime masterRuntimes = new CoordinateRuntime ( runtimes , null ) ; CalendarDateRange calendarDateRangeAll = null ; for ( Coordinate coord : g . getCoordinates ( ) ) { if ( coord instanceof CoordinateTimeAbstract ) { CalendarDateRange calendarDateRange = ( ( CoordinateTimeAbstract ) coord ) . makeCalendarDateRange ( null ) ; if ( calendarDateRangeAll == null ) calendarDateRangeAll = calendarDateRange ; else calendarDateRangeAll = calendarDateRangeAll . extend ( calendarDateRange ) ; } } assert calendarDateRangeAll != null ; // for each Group write an index file ok &= writeIndex ( gcname , indexFileForRuntime . getPath ( ) , masterRuntimes , runGroupList , allFiles , calendarDateRangeAll ) ; logger . info ( \"GribCollectionBuilder write {} ok={}\" , indexFileForRuntime . getPath ( ) , ok ) ; } // if theres more than one runtime, create a partition collection to collect all the runtimes together if ( multipleRuntimes ) { Collections . sort ( partitions ) ; // ?? PartitionManager part = new PartitionManagerFromIndexList ( dcm , partitions , logger ) ; part . putAuxInfo ( FeatureCollectionConfig . AUX_CONFIG , dcm . getAuxInfo ( FeatureCollectionConfig . AUX_CONFIG ) ) ; ok &= GribCdmIndex . updateGribCollectionFromPCollection ( isGrib1 , part , CollectionUpdateType . always , errlog , logger ) ; } long took = System . currentTimeMillis ( ) - start ; logger . debug ( \"That took {} msecs\" , took ) ; return ok ; }", "nl": "creates seperate collection and index for each runtime ."}}
{"translation": {"code": "public String readError ( ) throws IOException { state = State . ERROR ; // Read the error body databuffer byte [ ] bytes = new byte [ this . chunksize ] ; try { if ( read ( bytes , 0 , this . chunksize ) < this . chunksize ) throw new ErrorException ( \"Short chunk\" ) ; } catch ( IOException ioe ) { throw new ErrorException ( ioe ) ; } String document = new String ( bytes , DapUtil . UTF8 ) ; return document ; }", "nl": "Read an error chunk"}}
{"translation": {"code": "public String toConstraintString ( ) { StringBuilder buf = new StringBuilder ( ) ; boolean first = true ; for ( int i = 0 ; i < segments . size ( ) ; i ++ ) { Segment seg = segments . get ( i ) ; if ( ! seg . var . isTopLevel ( ) ) continue ; if ( ! first ) buf . append ( \";\" ) ; first = false ; dumpvar ( seg , buf , true ) ; } return buf . toString ( ) ; }", "nl": "Convert the view to a constraint string suitable for use in a URL except not URL encoded ."}}
{"translation": {"code": "protected Object eval ( DapVariable var , DapSequence seq , DataCursor record , CEAST expr ) throws DapException { switch ( expr . sort ) { case CONSTANT : return expr . value ; case SEGMENT : return fieldValue ( var , seq , record , expr . name ) ; case EXPR : Object lhs = eval ( var , seq , record , expr . lhs ) ; Object rhs = ( expr . rhs == null ? null : eval ( var , seq , record , expr . rhs ) ) ; if ( rhs != null ) switch ( expr . op ) { case LT : return compare ( lhs , rhs ) < 0 ; case LE : return compare ( lhs , rhs ) <= 0 ; case GT : return compare ( lhs , rhs ) > 0 ; case GE : return compare ( lhs , rhs ) >= 0 ; case EQ : return lhs . equals ( rhs ) ; case NEQ : return ! lhs . equals ( rhs ) ; case REQ : return lhs . toString ( ) . matches ( rhs . toString ( ) ) ; case AND : return ( ( Boolean ) lhs ) && ( ( Boolean ) rhs ) ; } else switch ( expr . op ) { case NOT : return ! ( ( Boolean ) lhs ) ; } } throw new DapException ( \"Malformed Filter\" ) ; }", "nl": "Evaluate a filter with respect to a Sequence record . Assumes the filter has been canonicalized so that the lhs is a variable ."}}
{"translation": {"code": "static public List < DapVariable > getStructurePath ( DapVariable var ) { List < DapNode > path = var . getPath ( ) ; List < DapVariable > structpath = new ArrayList < DapVariable > ( ) ; for ( int i = 0 ; i < path . size ( ) ; i ++ ) { DapNode node = path . get ( i ) ; switch ( node . getSort ( ) ) { case DATASET : case GROUP : break ; case VARIABLE : structpath . add ( ( DapVariable ) node ) ; break ; default : assert false : \"Internal error\" ; } } return structpath ; }", "nl": "Given a dap variable get the path from the top - level variable to and including the given variable such that all but the last element is a structure ."}}
{"translation": {"code": "static public byte [ ] extract ( ByteBuffer buf ) { int len = buf . limit ( ) ; byte [ ] bytes = new byte [ len ] ; buf . rewind ( ) ; buf . get ( bytes ) ; return bytes ; }", "nl": "Properly extract the byte contents of a ByteBuffer"}}
{"translation": {"code": "static public String locateRelative ( String relpath , String abspath , boolean wantdir ) { // clean up the path and filename relpath = relpath . trim ( ) . replace ( ' ' , ' ' ) ; if ( relpath . charAt ( 0 ) == ' ' ) relpath = relpath . substring ( 1 ) ; if ( relpath . endsWith ( \"/\" ) ) relpath = relpath . substring ( 0 , relpath . length ( ) - 1 ) ; String [ ] pieces = relpath . split ( \"[/]\" ) ; String partial = abspath ; for ( int i = 0 ; i < pieces . length - 1 ; i ++ ) { String nextdir = locateFile ( pieces [ i ] , abspath , true ) ; if ( nextdir == null ) return null ; partial = nextdir ; } // See if the final file|dir exists in this dir String finalpath = locateFile ( pieces [ pieces . length - 1 ] , partial , wantdir ) ; return finalpath ; }", "nl": "Walk the specified dir tree to locate file specified by relative path . Use breadth first search ."}}
{"translation": {"code": "static public int size ( DapType type ) { switch ( type . getTypeSort ( ) ) { case Char : // remember serial size is 1, not 2. case UInt8 : case Int8 : return 1 ; case Int16 : case UInt16 : return 2 ; case Int32 : case UInt32 : case Float32 : return 4 ; case Int64 : case UInt64 : case Float64 : return 8 ; case Enum : return size ( ( ( DapEnumeration ) type ) . getBaseType ( ) ) ; default : break ; } return 0 ; }", "nl": "Conmpute the size in databuffer of the daptype wrt to a serialization ; 0 if undefined ."}}
{"translation": {"code": "static public void dumpbytes ( ByteBuffer buf0 ) { int stop = buf0 . limit ( ) ; int size = stop + 8 ; int savepos = buf0 . position ( ) ; assert savepos == 0 ; byte [ ] bytes = new byte [ size ] ; Arrays . fill ( bytes , ( byte ) 0 ) ; buf0 . get ( bytes , 0 , stop ) ; buf0 . position ( savepos ) ; ByteBuffer buf = ByteBuffer . wrap ( bytes ) . order ( buf0 . order ( ) ) ; buf . position ( 0 ) ; buf . limit ( size ) ; int i = 0 ; try { for ( i = 0 ; buf . position ( ) < stop ; i ++ ) { savepos = buf . position ( ) ; int iv = buf . getInt ( ) ; buf . position ( savepos ) ; long lv = buf . getLong ( ) ; buf . position ( savepos ) ; short sv = buf . getShort ( ) ; buf . position ( savepos ) ; byte b = buf . get ( ) ; int ub = ( ( int ) b ) & 0x000000FF ; long uiv = ( ( long ) iv ) & 0xFFFFFFFF  L ; int usv = ( ( int ) sv ) & 0xFFFF ; int ib = ( int ) b ; char c = ( char ) ub ; String s = Character . toString ( c ) ; if ( c == ' ' ) s = \"\\\\r\" ; else if ( c == ' ' ) s = \"\\\\n\" ; else if ( c < ' ' || c >= 0x7f ) s = \"?\" ; System . err . printf ( \"[%03d] %02x %03d %4d '%s'\" , i , ub , ub , ib , s ) ; System . err . printf ( \"\\t%12d 0x%08x\" , iv , uiv ) ; System . err . printf ( \"\\t%5d\\t0x%04x\" , sv , usv ) ; System . err . println ( ) ; System . err . flush ( ) ; } } catch ( Exception e ) { System . err . println ( \"failure:\" + e ) ; } finally { System . err . flush ( ) ; //new Exception().printStackTrace(System.err); System . err . flush ( ) ; } }", "nl": "Dump the contents of a buffer from 0 to position"}}
{"translation": {"code": "static public void dumpbytes ( ByteBuffer buf0 , boolean skipdmr ) { int savepos = buf0 . position ( ) ; int limit0 = buf0 . limit ( ) ; int skipcount = 0 ; if ( limit0 > MAXLIMIT ) limit0 = MAXLIMIT ; if ( limit0 >= buf0 . limit ( ) ) limit0 = buf0 . limit ( ) ; if ( skipdmr ) { ByteOrder saveorder = buf0 . order ( ) ; buf0 . order ( ByteOrder . BIG_ENDIAN ) ; // must read in network order skipcount = buf0 . getInt ( ) ; //dmr count buf0 . order ( saveorder ) ; skipcount &= 0xFFFFFF ; // mask off the flags to get true count skipcount += 4 ; // skip the count also } byte [ ] bytes = new byte [ ( limit0 + 8 ) - skipcount ] ; Arrays . fill ( bytes , ( byte ) 0 ) ; buf0 . position ( savepos + skipcount ) ; buf0 . get ( bytes , 0 , limit0 - skipcount ) ; buf0 . position ( savepos ) ; System . err . println ( \"order=\" + buf0 . order ( ) ) ; ByteBuffer buf = ByteBuffer . wrap ( bytes ) . order ( buf0 . order ( ) ) ; dumpbytes ( buf ) ; }", "nl": "Provide a simple dump of binary data"}}
{"translation": {"code": "public String readDMR ( ) throws DapException { try { if ( state != State . INITIAL ) throw new DapException ( \"Attempt to read DMR twice\" ) ; byte [ ] dmr8 = null ; if ( requestmode == RequestMode . DMR ) { // The whole buffer is the dmr; // but we do not know the length ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; int c ; while ( ( c = input . read ( ) ) >= 0 ) { baos . write ( c ) ; } baos . close ( ) ; dmr8 = baos . toByteArray ( ) ; } else if ( requestmode == RequestMode . DAP ) { // Pull in the DMR chunk header if ( ! readHeader ( input ) ) throw new DapException ( \"Malformed chunk count\" ) ; // Read the DMR databuffer dmr8 = new byte [ this . chunksize ] ; int red = read ( dmr8 , 0 , this . chunksize ) ; if ( red < this . chunksize ) throw new DapException ( \"Short chunk\" ) ; } else assert false : \"Internal error\" ; // Convert DMR to a string String dmr = new String ( dmr8 , DapUtil . UTF8 ) ; // Clean it up dmr = dmr . trim ( ) ; // Make sure it has trailing \\r\\n\" if ( dmr . endsWith ( \"\\r\\n\" ) ) { // do nothing } else if ( dmr . endsWith ( \"\\n\" ) ) dmr = dmr . substring ( 0 , dmr . length ( ) - 2 ) + \"\\r\\n\" ; else dmr = dmr + \"\\r\\n\" ; // Figure out the endian-ness of the response this . remoteorder = ( flags & DapUtil . CHUNK_LITTLE_ENDIAN ) == 0 ? ByteOrder . BIG_ENDIAN : ByteOrder . LITTLE_ENDIAN ; this . nochecksum = ( flags & DapUtil . CHUNK_NOCHECKSUM ) != 0 ; // Set the state if ( ( flags & DapUtil . CHUNK_ERROR ) != 0 ) state = State . ERROR ; else if ( ( flags & DapUtil . CHUNK_END ) != 0 ) state = State . END ; else state = State . DATA ; return dmr ; //return the DMR } catch ( IOException ioe ) { throw new DapException ( ioe . getMessage ( ) ) ; } }", "nl": "Read the DMR trimmed ."}}
{"translation": {"code": "static long MAP ( Slice target , long i ) throws DapException { if ( i < 0 ) throw new DapException ( \"Slice.compose: i must be >= 0\" ) ; if ( i > target . getStop ( ) ) throw new DapException ( \"i must be < stop\" ) ; return target . getFirst ( ) + i * target . getStride ( ) ; }", "nl": "Map ith element of one range wrt a target range"}}
{"translation": {"code": "static public String fqnPrefix ( String fqn ) { int structindex = fqn . lastIndexOf ( ' ' ) ; int groupindex = fqn . lastIndexOf ( ' ' ) ; if ( structindex >= 0 ) return fqn . substring ( 0 , structindex ) ; else return fqn . substring ( 0 , groupindex ) ; }", "nl": "return prefix name part of an fqn ; result will be escaped ."}}
{"translation": {"code": "static public Slice compose ( Slice target , Slice src ) throws DapException { long sr_stride = target . getStride ( ) * src . getStride ( ) ; long sr_first = MAP ( target , src . getFirst ( ) ) ; long lastx = MAP ( target , src . getLast ( ) ) ; long sr_last = ( target . getLast ( ) < lastx ? target . getLast ( ) : lastx ) ; //min(last(),lastx) return new Slice ( sr_first , sr_last + 1 , sr_stride , sr_last + 1 ) . finish ( ) ; }", "nl": "Take two slices and compose src wrt target Assume neither argument is null . This code should match ucar . ma2 . Section in thredds and dceconstraint . c in the netcdf - c library ."}}
{"translation": {"code": "static public String entityEscape ( String s , String wrt ) { if ( wrt == null ) wrt = ENTITYESCAPES ; StringBuilder escaped = new StringBuilder ( ) ; for ( int i = 0 ; i < s . length ( ) ; i ++ ) { char c = s . charAt ( i ) ; int index = wrt . indexOf ( c ) ; if ( index < 0 ) escaped . append ( c ) ; else switch ( c ) { case ' ' : escaped . append ( ' ' + ENTITY_AMP + ' ' ) ; break ; case ' ' : escaped . append ( ' ' + ENTITY_LT + ' ' ) ; break ; case ' ' : escaped . append ( ' ' + ENTITY_GT + ' ' ) ; break ; case ' ' : escaped . append ( ' ' + ENTITY_QUOT + ' ' ) ; break ; case ' ' : escaped . append ( ' ' + ENTITY_APOS + ' ' ) ; break ; case ' ' : case ' ' : case ' ' : escaped . append ( c ) ; // These are the only legal control chars break ; case ' ' : // What to do about nul? currrently we suppress it break ; default : if ( c >= ' ' ) escaped . append ( c ) ; break ; } } return escaped . toString ( ) ; }", "nl": "Escape selected characters in a string using XML entities"}}
{"translation": {"code": "static public String fqnSuffix ( String fqn ) { int structindex = fqn . lastIndexOf ( ' ' ) ; int groupindex = fqn . lastIndexOf ( ' ' ) ; if ( structindex >= 0 ) return fqn . substring ( structindex + 1 , fqn . length ( ) ) ; else return fqn . substring ( groupindex + 1 , fqn . length ( ) ) ; }", "nl": "return last name part of an fqn ; result will be escaped ."}}
{"translation": {"code": "public String toConstraintString ( ) throws DapException { assert this . first != UNDEFINED && this . stride != UNDEFINED && this . stop != UNDEFINED ; if ( ( this . stop - this . first ) == 0 ) { return String . format ( \"[0]\" ) ; } else if ( this . stride == 1 ) { if ( ( this . stop - this . first ) == 1 ) return String . format ( \"[%d]\" , this . first ) ; else return String . format ( \"[%d:%d]\" , this . first , this . stop - 1 ) ; } else return String . format ( \"[%d:%d:%d]\" , this . first , this . stride , this . stop - 1 ) ; }", "nl": "Convert this slice to a string suitable for use in a constraint"}}
{"translation": {"code": "boolean readHeader ( InputStream input ) throws IOException { byte [ ] bytehdr = new byte [ 4 ] ; int red = input . read ( bytehdr ) ; if ( red == - 1 ) return false ; if ( red < 4 ) throw new IOException ( \"Short binary chunk count\" ) ; this . flags = ( ( int ) bytehdr [ 0 ] ) & 0xFF ; // Keep unsigned bytehdr [ 0 ] = 0 ; ByteBuffer buf = ByteBuffer . wrap ( bytehdr ) . order ( ByteOrder . BIG_ENDIAN ) ; this . chunksize = buf . getInt ( ) ; this . avail = this . chunksize ; return true ; }", "nl": "Read the size + flags header from the input stream and use it to initialize the chunk state"}}
{"translation": {"code": "public int read ( byte [ ] buf , int off , int len ) throws IOException { // Sanity check if ( off < 0 || len < 0 ) throw new IndexOutOfBoundsException ( ) ; // Runtime if ( off >= buf . length || buf . length < ( off + len ) ) throw new IndexOutOfBoundsException ( ) ; //Runtime if ( requestmode == RequestMode . DMR ) throw new UnsupportedOperationException ( \"Attempt to read databuffer when DMR only\" ) ; // Runtime // Attempt to read len bytes out of a sequence of chunks int count = len ; int pos = off ; while ( count > 0 ) { if ( avail <= 0 ) { if ( ( flags & DapUtil . CHUNK_END ) != 0 || ! readHeader ( input ) ) return ( len - count ) ; // return # databuffer read // See if we have an error chunk, // and if so, turn it into an exception if ( ( flags & DapUtil . CHUNK_ERROR ) != 0 ) { String document = readError ( ) ; throwError ( document ) ; } } else { int actual = ( this . avail < count ? this . avail : count ) ; int red = input . read ( buf , pos , actual ) ; if ( red < 0 ) throw new IOException ( \"Unexpected EOF\" ) ; pos += red ; count -= red ; this . avail -= red ; } } return len ; }", "nl": "Reads up to len databuffer of databuffer from the input stream into an array of databuffer . An attempt is made to read as many as len databuffer but a smaller number may be read . The number of databuffer actually read is returned as an integer ."}}
{"translation": {"code": "public boolean references ( DapNode node ) { boolean isref = false ; switch ( node . getSort ( ) ) { case DIMENSION : DapDimension dim = this . redef . get ( ( DapDimension ) node ) ; if ( dim == null ) dim = ( DapDimension ) node ; isref = this . dimrefs . contains ( dim ) ; break ; case ENUMERATION : isref = ( this . enums . contains ( ( DapEnumeration ) node ) ) ; break ; case VARIABLE : isref = ( findVariableIndex ( ( DapVariable ) node ) >= 0 ) ; break ; case GROUP : case DATASET : isref = ( this . groups . contains ( ( DapGroup ) node ) ) ; break ; default : break ; } return isref ; }", "nl": "Reference X match"}}
{"translation": {"code": "static public String locateFile ( String filename , String abspath , boolean wantdir ) { Deque < String > q = new ArrayDeque < String > ( ) ; // clean up the path and filename filename = filename . trim ( ) . replace ( ' ' , ' ' ) ; abspath = abspath . trim ( ) . replace ( ' ' , ' ' ) ; if ( filename . charAt ( 0 ) == ' ' ) filename = filename . substring ( 1 ) ; if ( filename . endsWith ( \"/\" ) ) filename = filename . substring ( 0 , filename . length ( ) - 1 ) ; if ( abspath . endsWith ( \"/\" ) ) abspath = abspath . substring ( 0 , abspath . length ( ) - 1 ) ; q . addFirst ( abspath ) ; // prime the search queue for ( ; ; ) { // breadth first search String currentpath = q . poll ( ) ; if ( currentpath == null ) break ; // done searching File current = new File ( currentpath ) ; File [ ] contents = current . listFiles ( ) ; if ( contents != null ) { for ( File subfile : contents ) { if ( ! subfile . getName ( ) . equals ( filename ) ) continue ; if ( ( wantdir && subfile . isDirectory ( ) ) || ( ! wantdir && subfile . isFile ( ) ) ) { // Assume this is it return DapUtil . canonicalpath ( subfile . getAbsolutePath ( ) ) ; } } for ( File subfile : contents ) { if ( subfile . isDirectory ( ) ) q . addFirst ( currentpath + \"/\" + subfile . getName ( ) ) ; } } } return null ; }", "nl": "Walk the specified subtree dir tree to try to locate file|dir named filename . Use breadth first search ."}}
{"translation": {"code": "protected boolean matches ( DapVariable var , DapSequence seq , DataCursor rec , CEAST filter ) throws DapException { Object value = eval ( var , seq , rec , filter ) ; return ( ( Boolean ) value ) ; }", "nl": "Evaluate a filter with respect to a Sequence record ."}}
{"translation": {"code": "protected void compileAST ( CEAST ast ) throws DapException { switch ( ast . sort ) { case CONSTRAINT : for ( CEAST clause : ast . clauses ) { compileAST ( clause ) ; } // invoke semantic checks this . ce . expand ( ) ; this . ce . finish ( ) ; break ; case PROJECTION : scopestack . clear ( ) ; compileAST ( ast . tree ) ; break ; case SEGMENT : compilesegment ( ast ) ; break ; case SELECTION : scopestack . clear ( ) ; compileselection ( ast ) ; break ; case DEFINE : dimredef ( ast ) ; break ; default : assert false : \"uknown CEAST node type\" ; } }", "nl": "Recursive AST walker ; compilation of filters is done elsewhere ."}}
{"translation": {"code": "protected void computeenums ( ) { for ( int i = 0 ; i < variables . size ( ) ; i ++ ) { DapVariable var = variables . get ( i ) ; if ( var . getSort ( ) != DapSort . VARIABLE ) continue ; DapType daptype = var . getBaseType ( ) ; if ( ! daptype . isEnumType ( ) ) continue ; if ( ! this . enums . contains ( ( DapEnumeration ) daptype ) ) this . enums . add ( ( DapEnumeration ) daptype ) ; } }", "nl": "Walk all the included variables and accumulate the referenced enums"}}
{"translation": {"code": "public Map < String , DapAttribute > getAttributes ( ) { if ( attributes == null ) attributes = new HashMap < String , DapAttribute > ( ) ; return attributes ; }", "nl": "attributes are not allowed on some node types"}}
{"translation": {"code": "synchronized public DapAttribute setAttribute ( DapAttribute attr ) throws DapException { if ( attributes == null ) attributes = new HashMap < String , DapAttribute > ( ) ; DapAttribute old = attributes . get ( attr . getShortName ( ) ) ; attributes . put ( attr . getShortName ( ) , attr ) ; attr . setParent ( this ) ; return old ; }", "nl": "This may occur after initial construction"}}
{"translation": {"code": "@ Override protected Array readData ( Variable cdmvar , Section section ) throws IOException , InvalidRangeException { // The section is applied wrt to the DataDMR, so it // takes into account any constraint used in forming the dataDMR. // We use the Section to produce a view of the underlying variable array. assert this . dsp != null ; Array result = arraymap . get ( cdmvar ) ; if ( result == null ) throw new IOException ( \"No data for variable: \" + cdmvar . getFullName ( ) ) ; if ( section != null ) { if ( cdmvar . getRank ( ) != section . getRank ( ) ) throw new InvalidRangeException ( String . format ( \"Section rank != %s rank\" , cdmvar . getFullName ( ) ) ) ; List < Range > ranges = section . getRanges ( ) ; // Case out the possibilities if ( CDMUtil . hasVLEN ( ranges ) ) { ranges = ranges . subList ( 0 , ranges . size ( ) - 1 ) ; // may produce empty list } if ( ranges . size ( ) > 0 && ! CDMUtil . isWhole ( ranges , cdmvar ) ) result = result . sectionNoReduce ( ranges ) ; } return result ; }", "nl": "Primary read entry point . This is the primary implementor of Variable . read ."}}
{"translation": {"code": "public Object nextFloat ( DapType basetype ) throws DapException { TypeSort atomtype = basetype . getTypeSort ( ) ; switch ( atomtype ) { case Float32 : return new float [ ] { random . nextFloat ( ) } ; case Float64 : return new double [ ] { random . nextDouble ( ) } ; default : break ; } throw new DapException ( \"Unexpected type: \" + basetype ) ; }", "nl": "return a float type value"}}
{"translation": {"code": "public DapGroup getGroup ( ) { if ( this . sort == DapSort . DATASET ) return null ; // Walk the parent node until we find a group DapNode group = parent ; while ( group != null ) { switch ( group . getSort ( ) ) { case DATASET : case GROUP : return ( DapGroup ) group ; default : group = group . getParent ( ) ; break ; } } return ( DapGroup ) group ; }", "nl": "Closest containing group"}}
{"translation": {"code": "public DapNode getContainer ( ) { DapNode parent = this . parent ; switch ( getSort ( ) ) { default : break ; case ENUMCONST : parent = ( ( DapEnumConst ) this ) . getParent ( ) . getContainer ( ) ; break ; case ATTRIBUTE : case ATTRIBUTESET : case OTHERXML : parent = ( ( DapAttribute ) this ) . getParent ( ) ; if ( parent instanceof DapVariable ) parent = parent . getContainer ( ) ; break ; case MAP : parent = ( ( DapMap ) this ) . getVariable ( ) . getContainer ( ) ; break ; } return parent ; }", "nl": "Closest containing group structure sequence"}}
{"translation": {"code": "public String getEscapedShortName ( ) { if ( this . escapedname == null ) this . escapedname = Escape . backslashEscape ( getShortName ( ) , null ) ; return this . escapedname ; }", "nl": "Here escaped means backslash escaped short name"}}
{"translation": {"code": "public NodeMap < CDMNode , DapNode > create ( ) throws DapException { // Netcdf Dataset will already have a root group Group cdmroot = ncfile . getRootGroup ( ) ; this . nodemap . put ( cdmroot , this . dmr ) ; fillGroup ( cdmroot , this . dmr , ncfile ) ; return this . nodemap ; }", "nl": "Do the conversion and return a NodeMap representing the conversion ."}}
{"translation": {"code": "public List < DapNode > getContainerPath ( ) { List < DapNode > path = new ArrayList < DapNode > ( ) ; DapNode current = this . getContainer ( ) ; for ( ; ; ) { path . add ( 0 , current ) ; if ( current . getContainer ( ) == null ) break ; current = current . getContainer ( ) ; } return path ; }", "nl": "Get the transitive list of containers Not including this node"}}
{"translation": {"code": "protected DapDataset parseDMR ( String document ) throws DapException { // Parse the dmr Dap4Parser parser ; //if(USEDOM) parser = new DOM4Parser ( null ) ; //else //    parser = new DOM4Parser(new DefaultDMRFactory()); if ( PARSEDEBUG ) parser . setDebugLevel ( 1 ) ; try { if ( ! parser . parse ( document ) ) throw new DapException ( \"DMR Parse failed\" ) ; } catch ( SAXException se ) { throw new DapException ( se ) ; } if ( parser . getErrorResponse ( ) != null ) throw new DapException ( \"Error Response Document not supported\" ) ; DapDataset result = parser . getDMR ( ) ; processAttributes ( result ) ; return result ; }", "nl": "It is common to want to parse a DMR text to a DapDataset so provide this utility ."}}
{"translation": {"code": "public void sort ( ) { List < DapNode > sorted = new ArrayList < DapNode > ( ) ; sortR ( this , sorted ) ; // Assign indices for ( int i = 0 ; i < sorted . size ( ) ; i ++ ) { sorted . get ( i ) . setIndex ( i ) ; } this . nodelist = sorted ; }", "nl": "Sort the nodelist into prefix left to right order"}}
{"translation": {"code": "public void finish ( ) { if ( this . finished ) return ; if ( this . ce == null ) this . visiblenodes = nodelist ; else { this . visiblenodes = new ArrayList < DapNode > ( nodelist . size ( ) ) ; for ( int i = 0 ; i < nodelist . size ( ) ; i ++ ) { DapNode node = nodelist . get ( i ) ; if ( ce . references ( node ) ) visiblenodes . add ( node ) ; } } this . topvariables = new ArrayList < DapVariable > ( ) ; this . allvariables = new ArrayList < DapVariable > ( ) ; this . allgroups = new ArrayList < DapGroup > ( ) ; this . allenums = new ArrayList < DapEnumeration > ( ) ; this . allcompounds = new ArrayList < DapStructure > ( ) ; this . alldimensions = new ArrayList < DapDimension > ( ) ; finishR ( this ) ; }", "nl": "Compute inferred information"}}
{"translation": {"code": "public String getScalarString ( int recnum , StructureMembers . Member m ) { Array data = m . getDataArray ( ) ; return ( String ) data . getObject ( recnum ) . toString ( ) ; }", "nl": "Get member databuffer of type String or char ."}}
{"translation": {"code": "public StructureData getScalarStructure ( int index , StructureMembers . Member m ) { if ( m . getDataType ( ) != DataType . STRUCTURE ) throw new ForbiddenConversionException ( \"Atomic field cannot be converted to Structure\" ) ; Array ca = memberArray ( index , memberIndex ( m ) ) ; if ( ca . getDataType ( ) != DataType . STRUCTURE && ca . getDataType ( ) != DataType . SEQUENCE ) throw new ForbiddenConversionException ( \"Attempt to access non-structure member\" ) ; CDMArrayStructure as = ( CDMArrayStructure ) ca ; return as . getStructureData ( 0 ) ; }", "nl": "Non - atomic cases"}}
{"translation": {"code": "public List < DapGroup > getGroupPath ( ) { List < DapGroup > path = new ArrayList < DapGroup > ( ) ; DapNode current = this ; for ( ; ; ) { if ( current . getSort ( ) == DapSort . GROUP || current . getSort ( ) == DapSort . DATASET ) path . add ( 0 , ( DapGroup ) current ) ; if ( current . getContainer ( ) == null ) break ; current = current . getContainer ( ) ; } return path ; }", "nl": "Get the transitive list of containing groups Possibly including this node"}}
{"translation": {"code": "static StructureMembers computemembers ( DapVariable var ) { DapStructure ds = ( DapStructure ) var . getBaseType ( ) ; StructureMembers sm = new StructureMembers ( ds . getShortName ( ) ) ; List < DapVariable > fields = ds . getFields ( ) ; for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { DapVariable field = fields . get ( i ) ; DapType dt = field . getBaseType ( ) ; DataType cdmtype = CDMTypeFcns . daptype2cdmtype ( dt ) ; StructureMembers . Member m = sm . addMember ( field . getShortName ( ) , \"\" , null , cdmtype , CDMUtil . computeEffectiveShape ( field . getDimensions ( ) ) ) ; m . setDataParam ( i ) ; // So we can index into various lists // recurse if this field is itself a structure if ( dt . getTypeSort ( ) . isStructType ( ) ) { StructureMembers subsm = computemembers ( field ) ; m . setStructureMembers ( subsm ) ; } } return sm ; }", "nl": "Compute the StructureMembers object from a DapStructure . May need to recurse if a field is itself a Structure"}}
{"translation": {"code": "public String computefqn ( ) { List < DapNode > path = getPath ( ) ; // excludes root/wrt StringBuilder fqn = new StringBuilder ( ) ; DapNode parent = path . get ( 0 ) ; for ( int i = 1 ; i < path . size ( ) ; i ++ ) { // start at 1 to skip root DapNode current = path . get ( i ) ; // Depending on what parent is, use different delimiters switch ( parent . getSort ( ) ) { case DATASET : case GROUP : case ENUMERATION : fqn . append ( ' ' ) ; fqn . append ( Escape . backslashEscape ( current . getShortName ( ) , \"/.\" ) ) ; break ; // These use '.' case STRUCTURE : case SEQUENCE : case ENUMCONST : case VARIABLE : fqn . append ( ' ' ) ; fqn . append ( current . getEscapedShortName ( ) ) ; break ; default : // Others should never happen throw new IllegalArgumentException ( \"Illegal FQN parent\" ) ; } parent = current ; } return fqn . toString ( ) ; }", "nl": "Compute the FQN of this node"}}
{"translation": {"code": "static public String nullify ( String path ) { return ( path != null && path . length ( ) == 0 ? null : path ) ; }", "nl": "Convert paths to null"}}
{"translation": {"code": "@ Override public void fatalError ( SAXParseException e ) throws SAXException { throw new SAXParseException ( String . format ( \"Sax fatal error: %s; %s%n\" , e , report ( this . locator ) ) , this . locator ) ; }", "nl": "Error handling Events"}}
{"translation": {"code": "void printDimrefs ( DapVariable var ) throws DapException { if ( var . getRank ( ) == 0 ) return ; List < DapDimension > dimset = this . ce . getConstrainedDimensions ( var ) ; if ( dimset == null ) throw new DapException ( \"Unknown variable: \" + var ) ; assert var . getRank ( ) == dimset . size ( ) ; for ( int i = 0 ; i < var . getRank ( ) ; i ++ ) { DapDimension dim = dimset . get ( i ) ; printer . marginPrint ( \"<Dim\" ) ; if ( dim . isShared ( ) ) { String fqn = dim . getFQN ( ) ; assert ( fqn != null ) : \"Illegal Dimension reference\" ; fqn = fqnXMLEscape ( fqn ) ; printXMLAttribute ( \"name\" , fqn , XMLESCAPED ) ; } else { long size = dim . getSize ( ) ; // the size for printing purposes printXMLAttribute ( \"size\" , Long . toString ( size ) , NILFLAGS ) ; } printer . println ( \"/>\" ) ; } }", "nl": "Print the dimrefs for a variable s dimensions . If the variable has a non - whole projection then use size else use the dimension name ."}}
{"translation": {"code": "protected void printXMLAttribute ( String name , String value , int flags ) throws DapException { if ( name == null ) return ; if ( ( flags & NONNIL ) == 0 && ( value == null || value . length ( ) == 0 ) ) return ; if ( ( flags & PERLINE ) != 0 ) { printer . eol ( ) ; printer . margin ( ) ; } printer . print ( \" \" + name + \"=\" ) ; printer . print ( \"\\\"\" ) ; if ( value != null ) { // add xml entity escaping if ( ( flags & XMLESCAPED ) == 0 ) value = Escape . entityEscape ( value , \"\\\"\" ) ; printer . print ( value ) ; } printer . print ( \"\\\"\" ) ; }", "nl": "PrintXMLAttributes helper function"}}
{"translation": {"code": "void printXMLAttributes ( DapNode node , CEConstraint ce , int flags ) throws IOException { if ( ( flags & PERLINE ) != 0 ) printer . indent ( 2 ) ; // Print name first, if non-null and !NONAME // Note that the short name needs to use // entity escaping (which is done by printXMLattribute), // but backslash escaping is not required. String name = node . getShortName ( ) ; if ( name != null && ( flags & NONAME ) == 0 ) { name = node . getShortName ( ) ; printXMLAttribute ( \"name\" , name , flags ) ; } switch ( node . getSort ( ) ) { case DATASET : DapDataset dataset = ( DapDataset ) node ; printXMLAttribute ( \"dapVersion\" , dataset . getDapVersion ( ) , flags ) ; printXMLAttribute ( \"dmrVersion\" , dataset . getDMRVersion ( ) , flags ) ; // boilerplate printXMLAttribute ( \"xmlns\" , \"http://xml.opendap.org/ns/DAP/4.0#\" , flags ) ; printXMLAttribute ( \"xmlns:dap\" , \"http://xml.opendap.org/ns/DAP/4.0#\" , flags ) ; break ; case DIMENSION : DapDimension orig = ( DapDimension ) node ; if ( orig . isShared ( ) ) { //not Anonymous // name will have already been printed // Now, we need to get the size as defined by the constraint DapDimension actual = this . ce . getRedefDim ( orig ) ; if ( actual == null ) actual = orig ; long size = actual . getSize ( ) ; printXMLAttribute ( \"size\" , Long . toString ( size ) , flags ) ; } break ; case ENUMERATION : printXMLAttribute ( \"basetype\" , ( ( DapEnumeration ) node ) . getBaseType ( ) . getTypeName ( ) , flags ) ; break ; case VARIABLE : DapVariable var = ( DapVariable ) node ; DapType basetype = var . getBaseType ( ) ; if ( basetype . isEnumType ( ) ) { printXMLAttribute ( \"enum\" , basetype . getTypeName ( ) , flags ) ; } break ; case ATTRIBUTE : DapAttribute attr = ( DapAttribute ) node ; basetype = attr . getBaseType ( ) ; printXMLAttribute ( \"type\" , basetype . getTypeName ( ) , flags ) ; if ( attr . getBaseType ( ) . isEnumType ( ) ) { printXMLAttribute ( \"enum\" , basetype . getTypeName ( ) , flags ) ; } break ; default : break ; // node either has no attributes or name only } //switch if ( ! this . testing ) printReserved ( node ) ; if ( ( flags & PERLINE ) != 0 ) { printer . outdent ( 2 ) ; } }", "nl": "Print info from the node that needs to be in the form of xml attributes"}}
{"translation": {"code": "public String buildXML ( ) { StringBuilder response = new StringBuilder ( ) ; response . append ( \"<Error\" ) ; if ( code > 0 ) response . append ( String . format ( \" httpcode=\\\"%d\\\"\" , code ) ) ; response . append ( \">\\n\" ) ; if ( message != null ) response . append ( \"<Message>\" + getMessage ( ) + \"</Message>\\n\" ) ; if ( context != null ) response . append ( \"<Context>\" + getContext ( ) + \"</Context>\\n\" ) ; if ( otherinfo != null ) response . append ( \"<OtherInformation>\" + getOtherInfo ( ) + \"</OtherInformation>\\n\" ) ; return response . toString ( ) ; }", "nl": "Convert an ErrorResponse to the equivalent XML"}}
{"translation": {"code": "protected int expansionCount ( DapStructure struct ) { int count = 0 ; for ( DapVariable field : struct . getFields ( ) ) { if ( findVariableIndex ( field ) >= 0 ) count ++ ; } return count ; }", "nl": "Count the number of fields of a structure that already in this view ."}}
{"translation": {"code": "@ Override public void flush ( ) throws IOException { if ( mode == RequestMode . DMR ) return ; // leave to close() to do this if ( dmr8 != null ) { sendDXR ( dmr8 ) ; dmr8 = null ; } }", "nl": "Overload flush to also write out the DMR"}}
{"translation": {"code": "public void writeError ( int httpcode , String msg , String cxt , String other ) throws IOException { dmr8 = null ; ErrorResponse response = new ErrorResponse ( httpcode , msg , cxt , other ) ; String errorbody = response . buildXML ( ) ; // Convert the error body into utf8 then to byte[] byte [ ] errbody8 = DapUtil . extract ( DapUtil . UTF8 . encode ( errorbody ) ) ; if ( mode == RequestMode . DMR ) { sendDXR ( errbody8 ) ; } else { //mode == DATA // clear any partial chunk chunk . clear ( ) ; // create an error header int flags = DapUtil . CHUNK_ERROR | DapUtil . CHUNK_END ; chunkheader ( errbody8 . length , flags , header ) ; output . write ( DapUtil . extract ( header ) ) ; output . write ( errbody8 ) ; output . flush ( ) ; } state = State . ERROR ; }", "nl": "Write an error chunk . If mode == DMR then replaces the dmr else reset the current chunk thus losing any partial write ."}}
{"translation": {"code": "void sendDXR ( byte [ ] dxr8 ) throws IOException { if ( dxr8 == null || dxr8 . length == 0 ) return ; // do nothing if ( mode == RequestMode . DMR || mode == RequestMode . DSR ) { state = State . END ; } else { //mode == DATA // Prefix with chunk header int flags = DapUtil . CHUNK_DATA ; if ( this . writeorder == ByteOrder . LITTLE_ENDIAN ) flags |= DapUtil . CHUNK_LITTLE_ENDIAN ; chunkheader ( dxr8 . length , flags , this . header ) ; // write the header output . write ( DapUtil . extract ( this . header ) ) ; state = State . DATA ; } // write the DXR output . write ( dxr8 ) ; output . flush ( ) ; }", "nl": "Output the specifiedd DMR or DSR or ... but xml only ."}}
{"translation": {"code": "public void writeDSR ( String dsr ) throws IOException { if ( state != State . INITIAL ) throw new DapException ( \"Attempt to write DSR twice\" ) ; if ( dsr == null ) throw new DapException ( \"Attempt to write empty DSR\" ) ; // Strip off any trailing sequence of CR or LF. int len = dsr . length ( ) ; while ( len > 0 ) { char c = dsr . charAt ( len - 1 ) ; if ( c != ' ' && c != ' ' ) break ; len -- ; } if ( dsr . length ( ) == 0 ) throw new DapException ( \"Attempt to write empty DSR\" ) ; dsr = dsr . substring ( 0 , len ) + DapUtil . CRLF ; // Add <?xml...?> prefix dsr = XMLDOCUMENTHEADER + \"\\n\" + dsr ; // Convert the dsr to UTF-8 and then to byte[] byte [ ] dsr8 = DapUtil . extract ( DapUtil . UTF8 . encode ( dsr ) ) ; sendDXR ( dsr8 ) ; state = State . END ; }", "nl": "Write the DSR ; do not bother to cache ."}}
{"translation": {"code": "public DapException buildException ( ) { String XML = buildXML ( ) ; DapException dapex = new DapException ( XML ) . setCode ( code ) ; return dapex ; }", "nl": "Convert an ErrorResponse to the equivalent DapException ."}}
{"translation": {"code": "protected void build ( DapDataset dmr , byte [ ] serialdata , ByteOrder order ) throws DapException { setDMR ( dmr ) ; // \"Compile\" the databuffer section of the server response this . databuffer = ByteBuffer . wrap ( serialdata ) . order ( order ) ; D4DataCompiler compiler = new D4DataCompiler ( this , getChecksumMode ( ) , getOrder ( ) , this . databuffer ) ; compiler . compile ( ) ; }", "nl": "Build the data from the incoming serial data Note that some DSP s will not use"}}
{"translation": {"code": "public boolean isTopLevel ( ) { return parent == null || parent . getSort ( ) == DapSort . DATASET || parent . getSort ( ) == DapSort . GROUP ; }", "nl": "Misc . Methods"}}
{"translation": {"code": "public void close ( ) throws IOException { if ( closed ) return ; closed = true ; if ( dmr8 != null ) { sendDXR ( dmr8 ) ; dmr8 = null ; } if ( mode == RequestMode . DMR ) return ; // only DMR should be sent // If there is no partial chunk to write then // we are done; else verify we can write and write the last // chunk; => multiple closes are ok. if ( chunk == null || chunk . position ( ) == 0 ) return ; // There is data left to write. verifystate ( ) ; // are we in a state supporting data write? // Force out the current chunk (might be empty) // but do not close the underlying output stream state = State . DATA ; // pretend int flags = DapUtil . CHUNK_END ; writeChunk ( flags ) ; state = State . END ; this . output . flush ( ) ; // Do not close if ( this . saveoutput != null ) { // write to true output target this . saveoutput . write ( ( ( ByteArrayOutputStream ) this . output ) . toByteArray ( ) ) ; } }", "nl": "Closes this output stream and releases any system resources associated with this stream . Except the underlying stream is not actually closed ; that is left to the servlet level"}}
{"translation": {"code": "protected void computegroups ( ) { // 1. variables for ( int i = 0 ; i < variables . size ( ) ; i ++ ) { DapVariable var = variables . get ( i ) ; List < DapGroup > path = var . getGroupPath ( ) ; for ( DapGroup group : path ) { if ( ! this . groups . contains ( group ) ) this . groups . add ( group ) ; } } // 2. Dimensions for ( DapDimension dim : this . dimrefs ) { if ( ! dim . isShared ( ) ) continue ; List < DapGroup > path = dim . getGroupPath ( ) ; for ( DapGroup group : path ) { if ( ! this . groups . contains ( group ) ) this . groups . add ( group ) ; } } // 2. enumerations for ( DapEnumeration en : this . enums ) { List < DapGroup > path = en . getGroupPath ( ) ; for ( DapGroup group : path ) { if ( ! this . groups . contains ( group ) ) this . groups . add ( group ) ; } } }", "nl": "Walk all the included declarations and accumulate the set of referenced groups"}}
{"translation": {"code": "static public String backslashUnescape ( String s ) { StringBuilder clear = new StringBuilder ( ) ; for ( int i = 0 ; i < s . length ( ) ; ) { char c = s . charAt ( i ++ ) ; if ( c == ' ' ) { c = s . charAt ( i ++ ) ; switch ( c ) { case ' ' : c = ' ' ; break ; case ' ' : c = ' ' ; break ; case ' ' : c = ' ' ; break ; case ' ' : c = ' ' ; break ; default : break ; } clear . append ( c ) ; } else clear . append ( c ) ; } return clear . toString ( ) ; }", "nl": "Remove backslashed characters in a string"}}
{"translation": {"code": "protected void builddimrefs ( DapVariable dapvar , List < Dimension > cdmdims ) throws DapException { if ( cdmdims == null || cdmdims . size ( ) == 0 ) return ; // It is unfortunately the case that the dimensions // associated with the variable are not // necessarily the same object as those dimensions // as declared, so we need to use a non-trivial // matching algorithm. for ( Dimension cdmdim : cdmdims ) { DapDimension dapdim = null ; if ( cdmdim . isShared ( ) ) { Dimension declareddim = finddimdecl ( cdmdim ) ; if ( declareddim == null ) throw new DapException ( \"Unprocessed cdm dimension: \" + cdmdim ) ; dapdim = ( DapDimension ) this . nodemap . get ( declareddim ) ; assert dapdim != null ; } else if ( cdmdim . isVariableLength ( ) ) { // ignore continue ; } else { //anonymous dapdim = builddim ( cdmdim ) ; } assert ( dapdim != null ) : \"Internal error\" ; dapvar . addDimension ( dapdim ) ; } }", "nl": "Assign dimensions to a variable"}}
{"translation": {"code": "public void writeAtomicArray ( DapType daptype , Object values ) throws IOException { assert values != null && values . getClass ( ) . isArray ( ) ; ByteBuffer buf = SerialWriter . encodeArray ( daptype , values , this . order ) ; byte [ ] bytes = buf . array ( ) ; int len = buf . position ( ) ; writeBytes ( bytes , len ) ; if ( DEBUG ) { System . err . printf ( \"%s: \" , daptype . getShortName ( ) ) ; for ( int i = 0 ; i < len ; i ++ ) { int x = ( int ) ( order == ByteOrder . BIG_ENDIAN ? bytes [ i ] : bytes [ ( len - 1 ) - i ] ) ; System . err . printf ( \"%02x\" , ( int ) ( x & 0xff ) ) ; } System . err . println ( ) ; } }", "nl": "Write out an array of atomic values"}}
{"translation": {"code": "public DapVariable findVariable ( String name ) { DapNode var = findInGroup ( name , DapSort . VARIABLE ) ; return ( DapVariable ) var ; }", "nl": "Locate a variable in this group"}}
{"translation": {"code": "public void writeCount ( long count ) throws IOException { countbuffer . clear ( ) ; countbuffer . putLong ( count ) ; byte [ ] countbuf = countbuffer . array ( ) ; int len = countbuffer . position ( ) ; writeBytes ( countbuf , len ) ; if ( DEBUG ) { System . err . printf ( \"count: %d%n\" , count ) ; } }", "nl": "Write out a prefix count"}}
{"translation": {"code": "public void indent ( int n ) { depth += n ; if ( depth < 0 ) depth = 0 ; else if ( depth > MAXDEPTH ) depth = MAXDEPTH ; }", "nl": "Set depth + = n"}}
{"translation": {"code": "void updateGroups ( List < DapGroup > groups ) { // Verify that the incoming groups are all and only in the list of groups. assert ( groups . size ( ) == this . groups . size ( ) ) : \"Update groups: not same size\" ; for ( DapGroup g : groups ) { if ( ! this . groups . contains ( g ) ) assert ( false ) : \"Update groups: attempt to add new group\" ; } }", "nl": "We will need to re - order the groups"}}
{"translation": {"code": "public void setIndent ( int n ) { depth = n ; if ( depth < 0 ) depth = 0 ; else if ( depth > MAXDEPTH ) depth = MAXDEPTH ; }", "nl": "Set depth = n"}}
{"translation": {"code": "public DDS getDDS ( String CE ) throws IOException , ParseException , DAP2Exception { DDSCommand command = new DDSCommand ( ) ; command . setURL ( CE == null || CE . length ( ) == 0 ? urlString : urlString + \"?\" + CE ) ; if ( filePath != null ) { try ( FileInputStream is = new FileInputStream ( filePath + \".dds\" ) ) { command . process ( is ) ; } } else if ( stream != null ) { command . process ( stream ) ; } else { // must be a remote url openConnection ( urlString + \".dds\" + ( getCompleteCE ( CE ) ) , command ) ; } return command . dds ; }", "nl": "Returns the DDS object from the dataset referenced by this object s URL . The DDS object is referred to by appending . dds to the end of a OPeNDAP URL ."}}
{"translation": {"code": "public D4Cursor compileSequence ( DapVariable var , DapSequence dapseq , D4Cursor container ) throws DapException { int pos = getPos ( this . databuffer ) ; D4Cursor seq = new D4Cursor ( Scheme . SEQUENCE , this . dsp , var , container ) . setOffset ( pos ) ; List < DapVariable > dfields = dapseq . getFields ( ) ; // Get the count of the number of records long nrecs = getCount ( this . databuffer ) ; for ( int r = 0 ; r < nrecs ; r ++ ) { pos = getPos ( this . databuffer ) ; D4Cursor rec = ( D4Cursor ) new D4Cursor ( D4Cursor . Scheme . RECORD , this . dsp , var , container ) . setOffset ( pos ) . setRecordIndex ( r ) ; for ( int m = 0 ; m < dfields . size ( ) ; m ++ ) { DapVariable dfield = dfields . get ( m ) ; D4Cursor dvfield = compileVar ( dfield , rec ) ; rec . addField ( m , dvfield ) ; assert dfield . getParent ( ) != null ; } seq . addRecord ( rec ) ; } return seq ; }", "nl": "Compile a sequence as a set of records ."}}
{"translation": {"code": "protected D4Cursor compileSequenceArray ( DapVariable var , D4Cursor container ) throws DapException { DapSequence dapseq = ( DapSequence ) var . getBaseType ( ) ; D4Cursor seqarray = new D4Cursor ( Scheme . SEQARRAY , this . dsp , var , container ) . setOffset ( getPos ( this . databuffer ) ) ; List < DapDimension > dimset = var . getDimensions ( ) ; long dimproduct = DapUtil . dimProduct ( dimset ) ; D4Cursor [ ] instances = new D4Cursor [ ( int ) dimproduct ] ; Odometer odom = Odometer . factory ( DapUtil . dimsetToSlices ( dimset ) , dimset ) ; while ( odom . hasNext ( ) ) { Index index = odom . next ( ) ; D4Cursor instance = compileSequence ( var , dapseq , seqarray ) ; instance . setIndex ( index ) ; instances [ ( int ) index . index ( ) ] = instance ; } seqarray . setElements ( instances ) ; return seqarray ; }", "nl": "Compile a sequence array ."}}
{"translation": {"code": "public void addDecl ( DapNode newdecl ) throws DapException { DapSort newsort = newdecl . getSort ( ) ; String newname = newdecl . getShortName ( ) ; boolean suppress = false ; // Look for name conflicts (ignore anonymous dimensions) if ( newsort != DapSort . DIMENSION || newname != null ) { for ( DapNode decl : decls ) { if ( newsort == decl . getSort ( ) && newname . equals ( decl . getShortName ( ) ) ) throw new DapException ( \"DapGroup: attempt to add duplicate decl: \" + newname ) ; } } else { // Anonymous DapDimension anon = ( DapDimension ) newdecl ; assert ( newsort == DapSort . DIMENSION && newname == null ) ; // Search for matching anonymous dimension boolean found = false ; for ( DapDimension dim : dimensions ) { if ( ! dim . isShared ( ) && dim . getSize ( ) == anon . getSize ( ) ) { found = true ; break ; } } // Define the anondecl in root group if ( ! found && ! isTopLevel ( ) ) getDataset ( ) . addDecl ( anon ) ; suppress = found || ! isTopLevel ( ) ; } if ( ! suppress ) { decls . add ( newdecl ) ; newdecl . setParent ( this ) ; // Cross link } switch ( newdecl . getSort ( ) ) { case ATTRIBUTE : case ATTRIBUTESET : case OTHERXML : super . addAttribute ( ( DapAttribute ) newdecl ) ; break ; case DIMENSION : if ( ! suppress ) dimensions . add ( ( DapDimension ) newdecl ) ; break ; case ENUMERATION : enums . add ( ( DapEnumeration ) newdecl ) ; break ; case ATOMICTYPE : break ; // do nothing case STRUCTURE : case SEQUENCE : compounds . add ( ( DapStructure ) newdecl ) ; break ; case VARIABLE : variables . add ( ( DapVariable ) newdecl ) ; break ; case GROUP : case DATASET : if ( this != ( DapGroup ) newdecl ) groups . add ( ( DapGroup ) newdecl ) ; break ; default : throw new ClassCastException ( newdecl . getShortName ( ) ) ; } }", "nl": "Add single declaration"}}
{"translation": {"code": "protected void doDMR ( DapRequest drq , DapContext cxt ) throws IOException { // Convert the url to an absolute path String realpath = getResourcePath ( drq , drq . getDatasetPath ( ) ) ; DSP dsp = DapCache . open ( realpath , cxt ) ; DapDataset dmr = dsp . getDMR ( ) ; /* Annotate with our endianness */ ByteOrder order = ( ByteOrder ) cxt . get ( Dap4Util . DAP4ENDIANTAG ) ; setEndianness ( dmr , order ) ; // Process any constraint view CEConstraint ce = null ; String sce = drq . queryLookup ( DapProtocol . CONSTRAINTTAG ) ; ce = CEConstraint . compile ( sce , dmr ) ; setConstraint ( dmr , ce ) ; // Provide a PrintWriter for capturing the DMR. StringWriter sw = new StringWriter ( ) ; PrintWriter pw = new PrintWriter ( sw ) ; // Get the DMR as a string DMRPrinter dapprinter = new DMRPrinter ( dmr , ce , pw , drq . getFormat ( ) ) ; if ( cxt . get ( Dap4Util . DAP4TESTTAG ) != null ) dapprinter . testprint ( ) ; else dapprinter . print ( ) ; pw . close ( ) ; sw . close ( ) ; String sdmr = sw . toString ( ) ; if ( DEBUG ) System . err . println ( \"Sending: DMR:\\n\" + sdmr ) ; addCommonHeaders ( drq ) ; // Add relevant headers // Wrap the outputstream with a Chunk writer OutputStream out = drq . getOutputStream ( ) ; ChunkWriter cw = new ChunkWriter ( out , RequestMode . DMR , order ) ; cw . cacheDMR ( sdmr ) ; cw . close ( ) ; }", "nl": "Process a DMR request ."}}
{"translation": {"code": "protected D4Cursor compileStructure ( DapVariable var , DapStructure dapstruct , D4Cursor container ) throws DapException { int pos = getPos ( this . databuffer ) ; D4Cursor d4ds = new D4Cursor ( Scheme . STRUCTURE , ( D4DSP ) this . dsp , var , container ) . setOffset ( pos ) ; List < DapVariable > dfields = dapstruct . getFields ( ) ; for ( int m = 0 ; m < dfields . size ( ) ; m ++ ) { DapVariable dfield = dfields . get ( m ) ; D4Cursor dvfield = compileVar ( dfield , d4ds ) ; d4ds . addField ( m , dvfield ) ; assert dfield . getParent ( ) != null ; } return d4ds ; }", "nl": "Compile a structure instance ."}}
{"translation": {"code": "public void dataset ( DapDataset dmr ) throws DapException { // Iterate over the variables in order for ( DapVariable var : this . dmr . getTopVariables ( ) ) { if ( ! this . ce . references ( var ) ) continue ; variable ( var ) ; } }", "nl": "Node specific generators"}}
{"translation": {"code": "protected DapRequest getRequestState ( HttpServletRequest rq , HttpServletResponse rsp ) throws IOException { return new DapRequest ( this , rq , rsp ) ; }", "nl": "Merge the servlet inputs into a single object for easier transport as well as adding value ."}}
{"translation": {"code": "protected void senderror ( DapRequest drq , int httpcode , Throwable t ) throws IOException { if ( httpcode == 0 ) httpcode = HttpServletResponse . SC_BAD_REQUEST ; ErrorResponse err = new ErrorResponse ( ) ; err . setCode ( httpcode ) ; if ( t == null ) { err . setMessage ( \"Servlet error: \" + drq . getURL ( ) ) ; } else { StringWriter sw = new StringWriter ( ) ; PrintWriter p = new PrintWriter ( sw ) ; t . printStackTrace ( p ) ; p . close ( ) ; sw . close ( ) ; err . setMessage ( sw . toString ( ) ) ; } err . setContext ( drq . getURL ( ) ) ; String errormsg = err . buildXML ( ) ; drq . getResponse ( ) . sendError ( httpcode , errormsg ) ; }", "nl": "Generate an error based on the parameters"}}
{"translation": {"code": "public CDMDSP open ( NetcdfDataset ncd ) throws DapException { assert this . context != null ; this . dmrfactory = new DMRFactory ( ) ; this . ncdfile = ncd ; setLocation ( this . ncdfile . getLocation ( ) ) ; buildDMR ( ) ; return this ; }", "nl": "Provide an extra API for use in testing"}}
{"translation": {"code": "protected void dimredef ( CEAST node ) throws DapException { DapDimension dim = ( DapDimension ) dataset . findByFQN ( node . name , DapSort . DIMENSION ) ; if ( dim == null ) throw new DapException ( \"Constraint dim redef: no dimension name: \" + node . name ) ; Slice slice = node . slice ; slice . finish ( ) ; ce . addRedef ( dim , slice ) ; }", "nl": "Process a dim redefinition"}}
{"translation": {"code": "static public List < Slice > createSlices ( List < Range > rangelist ) throws dap4 . core . util . DapException { List < Slice > slices = new ArrayList < Slice > ( rangelist . size ( ) ) ; for ( int i = 0 ; i < rangelist . size ( ) ; i ++ ) { Range r = rangelist . get ( i ) ; // r does not store last int stride = r . stride ( ) ; int first = r . first ( ) ; int n = r . length ( ) ; int stop = first + ( n * stride ) ; Slice cer = new Slice ( first , stop - 1 , stride ) ; slices . add ( cer ) ; } return slices ; }", "nl": "Convert a list of ucar . ma2 . Range to a list of Slice More or less the inverst of create CDMRanges"}}
{"translation": {"code": "static public NetcdfFile unwrapfile ( NetcdfFile file ) { for ( ; ; ) { if ( file instanceof NetcdfDataset ) { NetcdfDataset ds = ( NetcdfDataset ) file ; file = ds . getReferencedFile ( ) ; if ( file == null ) break ; } else break ; } return file ; }", "nl": "NetcdfDataset can wrap a NetcdfFile . Goal of this procedure is to get down to the lowest level NetcdfFile instance ."}}
{"translation": {"code": "static public boolean containsVLEN ( List < Dimension > dimset ) { if ( dimset == null ) return false ; for ( Dimension dim : dimset ) { if ( dim . isVariableLength ( ) ) return true ; } return false ; }", "nl": "Test if any dimension is variable length"}}
{"translation": {"code": "static public int [ ] computeEffectiveShape ( List < DapDimension > dimset ) { if ( dimset == null || dimset . size ( ) == 0 ) return new int [ 0 ] ; int effectiverank = dimset . size ( ) ; int [ ] shape = new int [ effectiverank ] ; for ( int i = 0 ; i < effectiverank ; i ++ ) { shape [ i ] = ( int ) dimset . get ( i ) . getSize ( ) ; } return shape ; }", "nl": "Compute the shape inferred from a set of slices . Effective means that any trailing vlen will be ignored ."}}
{"translation": {"code": "public void compilefilter ( DapVariable var , DapSequence seq , CEAST expr ) throws DapException { if ( expr == null ) return ; if ( expr . sort == CEAST . Sort . SEGMENT ) { // This must be a simple segment and it must appear in seq if ( expr . subnodes != null ) throw new DapException ( \"compilefilter: Non-simple segment:\" + expr . name ) ; // Look for the name in the top-level field of seq DapVariable field = seq . findByName ( expr . name ) ; if ( field == null ) throw new DapException ( \"compilefilter: Unknown filter variable:\" + expr . name ) ; expr . field = field ; } else if ( expr . sort == CEAST . Sort . EXPR ) { if ( expr . lhs != null ) compilefilter ( var , seq , expr . lhs ) ; if ( expr . rhs != null ) compilefilter ( var , seq , expr . rhs ) ; // If both lhs and rhs are non-null, // canonicalize any comparison so that it is var op const if ( expr . lhs != null && expr . rhs != null ) { boolean leftvar = ( expr . lhs . sort == CEAST . Sort . SEGMENT ) ; boolean rightvar = ( expr . rhs . sort == CEAST . Sort . SEGMENT ) ; if ( rightvar && ! leftvar ) { // swap operands CEAST tmp = expr . lhs ; expr . lhs = expr . rhs ; expr . rhs = tmp ; // fix operator switch ( expr . op ) { case LT : //x<y -> y>x expr . op = CEAST . Operator . GT ; break ; case LE : //x<=y -> y>=x expr . op = CEAST . Operator . GE ; break ; case GT : //x>y -> y<x expr . op = CEAST . Operator . LT ; break ; case GE : //x>=y -> y<=x expr . op = CEAST . Operator . LE ; break ; default : break ; // leave as is } } } } else if ( expr . sort == CEAST . Sort . CONSTANT ) { return ; } else throw new DapException ( \"compilefilter: Unexpected node type:\" + expr . sort ) ; }", "nl": "Convert field references in a filter"}}
{"translation": {"code": "public void buildDMR ( ) throws DapException { if ( getDMR ( ) != null ) return ; try { if ( DUMPCDL ) { System . out . println ( \"writecdl:\" ) ; this . ncdfile . writeCDL ( System . out , false ) ; System . out . flush ( ) ; } // Use the file path to define the dataset name String name = this . ncdfile . getLocation ( ) ; // Normalize the name name = DapUtil . canonicalpath ( name ) ; // Remove any path prefix int index = name . lastIndexOf ( ' ' ) ; if ( index >= 0 ) name = name . substring ( index + 1 , name . length ( ) ) ; // Initialize the root dataset node setDMR ( ( DapDataset ) dmrfactory . newDataset ( name ) . annotate ( NetcdfDataset . class , this . ncdfile ) ) ; // Map the CDM root group to this group recordNode ( this . ncdfile . getRootGroup ( ) , getDMR ( ) ) ; getDMR ( ) . setBase ( DapUtil . canonicalpath ( this . ncdfile . getLocation ( ) ) ) ; // Now recursively build the tree. Start by // Filling the dataset with the contents of the ncfile // root group. fillgroup ( getDMR ( ) , this . ncdfile . getRootGroup ( ) ) ; // Add an order index to the tree getDMR ( ) . sort ( ) ; // Now locate the coordinate variables for maps /* Walk looking for VariableDS instances */ processmappedvariables ( this . ncdfile . getRootGroup ( ) ) ; // Now set the view getDMR ( ) . finish ( ) ; } catch ( DapException e ) { setDMR ( null ) ; throw new DapException ( e ) ; } }", "nl": "Extract the metadata from the NetcdfDataset and build the DMR ."}}
{"translation": {"code": "public void compile ( ) throws DapException { assert ( this . dataset != null && this . databuffer != null ) ; // iterate over the variables represented in the databuffer for ( DapVariable vv : this . dataset . getTopVariables ( ) ) { D4Cursor data = compileVar ( vv , null ) ; this . dsp . addVariableData ( vv , data ) ; } }", "nl": "The goal here is to process the serialized databuffer and locate top - level variable positions in the serialized databuffer . Access to non - top - level variables is accomplished on the fly ."}}
{"translation": {"code": "public void yyerror ( String s ) { System . err . println ( \"CEParserImpl.yyerror: \" + s + \"; parse failed at char: \" + charno + \"; near: \" ) ; String context = getInput ( ) ; int show = ( context . length ( ) < CONTEXTLEN ? context . length ( ) : CONTEXTLEN ) ; System . err . println ( context . substring ( context . length ( ) - show ) + \"^\" ) ; new Exception ( ) . printStackTrace ( System . err ) ; }", "nl": "Entry point for error reporting . Emits an error in a user - defined way . Part of Lexer interface ."}}
{"translation": {"code": "protected D4Cursor compileStructureArray ( DapVariable var , D4Cursor container ) throws DapException { DapStructure dapstruct = ( DapStructure ) var . getBaseType ( ) ; D4Cursor structarray = new D4Cursor ( Scheme . STRUCTARRAY , this . dsp , var , container ) . setOffset ( getPos ( this . databuffer ) ) ; List < DapDimension > dimset = var . getDimensions ( ) ; long dimproduct = DapUtil . dimProduct ( dimset ) ; D4Cursor [ ] instances = new D4Cursor [ ( int ) dimproduct ] ; Odometer odom = Odometer . factory ( DapUtil . dimsetToSlices ( dimset ) , dimset ) ; while ( odom . hasNext ( ) ) { Index index = odom . next ( ) ; D4Cursor instance = compileStructure ( var , dapstruct , structarray ) ; instance . setIndex ( index ) ; instances [ ( int ) index . index ( ) ] = instance ; } structarray . setElements ( instances ) ; return structarray ; }", "nl": "Compile a structure array ."}}
{"translation": {"code": "static public CalendarDateUnit of ( Calendar calt , CalendarPeriod . Field periodField , CalendarDate baseDate ) { if ( calt == null ) calt = Calendar . getDefault ( ) ; return new CalendarDateUnit ( calt , periodField , baseDate ) ; }", "nl": "Create a CalendarDateUnit from a calendar a CalendarPeriod . Field and a base date"}}
{"translation": {"code": "public File getExistingFileOrCache ( String fileLocation ) { File f = new File ( fileLocation ) ; if ( f . exists ( ) ) return f ; if ( neverUseCache ) return null ; File fc = new File ( makeCachePath ( fileLocation ) ) ; if ( fc . exists ( ) ) return fc ; return null ; }", "nl": "Looking for an existing file in cache or no"}}
{"translation": {"code": "public Grib1Parameter getLocalParameter ( int id ) { if ( parameters == null ) { parameters = readParameterTable ( ) ; } return parameters . get ( id ) ; }", "nl": "Get the parameter with id but dont look in default table ."}}
{"translation": {"code": "public Grib1Parameter getParameter ( int id ) { if ( parameters == null ) { parameters = readParameterTable ( ) ; } return parameters . get ( id ) ; }", "nl": "Get the parameter with id . If not found look in default table ."}}
{"translation": {"code": "public static void validate ( XmlObject doc , boolean strict ) throws XmlException { // Create an XmlOptions instance and set the error listener. Set < XmlError > validationErrors = new HashSet <> ( ) ; XmlOptions validationOptions = new XmlOptions ( ) ; validationOptions . setErrorListener ( validationErrors ) ; // Validate the XML document final boolean isValid = doc . validate ( validationOptions ) ; // Create Exception with error message if the xml document is invalid if ( ! isValid && ! strict ) { // check if we have special validation cases which could let the message pass anyhow validationErrors = filterToOnlySerious ( validationErrors ) ; } if ( ! validationErrors . isEmpty ( ) ) { throw new XmlException ( createErrorMessage ( validationErrors ) ) ; } }", "nl": "Validates an xml doc . If the validation fails the exception contains a detailed list of errors ."}}
{"translation": {"code": "public void badURL ( HttpServletRequest request , HttpServletResponse response ) throws Exception { if ( Debug . isSet ( \"showResponse\" ) ) { log . debug ( \"Sending Bad URL Page.\" ) ; } //log.info(\"DODSServlet.badURL \" + rs.getRequest().getRequestURI()); response . setContentType ( \"text/html\" ) ; response . setHeader ( \"XDODS-Server\" , getServerVersion ( ) ) ; response . setHeader ( \"Content-Description\" , \"dods-error\" ) ; // Commented because of a bug in the OPeNDAP C++ stuff... //rs.getResponse().setHeader(\"Content-Encoding\", \"plain\"); PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( response . getOutputStream ( ) , Util . UTF8 ) ) ; printBadURLPage ( pw ) ; printHelpPage ( pw ) ; pw . flush ( ) ; response . setStatus ( HttpServletResponse . SC_OK ) ; }", "nl": "Sends an html document to the client explaining that they have used a poorly formed URL and then the help page ..."}}
{"translation": {"code": "public void dap2ExceptionHandler ( DAP2Exception de , HttpServletResponse response ) { //log.info(\"DODSServlet.dodsExceptionHandler (\" + de.getErrorCode() + \") \" + de.getErrorMessage()); if ( Debug . isSet ( \"showException\" ) ) { log . error ( de . toString ( ) ) ; de . printStackTrace ( ) ; printDODSException ( de ) ; } // Convert Dap2Excaption code to an HttpCode switch ( de . getErrorCode ( ) ) { case DAP2Exception . NO_SUCH_FILE : case DAP2Exception . CANNOT_READ_FILE : response . setStatus ( HttpStatus . SC_NOT_FOUND ) ; break ; case DAP2Exception . NO_AUTHORIZATION : response . setStatus ( HttpStatus . SC_UNAUTHORIZED ) ; break ; case DAP2Exception . NO_SUCH_VARIABLE : case DAP2Exception . MALFORMED_EXPR : case DAP2Exception . UNKNOWN_ERROR : // fall thru default : response . setStatus ( HttpStatus . SC_BAD_REQUEST ) ; break ; } try { BufferedOutputStream eOut = new BufferedOutputStream ( response . getOutputStream ( ) ) ; response . setHeader ( \"Content-Description\" , \"dods-error\" ) ; // This should probably be set to \"plain\" but this works, the // C++ slients don't barf as they would if I sent \"plain\" AND // the C++ don't expect compressed data if I do this... response . setHeader ( \"Content-Encoding\" , \"\" ) ; de . print ( eOut ) ; } catch ( IOException ioe ) { log . error ( \"Cannot respond to client! IO Error: \" + ioe . getMessage ( ) ) ; } }", "nl": "Sends a OPeNDAP DAP2 error to the client ."}}
{"translation": {"code": "public void doGetCatalog ( ReqState rs ) throws Exception { rs . getResponse ( ) . setHeader ( \"XDODS-Server\" , getServerVersion ( ) ) ; rs . getResponse ( ) . setContentType ( \"text/xml\" ) ; rs . getResponse ( ) . setHeader ( \"Content-Description\" , \"dods-catalog\" ) ; PrintWriter pw = new PrintWriter ( new OutputStreamWriter ( rs . getResponse ( ) . getOutputStream ( ) , Util . UTF8 ) ) ; printCatalog ( rs , pw ) ; pw . flush ( ) ; rs . getResponse ( ) . setStatus ( HttpServletResponse . SC_OK ) ; }", "nl": "Handler for OPeNDAP catalog . xml requests ."}}
{"translation": {"code": "protected void printCatalog ( ReqState rs , PrintWriter os ) throws IOException { os . println ( \"Catalog not available for this server\" ) ; os . println ( \"Server version = \" + getServerVersion ( ) ) ; }", "nl": "to be overridden by servers that implement catalogs"}}
{"translation": {"code": "protected void printStatus ( PrintWriter os ) { os . println ( \"<h2>Server version = \" + getServerVersion ( ) + \"</h2>\" ) ; os . println ( \"<h2>Number of Requests Received = \" + HitCounter + \"</h2>\" ) ; if ( track ) { int n = prArr . size ( ) ; int pending = 0 ; StringBuilder preqs = new StringBuilder ( ) ; for ( int i = 0 ; i < n ; i ++ ) { ReqState rs = ( ReqState ) prArr . get ( i ) ; RequestDebug reqD = ( RequestDebug ) rs . getUserObject ( ) ; if ( ! reqD . done ) { preqs . append ( \"<pre>-----------------------\\n\" ) ; preqs . append ( \"Request[\" ) ; preqs . append ( reqD . reqno ) ; preqs . append ( \"](\" ) ; preqs . append ( reqD . threadDesc ) ; preqs . append ( \") is pending.\\n\" ) ; preqs . append ( rs . toString ( ) ) ; preqs . append ( \"</pre>\" ) ; pending ++ ; } } os . println ( \"<h2>\" + pending + \" Pending Request(s)</h2>\" ) ; os . println ( preqs . toString ( ) ) ; } }", "nl": "to be overridden by servers that implement status report"}}
{"translation": {"code": "public void parseExceptionHandler ( ParseException pe , HttpServletResponse response ) { //log.error(\"DODSServlet.parseExceptionHandler\", pe); if ( Debug . isSet ( \"showException\" ) ) { log . error ( pe . toString ( ) ) ; printThrowable ( pe ) ; } try { BufferedOutputStream eOut = new BufferedOutputStream ( response . getOutputStream ( ) ) ; response . setHeader ( \"Content-Description\" , \"dods-error\" ) ; // This should probably be set to \"plain\" but this works, the // C++ slients don't barf as they would if I sent \"plain\" AND // the C++ don't expect compressed data if I do this... response . setHeader ( \"Content-Encoding\" , \"\" ) ; // response.setContentType(\"text/plain\"); // Strip any double quotes out of the parser error message. // These get stuck in auto-magically by the javacc generated parser // code and they break our error parser (bummer!) String msg = pe . getMessage ( ) . replace ( ' ' , ' ' ) ; DAP2Exception de2 = new DAP2Exception ( opendap . dap . DAP2Exception . CANNOT_READ_FILE , msg ) ; de2 . print ( eOut ) ; } catch ( IOException ioe ) { log . error ( \"Cannot respond to client! IO Error: \" + ioe . getMessage ( ) ) ; } }", "nl": "Turns a ParseException into a OPeNDAP DAP2 error and sends it to the client ."}}
{"translation": {"code": "private void printBadURLPage ( PrintWriter pw ) { pw . println ( \"<h3>Error in URL</h3>\" ) ; pw . println ( \"The URL extension did not match any that are known by this\" ) ; pw . println ( \"server. Below is a list of the five extensions that are be recognized by\" ) ; pw . println ( \"all OPeNDAP servers. If you think that the server is broken (that the URL you\" ) ; pw . println ( \"submitted should have worked), then please contact the\" ) ; pw . println ( \"OPeNDAP user support coordinator at: \" ) ; pw . println ( \"<a href=\\\"mailto:support@unidata.ucar.edu\\\">support@unidata.ucar.edu</a><p>\" ) ; }", "nl": "Prints the Bad URL Page page to the passed PrintWriter"}}
{"translation": {"code": "public int [ ] computeUnlimitedChunking ( List < Dimension > dims , int elemSize ) { int maxElements = defaultChunkSize / elemSize ; int [ ] result = fillRightmost ( convertUnlimitedShape ( dims ) , maxElements ) ; long resultSize = new Section ( result ) . computeSize ( ) ; if ( resultSize < minChunksize ) { maxElements = minChunksize / elemSize ; result = incrUnlimitedShape ( dims , result , maxElements ) ; } return result ; }", "nl": "make it easy to test by using dimension list"}}
{"translation": {"code": "public long makeGridFileSizeEstimate ( ucar . nc2 . dt . GridDataset gds , List < String > gridList , LatLonRect llbb , int horizStride , Range zRange , CalendarDateRange dateRange , int stride_time , boolean addLatLon ) throws IOException , InvalidRangeException { return makeOrTestSize ( null , gds , gridList , llbb , horizStride , zRange , dateRange , stride_time , addLatLon , true , NetcdfFileWriter . Version . netcdf3 ) ; }", "nl": "Write a netcdf - 3 file from a subset of a grid dataset as long as it doesnt exceed a certain file size ."}}
{"translation": {"code": "public void makeFile ( String location , ucar . nc2 . dt . GridDataset gds , List < String > gridList , LatLonRect llbb , CalendarDateRange range , boolean addLatLon , int horizStride , int stride_z , int stride_time ) throws IOException , InvalidRangeException { makeFile ( location , gds , gridList , llbb , horizStride , null , range , stride_time , addLatLon , NetcdfFileWriter . Version . netcdf3 ) ; }", "nl": "Write a CF compliant Netcdf - 3 file from any gridded dataset ."}}
{"translation": {"code": "static public void makeFile ( String location , ucar . nc2 . dt . GridDataset gds , List < String > gridList , LatLonRect llbb , CalendarDateRange range ) throws IOException , InvalidRangeException { CFGridWriter writer = new CFGridWriter ( ) ; writer . makeFile ( location , gds , gridList , llbb , range , false , 1 , 1 , 1 ) ; }", "nl": "Write a netcdf - 3 file from a subset of a grid dataset"}}
{"translation": {"code": "protected void replaceDataVars ( StructureMembers sm ) { for ( StructureMembers . Member m : sm . getMembers ( ) ) { VariableSimpleIF org = this . cols . get ( m . getName ( ) ) ; int rank = org . getRank ( ) ; List < Dimension > orgDims = org . getDimensions ( ) ; // only keep the last n\r int n = m . getShape ( ) . length ; List < Dimension > dims = orgDims . subList ( rank - n , rank ) ; VariableSimpleImpl result = new VariableSimpleImpl ( org . getShortName ( ) , org . getDescription ( ) , org . getUnitsString ( ) , org . getDataType ( ) , dims ) ; for ( Attribute att : org . getAttributes ( ) ) result . ( att ) ; this . cols . put ( m . getName ( ) , result ) ; } }", "nl": "change shape of the data variables"}}
{"translation": {"code": "static public List < String > getProtocols ( String url , int [ ] breakpoint ) { // break off any leading protocols; // there may be more than one. // Watch out for Windows paths starting with a drive letter. // Each protocol has trailing ':'  removed List < String > allprotocols = new ArrayList <> ( ) ; // all leading protocols upto path or host // Note, we cannot use split because of the context sensitivity StringBuilder buf = new StringBuilder ( url ) ; int protosize = 0 ; for ( ; ; ) { int index = buf . indexOf ( \":\" ) ; if ( index < 0 ) break ; // no more protocols String protocol = buf . substring ( 0 , index ) ; // Check for windows drive letter if ( index == 1 //=>|protocol| == 1 => windows drive letter && \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" . indexOf ( buf . charAt ( 0 ) ) >= 0 ) break ; allprotocols . add ( protocol ) ; buf . delete ( 0 , index + 1 ) ; // remove the leading protocol protosize += ( index + 1 ) ; if ( buf . indexOf ( \"/\" ) == 0 ) break ; // anything after this is not a protocol } breakpoint [ 0 ] = protosize ; return allprotocols ; }", "nl": "Return the set of leading protocols for a url ; may be more than one ."}}
{"translation": {"code": "public boolean dspMatch ( String path , DapContext context ) { for ( String ext : SYNEXTENSIONS ) { if ( path . endsWith ( ext ) ) return true ; } return false ; }", "nl": "A path is a Synthetic path if it ends in . dmr or . syn"}}
{"translation": {"code": "static public boolean hasDriveLetter ( String path ) { boolean hasdr = false ; if ( path != null && path . length ( ) >= 2 ) { hasdr = ( DRIVELETTERS . indexOf ( path . charAt ( 0 ) ) >= 0 && path . charAt ( 1 ) == ' ' ) ; } return hasdr ; }", "nl": "return true if this path appears to start with a windows drive letter"}}
{"translation": {"code": "@ Override public boolean references ( DapNode node ) { switch ( node . getSort ( ) ) { case DIMENSION : case ENUMERATION : case VARIABLE : case GROUP : case DATASET : return true ; default : break ; } return false ; }", "nl": "Selected consult or iterator overrides for efficiency"}}
{"translation": {"code": "public String getCapabilities ( String url ) throws IOException { // Save the original url String saveurl = this . xuri . getOriginal ( ) ; parseURL ( url ) ; String fdsurl = buildURL ( this . xuri . assemble ( XURI . URLALL ) , DSRSUFFIX , null , null ) ; try { // Make the request and return an input stream for accessing the databuffer // Should fill in context bigendian and stream fields InputStream stream = callServer ( fdsurl ) ; // read the result, convert to string and return. byte [ ] bytes = DapUtil . readbinaryfile ( stream ) ; String document = new String ( bytes , DapUtil . UTF8 ) ; return document ; } finally { parseURL ( saveurl ) ; } }", "nl": "Provide a method for getting the capabilities document ."}}
{"translation": {"code": "public void outputBytes ( byte [ ] bytes , int start , int count ) throws IOException { if ( DUMPDATA ) { System . err . printf ( \"output %d/%d:\" , start , count ) ; for ( int i = 0 ; i < count ; i ++ ) { System . err . printf ( \" %02x\" , bytes [ i ] ) ; } System . err . println ( \"\" ) ; System . err . flush ( ) ; } output . write ( bytes , start , count ) ; }", "nl": "Deliberate choke point for debugging"}}
{"translation": {"code": "public int nextCount ( int max ) throws DapException { int min = 1 ; if ( max < min || min < 1 ) throw new DapException ( \"bad range\" ) ; int range = ( max + 1 ) - min ; // min..max+1 -> 0..(max+1)-min int n = random . nextInt ( range ) ; //  0..(max+1)-min n = n + min ; // min..(max+1) if ( DEBUG ) System . err . println ( \"RandomValue.nextCount: \" + n ) ; return n ; }", "nl": "Return an integer in range 1 .. max inclusive ."}}
{"translation": {"code": "static public String join ( String [ ] array , String sep , int from , int upto ) { if ( sep == null ) sep = \"\" ; if ( from < 0 || upto > array . length ) throw new IndexOutOfBoundsException ( ) ; if ( upto <= from ) return \"\" ; StringBuilder result = new StringBuilder ( ) ; boolean first = true ; for ( int i = from ; i < upto ; i ++ , first = false ) { if ( ! first ) result . append ( sep ) ; result . append ( array [ i ] ) ; } return result . toString ( ) ; }", "nl": "Given an Array of Strings and a separator and a count concat the first count elements of an array with separator between them . A null string is treated like ."}}
{"translation": {"code": "static public long makeSizeEstimate ( ucar . nc2 . dt . GridDataset gds , List < String > gridList , LatLonRect llbb , ProjectionRect projRect , int horizStride , Range zRange , CalendarDateRange dateRange , int stride_time , boolean addLatLon ) throws IOException , InvalidRangeException { CFGridWriter2 writer2 = new CFGridWriter2 ( ) ; return writer2 . writeOrTestSize ( gds , gridList , llbb , projRect , horizStride , zRange , dateRange , stride_time , addLatLon , true , null ) ; }", "nl": "Compute the size of the file without writing"}}
{"translation": {"code": "static public StructureDataDeep copy ( StructureData sdata , StructureMembers members ) { ArrayStructureBB abb = copyToArrayBB ( sdata , members , ByteOrder . BIG_ENDIAN ) ; return new StructureDataDeep ( abb ) ; }", "nl": "Make deep copy from sdata to another StructureData object whose data is self contained"}}
{"translation": {"code": "static public ArrayStructureBB copyToArrayBB ( StructureData sdata , StructureMembers sm , ByteOrder bo ) { int size = sm . getStructureSize ( ) ; ByteBuffer bb = ByteBuffer . allocate ( size ) ; // default is big endian bb . order ( bo ) ; ArrayStructureBB abb = new ArrayStructureBB ( sm , new int [ ] { 1 } , bb , 0 ) ; ArrayStructureBB . setOffsets ( sm ) ; copyToArrayBB ( sdata , abb ) ; return abb ; }", "nl": "Make deep copy from a StructureData to a ArrayStructureBB whose data is contained in a ByteBuffer"}}
{"translation": {"code": "static public ArrayStructureBB copyToArrayBB ( StructureData sdata ) { return copyToArrayBB ( sdata , new StructureMembers ( sdata . getStructureMembers ( ) ) , ByteOrder . BIG_ENDIAN ) ; }", "nl": "Make deep copy from a StructureData to a ArrayStructureBB whose data is contained in a ByteBuffer ."}}
{"translation": {"code": "static public ArrayStructureBB copyToArrayBB ( ArrayStructure as , ByteOrder bo , boolean canonical ) throws IOException { if ( ! canonical && as . getClass ( ) . equals ( ArrayStructureBB . class ) ) { // no subclasses, LOOK detect already canonical later ArrayStructureBB abb = ( ArrayStructureBB ) as ; ByteBuffer bb = abb . getByteBuffer ( ) ; if ( bo == null || bo . equals ( bb . order ( ) ) ) return abb ; } StructureMembers smo = as . getStructureMembers ( ) ; StructureMembers sm = new StructureMembers ( smo ) ; ArrayStructureBB abb = new ArrayStructureBB ( sm , as . getShape ( ) ) ; ArrayStructureBB . setOffsets ( sm ) ; // this makes the packing canonical if ( bo != null ) { ByteBuffer bb = abb . getByteBuffer ( ) ; bb . order ( bo ) ; } try ( StructureDataIterator iter = as . getStructureDataIterator ( ) ) { while ( iter . hasNext ( ) ) copyToArrayBB ( iter . next ( ) , abb ) ; } return abb ; }", "nl": "Make deep copy from an ArrayStructure to a ArrayStructureBB whose data is contained in a ByteBuffer"}}
{"translation": {"code": "public int dasparse ( String text , DAS das ) throws ParseException { return dapparse ( text , null , das , null ) ; }", "nl": "Call this to parse a DAS"}}
{"translation": {"code": "public int ddsparse ( String text , DDS dds ) throws ParseException { return dapparse ( text , dds , null , null ) ; }", "nl": "Call this to parse a DDS"}}
{"translation": {"code": "private boolean isExtra ( Variable v ) { return v != null && extras != null && extras . contains ( v ) ; }", "nl": "Has v already been added to the set of extra variables?"}}
{"translation": {"code": "private boolean isCoordinate ( Variable v ) { if ( v == null ) return false ; String name = v . getShortName ( ) ; return ( latVE != null && latVE . axisName . equals ( name ) ) || ( lonVE != null && lonVE . axisName . equals ( name ) ) || ( altVE != null && altVE . axisName . equals ( name ) ) || ( stnAltVE != null && stnAltVE . axisName . equals ( name ) ) || ( timeVE != null && timeVE . axisName . equals ( name ) ) || ( nomTimeVE != null && nomTimeVE . axisName . equals ( name ) ) ; }", "nl": "Is v a coordinate axis for this feature type?"}}
{"translation": {"code": "static public ArrayStructureBB copyToArrayBB ( Structure s , ArrayStructure as , ByteOrder bo ) throws IOException { StructureMembers sm = s . makeStructureMembers ( ) ; ArrayStructureBB abb = new ArrayStructureBB ( sm , as . getShape ( ) ) ; ArrayStructureBB . setOffsets ( sm ) ; if ( bo != null ) { ByteBuffer bb = abb . getByteBuffer ( ) ; bb . order ( bo ) ; } try ( StructureDataIterator iter = as . getStructureDataIterator ( ) ) { while ( iter . hasNext ( ) ) copyToArrayBB ( iter . next ( ) , abb ) ; } return abb ; }", "nl": "Make deep copy to an ArrayStructureBB whose data is contained in a ByteBuffer . Use the order of the members in the given Structure ; skip copying any not in the Structure"}}
{"translation": {"code": "public Slice finish ( ) throws DapException { // Attempt to repair undefined values if ( this . first == UNDEFINED ) this . first = 0 ; // default if ( this . stride == UNDEFINED ) this . stride = 1 ; // default if ( this . stop == UNDEFINED && this . maxsize != UNDEFINED ) this . stop = this . maxsize ; if ( this . stop == UNDEFINED && this . maxsize == UNDEFINED ) this . stop = this . first + 1 ; if ( this . maxsize == UNDEFINED && this . stop != UNDEFINED ) this . maxsize = this . stop ; // else (this.stop != UNDEFINED && this.maxsize != UNDEFINED) assert ( this . first != UNDEFINED ) ; assert ( this . stride != UNDEFINED ) ; assert ( this . stop != UNDEFINED ) ; // sanity checks if ( this . first > this . maxsize ) throw new DapException ( \"Slice: first index > max size\" ) ; if ( this . stop > ( this . maxsize + 1 ) ) throw new DapException ( \"Slice: stop > max size\" ) ; if ( this . first < 0 ) throw new DapException ( \"Slice: first index < 0\" ) ; if ( this . stop < 0 ) throw new DapException ( \"Slice: stop index < 0\" ) ; if ( this . stride <= 0 ) throw new DapException ( \"Slice: stride index <= 0\" ) ; if ( this . first > this . stop ) throw new DapException ( \"Slice: first index > last\" ) ; return this ; // fluent interface }", "nl": "Perform sanity checks on a slice and repair where possible ."}}
{"translation": {"code": "@ Override public boolean hasNext ( ) { if ( this . current >= odomset . size ( ) ) return false ; Odometer ocurrent = odomset . get ( this . current ) ; if ( ocurrent . hasNext ( ) ) return true ; // Try to move to next odometer this . current ++ ; return hasNext ( ) ; }", "nl": "Iterator API Overrides"}}
{"translation": {"code": "public int step ( int firstpos , int lastpos ) { for ( int i = lastpos - 1 ; i >= firstpos ; i -- ) { // walk backwards if ( this . index . indices [ i ] > this . endpoint [ i ] ) this . index . indices [ i ] = this . slices . get ( i ) . getFirst ( ) ; // reset this position else { this . index . indices [ i ] += this . slices . get ( i ) . getStride ( ) ; // move to next indices return i ; } } return - 1 ; }", "nl": "return - 1 if we have completed ."}}
{"translation": {"code": "@ Override public boolean hasNext ( ) { switch ( state ) { case INITIAL : return ( slice . getFirst ( ) < slice . getStop ( ) ) ; case STARTED : return ( this . index < slice . getLast ( ) ) ; case DONE : } return false ; }", "nl": "Iterator interface extended"}}
{"translation": {"code": "@ Override public String toConstraintString ( ) throws DapException { assert this . first != UNDEFINED && this . stride != UNDEFINED && this . stop != UNDEFINED ; StringBuilder buf = new StringBuilder ( ) ; buf . append ( \"[\" ) ; boolean first = true ; for ( Slice sub : this . subslices ) { if ( ! first ) buf . append ( \",\" ) ; first = false ; if ( ( sub . stop - sub . first ) == 0 ) { buf . append ( \"0\" ) ; } else if ( sub . stride == 1 ) { if ( ( sub . stop - sub . first ) == 1 ) buf . append ( sub . first ) ; else buf . append ( String . format ( \"%d:%d\" , sub . first , sub . stop - 1 ) ) ; } else buf . append ( String . format ( \"%d:%d:%d\" , sub . first , sub . stride , sub . stop - 1 ) ) ; } buf . append ( \"]\" ) ; return buf . toString ( ) ; }", "nl": "Convert this multislice to a string suitable for use in a constraint"}}
{"translation": {"code": "public float [ ] getAltitudes ( ) { if ( myASIBs == null ) return null ; float [ ] alts = new float [ nRays ] ; for ( int i = 0 ; i < nRays ; i ++ ) alts [ i ] = myASIBs [ i ] . getAltitude ( ) ; return alts ; }", "nl": "Get the array of per - ray altitudes . If we do not have per - ray position information null is returned ."}}
{"translation": {"code": "public float [ ] getLongitudes ( ) { if ( myASIBs == null ) return null ; float [ ] lons = new float [ nRays ] ; for ( int i = 0 ; i < nRays ; i ++ ) lons [ i ] = myASIBs [ i ] . getLongitude ( ) ; return lons ; }", "nl": "Get the array of per - ray longitudes . If we do not have per - ray position information null is returned ."}}
{"translation": {"code": "public float [ ] getLatitudes ( ) { if ( myASIBs == null ) return null ; float [ ] lats = new float [ nRays ] ; for ( int i = 0 ; i < nRays ; i ++ ) lats [ i ] = myASIBs [ i ] . getLatitude ( ) ; return lats ; }", "nl": "Get the array of per - ray latitudes . If we do not have per - ray position information null is returned ."}}
{"translation": {"code": "protected short grabShort ( byte [ ] bytes , int offset ) { int ndx0 = offset + ( littleEndianData ? 1 : 0 ) ; int ndx1 = offset + ( littleEndianData ? 0 : 1 ) ; // careful that we only allow sign extension on the highest order byte return ( short ) ( bytes [ ndx0 ] << 8 | ( bytes [ ndx1 ] & 0xff ) ) ; }", "nl": "Unpack a two - byte integer from the given byte array ."}}
{"translation": {"code": "private byte [ ] readBytes ( InputStream is ) throws IOException { int totalRead = 0 ; byte [ ] content = new byte [ 1000000 ] ; while ( true ) { int howMany = is . read ( content , totalRead , content . length - totalRead ) ; if ( howMany < 0 ) { break ; } if ( howMany == 0 ) { continue ; } totalRead += howMany ; if ( totalRead >= content . length ) { byte [ ] tmp = content ; int newLength = ( ( content . length < 25000000 ) ? content . length * 2 : content . length + 5000000 ) ; content = new byte [ newLength ] ; System . arraycopy ( tmp , 0 , content , 0 , totalRead ) ; } } is . close ( ) ; byte [ ] results = new byte [ totalRead ] ; System . arraycopy ( content , 0 , results , 0 , totalRead ) ; return results ; }", "nl": "Read the bytes in the given input stream ."}}
{"translation": {"code": "private String readContents ( InputStream is ) throws IOException { return new String ( readBytes ( is ) , CDM . utf8Charset ) ; }", "nl": "Read in the bytes from the given InputStream and construct and return a String . Closes the InputStream argument ."}}
{"translation": {"code": "public String get ( int index ) { if ( index >= size ) throw new IllegalArgumentException ( ErddapString2 . ERROR + \" in StringArray.get: index (\" + index + \") >= size (\" + size + \").\" ) ; return array [ index ] ; }", "nl": "This gets a specified element ."}}
{"translation": {"code": "public void ensureCapacity ( long minCapacity ) { if ( array . length < minCapacity ) { //ensure minCapacity is < Integer.MAX_VALUE ErddapMath2 . ensureArraySizeOkay ( minCapacity , \"StringArray\" ) ; //caller may know exact number needed, so don't double above 2x current size int newCapacity = ( int ) Math . min ( Integer . MAX_VALUE - 1 , array . length + ( long ) array . length ) ; if ( newCapacity < minCapacity ) newCapacity = ( int ) minCapacity ; //safe since checked above String [ ] newArray = new String [ newCapacity ] ; System . arraycopy ( array , 0 , newArray , 0 , size ) ; array = newArray ; //do last to minimize concurrency problems } }", "nl": "This ensures that the capacity is at least minCapacity ."}}
{"translation": {"code": "public static void ensureArraySizeOkay ( long tSize , String attributeTo ) { if ( tSize >= Integer . MAX_VALUE ) throw new RuntimeException ( memoryTooMuchData + \"  \" + MessageFormat . format ( memoryArraySize , \"\" + tSize , \"\" + Integer . MAX_VALUE ) + ( attributeTo == null || attributeTo . length ( ) == 0 ? \"\" : \" (\" + attributeTo + \")\" ) ) ; }", "nl": "Even if JavaBits is 64 the limit on an array size is Integer . MAX_VALUE ."}}
{"translation": {"code": "public static void main ( String [ ] args ) { String fileIn = ( args . length > 0 ) ? args [ 0 ] : \"Q:/cdmUnitTest/formats/grib2/LMPEF_CLM_050518_1200.grb\" ; String fileOut = ( args . length > 1 ) ? args [ 1 ] : \"C:/tmp/ds.mint.bi\" ; try ( GribToNetcdfWriter writer = new GribToNetcdfWriter ( fileIn , fileOut ) ) { writer . write ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } }", "nl": "Write Grib file to a netcdf4 file . Experimental ."}}
{"translation": {"code": "public static float bitShave ( float value , int bitMask ) { if ( Float . isNaN ( value ) ) return value ; // ?? int bits = Float . floatToRawIntBits ( value ) ; int shave = bits & bitMask ; return Float . intBitsToFloat ( shave ) ; }", "nl": "Shave n bits off the float"}}
{"translation": {"code": "public void addAll ( FeatureDatasetPoint fdPoint ) throws IOException { try ( PointFeatureIterator pointFeatIter = new FlattenedDatasetPointCollection ( fdPoint ) . getPointFeatureIterator ( ) ) { while ( pointFeatIter . hasNext ( ) ) { StationPointFeature pointFeat = ( StationPointFeature ) pointFeatIter . next ( ) ; add ( pointFeat ) ; } } }", "nl": "fdPoint remains open ."}}
{"translation": {"code": "public String readStringMax ( int nbytes ) throws IOException { byte [ ] b = new byte [ nbytes ] ; readFully ( b ) ; int count ; for ( count = 0 ; count < nbytes ; count ++ ) if ( b [ count ] == 0 ) break ; return new String ( b , 0 , count , CDM . utf8Charset ) ; }", "nl": "Read a String of max length zero terminate ."}}
{"translation": {"code": "@ Override public LatLonPoint projToLatLon ( ProjectionPoint world , LatLonPointImpl result ) { double fromX = world . getX ( ) - falseEasting ; double fromY = world . getY ( ) - falseNorthing ; double toLat_r = fromY / earthRadius ; double toLon_r ; if ( Misc . nearlyEquals ( Math . abs ( toLat_r ) , PI_OVER_2 , 1e-10 ) ) { toLat_r = toLat_r < 0 ? - PI_OVER_2 : + PI_OVER_2 ; toLon_r = Math . toRadians ( centMeridian ) ; // if lat == +- pi/2, set lon = centMeridian (Snyder 248)\r } else if ( Math . abs ( toLat_r ) < PI_OVER_2 ) { toLon_r = Math . toRadians ( centMeridian ) + fromX / ( earthRadius * Math . cos ( toLat_r ) ) ; } else { return INVALID ; // Projection point is off the map.\r } if ( Misc . nearlyEquals ( Math . abs ( toLon_r ) , PI , 1e-10 ) ) { toLon_r = toLon_r < 0 ? - PI : + PI ; } else if ( Math . abs ( toLon_r ) > PI ) { return INVALID ; // Projection point is off the map.\r } result . setLatitude ( Math . toDegrees ( toLat_r ) ) ; result . setLongitude ( Math . toDegrees ( toLon_r ) ) ; return result ; }", "nl": "Convert projection coordinates to a LatLonPoint"}}
{"translation": {"code": "@ Deprecated public String getName ( ) { switch ( sort ) { case ATTRIBUTE : case DIMENSION : case ENUMERATION : // for these cases, getName is getShortName return getShortName ( ) ; case VARIABLE : // Atomic case SEQUENCE : case STRUCTURE : case GROUP : // for these cases, getName is getFullName return getFullName ( ) ; default : break ; } return getShortName ( ) ; // default }", "nl": "getName is deprecated because as the code below shows it has no consistent meaning . Sometimes it returns the short name sometimes it returns the full name ."}}
{"translation": {"code": "private float [ ] getData0 ( RandomAccessFile raf , Grib2Drs . Type0 gdrs ) throws IOException { int nb = gdrs . numberOfBits ; int D = gdrs . decimalScaleFactor ; float DD = ( float ) java . lang . Math . pow ( ( double ) 10 , ( double ) D ) ; float R = gdrs . referenceValue ; int E = gdrs . binaryScaleFactor ; float EE = ( float ) java . lang . Math . pow ( 2.0 , ( double ) E ) ; // LOOK: can # datapoints differ from bitmap and data ? // dataPoints are number of points encoded, it could be less than the // totalNPoints in the grid record if bitMap is used, otherwise equal float [ ] data = new float [ totalNPoints ] ; //  Y * 10**D = R + (X1 + X2) * 2**E //   E = binary scale factor //   D = decimal scale factor //   R = reference value //   X1 = 0 //   X2 = scaled encoded value //   data[ i ] = (R + ( X1 + X2) * EE)/DD ; BitReader reader = new BitReader ( raf , startPos + 5 ) ; if ( bitmap == null ) { for ( int i = 0 ; i < totalNPoints ; i ++ ) { //data[ i ] = (R + ( X1 + X2) * EE)/DD ; data [ i ] = ( R + reader . bits2UInt ( nb ) * EE ) / DD ; } } else { for ( int i = 0 ; i < totalNPoints ; i ++ ) { if ( GribNumbers . testBitIsSet ( bitmap [ i / 8 ] , i % 8 ) ) { data [ i ] = ( R + reader . bits2UInt ( nb ) * EE ) / DD ; } else { data [ i ] = staticMissingValue ; //data[i] = R / DD; } } } return data ; }", "nl": "Grid point data - simple packing"}}
{"translation": {"code": "private String yysyntax_error ( int yystate , int tok ) { if ( yyErrorVerbose ) { /* There are many possibilities here to consider:\n           - If this state is a consistent state with a default action,\n             then the only way this function was invoked is if the\n             default action is an error action.  In that case, don't\n             check for expected tokens because there are none.\n           - The only way there can be no lookahead present (in tok) is\n             if this state is a consistent state with a default action.\n             Thus, detecting the absence of a lookahead is sufficient to\n             determine that there is no unexpected or expected token to\n             report.  In that case, just report a simple \"syntax error\".\n           - Don't assume there isn't a lookahead just because this\n             state is a consistent state with a default action.  There\n             might have been a previous inconsistent state, consistent\n             state with a non-default action, or user semantic action\n             that manipulated yychar.  (However, yychar is currently out\n             of scope during semantic actions.)\n           - Of course, the expected token list depends on states to\n             have correct lookahead information, and it depends on the\n             parser not to perform extra reductions after fetching a\n             lookahead from the scanner and before detecting a syntax\n             error.  Thus, state merging (from LALR or IELR) and default\n             reductions corrupt the expected token list.  However, the\n             list is correct for canonical LR with one exception: it\n             will still contain any token that will not be accepted due\n             to an error action in a later state.\n        */ if ( tok != yyempty_ ) { /* FIXME: This method of building the message is not compatible\n               with internationalization.  */ StringBuffer res = new StringBuffer ( \"syntax error, unexpected \" ) ; res . append ( yytnamerr_ ( yytname_ [ tok ] ) ) ; int yyn = yypact_ [ yystate ] ; if ( ! yy_pact_value_is_default_ ( yyn ) ) { /* Start YYX at -YYN if negative to avoid negative\n                   indexes in YYCHECK.  In other words, skip the first\n                   -YYN actions for this state because they are default\n                   actions.  */ int yyxbegin = yyn < 0 ? - yyn : 0 ; /* Stay within bounds of both yycheck and yytname.  */ int yychecklim = yylast_ - yyn + 1 ; int yyxend = yychecklim < yyntokens_ ? yychecklim : yyntokens_ ; int count = 0 ; for ( int x = yyxbegin ; x < yyxend ; ++ x ) if ( yycheck_ [ x + yyn ] == x && x != yyterror_ && ! yy_table_value_is_error_ ( yytable_ [ x + yyn ] ) ) ++ count ; if ( count < 5 ) { count = 0 ; for ( int x = yyxbegin ; x < yyxend ; ++ x ) if ( yycheck_ [ x + yyn ] == x && x != yyterror_ && ! yy_table_value_is_error_ ( yytable_ [ x + yyn ] ) ) { res . append ( count ++ == 0 ? \", expecting \" : \" or \" ) ; res . append ( yytnamerr_ ( yytname_ [ x ] ) ) ; } } } return res . toString ( ) ; } } return \"syntax error\" ; }", "nl": "Generate an error message ."}}
{"translation": {"code": "private void yy_reduce_print ( int yyrule , YYStack yystack ) { if ( yydebug == 0 ) return ; int yylno = yyrline_ [ yyrule ] ; int yynrhs = yyr2_ [ yyrule ] ; /* Print the symbols being reduced, and their result.  */ yycdebug ( \"Reducing stack by rule \" + ( yyrule - 1 ) + \" (line \" + yylno + \"), \" ) ; /* The symbols being reduced.  */ for ( int yyi = 0 ; yyi < yynrhs ; yyi ++ ) yy_symbol_print ( \"   $\" + ( yyi + 1 ) + \" =\"  , yystos_ [ yystack . stateAt ( yynrhs - ( yyi + 1 ) ) ] , ( ( yystack . valueAt ( yynrhs - ( yyi + 1 ) ) ) ) ) ; }", "nl": "Report on the debug stream that the rule yyrule is going to be reduced ."}}
{"translation": {"code": "private int yy_lr_goto_state_ ( int yystate , int yysym ) { int yyr = yypgoto_ [ yysym - yyntokens_ ] + yystate ; if ( 0 <= yyr && yyr <= yylast_ && yycheck_ [ yyr ] == yystate ) return yytable_ [ yyr ] ; else return yydefgoto_ [ yysym - yyntokens_ ] ; }", "nl": "Compute post - reduction state ."}}
{"translation": {"code": "public double [ ] GOES_to_GEOS ( double lamda_goes , double theta_goes ) { double theta_geos = Math . asin ( Math . sin ( theta_goes ) * Math . cos ( lamda_goes ) ) ; double lamda_geos = Math . atan ( Math . tan ( lamda_goes ) / Math . cos ( theta_goes ) ) ; return new double [ ] { lamda_geos , theta_geos } ; }", "nl": "Transform view angle coordinates in the GOES scan geometry frame to view angle coordinates in the GEOS scan geometry frame ."}}
{"translation": {"code": "public double [ ] earthToSat ( double geographic_lon , double geographic_lat ) { geographic_lat = geographic_lat * DEG_TO_RAD ; geographic_lon = geographic_lon * DEG_TO_RAD ; double geocentric_lat = Math . atan ( ( ( r_pol * r_pol ) / ( r_eq * r_eq ) ) * Math . tan ( geographic_lat ) ) ; double r_earth = r_pol / Math . sqrt ( 1.0 - ( ( r_eq * r_eq - r_pol * r_pol ) / ( r_eq * r_eq ) ) * Math . cos ( geocentric_lat ) * Math . cos ( geocentric_lat ) ) ; double r_1 = h - r_earth * Math . cos ( geocentric_lat ) * Math . cos ( geographic_lon - sub_lon ) ; double r_2 = - r_earth * Math . cos ( geocentric_lat ) * Math . sin ( geographic_lon - sub_lon ) ; double r_3 = r_earth * Math . sin ( geocentric_lat ) ; if ( r_1 > h ) { // often two geoid intersect points, use the closer one. return new double [ ] { Double . NaN , Double . NaN } ; } double lamda_sat = Double . NaN ; double theta_sat = Double . NaN ; if ( scan_geom . equals ( GEOS ) ) { // GEOS (eg. SEVIRI, MSG)  CGMS 03, 4.4.3.2, Normalized Geostationary Projection lamda_sat = Math . atan ( - r_2 / r_1 ) ; theta_sat = Math . asin ( r_3 / Math . sqrt ( r_1 * r_1 + r_2 * r_2 + r_3 * r_3 ) ) ; } else if ( scan_geom . equals ( GOES ) ) { // GOES (eg. GOES-R ABI) lamda_sat = Math . asin ( - r_2 / Math . sqrt ( r_1 * r_1 + r_2 * r_2 + r_3 * r_3 ) ) ; theta_sat = Math . atan ( r_3 / r_1 ) ; } return new double [ ] { lamda_sat , theta_sat } ; }", "nl": "Transform geographic Earth coordinates to satellite view angle coordinate system also known as the intermediate coordinate system in CGMS Normalized Geostationary Projection ."}}
{"translation": {"code": "public double [ ] satToEarth ( double x , double y ) { if ( scan_geom . equals ( GOES ) ) { // convert from GOES to GEOS for transfrom below double [ ] lambda_theta_geos = GOES_to_GEOS ( x , y ) ; x = lambda_theta_geos [ 0 ] ; y = lambda_theta_geos [ 1 ] ; } double c1 = ( h * Math . cos ( x ) * Math . cos ( y ) ) * ( h * Math . cos ( x ) * Math . cos ( y ) ) ; double c2 = ( Math . cos ( y ) * Math . cos ( y ) + fp * Math . sin ( y ) * Math . sin ( y ) ) * d ; if ( c1 < c2 ) { return new double [ ] { Double . NaN , Double . NaN } ; } double s_d = Math . sqrt ( c1 - c2 ) ; double s_n = ( h * Math . cos ( x ) * Math . cos ( y ) - s_d ) / ( Math . cos ( y ) * Math . cos ( y ) + fp * Math . sin ( y ) * Math . sin ( y ) ) ; double s_1 = h - s_n * Math . cos ( x ) * Math . cos ( y ) ; double s_2 = s_n * Math . sin ( x ) * Math . cos ( y ) ; double s_3 = - s_n * Math . sin ( y ) ; double s_xy = Math . sqrt ( s_1 * s_1 + s_2 * s_2 ) ; double geographic_lon = Math . atan ( s_2 / s_1 ) + sub_lon ; double geographic_lat = Math . atan ( - fp * ( s_3 / s_xy ) ) ; double lonDegrees = RAD_TO_DEG * geographic_lon ; double latDegrees = RAD_TO_DEG * geographic_lat ; // force output longitude to -180 to 180 range if ( lonDegrees < - 180.0 ) lonDegrees += 360.0 ; if ( lonDegrees > 180.0 ) lonDegrees -= 360.0 ; return new double [ ] { lonDegrees , latDegrees } ; }", "nl": "Transform satellite view angle coordinates known as the intermeidate coordinates in the CGMS Normalized Geostationary Projection to geographic Earth coordinates ."}}