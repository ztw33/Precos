{"translation": {"code": "public synchronized void removeAttribute ( DapAttribute attr ) throws DapException { if ( this . attributes == null ) return ; String name = attr . getShortName ( ) ; if ( this . attributes . containsKey ( name ) ) this . attributes . remove ( name ) ; }", "nl": "Used by AbstractDSP to suppress certain attributes ."}}
{"translation": {"code": "protected void processAttributes ( DapDataset dataset ) throws DapException { List < DapNode > nodes = dataset . getNodeList ( ) ; for ( DapNode node : nodes ) { switch ( node . getSort ( ) ) { case GROUP : case DATASET : case VARIABLE : Map < String , DapAttribute > attrs = node . getAttributes ( ) ; if ( attrs . size ( ) > 0 ) { List < DapAttribute > suppressed = new ArrayList <> ( ) ; for ( DapAttribute dattr : attrs . values ( ) ) { if ( suppress ( dattr . getShortName ( ) ) ) suppressed . add ( dattr ) ; } for ( DapAttribute dattr : suppressed ) { node . removeAttribute ( dattr ) ; } } break ; default : break ; /*ignore*/ } } // Try to extract the byte order getEndianAttribute ( dataset ) ; }", "nl": "Walk the dataset tree and remove selected attributes such as _Unsigned"}}
{"translation": {"code": "private void add ( final String name , final String symbol , final double definition ) throws PrefixExistsException { addName ( name , definition ) ; addSymbol ( symbol , definition ) ; }", "nl": "Adds a prefix to the database ."}}
{"translation": {"code": "public synchronized void clearCache ( boolean force ) { List < CacheElement . CacheFile > deleteList = new ArrayList <> ( 2 * cache . size ( ) ) ; if ( force ) { cache . clear ( ) ; // deletes everything from the cache deleteList . addAll ( files . values ( ) ) ; // add everything to the delete list files . clear ( ) ; // counter.set(0); } else { // add unlocked files to the delete list, remove from files hash Iterator < CacheElement . CacheFile > iter = files . values ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { CacheElement . CacheFile file = iter . next ( ) ; if ( file . isLocked . compareAndSet ( false , true ) ) { file . remove ( ) ; // remove from the containing CacheElement deleteList . add ( file ) ; iter . remove ( ) ; } } // remove empty cache elements for ( CacheElement elem : cache . values ( ) ) { if ( elem . list . size ( ) == 0 ) cache . remove ( elem . hashKey ) ; } } // close all files in deleteList for ( CacheElement . CacheFile file : deleteList ) { if ( force && file . isLocked . get ( ) ) cacheLog . warn ( \"FileCacheARC \" + name + \" force close locked file= \" + file ) ; //counter.decrementAndGet(); if ( file . ncfile == null ) continue ; try { file . ncfile . setFileCache ( null ) ; file . ncfile . close ( ) ; file . ncfile = null ; // help the gc } catch ( IOException e ) { log . error ( \"FileCacheARC \" + name + \" close failed on \" + file ) ; } } if ( cacheLog . isDebugEnabled ( ) ) cacheLog . debug ( \"*FileCacheARC \" + name + \" clearCache force= \" + force + \" deleted= \" + deleteList . size ( ) + \" left=\" + files . size ( ) ) ; //System.out.println(\"\\n*NetcdfFileCache.clearCache force= \" + force + \" deleted= \" + deleteList.size() + \" left=\" + counter.get()); }", "nl": "Remove all cache entries ."}}
{"translation": {"code": "static private void swap ( String a [ ] , int i , int j ) { String T ; T = a [ i ] ; a [ i ] = a [ j ] ; a [ j ] = T ; }", "nl": "Private method to swap two elements in the array"}}
{"translation": {"code": "static private void quickSort ( String a [ ] , int lo0 , int hi0 ) { int lo = lo0 ; int hi = hi0 ; String mid ; if ( hi0 > lo0 ) { // Arbitrarily establishing partition element as the array midpoint */ //Coverity[FB.IM_AVERAGE_COMPUTATION_COULD_OVERFLOW] mid = a [ ( lo0 + hi0 ) / 2 ] ; // loop through the array until indices cross while ( lo <= hi ) { // find the first element that is >= the partition element // starting from the left index. while ( ( lo < hi0 ) && ( a [ lo ] . compareTo ( mid ) < 0 ) ) ++ lo ; // find an element that is <= the partition element // starting from the right index. while ( ( hi > lo0 ) && ( a [ hi ] . compareTo ( mid ) > 0 ) ) -- hi ; // if the indexes have not crossed, swap if ( lo <= hi ) { swap ( a , lo , hi ) ; ++ lo ; -- hi ; } } // If the right index has not reached the left side of array, // sort the left partition. if ( lo0 < hi ) quickSort ( a , lo0 , hi ) ; // If the left index has not reached the right side of array, // sort the right partition. if ( lo < hi0 ) quickSort ( a , lo , hi0 ) ; } }", "nl": "Internal recursive method to perform Quick Sort on name array ."}}
{"translation": {"code": "private void setNavBlockAttributes ( Variable v ) { if ( ( navBlock == null ) || ( ad == null ) ) { return ; } v . addAttribute ( new Attribute ( \"navigation_type\" , McIDASUtil . intBitsToString ( navBlock [ 0 ] ) ) ) ; }", "nl": "Set the navigation block attributes on the variable"}}
{"translation": {"code": "public void reacquire ( ) throws IOException { try { areaReader . af = new AreaFile ( location ) ; } catch ( Throwable e ) { throw new IOException ( e ) ; } }", "nl": "reacquire any resources like file handles"}}
{"translation": {"code": "private void remove ( CacheElement . CacheFile want ) { want . remove ( ) ; files . remove ( want . ncfile ) ; try { want . ncfile . setFileCache ( null ) ; // unhook the caching\r want . ncfile . close ( ) ; } catch ( IOException e ) { log . error ( \"close failed on \" + want . ncfile . getLocation ( ) , e ) ; } want . ncfile = null ; }", "nl": "LOOK should you remove the entire CacheElement ?"}}
{"translation": {"code": "RandomAccessFile getRaf ( int partno , int fileno ) throws IOException { Partition part = getPartition ( partno ) ; try ( GribCollectionImmutable gc = part . getGribCollection ( ) ) { return gc . getDataRaf ( fileno ) ; } }", "nl": "stuff for Iosp"}}
{"translation": {"code": "public Coordinate getCoordinate ( int index ) { int grpIndex = coordIndex . get ( index ) ; return group . coords . get ( grpIndex ) ; }", "nl": "get the ith coordinate"}}
{"translation": {"code": "private static void initUnitTable ( ) { unitTable = new Hashtable <> ( ) ; // temperatures unitTable . put ( \"t\" , \"K\" ) ; unitTable . put ( \"td\" , \"K\" ) ; unitTable . put ( \"thte\" , \"K\" ) ; // winds unitTable . put ( \"u\" , \"m/s\" ) ; unitTable . put ( \"v\" , \"m/s\" ) ; unitTable . put ( \"w\" , \"m/s\" ) ; // pressure unitTable . put ( \"p\" , \"hPa\" ) ; unitTable . put ( \"mmsl\" , \"hPa\" ) ; // moisture unitTable . put ( \"rh\" , \"%\" ) ; // misc unitTable . put ( \"rhfz\" , \"%\" ) ; unitTable . put ( \"zagl\" , \"m\" ) ; }", "nl": "Initialize the unit table . This is used if there are no units in the file ."}}
{"translation": {"code": "public boolean count ( String name , Comparable value ) { Counter counter = map . get ( name ) ; if ( counter == null ) { counter = add ( name ) ; } return counter . count ( value ) ; }", "nl": "Add value to the named counter . Add counter if it doesnt already exist ."}}
{"translation": {"code": "public static File getExistingFileOrCache ( String fileLocation ) { File result = getDiskCache2 ( ) . getExistingFileOrCache ( fileLocation ) ; if ( result == null && Grib . debugGbxIndexOnly && fileLocation . endsWith ( \".gbx9.ncx4\" ) ) { // might create only from gbx9 for debugging int length = fileLocation . length ( ) ; String maybeIndexAlreadyExists = fileLocation . substring ( 0 , length - 10 ) + \".ncx4\" ; result = getDiskCache2 ( ) . getExistingFileOrCache ( maybeIndexAlreadyExists ) ; } return result ; }", "nl": "Looking for an existing file in cache or not"}}
{"translation": {"code": "static synchronized public String find ( String key , String url ) { if ( key == null ) return null ; if ( ! initialized ) RC . initialize ( ) ; Triple t = dfaltRC . lookup ( key , url ) ; return ( t == null ? null : t . value ) ; }", "nl": "Allow users to search the default rc"}}
{"translation": {"code": "static void setWellKnown ( ) { if ( dfaltRC . triplestore . size ( ) == 0 ) return ; // Walk the set of triples looking for those that have no url for ( String key : dfaltRC . keySet ( ) ) { Triple triple = dfaltRC . lookup ( key ) ; if ( triple . url == null ) { RC . set ( key , triple . value ) ; // let set sort it out } } }", "nl": "Record some well known parameters"}}
{"translation": {"code": "@ Override public VertCoordType getVertUnit ( int code ) { //     VertCoordType(int code, String desc, String abbrev, String units, String datum, boolean isPositiveUp, boolean isLayer)\r switch ( code ) { case 11 : case 12 : return new VertCoordType ( code , \"m\" , null , true ) ; case 20 : return new VertCoordType ( code , \"K\" , null , false ) ; case 100 : return new VertCoordType ( code , \"Pa\" , null , false ) ; case 102 : return new VertCoordType ( code , \"m\" , \"mean sea level\" , true ) ; case 103 : return new VertCoordType ( code , \"m\" , \"ground\" , true ) ; case 104 : case 105 : return new VertCoordType ( code , \"sigma\" , null , false ) ; // positive?\r case 106 : return new VertCoordType ( code , \"m\" , \"land surface\" , false ) ; case 107 : return new VertCoordType ( code , \"K\" , null , true ) ; // positive?\r case 108 : return new VertCoordType ( code , \"Pa\" , \"ground\" , true ) ; case 109 : return new VertCoordType ( code , \"K m2 kg-1 s-1\" , null , true ) ; // positive?\r case 114 : return new VertCoordType ( code , \"numeric\" , null , false ) ; case 117 : return new VertCoordType ( code , \"m\" , null , true ) ; case 119 : return new VertCoordType ( code , \"Pa\" , null , false ) ; // ??\r case 160 : return new VertCoordType ( code , \"m\" , \"sea level\" , false ) ; case 161 : return new VertCoordType ( code , \"m\" , \"water surface\" , false ) ; // LOOK NCEP specific\r case 235 : return new VertCoordType ( code , \"0.1 C\" , null , true ) ; case 237 : return new VertCoordType ( code , \"m\" , null , true ) ; case 238 : return new VertCoordType ( code , \"m\" , null , true ) ; default : return new VertCoordType ( code , null , null , true ) ; } }", "nl": "Unit of vertical coordinate . from Grib2 code table 4 . 5 . Only levels with units get a dimension added"}}
{"translation": {"code": "@ Nonnull public DataFactory . Result openFeatureDataset ( Dataset Dataset , ucar . nc2 . util . CancelTask task ) throws IOException { return openFeatureDataset ( null , Dataset , task , new Result ( ) ) ; }", "nl": "Open a FeatureDataset from an Dataset object deciding on which Access to use ."}}
{"translation": {"code": "protected void update ( CollectionUpdateType force ) throws IOException { // this may be called from a background thread, or from checkState() request thread State localState ; synchronized ( lock ) { if ( first ) { state = checkState ( ) ; state . lastInvChange = System . currentTimeMillis ( ) ; return ; } // do the update in a local object localState = state . copy ( ) ; } updateCollection ( localState , force ) ; // makeDatasetTop(localState); localState . lastInvChange = System . currentTimeMillis ( ) ; // switch to live synchronized ( lock ) { state = localState ; } }", "nl": "Collection was changed update internal objects . called by CollectionUpdater trigger via handleCollectionEvent so in a quartz scheduler thread"}}
{"translation": {"code": "private ThreddsMetadata . GeospatialCoverage extractGeospatial ( GribCollectionImmutable . GroupGC group ) { GdsHorizCoordSys gdsCoordSys = group . getGdsHorizCoordSys ( ) ; LatLonRect llbb = GridCoordSys . getLatLonBoundingBox ( gdsCoordSys . proj , gdsCoordSys . getStartX ( ) , gdsCoordSys . getStartY ( ) , gdsCoordSys . getEndX ( ) , gdsCoordSys . getEndY ( ) ) ; double dx = 0.0 , dy = 0.0 ; if ( gdsCoordSys . isLatLon ( ) ) { dx = Math . abs ( gdsCoordSys . dx ) ; dy = Math . abs ( gdsCoordSys . dy ) ; } return new ThreddsMetadata . GeospatialCoverage ( llbb , null , dx , dy ) ; }", "nl": "LOOK how come we arent using MetadataExtractor ??"}}
{"translation": {"code": "public GribCollectionImmutable . Dataset getSingleDatasetOrByTypeName ( GribCollectionImmutable gc , String typeName ) { if ( gc . getDatasets ( ) . size ( ) == 1 ) return gc . getDataset ( 0 ) ; for ( GribCollectionImmutable . Dataset ds : gc . getDatasets ( ) ) if ( ds . getType ( ) . toString ( ) . equalsIgnoreCase ( typeName ) ) return ds ; return null ; }", "nl": "kinda kludgey but trying not keep URLs stable"}}
{"translation": {"code": "public List < Dataset > getDatasetsLocal ( ) { List < Dataset > datasets = ( List < Dataset > ) flds . get ( Dataset . Datasets ) ; return datasets == null ? new ArrayList <> ( 0 ) : datasets ; }", "nl": "Get top level datasets contained directly in this catalog . Do not dereference catRefs ."}}
{"translation": {"code": "public static List < Property > removeDups ( List < Property > org ) { List < Property > result = new ArrayList <> ( org . size ( ) ) ; for ( Property p : org ) if ( ! result . contains ( p ) ) // O(n**2) result . add ( p ) ; return result ; }", "nl": "first one override"}}
{"translation": {"code": "public ThreddsMetadata extract ( Dataset threddsDataset ) throws IOException { ThreddsMetadata metadata = new ThreddsMetadata ( ) ; Map < String , Object > flds = metadata . getFlds ( ) ; try ( DataFactory . Result result = new DataFactory ( ) . openFeatureDataset ( threddsDataset , null ) ) { if ( result . fatalError ) { logger . warn ( \" openFeatureDataset failed, errs=%s%n\" , result . errLog ) ; return null ; } if ( result . featureType . isCoverageFeatureType ( ) ) { GridDataset gridDataset = ( GridDataset ) result . featureDataset ; // LOOK wrong flds . put ( Dataset . GeospatialCoverage , extractGeospatial ( gridDataset ) ) ; CalendarDateRange tc = extractCalendarDateRange ( gridDataset ) ; if ( tc != null ) flds . put ( Dataset . TimeCoverage , tc ) ; ThreddsMetadata . VariableGroup vars = extractVariables ( threddsDataset . getDataFormatName ( ) , gridDataset ) ; if ( vars != null ) flds . put ( Dataset . VariableGroups , vars ) ; } else if ( result . featureType . isPointFeatureType ( ) ) { PointDatasetImpl pobsDataset = ( PointDatasetImpl ) result . featureDataset ; LatLonRect llbb = pobsDataset . getBoundingBox ( ) ; if ( null != llbb ) flds . put ( Dataset . GeospatialCoverage , new ThreddsMetadata . GeospatialCoverage ( llbb , null , 0.0 , 0.0 ) ) ; CalendarDateRange tc = extractCalendarDateRange ( pobsDataset ) ; if ( tc != null ) flds . put ( Dataset . TimeCoverage , tc ) ; ThreddsMetadata . VariableGroup vars = extractVariables ( pobsDataset ) ; if ( vars != null ) flds . put ( Dataset . VariableGroups , vars ) ; } } catch ( IOException ioe ) { logger . error ( \"Error opening dataset \" + threddsDataset . getName ( ) , ioe ) ; } return metadata ; }", "nl": "extract info from underlying feature dataset"}}
{"translation": {"code": "public void transferMetadata ( DatasetNode from , boolean parentsAlso ) { if ( parentsAlso ) { ThreddsMetadata inherit = getInheritableMetadata ( ) ; // make sure exists inheritMetadata ( from , inherit . getFlds ( ) ) ; } // local metadata for ( Map . Entry < String , Object > entry : from . getFldIterator ( ) ) { if ( parentsAlso && entry . getKey ( ) . equals ( Dataset . ThreddsMetadataInheritable ) ) continue ; // already did this if ( Dataset . listFlds . contains ( entry . getKey ( ) ) ) addToNewList ( flds , entry . getKey ( ) , entry . getValue ( ) ) ; else flds . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } // tmi must be mutable, transfer if not ThreddsMetadata tmiOld = ( ThreddsMetadata ) get ( Dataset . ThreddsMetadataInheritable ) ; if ( tmiOld != null && tmiOld . isImmutable ( ) ) { ThreddsMetadata tmiNew = new ThreddsMetadata ( tmiOld ) ; flds . put ( Dataset . ThreddsMetadataInheritable , tmiNew ) ; } }", "nl": "transfer all metadata optionally also inheritable metadata from parents"}}
{"translation": {"code": "private ConfigCatalog readCatalog ( String catalogRelPath , String catalogFullPath ) { URI uri ; try { // uri = new URI(\"file:\" + StringUtil2.escape(catalogFullPath, \"/:-_.\")); // needed ? uri = new URI ( this . contextPath + \"/catalog/\" + catalogRelPath ) ; } catch ( URISyntaxException e ) { logCatalogInit . error ( ERROR + \"readCatalog(): URISyntaxException=\" + e . getMessage ( ) ) ; return null ; } ConfigCatalogBuilder builder = new ConfigCatalogBuilder ( ) ; try { // read the catalog logCatalogInit . info ( \"-------readCatalog(): path=\" + catalogRelPath ) ; ConfigCatalog cat = ( ConfigCatalog ) builder . buildFromLocation ( catalogFullPath , uri ) ; if ( builder . hasFatalError ( ) ) { logCatalogInit . error ( ERROR + \"   invalid catalog -- \" + builder . getErrorMessage ( ) ) ; return null ; } if ( builder . getErrorMessage ( ) . length ( ) > 0 ) logCatalogInit . debug ( builder . getErrorMessage ( ) ) ; return cat ; } catch ( Throwable t ) { logCatalogInit . error ( ERROR + \"  Exception on catalog=\" + catalogFullPath + \" \" + t . getMessage ( ) + \"\\n log=\" + builder . getErrorMessage ( ) , t ) ; return null ; } }", "nl": "Does the actual work of reading a catalog ."}}
{"translation": {"code": "public int writeCatalog ( HttpServletRequest req , HttpServletResponse res , Catalog cat , boolean isLocalCatalog ) throws IOException { String catHtmlAsString = convertCatalogToHtml ( cat , isLocalCatalog ) ; // Once this header is set, we know the encoding, and thus the actual // number of *bytes*, not characters, to encode res . setContentType ( ContentType . html . getContentHeader ( ) ) ; int len = ServletUtil . setResponseContentLength ( res , catHtmlAsString ) ; if ( ! req . getMethod ( ) . equals ( \"HEAD\" ) ) { PrintWriter writer = res . getWriter ( ) ; writer . write ( catHtmlAsString ) ; writer . flush ( ) ; } return len ; }", "nl": "Write an Catalog to the HttpServletResponse return the size in bytes of the catalog written to the response ."}}
{"translation": {"code": "private float [ ] getData41 ( RandomAccessFile raf , Grib2Drs . Type0 gdrs ) throws IOException { int nb = gdrs . numberOfBits ; int D = gdrs . decimalScaleFactor ; float DD = ( float ) java . lang . Math . pow ( ( double ) 10 , ( double ) D ) ; float R = gdrs . referenceValue ; int E = gdrs . binaryScaleFactor ; float EE = ( float ) java . lang . Math . pow ( 2.0 , ( double ) E ) ; // LOOK: can # datapoints differ from bitmap and data ? // dataPoints are number of points encoded, it could be less than the // totalNPoints in the grid record if bitMap is used, otherwise equal float [ ] data = new float [ totalNPoints ] ; // no data to decode, set to reference value if ( nb == 0 ) { Arrays . fill ( data , R ) ; return data ; } //  Y * 10**D = R + (X1 + X2) * 2**E //   E = binary scale factor //   D = decimal scale factor //   R = reference value //   X1 = 0 //   X2 = scaled encoded value //   data[ i ] = (R + ( X1 + X2) * EE)/DD ; byte [ ] buf = new byte [ dataLength - 5 ] ; raf . readFully ( buf ) ; InputStream in = new ByteArrayInputStream ( buf ) ; BufferedImage image = ImageIO . read ( in ) ; if ( nb != image . getColorModel ( ) . getPixelSize ( ) ) { logger . debug ( \"PNG pixel size disagrees with grib number of bits: \" , image . getColorModel ( ) . getPixelSize ( ) , nb ) ; } DataBuffer db = image . getRaster ( ) . getDataBuffer ( ) ; if ( bitmap == null ) { for ( int i = 0 ; i < dataNPoints ; i ++ ) { data [ i ] = ( R + db . getElem ( i ) * EE ) / DD ; } } else { for ( int bitPt = 0 , dataPt = 0 ; bitPt < totalNPoints ; bitPt ++ ) { if ( GribNumbers . testBitIsSet ( bitmap [ bitPt / 8 ] , bitPt % 8 ) ) { data [ bitPt ] = ( R + db . getElem ( dataPt ++ ) * EE ) / DD ; } else { data [ bitPt ] = staticMissingValue ; } } } return data ; }", "nl": "Code taken from esupport ticket ZVT - 415274"}}
{"translation": {"code": "private static String getValueFromThreddsConfig ( String key , String alternateKey , String defaultValue ) { String value = ThreddsConfig . get ( key , null ) ; if ( value == null && alternateKey != null ) value = ThreddsConfig . get ( alternateKey , null ) ; if ( value == null ) value = defaultValue ; return value ; }", "nl": "static so can be called from static enum classes"}}
{"translation": {"code": "static public String buildConventionAttribute ( String mainConv , String ... convAtts ) { List < String > result = new ArrayList <> ( ) ; result . add ( mainConv ) ; for ( String convs : convAtts ) { if ( convs == null ) continue ; List < String > ss = breakupConventionNames ( convs ) ; // may be a list\r for ( String s : ss ) { if ( matchConvention ( s ) == null ) // only add extra ones, not ones that compete with mainConv\r result . add ( s ) ; } } // now form comma separated result\r boolean start = true ; Formatter f = new Formatter ( ) ; for ( String s : result ) { if ( start ) f . format ( \"%s\" , s ) ; else f . format ( \", %s\" , s ) ; start = false ; } return f . toString ( ) ; }", "nl": "Build a list of Conventions"}}
{"translation": {"code": "public static String getTimeTypeName ( int timeRangeIndicator ) { String timeRange ; switch ( timeRangeIndicator ) { /* Forecast product valid for reference time + P1 (P1 > 0), or\r\n        Uninitialized analysis product for reference time (P1 = 0), or\r\n        Image product for reference time (P1 = 0) */ case 0 : timeRange = \"Uninitialized analysis / image product / forecast product valid for RT + P1\" ; break ; // Initialized analysis product for reference time (P1 = 0)\r case 1 : timeRange = \"Initialized analysis product for reference time\" ; break ; // Product with a valid time ranging between reference time + P1 and reference time + P2\r case 2 : timeRange = \"product valid, interval = (RT + P1) to (RT + P2)\" ; break ; // Average (reference time + P1 to reference time + P2)\r case 3 : timeRange = \"Average, interval = (RT + P1) to (RT + P2)\" ; break ; /* Accumulation  (reference  time  +  P1  to  reference  time  +  P2)  product  considered  valid  at\r\n        reference time + P2 */ case 4 : timeRange = \"Accumulation, interval = (RT + P1) to (RT + P2)\" ; break ; /* Difference  (reference  time  +  P2  minus  reference  time  +  P1)  product  considered  valid  at\r\n        reference time + P2 */ case 5 : timeRange = \"Difference, interval = (RT + P2) - (RT + P1)\" ; break ; // Average (reference time - P1 to reference time - P2)\r case 6 : timeRange = \"Average, interval = (RT - P1) to (RT - P2)\" ; break ; // Average (reference time - P1 to reference time + P2)\r case 7 : timeRange = \"Average, interval = (RT - P1) to (RT + P2)\" ; break ; // P1 occupies octets 19 and 20; product valid at reference time + P1\r case 10 : timeRange = \"product valid at RT + P1\" ; break ; /* Climatological  mean  value:  multiple  year  averages  of  quantities  which  are  themselves\r\n        means over some period of time (P2) less than a year. The reference time (R) indicates the\r\n        date and time of the start of a period of time, given by R to R + P2, over which a mean is\r\n        formed; N indicates the number of such period-means that are averaged together to form\r\n        the  climatological  value,  assuming  that  the  N  period-mean  fields  are  separated  by  one\r\n        year. The reference time indicates the start of the N-year climatology.\r\n\r\n        If P1 = 0 then the data averaged in the basic interval P2 are assumed to be continuous, i.e. all available data\r\n        are simply averaged together.\r\n\r\n        If P1 = 1 (the unit of time  octet 18, Code table 4  is not\r\n        relevant here) then the data averaged together in the basic interval P2 are valid only at the\r\n        time (hour, minute) given in the reference time, for all the days included in the P2 period.\r\n        The units of P2 are given by the contents of octet 18 and Code table 4 */ case 51 : timeRange = \"Climatological mean values from RT to (RT + P2)\" ; // if (p1 == 0) timeRange += \" continuous\";\r break ; /* Average  of  N  forecasts  (or  initialized  analyses);  each  product  has  forecast  period  of  P1\r\n        (P1 = 0 for initialized analyses); products have reference times at intervals of P2, beginning\r\n        at the given reference time */ case 113 : timeRange = \"Average of N forecasts, intervals = (refTime + i * P2, refTime + i * P2 + P1)\" ; break ; /* Accumulation of N forecasts (or initialized analyses); each product has forecast period of\r\n        P1  (P1  =  0  for  initialized  analyses);  products  have  reference  times  at  intervals  of  P2,\r\n        beginning at the given reference time */ case 114 : timeRange = \"Accumulation of N forecasts, intervals = (refTime + i * P2, refTime + i * P2 + P1)\" ; break ; /* Average of N forecasts, all with the same reference time; the first has a forecast period of\r\n         P1, the remaining forecasts follow at intervals of P2 */ case 115 : timeRange = \"Average of N forecasts, intervals = (refTime, refTime + P1 + i * P2)\" ; break ; /* Accumulation  of  N  forecasts,  all  with  the  same  reference  time;  the  first  has  a  forecast\r\n        period of P1, the remaining forecasts follow at intervals of P2 */ case 116 : timeRange = \"Accumulation of N forecasts, intervals = (refTime, refTime + P1 + i * P2)\" ; break ; /* Average of N forecasts; the first has a forecast period of P1, the subsequent ones have\r\n        forecast periods reduced from the previous one by an interval of P2; the reference time for\r\n        the first is given in octets 13 to 17, the subsequent ones have reference times increased\r\n        from the previous one by an interval of P2. Thus all the forecasts have the same valid time,\r\n        given by the initial reference time + P1 */ case 117 : timeRange = \"Average of N forecasts, intervals = (refTime + i * P2, refTime + P1)\" ; break ; /* Temporal  variance,  or  covariance,  of  N  initialized  analyses;  each  product  has  forecast\r\n        period of P1 = 0; products have reference times at intervals of P2, beginning at the given\r\n        reference time */ case 118 : timeRange = \"Temporal variance or covariance of N initialized analyses, timeCoord = (refTime + i * P2)\" ; break ; /* Standard deviation of N forecasts, all with the same reference time with respect to the time\r\n        average of forecasts; the first forecast has a forecast period of P1, the remaining forecasts\r\n        follow at intervals of P2 */ case 119 : timeRange = \"Standard Deviation of N forecasts, timeCoord = (refTime + P1 + i * P2)\" ; break ; // ECMWF \"Average of N Forecast\" added 11/21/2014. pretend its WMO standard. maybe should move to ecmwf ??\r // see \"http://emoslib.sourcearchive.com/documentation/000370.dfsg.2/grchk1_8F-source.html\"\r // C     Add Time range indicator = 120 Average of N Forecast. Each product\r // C             is an accumulation from forecast lenght P1 to forecast\r // C              lenght P2, with reference times at intervals P2-P1\r case 120 : timeRange = \"Average of N Forecasts (ECMWF), accumulation from forecast P1 to P2, with reference times at intervals P2-P1\" ; break ; // Average of N uninitialized analyses, starting at the reference time, at intervals of P2\r case 123 : timeRange = \"Average of N uninitialized analyses, intervals = (refTime, refTime + i * P2)\" ; break ; // Accumulation of N uninitialized analyses, starting at the reference time, at intervals of P2\r case 124 : timeRange = \"Accumulation of N uninitialized analyses, intervals = (refTime, refTime + i * P2)\" ; break ; /* Standard deviation of N forecasts, all with the same reference time with respect to time\r\n        average of the time tendency of forecasts; the first forecast has a forecast period of P1,\r\n        the remaining forecasts follow at intervals of P2 */ case 125 : timeRange = \"Standard deviation of N forecasts, intervals = (refTime, refTime + P1 + i * P2)\" ; break ; default : timeRange = \"Unknown Time Range Indicator \" + timeRangeIndicator ; } return timeRange ; }", "nl": "code table 5 - 2010 edition of WMO manual on codes"}}
{"translation": {"code": "private void transferInheritable2PublicMetadata ( InvDatasetImpl parent ) { if ( parent == null ) return ; logger . debug ( \" inheritFromParent= \" + parent . getID ( ) ) ; transfer2PublicMetadata ( parent . getLocalMetadataInheritable ( ) , true ) ; //transfer2PublicMetadata(parent.getCat6Metadata(), true); /* look through local metadata, find inherited InvMetadata elements\n    ThreddsMetadata tmd = parent.getLocalMetadata();\n    Iterator iter = tmd.getMetadata().iterator();\n    while (iter.hasNext()) {\n      InvMetadata meta = (InvMetadata) iter.next();\n      if (meta.isInherited()) {\n        if (!meta.isThreddsMetadata()) {\n          metadata.add(meta);\n        } else {\n          if (debugInherit) System.out.println(\"  inheritMetadata Element \" + tmd.isInherited() + \" \" + meta.isInherited());\n          meta.finish(); // make sure XLink is read in.\n          transfer2PublicMetadata(meta.getThreddsMetadata(), false);\n        }\n      }\n    } */ // recurse transferInheritable2PublicMetadata ( ( InvDatasetImpl ) parent . getParent ( ) ) ; }", "nl": "Look for InvMetadata elements in the parent that need to be added to the public metadata of this dataset . Recurse up through all ancestors ."}}
{"translation": {"code": "public static boolean rewritePointFeatureDataset ( String fileIn , String fileOut , boolean inMemory ) throws IOException { System . out . println ( \"Rewrite2 .nc files from \" + fileIn + \" to \" + fileOut + \" inMemory= \" + inMemory ) ; long start = System . currentTimeMillis ( ) ; // do it in memory for speed NetcdfFile ncfile = inMemory ? NetcdfFile . openInMemory ( fileIn ) : NetcdfFile . open ( fileIn ) ; NetcdfDataset ncd = new NetcdfDataset ( ncfile ) ; Formatter errlog = new Formatter ( ) ; FeatureDataset fd = FeatureDatasetFactoryManager . wrap ( FeatureType . ANY_POINT , ncd , null , errlog ) ; if ( fd == null ) return false ; if ( fd instanceof FeatureDatasetPoint ) { writePointFeatureCollection ( ( FeatureDatasetPoint ) fd , fileOut ) ; fd . close ( ) ; long took = System . currentTimeMillis ( ) - start ; System . out . println ( \" that took \" + ( took - start ) + \" msecs\" ) ; return true ; } return false ; }", "nl": "Open a ucar . nc2 . ft . PointFeatureCollection write out in CF point format ."}}
{"translation": {"code": "public ThreddsMetadata . Variables getVariables ( String vocab ) { ThreddsMetadata . Variables result = new ThreddsMetadata . Variables ( vocab , null , null , null , null ) ; if ( variables == null ) return result ; for ( ThreddsMetadata . Variables vs : variables ) { if ( vs . getVocabulary ( ) . equals ( vocab ) ) result . getVariableList ( ) . addAll ( vs . getVariableList ( ) ) ; } return result ; }", "nl": "get Variables from the specified vocabulary"}}
{"translation": {"code": "public Object readMetadataContentFromURL ( InvDataset dataset , java . net . URI uri ) throws java . io . IOException { Element elem = readContentFromURL ( uri ) ; Object contentObject = readMetadataContent ( dataset , elem ) ; if ( debugMetadataRead ) System . out . println ( \" convert to \" + contentObject . getClass ( ) . getName ( ) ) ; return contentObject ; }", "nl": "this is only called for ThredddsMetadata"}}
{"translation": {"code": "public InvDatasetImpl findDatasetByName ( String name ) { for ( InvDataset ds : getDatasets ( ) ) { if ( ds . getName ( ) . equals ( name ) ) return ( InvDatasetImpl ) ds ; } return null ; }", "nl": "Find an immediate child dataset by its name ."}}
{"translation": {"code": "public String getUserHead ( ) { return new StringBuilder ( ) . append ( \"<table width='100%'><tr><td>\\n\" ) . append ( \"  <img src='\" ) . append ( this . htmlConfig . prepareUrlStringForHtml ( this . htmlConfig . getHostInstLogoUrl ( ) ) ) . append ( \"'\\n\" ) . append ( \"       alt='\" ) . append ( this . htmlConfig . getHostInstLogoAlt ( ) ) . append ( \"'\\n\" ) . append ( \"       align='left' valign='top'\\n\" ) . append ( \"       hspace='10' vspace='2'>\\n\" ) . append ( \"  <h3><strong>\" ) . append ( this . tdsContext . getWebappDisplayName ( ) ) . append ( \"</strong></h3>\\n\" ) . append ( \"</td></tr></table>\\n\" ) . toString ( ) ; }", "nl": "public static final String UNIDATA_HEAD"}}
{"translation": {"code": "public void setContributors ( List < ThreddsMetadata . Contributor > a ) { List < ThreddsMetadata . Contributor > dest = tm . getContributors ( ) ; for ( ThreddsMetadata . Contributor item : a ) { if ( ! dest . contains ( item ) ) dest . add ( item ) ; } hashCode = 0 ; }", "nl": "LOOK these are wrong"}}
{"translation": {"code": "public String findProperty ( String name ) { InvProperty result = null ; for ( InvProperty p : properties ) { if ( p . getName ( ) . equals ( name ) ) result = p ; } return ( result == null ) ? null : result . getValue ( ) ; }", "nl": "Get named property ."}}
{"translation": {"code": "@ Override public java . util . List < InvDataset > getDatasets ( ) { read ( ) ; return useProxy ? proxy . getDatasets ( ) : super . getDatasets ( ) ; }", "nl": "Get a list of all the nested datasets ."}}
{"translation": {"code": "public void release ( ) { datasets = new java . util . ArrayList <> ( ) ; proxy = null ; useProxy = false ; init = false ; }", "nl": "Release resources - undo the read of the catalog . This is needed when crawling large catalogs . For modest catalogs that you will repeatedly examine do not use this method ."}}
{"translation": {"code": "public void readXMLasynch ( String uriString , CatalogSetCallback callback ) { InvCatalogImpl cat = readXML ( uriString ) ; callback . setCatalog ( cat ) ; }", "nl": "This allows the possibility of reading a catalog in another thread . The default implementation does not do that but a subclass may override and implement . If the catalog is read successfully it is passed on to the callback ."}}
{"translation": {"code": "public InvCatalogImpl readXML ( String catAsString , URI baseUri ) { return readXML ( new StringReader ( catAsString ) , baseUri ) ; }", "nl": "Create an InvCatalog by reading catalog XML from a String ."}}
{"translation": {"code": "public InvCatalogImpl readXML ( StringReader catAsStringReader , URI baseUri ) { XMLEntityResolver resolver = new XMLEntityResolver ( false ) ; SAXBuilder builder = resolver . getSAXBuilder ( ) ; Document inDoc ; try { inDoc = builder . build ( catAsStringReader ) ; } catch ( Exception e ) { InvCatalogImpl cat = new InvCatalogImpl ( baseUri . toString ( ) , null , null ) ; cat . appendErrorMessage ( \"**Fatal:  InvCatalogFactory.readXML(String catAsString, URI url) failed:\" + \"\\n  Exception= \" + e . getClass ( ) . getName ( ) + \" \" + e . getMessage ( ) + \"\\n  fatalMessages= \" + fatalMessages . toString ( ) + \"\\n  errMessages= \" + errMessages . toString ( ) + \"\\n  warnMessages= \" + warnMessages . toString ( ) + \"\\n\" , true ) ; return cat ; } return readXML ( inDoc , baseUri ) ; }", "nl": "Create an InvCatalog by reading catalog XML from a StringReader ."}}
{"translation": {"code": "public MetadataConverterIF getMetadataConverter ( String key ) { if ( key == null ) return null ; return metadataConverters . get ( key ) ; }", "nl": "Find the MetadataConverterIF registered for this key"}}
{"translation": {"code": "public void transferMetadata ( InvDatasetImpl fromDs , boolean copyInheritedMetadataFromParents ) { if ( fromDs == null ) return ; logger . debug ( \" transferMetadata= \" + fromDs . getName ( ) ) ; if ( this != fromDs ) getLocalMetadata ( ) . add ( fromDs . getLocalMetadata ( ) , false ) ; transferInheritableMetadata ( fromDs , getLocalMetadataInheritable ( ) , copyInheritedMetadataFromParents ) ; setResourceControl ( fromDs . getRestrictAccess ( ) ) ; }", "nl": "Transfer all inheritable metadata from fromDs to the local metadata of this dataset . Called by InvDatasetScan to transfer inheritable metaddata to the nested catalogRef"}}
{"translation": {"code": "public Object getUserProperty ( Object key ) { if ( userMap == null ) return null ; return userMap . get ( key ) ; }", "nl": "Look up the User property having the given key"}}
{"translation": {"code": "public boolean removeLocalMetadata ( InvMetadata metadata ) { InvDatasetImpl parentDataset = ( ( InvDatasetImpl ) metadata . getParentDataset ( ) ) ; List localMdata = parentDataset . getLocalMetadata ( ) . getMetadata ( ) ; if ( localMdata . contains ( metadata ) ) { if ( localMdata . remove ( metadata ) ) { hashCode = 0 ; // Need to recalculate the hash code. return ( true ) ; } } return ( false ) ; }", "nl": "Remove the given InvMetadata from the set of metadata local to this dataset ."}}
{"translation": {"code": "boolean validate ( StringBuilder out ) { this . isValid = true ; // If log from construction has content, append to validation output msg. if ( this . msgLog . length ( ) > 0 ) { out . append ( this . msgLog ) ; } // Check that name is not null (it can be an empty string). if ( this . getName ( ) == null ) { this . isValid = false ; out . append ( \" ** DatasetNamer (1): null value for name is not valid.\" ) ; } // Check that addLevel is not null. // boolean can't be null //if ( this.getAddLevel() == null) //{ //  this.isValid = false; //  out.append(\" ** DatasetNamer (2): null value for addLevel is not valid.\"); //} // Check that type is not null. if ( this . getType ( ) == null ) { this . isValid = false ; out . append ( \" ** DatasetNamer (3): null value for type is not valid (set with bad string?).\" ) ; } if ( this . getType ( ) == DatasetNamerType . REGULAR_EXPRESSION && ( this . getMatchPattern ( ) == null || this . getSubstitutePattern ( ) == null ) ) { this . isValid = false ; out . append ( \" ** DatasetNamer (4): invalid datasetNamer <\" + this . getName ( ) + \">;\" + \" type is \" + this . getType ( ) . toString ( ) + \": matchPattern(\" + this . getMatchPattern ( ) + \") and substitutionPattern(\" + this . getSubstitutePattern ( ) + \") \" + \"must not be null.\" ) ; } if ( this . getType ( ) == DatasetNamerType . DODS_ATTRIBUTE && ( this . getAttribContainer ( ) == null || this . getAttribName ( ) == null ) ) { this . isValid = false ; out . append ( \" ** DatasetNamer (5): invalid datasetNamer <\" + this . getName ( ) + \">;\" + \" type is \" + this . getType ( ) . toString ( ) + \": attriuteContainer(\" + this . getAttribContainer ( ) + \") and attributeName(\" + this . getAttribName ( ) + \") must not be null.\" ) ; } return ( this . isValid ) ; }", "nl": "Validate this DatasetNamer object . Return true if valid false if invalid ."}}
{"translation": {"code": "public void crawlDirectDatasets ( InvDataset ds , CancelTask task , PrintWriter out , Object context , boolean release ) { boolean isCatRef = ( ds instanceof InvCatalogRef ) ; if ( filter != null && filter . skipAll ( ds ) ) { if ( isCatRef && release ) ( ( InvCatalogRef ) ds ) . release ( ) ; return ; } if ( isCatRef ) { InvCatalogRef catref = ( InvCatalogRef ) ds ; if ( out != null ) out . println ( \" **CATREF \" + catref . getURI ( ) + \" (\" + ds . getName ( ) + \") \" ) ; countCatrefs ++ ; if ( ! listen . getCatalogRef ( catref , context ) ) { if ( release ) catref . release ( ) ; return ; } } // get datasets with data access (\"leaves\") List < InvDataset > dlist = ds . getDatasets ( ) ; List < InvDataset > leaves = new ArrayList < InvDataset > ( ) ; for ( InvDataset dds : dlist ) { if ( dds . hasAccess ( ) ) leaves . add ( dds ) ; } if ( leaves . size ( ) > 0 ) { if ( type == Type . first_direct ) { InvDataset dds = leaves . get ( 0 ) ; listen . getDataset ( dds , context ) ; } else if ( type == Type . random_direct ) { listen . getDataset ( chooseRandom ( leaves ) , context ) ; } else if ( type == Type . random_direct_middle ) { listen . getDataset ( chooseRandomNotFirstOrLast ( leaves ) , context ) ; } else { // do all of them for ( InvDataset dds : leaves ) { listen . getDataset ( dds , context ) ; if ( ( task != null ) && task . isCancel ( ) ) break ; } } } // recurse for ( InvDataset dds : dlist ) { if ( dds . hasNestedDatasets ( ) ) crawlDirectDatasets ( dds , task , out , context , release ) ; if ( ( task != null ) && task . isCancel ( ) ) break ; } /* if (out != null) {\n     int took = (int) (System.currentTimeMillis() - start);\n     out.println(\" ** \" + ds.getName() + \" took \" + took + \" msecs\\n\");\n   } */ if ( ds instanceof InvCatalogRef && release ) { InvCatalogRef catref = ( InvCatalogRef ) ds ; catref . release ( ) ; } }", "nl": "Crawl this dataset recursively . Only send back direct datasets"}}
{"translation": {"code": "public InvService findService ( String name ) { if ( name == null ) return null ; for ( InvService s : services ) { if ( name . equals ( s . getName ( ) ) ) return s ; // look for nested servers if ( s . getServiceType ( ) == ServiceType . COMPOUND ) { InvService result = s . findNestedService ( name ) ; if ( result != null ) return result ; } } return null ; }", "nl": "Find the named service declared in the top level of this catalog ."}}
{"translation": {"code": "public boolean removeDataset ( InvDatasetImpl ds ) { if ( this . datasets . remove ( ds ) ) { ds . setParent ( null ) ; InvCatalogImpl cat = ( InvCatalogImpl ) getParentCatalog ( ) ; if ( cat != null ) cat . removeDatasetByID ( ds ) ; return ( true ) ; } return ( false ) ; }", "nl": "Remove the given dataset element from this dataset if it is in the dataset ."}}
{"translation": {"code": "public boolean replaceDataset ( InvDatasetImpl remove , InvDatasetImpl add ) { for ( int i = 0 ; i < datasets . size ( ) ; i ++ ) { InvDataset dataset = datasets . get ( i ) ; if ( dataset . equals ( remove ) ) { datasets . set ( i , add ) ; InvCatalogImpl cat = ( InvCatalogImpl ) getParentCatalog ( ) ; if ( cat != null ) { cat . removeDatasetByID ( remove ) ; cat . addDatasetByID ( add ) ; } return true ; } } return false ; }", "nl": "Replace the given dataset if it is a nesetd dataset ."}}
{"translation": {"code": "public void addService ( InvService service ) { // System.out.println(\"--add dataset service= \"+service.getName()); servicesLocal . add ( service ) ; services . add ( service ) ; // add nested servers for ( InvService nested : service . getServices ( ) ) { services . add ( nested ) ; // System.out.println(\"--add expanded service= \"+nested.getName()); } hashCode = 0 ; }", "nl": "Add a service to this dataset ."}}
{"translation": {"code": "public NetcdfDataset openDataset ( InvDataset invDataset , boolean acquire , ucar . nc2 . util . CancelTask task , Formatter log ) throws IOException { Result result = new Result ( ) ; NetcdfDataset ncd = openDataset ( invDataset , acquire , task , result ) ; if ( log != null ) log . format ( \"%s\" , result . errLog ) ; return ( result . fatalError ) ? null : ncd ; }", "nl": "Try to open as a NetcdfDataset ."}}
{"translation": {"code": "public ThreddsDataFactory . Result openFeatureDataset ( InvDataset invDataset , ucar . nc2 . util . CancelTask task ) throws IOException { return openFeatureDataset ( null , invDataset , task , new Result ( ) ) ; }", "nl": "Open a FeatureDataset from an InvDataset object deciding on which InvAccess to use ."}}
{"translation": {"code": "public ThreddsMetadata getInheritableMetadata ( ) { ThreddsMetadata tmi = ( ThreddsMetadata ) get ( Dataset . ThreddsMetadataInheritable ) ; if ( tmi == null ) { tmi = new ThreddsMetadata ( ) ; put ( Dataset . ThreddsMetadataInheritable , tmi ) ; } return tmi ; }", "nl": "get the inheritable ThreddsMetadata object . If doesnt exist create new empty one"}}
{"translation": {"code": "public static void annotate ( InvDataset ds , NetcdfDataset ncDataset ) { ncDataset . setTitle ( ds . getName ( ) ) ; ncDataset . setId ( ds . getID ( ) ) ; // add properties as global attributes for ( InvProperty p : ds . getProperties ( ) ) { String name = p . getName ( ) ; if ( null == ncDataset . findGlobalAttribute ( name ) ) { ncDataset . addAttribute ( null , new Attribute ( name , p . getValue ( ) ) ) ; } } /* ThreddsMetadata.GeospatialCoverage geoCoverage = ds.getGeospatialCoverage();\n   if (geoCoverage != null) {\n     if ( null != geoCoverage.getNorthSouthRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lat_min\", new Double(geoCoverage.getLatSouth())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lat_max\", new Double(geoCoverage.getLatNorth())));\n     }\n     if ( null != geoCoverage.getEastWestRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lon_min\", new Double(geoCoverage.getLonWest())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_lon_max\", new Double(geoCoverage.getLonEast())));\n     }\n     if ( null != geoCoverage.getUpDownRange()) {\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_vertical_min\", new Double(geoCoverage.getHeightStart())));\n       ncDataset.addAttribute(null, new Attribute(\"geospatial_vertical_max\", new Double(geoCoverage.getHeightStart() + geoCoverage.getHeightExtent())));\n     }\n   }\n\n   DateRange timeCoverage = ds.getTimeCoverage();\n   if (timeCoverage != null) {\n     ncDataset.addAttribute(null, new Attribute(\"time_coverage_start\", timeCoverage.getStart().toDateTimeStringISO()));\n     ncDataset.addAttribute(null, new Attribute(\"time_coverage_end\", timeCoverage.getEnd().toDateTimeStringISO()));\n   } */ ncDataset . finish ( ) ; }", "nl": "Add information from the InvDataset to the NetcdfDataset ."}}
{"translation": {"code": "private boolean include ( MFile mfile ) { if ( includeFilters == null ) return true ; for ( MFileFilter filter : includeFilters ) { if ( filter . accept ( mfile ) ) return true ; } return false ; }", "nl": "inclusion is an OR"}}
{"translation": {"code": "public DataRoot findDataRoot ( String reqPath ) { String path = findLongestPathMatch ( reqPath ) ; if ( path == null ) return null ; DataRootExt dataRootExt = map . get ( path ) ; if ( dataRootExt == null ) { logger . error ( \"DataRootPathMatcher found path {} but not in map\" , path ) ; return null ; } return convert2DataRoot ( dataRootExt ) ; }", "nl": "Find the longest DataRoot match ."}}
{"translation": {"code": "protected void setBoundingBox ( ) { LatLonRect largestBB = null ; // look through all the coord systems for ( Object o : csHash . values ( ) ) { RadialCoordSys sys = ( RadialCoordSys ) o ; sys . setOrigin ( origin ) ; LatLonRect bb = sys . getBoundingBox ( ) ; if ( largestBB == null ) largestBB = bb ; else if ( bb != null ) largestBB . extend ( bb ) ; } boundingBox = largestBB ; }", "nl": "you must set EarthLocation before you call this ."}}
{"translation": {"code": "@ ExceptionHandler ( Throwable . class ) public ResponseEntity < String > handle ( Throwable ex ) throws Throwable { // If the exception is annotated with @ResponseStatus rethrow it and let // the framework handle it - like the OrderNotFoundException example // at the start of this post. // AnnotationUtils is a Spring Framework utility class. // see https://spring.io/blog/2013/11/01/exception-handling-in-spring-mvc if ( AnnotationUtils . findAnnotation ( ex . getClass ( ) , ResponseStatus . class ) != null ) throw ex ; logger . error ( \"uncaught exception\" , ex ) ; // ex.printStackTrace(); // temporary - remove in production HttpHeaders responseHeaders = new HttpHeaders ( ) ; responseHeaders . setContentType ( MediaType . TEXT_PLAIN ) ; String msg = ex . getMessage ( ) ; StringWriter sw = new StringWriter ( ) ; PrintWriter p = new PrintWriter ( sw ) ; ex . printStackTrace ( p ) ; p . close ( ) ; sw . close ( ) ; msg = sw . toString ( ) ; return new ResponseEntity <> ( \"Throwable exception handled : \" + htmlEscape ( msg ) , responseHeaders , HttpStatus . INTERNAL_SERVER_ERROR ) ; }", "nl": "LOOK this could be a problem"}}
{"translation": {"code": "private boolean andFilter ( MFile mfile ) { if ( andFilters == null ) return true ; for ( MFileFilter filter : andFilters ) { if ( ! filter . accept ( mfile ) ) return false ; } return true ; }", "nl": "all AND filters must be satisfied"}}
{"translation": {"code": "private void setColorScaleParams ( ) { if ( dataMinMaxType == ColorScale . MinMaxType . hold && ! isNewField ) return ; isNewField = false ; GeoReferencedArray dataArr = readHSlice ( wantLevel , wantTime , wantEnsemble , wantRunTime ) ; //else //  dataArr = makeVSlice(stridedGrid, wantSlice, wantTime, wantEnsemble, wantRunTime); if ( dataArr != null ) { MAMath . MinMax minmax = MAMath . getMinMaxSkipMissingData ( dataArr . getData ( ) , dataState . grid ) ; colorScale . setMinMax ( minmax . min , minmax . max ) ; colorScale . setGeoGrid ( dataState . grid ) ; } }", "nl": "set colorscale limits missing data"}}
{"translation": {"code": "@ Override public void addAll ( Iterable < Attribute > atts ) { for ( Attribute att : atts ) addAttribute ( att ) ; }", "nl": "Add all ; replace old if has same name"}}
{"translation": {"code": "@ Override public boolean removeAttribute ( String attName ) { Attribute att = findAttribute ( attName ) ; return att != null && atts . remove ( att ) ; }", "nl": "Remove an Attribute by name ."}}
{"translation": {"code": "static public ProjectionImpl makeProjection ( CoverageTransform gct , Formatter errInfo ) { // standard name\r String transform_name = gct . findAttValueIgnoreCase ( CF . GRID_MAPPING_NAME , null ) ; if ( null == transform_name ) { errInfo . format ( \"**Failed to find Coordinate Transform name from GridCoordTransform= %s%n\" , gct ) ; return null ; } transform_name = transform_name . trim ( ) ; // do we have a transform registered for this ?\r Class builderClass = null ; for ( Transform transform : transformList ) { if ( transform . transName . equals ( transform_name ) ) { builderClass = transform . transClass ; break ; } } if ( null == builderClass ) { errInfo . format ( \"**Failed to find CoordTransBuilder name= %s from GridCoordTransform= %s%n\" , transform_name , gct ) ; return null ; } // get an instance of that class\r HorizTransformBuilderIF builder ; try { builder = ( HorizTransformBuilderIF ) builderClass . newInstance ( ) ; } catch ( InstantiationException | IllegalAccessException e ) { log . error ( \"Cant create new instance \" + builderClass . getName ( ) , e ) ; return null ; } if ( null == builder ) { // cant happen - because this was tested in registerTransform()\r errInfo . format ( \"**Failed to build CoordTransBuilder object from class= %s for GridCoordTransform= %s%n\" , builderClass . getName ( ) , gct ) ; return null ; } String units = gct . findAttValueIgnoreCase ( CDM . UNITS , null ) ; builder . setErrorBuffer ( errInfo ) ; ProjectionCT ct = builder . makeCoordinateTransform ( gct , units ) ; assert ct != null ; return ct . getProjection ( ) ; }", "nl": "Make a CoordinateTransform object from the parameters in a GridCoordTransform using an intrinsic or registered CoordTransBuilder ."}}
{"translation": {"code": "protected double readAttributeDouble ( AttributeContainer v , String attname , double defValue ) { Attribute att = v . findAttributeIgnoreCase ( attname ) ; if ( att == null ) return defValue ; if ( att . isString ( ) ) return Double . parseDouble ( att . getStringValue ( ) ) ; else return att . getNumericValue ( ) . doubleValue ( ) ; }", "nl": "Read a variable attribute as a double ."}}
{"translation": {"code": "@ Override public boolean removeAttributeIgnoreCase ( String attName ) { Attribute att = findAttributeIgnoreCase ( attName ) ; return att != null && atts . remove ( att ) ; }", "nl": "Remove an Attribute by name ignoring case"}}
{"translation": {"code": "private void checkRequestedVars ( CoverageCollection gcd , NcssGridParamsBean params ) throws VariableNotContainedInDatasetException { // if var == all --> all variables requested if ( params . getVar ( ) . get ( 0 ) . equalsIgnoreCase ( \"all\" ) ) { params . setVar ( getAllGridNames ( gcd ) ) ; return ; } // Check vars are contained in the grid for ( String gridName : params . getVar ( ) ) { Coverage grid = gcd . findCoverage ( gridName ) ; if ( grid == null ) throw new VariableNotContainedInDatasetException ( \"Variable: \" + gridName + \" is not contained in the requested dataset\" ) ; } }", "nl": "Checks that all the requested vars exist . If all fills out the param . vars with all grid names Throws exception if some of the variables in the request are not contained in the dataset"}}
{"translation": {"code": "protected Array createView ( Index index ) { return ArrayObject . factory ( dataType , elementType , isVlen , index , storage ) ; }", "nl": "create new Array with given indexImpl and the same backing store"}}
{"translation": {"code": "Dimension getSharedDimension ( Group group , Dimension d ) { if ( d . getShortName ( ) == null ) return d ; if ( group == null ) group = rootGroup ; for ( Dimension sd : group . getDimensions ( ) ) { if ( sd . getShortName ( ) . equals ( d . getShortName ( ) ) && sd . getLength ( ) == d . getLength ( ) ) return sd ; } d . setShared ( true ) ; group . addDimension ( d ) ; return d ; }", "nl": "If an equivilent shared dimension already exists use it else add d to shared dimensions . Equivilent is same name and length ."}}
{"translation": {"code": "static public void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) { debugCE = debugFlag . isSet ( \"DODS/constraintExpression\" ) ; debugServerCall = debugFlag . isSet ( \"DODS/serverCall\" ) ; debugOpenResult = debugFlag . isSet ( \"DODS/debugOpenResult\" ) ; debugDataResult = debugFlag . isSet ( \"DODS/debugDataResult\" ) ; debugCharArray = debugFlag . isSet ( \"DODS/charArray\" ) ; debugConstruct = debugFlag . isSet ( \"DODS/constructNetcdf\" ) ; debugPreload = debugFlag . isSet ( \"DODS/preload\" ) ; debugTime = debugFlag . isSet ( \"DODS/timeCalls\" ) ; showNCfile = debugFlag . isSet ( \"DODS/showNCfile\" ) ; debugAttributes = debugFlag . isSet ( \"DODS/attributes\" ) ; debugCached = debugFlag . isSet ( \"DODS/cache\" ) ; }", "nl": "Debugging flags . This is a way to decouple setting flags from particular implementations ."}}
{"translation": {"code": "DodsV findByIndex ( int index ) { if ( children . size ( ) <= index ) return null ; return children . get ( index ) ; }", "nl": "Return a child by index"}}
{"translation": {"code": "private DateRange idvCompatibleRange ( DateRange range ) { CalendarDate start = range . getStart ( ) . getCalendarDate ( ) ; CalendarDate end = range . getEnd ( ) . getCalendarDate ( ) ; return new DateRange ( start . toDate ( ) , end . toDate ( ) ) ; }", "nl": "present and 14 days ."}}
{"translation": {"code": "public LatLonRect getLatLonBoundingBox ( ) { if ( llbb == null ) { if ( ( getXHorizAxis ( ) instanceof CoordinateAxis2D ) && ( getYHorizAxis ( ) instanceof CoordinateAxis2D ) ) { return null ; } CoordinateAxis horizXaxis = getXHorizAxis ( ) ; CoordinateAxis horizYaxis = getYHorizAxis ( ) ; if ( isLatLon ( ) ) { double startLat = horizYaxis . getMinValue ( ) ; double startLon = horizXaxis . getMinValue ( ) ; double deltaLat = horizYaxis . getMaxValue ( ) - startLat ; double deltaLon = horizXaxis . getMaxValue ( ) - startLon ; LatLonPoint llpt = new LatLonPointImpl ( startLat , startLon ) ; llbb = new LatLonRect ( llpt , deltaLat , deltaLon ) ; } else { ProjectionImpl dataProjection = getProjection ( ) ; ProjectionRect bb = getBoundingBox ( ) ; if ( bb != null ) llbb = dataProjection . projToLatLonBB ( bb ) ; } } return llbb ; /*  // look at all 4 corners of the bounding box\n        LatLonPointImpl llpt = (LatLonPointImpl) dataProjection.projToLatLon(bb.getLowerLeftPoint(), new LatLonPointImpl());\n        LatLonPointImpl lrpt = (LatLonPointImpl) dataProjection.projToLatLon(bb.getLowerRightPoint(), new LatLonPointImpl());\n        LatLonPointImpl urpt = (LatLonPointImpl) dataProjection.projToLatLon(bb.getUpperRightPoint(), new LatLonPointImpl());\n        LatLonPointImpl ulpt = (LatLonPointImpl) dataProjection.projToLatLon(bb.getUpperLeftPoint(), new LatLonPointImpl());\n\n        // Check if grid contains poles.\n        boolean includesNorthPole = false;\n        int[] resultNP;\n        resultNP = findXYindexFromLatLon(90.0, 0, null);\n        if (resultNP[0] != -1 && resultNP[1] != -1)\n          includesNorthPole = true;\n        boolean includesSouthPole = false;\n        int[] resultSP;\n        resultSP = findXYindexFromLatLon(-90.0, 0, null);\n        if (resultSP[0] != -1 && resultSP[1] != -1)\n          includesSouthPole = true;\n\n        if (includesNorthPole && !includesSouthPole) {\n          llbb = new LatLonRect(llpt, new LatLonPointImpl(90.0, 0.0)); // ??? lon=???\n          llbb.extend(lrpt);\n          llbb.extend(urpt);\n          llbb.extend(ulpt);\n          // OR\n          //llbb.extend( new LatLonRect( llpt, lrpt ));\n          //llbb.extend( new LatLonRect( lrpt, urpt ) );\n          //llbb.extend( new LatLonRect( urpt, ulpt ) );\n          //llbb.extend( new LatLonRect( ulpt, llpt ) );\n        } else if (includesSouthPole && !includesNorthPole) {\n          llbb = new LatLonRect(llpt, new LatLonPointImpl(-90.0, -180.0)); // ??? lon=???\n          llbb.extend(lrpt);\n          llbb.extend(urpt);\n          llbb.extend(ulpt);\n        } else {\n          double latMin = Math.min(llpt.getLatitude(), lrpt.getLatitude());\n          double latMax = Math.max(ulpt.getLatitude(), urpt.getLatitude());\n\n          // longitude is a bit tricky as usual\n          double lonMin = getMinOrMaxLon(llpt.getLongitude(), ulpt.getLongitude(), true);\n          double lonMax = getMinOrMaxLon(lrpt.getLongitude(), urpt.getLongitude(), false);\n\n          llpt.set(latMin, lonMin);\n          urpt.set(latMax, lonMax);\n\n          llbb = new LatLonRect(llpt, urpt);\n        }\n      }\n    }  */ }", "nl": "Get horizontal bounding box in lat lon coordinates ."}}
{"translation": {"code": "public String getName ( ) { String loc = ncd . getLocation ( ) ; int pos = loc . lastIndexOf ( ' ' ) ; if ( pos < 0 ) pos = loc . lastIndexOf ( ' ' ) ; return ( pos < 0 ) ? loc : loc . substring ( pos + 1 ) ; }", "nl": "the name of the dataset is the last part of the location"}}
{"translation": {"code": "public static boolean isSubset ( Collection < Dimension > subset , Collection < Dimension > set ) { for ( Dimension d : subset ) { if ( ! ( set . contains ( d ) ) ) return false ; } return true ; }", "nl": "Test if all the Dimensions in subset are in set"}}
{"translation": {"code": "static public ArrayStructureBB factory ( ArrayStructureBB org , Section section ) { if ( section == null || section . computeSize ( ) == org . getSize ( ) ) return org ; return new ArrayStructureBBsection ( org . getStructureMembers ( ) , org . getShape ( ) , org . getByteBuffer ( ) , section ) ; }", "nl": "Make a section of an ArrayStructureBB"}}
{"translation": {"code": "public synchronized void init ( ReadMode readMode , PreferencesExt prefs ) { if ( readMode == null ) readMode = defaultReadMode ; this . prefs = prefs ; trackerNumber = prefs . getLong ( \"trackerNumber\" , 1 ) ; numberCatalogs = prefs . getInt ( \"numberCatalogs\" , 10 ) ; nextCatId = prefs . getLong ( \"nextCatId\" , 1 ) ; makeDebugActions ( ) ; this . contentRootPath = this . tdsContext . getThreddsDirectory ( ) ; this . contextPath = tdsContext . getContextPath ( ) ; reread ( readMode , true ) ; }", "nl": "called from TdsInit on spring - managed auto - wired bean"}}
{"translation": {"code": "private void readCatsInDirectory ( ReadMode readMode , String dirPath , Path directory ) throws IOException { if ( exceedLimit ) return ; // do any catalogs first try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( directory , \"*.xml\" ) ) { for ( Path p : ds ) { if ( ! Files . isDirectory ( p ) ) { // path must be relative to rootDir String filename = p . getFileName ( ) . toString ( ) ; String path = dirPath . length ( ) == 0 ? filename : dirPath + \"/\" + filename ; // reletive starting from current directory CatalogExt ext = catalogTracker . get ( path ) ; long lastRead = ( ext == null ) ? 0 : ext . getLastRead ( ) ; checkCatalogToRead ( readMode , path , false , lastRead ) ; } } } // now recurse into the directory try ( DirectoryStream < Path > ds = Files . newDirectoryStream ( directory ) ) { for ( Path dir : ds ) { if ( Files . isDirectory ( dir ) ) { String dirPathChild = dirPath + \"/\" + dir . getFileName ( ) . toString ( ) ; // reletive starting from current directory readCatsInDirectory ( readMode , dirPathChild , dir ) ; } } } }", "nl": "dirPath is the directory relative to rootDir directory is absolute"}}
{"translation": {"code": "public @ Nonnull DataRoot convert2DataRoot ( DataRootExt dataRootExt ) { DataRoot dataRoot = dataRootExt . getDataRoot ( ) ; if ( dataRoot != null ) return dataRoot ; // otherwise must read the catalog that its in dataRoot = readDataRootFromCatalog ( dataRootExt ) ; dataRootExt . setDataRoot ( dataRoot ) ; return dataRoot ; }", "nl": "convert a dataRootExt to a dataRoot"}}
{"translation": {"code": "static AuthScope uriToAuthScope ( URI uri ) { assert ( uri != null ) ; return new AuthScope ( uri . getHost ( ) , uri . getPort ( ) , AuthScope . ANY_REALM , uri . getScheme ( ) ) ; }", "nl": "Create an AuthScope from a URI ; remove any principal"}}
{"translation": {"code": "private void setServices ( Iterable < DatasetBuilder > dsIter ) { for ( DatasetBuilder dsb : dsIter ) { for ( Service s : dsb . getServices ( ) ) { addService ( s ) ; } setServices ( dsb . getDatasets ( ) ) ; // recurse } }", "nl": "pull services out of the datasets and into the catalog"}}
{"translation": {"code": "public Iterable < Dataset > getAllDatasets ( ) { List < Dataset > all = new ArrayList <> ( ) ; addAll ( this , all ) ; return all ; }", "nl": "get all datasets contained directly in this catalog"}}
{"translation": {"code": "private void addGlobalServices ( CatalogBuilder cat ) { // look for datasets that want to use global services Set < String > allServiceNames = new HashSet <> ( ) ; findServices ( cat . getDatasets ( ) , allServiceNames ) ; // all services used if ( ! allServiceNames . isEmpty ( ) ) { List < Service > servicesMissing = new ArrayList <> ( ) ; // all services missing for ( String name : allServiceNames ) { if ( cat . hasServiceInDataset ( name ) ) continue ; Service s = globalServices . findGlobalService ( name ) ; if ( s != null ) servicesMissing . add ( s ) ; } servicesMissing . forEach ( cat :: addService ) ; } // look for datasets that want to use standard services for ( DatasetBuilder node : cat . getDatasets ( ) ) { String sname = ( String ) node . getFldOrInherited ( Dataset . ServiceName ) ; String urlPath = ( String ) node . get ( Dataset . UrlPath ) ; String ftypeS = ( String ) node . getFldOrInherited ( Dataset . FeatureType ) ; if ( sname == null && urlPath != null && ftypeS != null ) { Service s = globalServices . getStandardServices ( ftypeS ) ; if ( s != null ) { node . put ( Dataset . ServiceName , s . getName ( ) ) ; cat . addService ( s ) ; } } } }", "nl": "rigamorole to modify invariant catalogs ; we may need to add global services"}}
{"translation": {"code": "public Attribute deleteVariableAttribute ( String varName , String attName ) { if ( ! defineMode ) throw new UnsupportedOperationException ( \"not in define mode\" ) ; Variable v = findVariable ( varName ) ; if ( v == null ) return null ; Attribute att = v . findAttribute ( attName ) ; if ( null == att ) return null ; v . remove ( att ) ; return att ; }", "nl": "Delete a variable Attribute . Must be in define mode ."}}
{"translation": {"code": "public Attribute addGlobalAttribute ( String name , Array values ) { return addGlobalAttribute ( new Attribute ( name , values ) ) ; }", "nl": "Add a Global attribute of type Array to the file . Must be in define mode ."}}
{"translation": {"code": "public void addVariableAttribute ( String varName , String attName , String value ) { addVariableAttribute ( varName , new Attribute ( attName , value ) ) ; }", "nl": "Add an attribute of type String to the named Variable . Must be in define mode ."}}
{"translation": {"code": "public Attribute addGlobalAttribute ( String name , String value ) { return addGlobalAttribute ( new Attribute ( name , value ) ) ; }", "nl": "Add a Global attribute of type String to the file . Must be in define mode ."}}
{"translation": {"code": "private int findClosest ( double target ) { double minDiff = Double . MAX_VALUE ; double useValue = Double . MIN_VALUE ; int idxFound = - 1 ; for ( int i = 0 ; i < axis . getNcoords ( ) ; i ++ ) { double coord = axis . getCoordMidpoint ( i ) ; double diff = Math . abs ( coord - target ) ; if ( diff < minDiff || ( diff == minDiff && coord > useValue ) ) { minDiff = diff ; idxFound = i ; useValue = coord ; } } return idxFound ; }", "nl": "if its a tie use the larger one"}}
{"translation": {"code": "public void writeToStream ( Element elem , OutputStream outStream ) throws IOException { try ( Writer writer = new BufferedWriter ( new OutputStreamWriter ( new BufferedOutputStream ( outStream ) , xmlFormat . getEncoding ( ) ) ) ) { writeToWriter ( elem , writer ) ; } }", "nl": "Writes an NcML element to an output stream ."}}
{"translation": {"code": "public void writeToWriter ( Element elem , Writer writer ) throws IOException { xmlOutputter . setFormat ( xmlFormat ) ; elem . detach ( ) ; // In case this element had previously been added to a Document.\r xmlOutputter . output ( new Document ( elem ) , writer ) ; }", "nl": "Writes an NcML element to a Writer ."}}
{"translation": {"code": "public Array readData ( SectionIterable want ) throws IOException , InvalidRangeException { if ( vindex instanceof PartitionCollectionImmutable . VariableIndexPartitioned ) return readDataFromPartition ( ( PartitionCollectionImmutable . VariableIndexPartitioned ) vindex , want ) ; else return readDataFromCollection ( vindex , want ) ; }", "nl": "Read the section of data described by want"}}
{"translation": {"code": "public static boolean nearlyEqualsAbs ( float a , float b , float maxAbsDiff ) { return absoluteDifference ( a , b ) <= Math . abs ( maxAbsDiff ) ; }", "nl": "Check if two numbers are nearly equal with given absolute tolerance ."}}
{"translation": {"code": "public Optional < TimeOffsetAxis > subsetFromTime ( SubsetParams params , CalendarDate runDate ) { CoordAxisHelper helper = new CoordAxisHelper ( this ) ; CoverageCoordAxisBuilder builder = null ; if ( params . isTrue ( SubsetParams . timePresent ) ) { double offset = getOffsetInTimeUnits ( runDate , CalendarDate . present ( ) ) ; builder = helper . subsetClosest ( offset ) ; } CalendarDate dateWanted = ( CalendarDate ) params . get ( SubsetParams . time ) ; if ( dateWanted != null ) { // convertFrom, convertTo double offset = getOffsetInTimeUnits ( runDate , dateWanted ) ; builder = helper . subsetClosest ( offset ) ; } Integer stride = ( Integer ) params . get ( SubsetParams . timeStride ) ; if ( stride == null || stride < 0 ) stride = 1 ; CalendarDateRange dateRange = ( CalendarDateRange ) params . get ( SubsetParams . timeRange ) ; if ( dateRange != null ) { double min = getOffsetInTimeUnits ( runDate , dateRange . getStart ( ) ) ; double max = getOffsetInTimeUnits ( runDate , dateRange . getEnd ( ) ) ; Optional < CoverageCoordAxisBuilder > buildero = helper . subset ( min , max , stride ) ; if ( buildero . isPresent ( ) ) builder = buildero . get ( ) ; else return Optional . empty ( buildero . getErrorMessage ( ) ) ; } assert ( builder != null ) ; // all the offsets are reletive to rundate builder . setReferenceDate ( runDate ) ; return Optional . of ( new TimeOffsetAxis ( builder ) ) ; }", "nl": "normal case already handled this is the case where a time has been specified and only one runtime"}}
{"translation": {"code": "public Range shiftOrigin ( int origin ) throws InvalidRangeException { if ( this == VLEN ) return VLEN ; int first = first ( ) - origin ; int last = last ( ) - origin ; return new Range ( name , first , last , stride ) ; }", "nl": "Create a new Range shifting this range by a constant factor ."}}
{"translation": {"code": "public List < RangeIterator > getRanges ( ) { List < RangeIterator > result = new ArrayList <> ( ) ; result . add ( getYAxis ( ) . getRange ( ) ) ; RangeIterator lonRange = getXAxis ( ) . getRangeIterator ( ) ; if ( lonRange == null ) lonRange = getXAxis ( ) . getRange ( ) ; // clumsy result . add ( lonRange ) ; return result ; }", "nl": "return y x range"}}
{"translation": {"code": "public Optional < CoverageCoordAxis > subsetByIntervals ( List < MAMath . MinMax > lonIntvs , int stride ) { if ( axisType != AxisType . Lon ) return Optional . empty ( \"subsetByIntervals only for longitude\" ) ; if ( ! isRegular ( ) ) return Optional . empty ( \"subsetByIntervals only for regular longitude\" ) ; CoordAxisHelper helper = new CoordAxisHelper ( this ) ; double start = Double . NaN ; boolean first = true ; List < RangeIterator > ranges = new ArrayList <> ( ) ; for ( MAMath . MinMax lonIntv : lonIntvs ) { if ( first ) start = lonIntv . min ; first = false ; Optional < RangeIterator > opt = helper . makeRange ( lonIntv . min , lonIntv . max , stride ) ; if ( ! opt . isPresent ( ) ) return Optional . empty ( opt . getErrorMessage ( ) ) ; ranges . add ( opt . get ( ) ) ; } try { RangeComposite compositeRange = new RangeComposite ( AxisType . Lon . toString ( ) , ranges ) ; int npts = compositeRange . length ( ) ; double end = start + npts * resolution ; CoverageCoordAxisBuilder builder = new CoverageCoordAxisBuilder ( this ) ; // copy builder . subset ( npts , start , end , resolution , null ) ; builder . setRange ( null ) ; builder . setCompositeRange ( compositeRange ) ; return Optional . of ( new CoverageCoordAxis1D ( builder ) ) ; } catch ( InvalidRangeException e ) { return Optional . empty ( e . getMessage ( ) ) ; } }", "nl": "only for longitude only for regular ( do we need a subclass for longitude 1D coords ??"}}
{"translation": {"code": "private ucar . ma2 . Array readRecordData ( ucar . nc2 . Structure s , Section section ) throws java . io . IOException { //if (s.isSubset()) //  return readRecordDataSubset(s, section); // has to be 1D Range recordRange = section . getRange ( 0 ) ; // create the ArrayStructure StructureMembers members = s . makeStructureMembers ( ) ; for ( StructureMembers . Member m : members . getMembers ( ) ) { Variable v2 = s . findVariable ( m . getName ( ) ) ; N3header . Vinfo vinfo = ( N3header . Vinfo ) v2 . getSPobject ( ) ; m . setDataParam ( ( int ) ( vinfo . begin - header . recStart ) ) ; } // protect agains too large of reads if ( header . recsize > Integer . MAX_VALUE ) throw new IllegalArgumentException ( \"Cant read records when recsize > \" + Integer . MAX_VALUE ) ; long nrecs = section . computeSize ( ) ; if ( nrecs * header . recsize > Integer . MAX_VALUE ) throw new IllegalArgumentException ( \"Too large read: nrecs * recsize= \" + ( nrecs * header . recsize ) + \"bytes exceeds \" + Integer . MAX_VALUE ) ; members . setStructureSize ( ( int ) header . recsize ) ; ArrayStructureBB structureArray = new ArrayStructureBB ( members , new int [ ] { recordRange . length ( ) } ) ; // note dependency on raf; should probably defer to subclass // loop over records byte [ ] result = structureArray . getByteBuffer ( ) . array ( ) ; int count = 0 ; for ( int recnum : recordRange ) { if ( debugRecord ) System . out . println ( \" read record \" + recnum ) ; raf . seek ( header . recStart + recnum * header . recsize ) ; // where the record starts if ( recnum != header . numrecs - 1 ) raf . readFully ( result , ( int ) ( count * header . recsize ) , ( int ) header . recsize ) ; else raf . read ( result , ( int ) ( count * header . recsize ) , ( int ) header . recsize ) ; // \"wart\" allows file to be one byte short. since its always padding, we allow count ++ ; } return structureArray ; }", "nl": "Read data from record structure . For N3 this is the only possible structure and there can be no nesting . Read all variables for each record put in ByteBuffer ."}}
{"translation": {"code": "@ Override public void openForWriting ( ucar . unidata . io . RandomAccessFile raf , ucar . nc2 . NetcdfFile ncfile , ucar . nc2 . util . CancelTask cancelTask ) throws IOException { open ( raf , ncfile , cancelTask ) ; }", "nl": "read existing file"}}
{"translation": {"code": "public void setShortNames ( String latVName , String lonVName , String altVName , String obsTimeVName , String nomTimeVName ) { this . latVName = latVName ; this . lonVName = lonVName ; this . zcoordVName = altVName ; this . obsTimeVName = obsTimeVName ; this . nomTimeVName = nomTimeVName ; }", "nl": "access it members"}}
{"translation": {"code": "public static FeatureType isCdmrfEndpoint ( String endpoint ) throws IOException { HTTPSession httpClient = HTTPFactory . newSession ( endpoint ) ; String url = endpoint + \"?req=featureType\" ; // get the header try ( HTTPMethod method = HTTPFactory . Get ( httpClient , url ) ) { method . setFollowRedirects ( true ) ; int statusCode = method . execute ( ) ; if ( statusCode != 200 ) return null ; String content = method . getResponseAsString ( ) ; return FeatureType . getType ( content ) ; } catch ( Throwable t ) { t . printStackTrace ( ) ; return null ; } }", "nl": "all CdmrFeatureDatasets must return their featureType - use as a fail - fast test of the endpoint"}}
{"translation": {"code": "static private ServiceType decodePathExtension ( String path ) { // Look at the path extensions if ( path . endsWith ( \".dds\" ) || path . endsWith ( \".das\" ) || path . endsWith ( \".dods\" ) ) return ServiceType . OPENDAP ; if ( path . endsWith ( \".dmr\" ) || path . endsWith ( \".dap\" ) || path . endsWith ( \".dsr\" ) ) return ServiceType . DAP4 ; if ( path . endsWith ( \".xml\" ) || path . endsWith ( \".ncml\" ) ) return ServiceType . NCML ; return null ; }", "nl": "Check path extension ; assumes no query or fragment"}}
{"translation": {"code": "static private ServiceType checkIfDap4 ( String location ) throws IOException { // Strip off any trailing DAP4 prefix if ( location . endsWith ( \".dap\" ) ) location = location . substring ( 0 , location . length ( ) - \".dap\" . length ( ) ) ; else if ( location . endsWith ( \".dmr\" ) ) location = location . substring ( 0 , location . length ( ) - \".dmr\" . length ( ) ) ; else if ( location . endsWith ( \".dmr.xml\" ) ) location = location . substring ( 0 , location . length ( ) - \".dmr.xml\" . length ( ) ) ; else if ( location . endsWith ( \".dsr\" ) ) location = location . substring ( 0 , location . length ( ) - \".dsr\" . length ( ) ) ; try ( HTTPMethod method = HTTPFactory . Get ( location + \".dmr.xml\" ) ) { int status = method . execute ( ) ; if ( status == 200 ) { Header h = method . getResponseHeader ( \"Content-Type\" ) ; if ( ( h != null ) && ( h . getValue ( ) != null ) ) { String v = h . getValue ( ) ; if ( v . startsWith ( \"application/vnd.opendap.org\" ) ) return ServiceType . DAP4 ; } } if ( status == HttpStatus . SC_UNAUTHORIZED || status == HttpStatus . SC_FORBIDDEN ) throw new IOException ( \"Unauthorized to open dataset \" + location ) ; // not dods return null ; } }", "nl": "check for dmr"}}
{"translation": {"code": "public long sendData2 ( Variable v , Section section , OutputStream out , NcStreamCompression compress ) throws IOException , InvalidRangeException { if ( show ) System . out . printf ( \" %s section=%s%n\" , v . getFullName ( ) , section ) ; boolean isVlen = v . isVariableLength ( ) ; //  && v.getRank() > 1;\r if ( isVlen ) v . read ( section ) ; NcStreamDataCol encoder = new NcStreamDataCol ( ) ; NcStreamProto . DataCol dataProto = encoder . encodeData2 ( v . getFullName ( ) , isVlen , section , v . read ( section ) ) ; // LOOK trap error, write error message ??\r // dataProto.writeDelimitedTo(out);\r long size = 0 ; size += writeBytes ( out , NcStream . MAGIC_DATA2 ) ; // data version 3\r byte [ ] datab = dataProto . toByteArray ( ) ; size += NcStream . writeVInt ( out , datab . length ) ; // dataProto len\r size += writeBytes ( out , datab ) ; // dataProto\r return size ; }", "nl": "LOOK compression not used"}}
{"translation": {"code": "static public URI parseToURI ( final String u ) throws URISyntaxException { StringBuilder buf = new StringBuilder ( ) ; int i = 0 ; while ( i < u . length ( ) ) { char c = u . charAt ( i ) ; if ( c == ' ' ) { if ( i + 1 == u . length ( ) ) throw new URISyntaxException ( u , \"Trailing '\\' at end of url\" ) ; buf . append ( \"%5c\" ) ; i ++ ; c = u . charAt ( i ) ; buf . append ( String . format ( \"%%%02x\" , ( int ) c ) ) ; } else buf . append ( c ) ; i ++ ; } return new URI ( buf . toString ( ) ) ; }", "nl": "Convert a uri string to an instance of java . net . URI . The critical thing is that this procedure can handle backslash escaped uris as well as %xx escaped uris ."}}
{"translation": {"code": "private Array decodeVlenData ( NcStreamProto . DataCol dproto , Section parentSection ) throws IOException { DataType dataType = NcStream . convertDataType ( dproto . getDataType ( ) ) ; ByteBuffer bb = dproto . getPrimdata ( ) . asReadOnlyByteBuffer ( ) ; ByteOrder bo = dproto . getBigend ( ) ? ByteOrder . BIG_ENDIAN : ByteOrder . LITTLE_ENDIAN ; bb . order ( bo ) ; Array alldata = Array . factory ( dataType , new int [ ] { dproto . getNelems ( ) } , bb ) ; // 1D array IndexIterator all = alldata . getIndexIterator ( ) ; int psize = ( int ) parentSection . computeSize ( ) ; Section section = NcStream . decodeSection ( dproto . getSection ( ) ) ; Section vsection = section . removeFirst ( parentSection ) ; int vsectionSize = ( int ) vsection . computeSize ( ) ; // the # of varlen Arrays at the inner structure // LOOK check for scalar // divide the primitive data into variable length arrays int countInner = 0 ; Array [ ] pdata = new Array [ psize ] ; for ( int pCount = 0 ; pCount < psize ; pCount ++ ) { Array [ ] vdata = new Array [ vsectionSize ] ; for ( int vCount = 0 ; vCount < vsectionSize ; vCount ++ ) { int vlen = dproto . getVlens ( countInner ++ ) ; Array primdata = Array . factory ( dataType , new int [ ] { vlen } ) ; IndexIterator prim = primdata . getIndexIterator ( ) ; for ( int i = 0 ; i < vlen ; i ++ ) { prim . setObjectNext ( all . getObjectNext ( ) ) ; // generic } vdata [ vCount ] = primdata ; } pdata [ pCount ] = Array . makeVlenArray ( vsection . getShape ( ) , vdata ) ; } // ArrayObject(parentShape) return Array . makeVlenArray ( parentSection . getShape ( ) , pdata ) ; }", "nl": "vlen inside a Structure"}}
{"translation": {"code": "static public String escapePathForURL ( String path ) { try { return new URI ( null , null , path , null ) . toString ( ) ; } catch ( URISyntaxException e ) { return path ; } }", "nl": "Escape the characters necessary for a path to be valid for a URL"}}
{"translation": {"code": "private void as ( final String symbol , final String name ) throws UnitExistsException , NoSuchUnitException , UnitParseException , SpecificationException , UnitDBException , PrefixDBException , OperationException , NameException , UnitSystemException { addSymbol ( symbol , name ) ; }", "nl": "Adds a symbol for a unit to the database ."}}
{"translation": {"code": "public static synchronized SI instance ( ) throws UnitSystemException { if ( si == null ) { try { si = new SI ( ) ; } catch ( final UnitException e ) { throw new UnitSystemException ( \"Couldn't initialize class SI\" , e ) ; } } return si ; }", "nl": "Returns an instance of the SI system of units ."}}
{"translation": {"code": "static public String nullify ( String s ) { if ( s != null && s . length ( ) == 0 ) s = null ; return s ; }", "nl": "Convert a zero - length string to null"}}
{"translation": {"code": "@ Deprecated static public void setGlobalCredentialsProvider ( AuthScope scope , CredentialsProvider provider ) throws HTTPException { setGlobalCredentialsProvider ( provider , scope ) ; }", "nl": "Deprecated but here for back compatibility"}}
{"translation": {"code": "public static String backslashDecode ( String s ) { StringBuilder buf = new StringBuilder ( s ) ; int i = 0 ; while ( i < buf . length ( ) ) { if ( buf . charAt ( i ) == ' ' ) { buf . deleteCharAt ( i ) ; } i ++ ; } return buf . toString ( ) ; }", "nl": "Define the DEFINITIVE URL BACKSLASH unescape function ."}}
{"translation": {"code": "@ Override public double getForecastTimeIntervalSizeInHours ( Grib2Pds pds ) { Grib2Pds . PdsInterval pdsIntv = ( Grib2Pds . PdsInterval ) pds ; // override here only if timeRangeUnit = 255 boolean needOverride = false ; for ( Grib2Pds . TimeInterval ti : pdsIntv . getTimeIntervals ( ) ) { needOverride = ( ti . timeRangeUnit == 255 ) ; } if ( ! needOverride ) return super . getForecastTimeIntervalSizeInHours ( pds ) ; return 12.0 ; }", "nl": "Only use in GribVariable to decide on variable identity when intvMerge = false . By returning a constant we dont intvMerge = false . Problem is we cant reconstruct interval length without reference time which is not in the pds ."}}
{"translation": {"code": "public static void setDebugFlags ( ucar . nc2 . util . DebugFlags debugFlag ) { debugRead = debugFlag . isSet ( \"Grib/showRead\" ) ; debugIndexOnly = debugFlag . isSet ( \"Grib/indexOnly\" ) ; debugIndexOnlyShow = debugFlag . isSet ( \"Grib/indexOnlyShow\" ) ; debugGbxIndexOnly = debugFlag . isSet ( \"Grib/debugGbxIndexOnly\" ) ; }", "nl": "we are running with only ncx index files no data"}}
{"translation": {"code": "private static final boolean checkFloat ( String s ) { try { //Coverity[FB.DLS_DEAD_LOCAL_STORE]= float val = Float . parseFloat ( s ) ; if ( DebugValueChecking ) { DAPNode . log . debug ( \"Attribute.checkFloat() - string: '\" + s + \"'   value: \" + val ) ; } return true ; } catch ( NumberFormatException e ) { if ( s . equalsIgnoreCase ( \"nan\" ) || s . equalsIgnoreCase ( \"inf\" ) ) return true ; return false ; } }", "nl": "Check if string is a valid Float32 ."}}
{"translation": {"code": "private static final boolean checkInt ( String s ) { try { //Coverity[FB.DLS_DEAD_LOCAL_STORE] int val = Integer . parseInt ( s ) ; if ( DebugValueChecking ) { DAPNode . log . debug ( \"Attribute.checkInt() - string: '\" + s + \"'   value: \" + val ) ; } return true ; } catch ( NumberFormatException e ) { return false ; } }", "nl": "Check if string is a valid Int32 ."}}
{"translation": {"code": "public void appendValue ( String value , boolean check ) throws NoSuchAttributeException , AttributeBadValueException { checkVectorUsage ( ) ; if ( check ) value = forceValue ( type , value ) ; ( ( Vector ) attr ) . addElement ( value ) ; }", "nl": "Append a value to this attribute ."}}
{"translation": {"code": "public int execute ( ) throws HTTPException { HttpResponse res = executeRaw ( ) ; if ( res != null ) return res . getStatusLine ( ) . getStatusCode ( ) ; else throw new HTTPException ( \"HTTPMethod.execute: null response\" ) ; }", "nl": "Create a request add headers and content then send to HTTPSession to do the bulk of the work ."}}
{"translation": {"code": "public long getDifference ( CalendarDate o , CalendarPeriod . Field fld ) { switch ( fld ) { case Millisec : return getDifferenceInMsecs ( o ) ; case Second : return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_SECOND ) ; case Minute : return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_MINUTE ) ; case Hour : return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_HOUR ) ; case Day : return ( long ) ( getDifferenceInMsecs ( o ) / MILLISECS_IN_DAY ) ; case Month : int tmonth = getFieldValue ( CalendarPeriod . Field . Month ) ; int omonth = o . getFieldValue ( CalendarPeriod . Field . Month ) ; int years = ( int ) this . getDifference ( o , CalendarPeriod . Field . Year ) ; return tmonth - omonth + 12 * years ; case Year : int tyear = getFieldValue ( CalendarPeriod . Field . Year ) ; int oyear = o . getFieldValue ( CalendarPeriod . Field . Year ) ; return tyear - oyear ; } return dateTime . getMillis ( ) - o . dateTime . getMillis ( ) ; }", "nl": "Get difference between two calendar dates in given Field units"}}
{"translation": {"code": "static protected String escapeString ( String s ) { StringBuilder buf = new StringBuilder ( ) ; for ( int i = 0 ; i < s . length ( ) ; i ++ ) { int c = s . charAt ( i ) ; switch ( c ) { case ' ' : buf . append ( \"\\\\\\\"\" ) ; break ; case ' ' : buf . append ( \"\\\\\\\\\" ) ; break ; case ' ' : buf . append ( ' ' ) ; break ; case ' ' : buf . append ( ' ' ) ; break ; case ' ' : buf . append ( ' ' ) ; break ; case ' ' : buf . append ( ' ' ) ; break ; default : if ( c < ' ' ) buf . append ( String . format ( \"\\\\x%02x\" , ( c & 0xff ) ) ) ; else buf . append ( ( char ) c ) ; break ; } } return buf . toString ( ) ; }", "nl": "Given a typical string insert backslashes before and \\\\ characters and control characters ."}}
{"translation": {"code": "protected Object readAtomicScalar ( VarNotes vi , TypeNotes ti ) throws DapException { DapVariable atomvar = ( DapVariable ) getTemplate ( ) ; // Get into memory Nc4prototypes nc4 = ( ( Nc4DSP ) this . dsp ) . getJNI ( ) ; int ret ; DapType basetype = ti . getType ( ) ; Object result = null ; if ( basetype . isFixedSize ( ) ) { long memsize = ( ( DapType ) ti . get ( ) ) . getSize ( ) ; Nc4Pointer mem = Nc4Pointer . allocate ( memsize ) ; readcheck ( nc4 , ret = nc4 . nc_get_var ( vi . gid , vi . id , mem . p ) ) ; setMemory ( mem ) ; result = getatomicdata ( ti . getType ( ) , 1 , mem . size , mem ) ; } else if ( basetype . isStringType ( ) ) { String [ ] s = new String [ 1 ] ; readcheck ( nc4 , ret = nc4 . nc_get_var_string ( vi . gid , vi . id , s ) ) ; result = s ; } else if ( basetype . isOpaqueType ( ) ) { Nc4Pointer mem = Nc4Pointer . allocate ( ti . getSize ( ) ) ; readcheck ( nc4 , ret = nc4 . nc_get_var ( vi . gid , vi . id , mem . p ) ) ; setMemory ( mem ) ; ByteBuffer [ ] buf = new ByteBuffer [ 1 ] ; buf [ 0 ] = mem . p . getByteBuffer ( 0 , ti . getSize ( ) ) ; result = buf ; } else throw new DapException ( \"Unexpected atomic type: \" + basetype ) ; return result ; }", "nl": "Read a top - level scalar atomic variable"}}
{"translation": {"code": "protected FrontPage getFrontPage ( DapRequest drq , DapContext cxt ) throws DapException { if ( this . defaultroots == null ) { // Figure out the directory containing // the files to display. String pageroot ; pageroot = getResourcePath ( drq , \"\" ) ; if ( pageroot == null ) throw new DapException ( \"Cannot locate resources directory\" ) ; this . defaultroots = new ArrayList <> ( ) ; this . defaultroots . add ( new Root ( \"testfiles\" , pageroot ) ) ; } return new FrontPage ( this . defaultroots , drq ) ; }", "nl": "Isolate front page builder so we can override if desired for testing ."}}
{"translation": {"code": "protected double getDouble ( dap4 . core . util . Index idx ) { assert data . getScheme ( ) == Scheme . ATOMIC ; try { Object value = data . read ( idx ) ; value = Convert . convert ( DapType . FLOAT64 , this . basetype , value ) ; return ( Double ) java . lang . reflect . Array . get ( value , 0 ) ; } catch ( IOException ioe ) { throw new IndexOutOfBoundsException ( ioe . getMessage ( ) ) ; } }", "nl": "Get the array element at a specific dap4 index as a double"}}
{"translation": {"code": "public DSPPrinter print ( ) throws DapException { DapDataset dmr = this . dsp . getDMR ( ) ; if ( this . ce == null ) this . ce = CEConstraint . getUniversal ( dmr ) ; this . printer . setIndent ( 0 ) ; List < DapVariable > topvars = dmr . getTopVariables ( ) ; for ( int i = 0 ; i < topvars . size ( ) ; i ++ ) { DapVariable top = topvars . get ( i ) ; List < Slice > slices = this . ce . getConstrainedSlices ( top ) ; if ( this . ce . references ( top ) ) { DataCursor data = dsp . getVariableData ( top ) ; printVariable ( data , slices ) ; } } printer . eol ( ) ; return this ; }", "nl": "Print data from a DSP - optionally constrained"}}
{"translation": {"code": "protected void writeRecord ( DataCursor record , SerialWriter dst ) throws IOException { DapVariable template = ( DapVariable ) record . getTemplate ( ) ; DapSequence seq = ( DapSequence ) template . getBaseType ( ) ; List < DapVariable > fields = seq . getFields ( ) ; for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { DapVariable field = fields . get ( i ) ; if ( ! this . ce . references ( field ) ) continue ; // not in the view DataCursor df = ( DataCursor ) record . readField ( i ) ; writeVariable ( df , dst ) ; } }", "nl": "Write out a single Record instance ."}}
{"translation": {"code": "@ Override public Object read ( List < Slice > slices ) throws DapException { switch ( this . scheme ) { case ATOMIC : return readAtomic ( slices ) ; case STRUCTURE : if ( ( ( DapVariable ) this . getTemplate ( ) ) . getRank ( ) > 0 || DapUtil . isScalarSlices ( slices ) ) throw new DapException ( \"Cannot slice a scalar variable\" ) ; CDMCursor [ ] instances = new CDMCursor [ 1 ] ; instances [ 0 ] = this ; return instances ; case SEQUENCE : if ( ( ( DapVariable ) this . getTemplate ( ) ) . getRank ( ) > 0 || DapUtil . isScalarSlices ( slices ) ) throw new DapException ( \"Cannot slice a scalar variable\" ) ; instances = new CDMCursor [ 1 ] ; instances [ 0 ] = this ; return instances ; case STRUCTARRAY : Odometer odom = Odometer . factory ( slices ) ; instances = new CDMCursor [ ( int ) odom . totalSize ( ) ] ; for ( int i = 0 ; odom . hasNext ( ) ; i ++ ) { instances [ i ] = readStructure ( odom . next ( ) ) ; } return instances ; case SEQARRAY : instances = readSequence ( slices ) ; return instances ; default : throw new DapException ( \"Attempt to slice a scalar object\" ) ; } }", "nl": "AbstractCursor Abstract Methods"}}
{"translation": {"code": "protected void writeSequence ( DataCursor data , SerialWriter dst ) throws IOException { DapVariable template = ( DapVariable ) data . getTemplate ( ) ; DapSequence ds = ( DapSequence ) template . getBaseType ( ) ; assert ( this . ce . references ( template ) ) ; List < Slice > slices = ce . getConstrainedSlices ( template ) ; Odometer odom = Odometer . factory ( slices ) ; if ( false ) while ( odom . hasNext ( ) ) { Index index = odom . next ( ) ; DataCursor [ ] instance = ( DataCursor [ ] ) data . read ( index ) ; writeSequence1 ( instance [ 0 ] , dst ) ; } else { DataCursor [ ] instances = ( DataCursor [ ] ) data . read ( slices ) ; for ( int i = 0 ; i < instances . length ; i ++ ) { writeSequence1 ( instances [ i ] , dst ) ; } } }", "nl": "Write out a single or array sequence instance"}}
{"translation": {"code": "protected void writeStructure1 ( DataCursor instance , SerialWriter dst ) throws IOException { assert instance . getScheme ( ) == DataCursor . Scheme . STRUCTURE ; DapVariable template = ( DapVariable ) instance . getTemplate ( ) ; assert ( this . ce . references ( template ) ) ; DapStructure ds = ( DapStructure ) template . getBaseType ( ) ; List < DapVariable > fields = ds . getFields ( ) ; for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { DapVariable field = fields . get ( i ) ; if ( ! this . ce . references ( field ) ) continue ; // not in the view DataCursor df = ( DataCursor ) instance . readField ( i ) ; writeVariable ( df , dst ) ; } }", "nl": "Write out a single structure instance"}}
{"translation": {"code": "DapGroup getGroupScope ( ) throws DapException { DapGroup gscope = ( DapGroup ) searchScope ( DapSort . GROUP , DapSort . DATASET ) ; if ( gscope == null ) throw new DapException ( \"Undefined Group Scope\" ) ; return gscope ; }", "nl": "Parser specific methods"}}
{"translation": {"code": "static public List < Slice > indexToSlices ( Index indices , DapVariable template ) throws dap4 . core . util . DapException { List < DapDimension > dims = template . getDimensions ( ) ; List < Slice > slices = indexToSlices ( indices , dims ) ; return slices ; }", "nl": "Provide a helper function to convert an Index object to a slice list ."}}
{"translation": {"code": "synchronized public void register ( Class < ? extends DSP > klass , boolean last ) { // is this already defined? if ( registered ( klass ) ) return ; if ( last ) registry . add ( new Registration ( klass ) ) ; else registry . add ( 0 , new Registration ( klass ) ) ; }", "nl": "Register a DSP class ."}}
{"translation": {"code": "public String assemble ( EnumSet < Parts > parts ) { StringBuilder uri = new StringBuilder ( ) ; // Note that format and base may be same, so case it out int useformat = ( parts . contains ( Parts . FORMAT ) ? 1 : 0 ) ; int usebase = ( parts . contains ( Parts . BASE ) ? 2 : 0 ) ; switch ( useformat + usebase ) { case 0 + 0 : // neither break ; case 1 + 0 : // FORMAT only uri . append ( this . formatprotocol + \":\" ) ; break ; case 2 + 0 : // BASE only uri . append ( this . baseprotocol + \":\" ) ; break ; case 2 + 1 : // both uri . append ( this . formatprotocol + \":\" ) ; if ( ! this . baseprotocol . equals ( this . formatprotocol ) ) uri . append ( this . formatprotocol + \":\" ) ; break ; } uri . append ( this . baseprotocol . equals ( \"file\" ) ? \"/\" : \"//\" ) ; if ( userinfo != null && parts . contains ( Parts . PWD ) ) uri . append ( this . userinfo + \":\" ) ; if ( this . host != null && parts . contains ( Parts . HOST ) ) uri . append ( this . host ) ; if ( this . path != null && parts . contains ( Parts . PATH ) ) uri . append ( this . path ) ; if ( this . query != null && parts . contains ( Parts . QUERY ) ) uri . append ( \"?\" + this . query ) ; if ( this . frag != null && parts . contains ( Parts . FRAG ) ) uri . append ( \"#\" + this . frag ) ; return uri . toString ( ) ; }", "nl": "Reassemble the url using the specified parts"}}
{"translation": {"code": "synchronized public void unregister ( Class < ? extends DSP > klass ) { for ( int i = 0 ; i < registry . size ( ) ; i ++ ) { if ( registry . get ( i ) . dspclass == klass ) { registry . remove ( i ) ; break ; } } }", "nl": "Unregister dsp ."}}
{"translation": {"code": "public DapDataset compile ( ) throws DapException { // create and fill the root group buildrootgroup ( this . ncid ) ; if ( this . dmr != null ) dmr . finish ( ) ; return this . dmr ; }", "nl": "Main entry point"}}
{"translation": {"code": "protected Object getObject ( dap4 . core . util . Index idx ) { assert data . getScheme ( ) == Scheme . ATOMIC ; try { Object value = data . read ( idx ) ; value = java . lang . reflect . Array . get ( value , 0 ) ; return value ; } catch ( IOException ioe ) { throw new IndexOutOfBoundsException ( ioe . getMessage ( ) ) ; } }", "nl": "Get the array element at a specific dap4 index as an Object"}}
{"translation": {"code": "static public List < String > backslashsplit ( String s , char sep ) { List < String > path = new ArrayList < String > ( ) ; int len = s . length ( ) ; StringBuilder piece = new StringBuilder ( ) ; int i = 0 ; for ( ; i <= len - 1 ; i ++ ) { char c = s . charAt ( i ) ; if ( c == ' ' && i < ( len - 1 ) ) { piece . append ( c ) ; // keep escapes in place piece . append ( s . charAt ( ++ i ) ) ; } else if ( c == sep ) { path . add ( piece . toString ( ) ) ; piece . setLength ( 0 ) ; } else piece . append ( c ) ; } path . add ( piece . toString ( ) ) ; return path ; }", "nl": "Split a string with respect to a separator character and taking backslashes into consideration ."}}
{"translation": {"code": "synchronized public void register ( String className , boolean last ) throws DapException { try { Class < ? extends DSP > klass = ( Class < ? extends DSP > ) loader . loadClass ( className ) ; register ( klass , last ) ; } catch ( ClassNotFoundException e ) { throw new DapException ( e ) ; } }", "nl": "Register a DSP using its class string name ."}}
{"translation": {"code": "static public boolean iospDeRegister ( Class iospClass ) { for ( int i = 0 ; i < registeredProviders . size ( ) ; i ++ ) { IOServiceProvider spi = registeredProviders . get ( i ) ; if ( spi . getClass ( ) == iospClass ) { registeredProviders . remove ( i ) ; return true ; } } return false ; }", "nl": "See if a specific IOServiceProvider is registered and if so remove it ."}}
{"translation": {"code": "static public void registerIOProviderPreferred ( Class iospClass , Class target ) throws IllegalAccessException , InstantiationException { iospDeRegister ( iospClass ) ; // forcibly de-register int pos = - 1 ; for ( int i = 0 ; i < registeredProviders . size ( ) ; i ++ ) { IOServiceProvider candidate = registeredProviders . get ( i ) ; if ( candidate . getClass ( ) == target ) { if ( pos < i ) pos = i ; break ; // this is where is must be placed } } if ( pos < 0 ) pos = 0 ; IOServiceProvider spi = ( IOServiceProvider ) iospClass . newInstance ( ) ; // fail fast registeredProviders . add ( pos , spi ) ; // insert before target }", "nl": "Register an IOServiceProvider . A new instance will be created when one of its files is opened . This differs from the above in that it specifically locates the target iosp and inserts the new one in front of it in order to override the target . If the iospclass is already registered remove it and reinsert . If the target class is not present then insert at front of the registry"}}
{"translation": {"code": "protected void buildseqtypes ( Variable cdmvar ) throws DapException { if ( CDMUtil . hasVLEN ( cdmvar ) ) { buildseqtype ( cdmvar ) ; } if ( cdmvar . getDataType ( ) == DataType . STRUCTURE || cdmvar . getDataType ( ) == DataType . SEQUENCE ) { Structure struct = ( Structure ) cdmvar ; List < Variable > fields = struct . getVariables ( ) ; for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { Variable field = fields . get ( i ) ; buildseqtypes ( field ) ; // recurse for inner vlen dims } } }", "nl": "Walk this variable including fields to construct sequence types for any contained vlen dimensions"}}
{"translation": {"code": "public void setValues ( List values ) { if ( values == null || values . size ( ) == 0 ) throw new IllegalArgumentException ( \"Cannot determine attribute's type\" ) ; int n = values . size ( ) ; Class c = values . get ( 0 ) . getClass ( ) ; Object pa ; if ( c == String . class ) { String [ ] va = new String [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( String ) values . get ( i ) ; } else if ( c == Integer . class ) { int [ ] va = new int [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Integer ) values . get ( i ) ; } else if ( c == Double . class ) { double [ ] va = new double [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Double ) values . get ( i ) ; } else if ( c == Float . class ) { float [ ] va = new float [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Float ) values . get ( i ) ; } else if ( c == Short . class ) { short [ ] va = new short [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Short ) values . get ( i ) ; } else if ( c == Byte . class ) { byte [ ] va = new byte [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Byte ) values . get ( i ) ; } else if ( c == Long . class ) { long [ ] va = new long [ n ] ; pa = va ; for ( int i = 0 ; i < n ; i ++ ) va [ i ] = ( Long ) values . get ( i ) ; } else { throw new IllegalArgumentException ( \"Unknown type for Attribute = \" + c . getName ( ) ) ; } setValues ( Array . factory ( this . dataType , new int [ ] { n } , pa ) ) ; }", "nl": "set the values from a list"}}
{"translation": {"code": "@ Override public int fieldIndex ( String name ) throws DapException { DapStructure ds ; if ( getTemplate ( ) . getSort ( ) . isCompound ( ) ) ds = ( DapStructure ) getTemplate ( ) ; else if ( getTemplate ( ) . getSort ( ) . isVar ( ) && ( ( ( DapVariable ) getTemplate ( ) ) . getBaseType ( ) . getSort ( ) . isCompound ( ) ) ) ds = ( DapStructure ) ( ( DapVariable ) getTemplate ( ) ) . getBaseType ( ) ; else throw new DapException ( \"Attempt to get field name on non-compound object\" ) ; int i = ds . indexByName ( name ) ; if ( i < 0 ) throw new DapException ( \"Unknown field name: \" + name ) ; return i ; }", "nl": "Selected DataCursor API overrides"}}
{"translation": {"code": "public void writeBytes ( byte [ ] bytes , int len ) throws IOException { outputBytes ( bytes , 0 , len ) ; if ( this . checksummode . enabled ( ChecksumMode . DAP ) ) { this . checksum . update ( bytes , 0 , len ) ; if ( DUMPCSUM ) { System . err . print ( \"SSS \" ) ; for ( int i = 0 ; i < len ; i ++ ) { System . err . printf ( \"%02x\" , bytes [ i ] ) ; } System . err . println ( ) ; } } }", "nl": "Write out a set of bytes"}}
{"translation": {"code": "static Notes factory ( NoteSort ns , int g , int id , Nc4DSP dsp ) { Notes note = null ; switch ( ns ) { case TYPE : note = new TypeNotes ( g , id , dsp ) ; break ; case VAR : note = new VarNotes ( g , id , dsp ) ; break ; case DIM : note = new DimNotes ( g , id , dsp ) ; break ; case GROUP : note = new GroupNotes ( g , id , dsp ) ; break ; } return note ; }", "nl": "Use a factory so we can debug constructor calls"}}
{"translation": {"code": "protected EnumTypedef findMatchingEnum ( EnumTypedef varenum ) throws DapException { List < EnumTypedef > candidates = new ArrayList <> ( ) ; for ( Map . Entry < DapNode , CDMNode > entry : this . nodemap . getCDMMap ( ) . entrySet ( ) ) { CDMNode cdmnode = entry . getValue ( ) ; if ( cdmnode . getSort ( ) != CDMSort . ENUMERATION ) continue ; // Compare the enumeration (note names will differ) EnumTypedef target = ( EnumTypedef ) cdmnode ; /* Ideally, we should test the types of the enums,\n               but, unfortunately, the var enum is always enum4.\n            if(target.getBaseType() != varenum.getBaseType())\n                continue;\n            */ Map < Integer , String > targetmap = target . getMap ( ) ; Map < Integer , String > varmap = varenum . getMap ( ) ; if ( targetmap . size ( ) != varmap . size ( ) ) continue ; boolean match = true ; // until otherwise shown for ( Map . Entry < Integer , String > tpair : targetmap . entrySet ( ) ) { String tname = tpair . getValue ( ) ; int value = ( int ) tpair . getKey ( ) ; boolean found = false ; for ( Map . Entry < Integer , String > vpair : varmap . entrySet ( ) ) { if ( tname . equals ( vpair . getValue ( ) ) && value == ( int ) vpair . getKey ( ) ) { found = true ; break ; } } if ( ! found ) { match = false ; break ; } } if ( ! match ) continue ; // Save it unless it is shadowed by a closer enum boolean shadowed = false ; for ( EnumTypedef etd : candidates ) { if ( shadows ( etd . getGroup ( ) , target . getGroup ( ) ) ) { shadowed = true ; break ; } } if ( ! shadowed ) candidates . add ( target ) ; } switch ( candidates . size ( ) ) { case 0 : throw new DapException ( \"CDMDSP: No matching enum type decl: \" + varenum . getShortName ( ) ) ; case 1 : break ; default : throw new DapException ( \"CDMDSP: Multiple matching enum type decls: \" + varenum . getShortName ( ) ) ; } return candidates . get ( 0 ) ; }", "nl": "Unfortunately the CDM Iosp does not actually use the declared enums . Rather for every enum type d variable a new enum decl is defined . So we need to find the original enum decl that matches the variable s enum ."}}
{"translation": {"code": "static public long getVarId ( VarNotes note ) { return getVarId ( note . gid , note . id , note . getFieldIndex ( ) ) ; }", "nl": "Manage the compound id for variables"}}
{"translation": {"code": "void passReserved ( XMLAttributeMap map , DapNode node ) throws ParseException { try { DapAttribute attr = null ; for ( Map . Entry < String , SaxEvent > entry : map . entrySet ( ) ) { SaxEvent event = entry . getValue ( ) ; String key = entry . getKey ( ) ; String value = event . value ; if ( isReserved ( key ) ) node . addXMLAttribute ( key , value ) ; } } catch ( DapException de ) { throw new ParseException ( de ) ; } }", "nl": "add any reserved xml attributes to a node unchanged"}}
{"translation": {"code": "public void initOnce ( HttpServletRequest req ) throws SendError { if ( once ) return ; once = true ; log . info ( getClass ( ) . getName ( ) + \" GET initialization\" ) ; if ( this . tdsContext == null ) throw new SendError ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR , \"Cannot find TDS Context\" ) ; // Get server host + port name StringBuilder buf = new StringBuilder ( ) ; buf . append ( req . getServerName ( ) ) ; int port = req . getServerPort ( ) ; if ( port > 0 ) { buf . append ( \":\" ) ; buf . append ( port ) ; } this . server = buf . toString ( ) ; // Obtain servlet path info String tmp = HTTPUtil . canonicalpath ( req . getContextPath ( ) ) ; this . threddsname = HTTPUtil . nullify ( HTTPUtil . relpath ( tmp ) ) ; tmp = HTTPUtil . canonicalpath ( req . getServletPath ( ) ) ; this . requestname = HTTPUtil . nullify ( HTTPUtil . relpath ( tmp ) ) ; if ( this . threddsname == null ) this . threddsname = DEFAULTSERVLETNAME ; // Get the upload dir File updir = tdsContext . getUploadDir ( ) ; if ( updir == null ) { log . warn ( \"No tds.upload.dir specified\" ) ; this . uploaddir = null ; } else this . uploaddir = HTTPUtil . canonicalpath ( updir . getAbsolutePath ( ) ) ; // Get the download dir File downdir = tdsContext . getDownloadDir ( ) ; if ( downdir == null ) { log . warn ( \"No tds.download.dir specified\" ) ; this . downloaddir = null ; } else this . downloaddir = HTTPUtil . canonicalpath ( downdir . getAbsolutePath ( ) ) ; }", "nl": "Invoked on first get so that everything is available especially Spring stuff ."}}
{"translation": {"code": "protected String pull ( Node n , String name ) { NamedNodeMap map = n . getAttributes ( ) ; Node attr = map . getNamedItem ( name ) ; if ( attr == null ) return null ; return attr . getNodeValue ( ) ; }", "nl": "XML Attribute utilities"}}
{"translation": {"code": "protected void passReserved ( Node node , DapNode dap ) throws ParseException { try { NamedNodeMap attrs = node . getAttributes ( ) ; for ( int i = 0 ; i < attrs . getLength ( ) ; i ++ ) { Node n = attrs . item ( i ) ; String key = n . getNodeName ( ) ; String value = n . getNodeValue ( ) ; if ( isReserved ( key ) ) dap . addXMLAttribute ( key , value ) ; } } catch ( DapException de ) { throw new ParseException ( de ) ; } }", "nl": "Pass reserved xml attributes unchanged"}}
{"translation": {"code": "public static String scanGeomToSweepAngleAxis ( String scanGeometry ) { String sweepAngleAxis = \"y\" ; if ( scanGeometry . equals ( GOES ) ) { sweepAngleAxis = \"x\" ; } return sweepAngleAxis ; }", "nl": "Find sweep_angle_axis associated with a scan geometry"}}
{"translation": {"code": "private WFSExceptionWriter getFeature ( PrintWriter out , HttpServletRequest hsreq , SimpleGeometryCSBuilder sgcs , String ftName , String fullFtName ) { List < SimpleGeometry > geometryList = new ArrayList < SimpleGeometry > ( ) ; GeometryType geoT = sgcs . getGeometryType ( ftName ) ; if ( geoT == null ) { return new WFSExceptionWriter ( \"Feature Type of \" + fullFtName + \" not found.\" , \"GetFeature\" , \"OperationProcessingFailed\" ) ; } try { switch ( geoT ) { case POINT : Point pt = sgcs . getPoint ( ftName , 0 ) ; int j = 0 ; while ( pt != null ) { geometryList . add ( pt ) ; j ++ ; pt = sgcs . getPoint ( ftName , j ) ; } break ; case LINE : Line line = sgcs . getLine ( ftName , 0 ) ; int k = 0 ; while ( line != null ) { geometryList . add ( line ) ; k ++ ; line = sgcs . getLine ( ftName , k ) ; } break ; case POLYGON : Polygon poly = sgcs . getPolygon ( ftName , 0 ) ; int i = 0 ; while ( poly != null ) { geometryList . add ( poly ) ; i ++ ; poly = sgcs . getPolygon ( ftName , i ) ; } break ; } } // Perhaps will change this to be implemented in the CFPolygon class\r catch ( ArrayIndexOutOfBoundsException aout ) { } WFSGetFeatureWriter gfdw = new WFSGetFeatureWriter ( out , WFSController . constructServerPath ( hsreq ) , WFSController . getXMLNamespaceXMLNSValue ( hsreq ) , geometryList , ftName ) ; gfdw . startXML ( ) ; gfdw . writeMembers ( ) ; gfdw . finishXML ( ) ; return null ; }", "nl": "Processes GetFeature requests ."}}
{"translation": {"code": "@ RequestMapping ( \"**\" ) public void httpHandler ( HttpServletRequest hsreq , HttpServletResponse hsres ) { try { PrintWriter wr = hsres . getWriter ( ) ; List < String > paramNames = new LinkedList < String > ( ) ; Enumeration < String > paramNamesE = hsreq . getParameterNames ( ) ; while ( paramNamesE . hasMoreElements ( ) ) paramNames . add ( paramNamesE . nextElement ( ) ) ; // Prepare parameters\r String request = null ; String version = null ; String service = null ; String typeNames = null ; String datasetReqPath = null ; String actualPath = null ; String actualFTName = null ; NetcdfDataset dataset = null ; if ( hsreq . getServletPath ( ) . length ( ) > 4 ) { datasetReqPath = hsreq . getServletPath ( ) . substring ( 4 , hsreq . getServletPath ( ) . length ( ) ) ; } actualPath = TdsRequestedDataset . getLocationFromRequestPath ( datasetReqPath ) ; if ( actualPath != null ) dataset = NetcdfDataset . openDataset ( actualPath ) ; else return ; List < CoordinateSystem > csList = dataset . getCoordinateSystems ( ) ; SimpleGeometryCSBuilder cs = new SimpleGeometryCSBuilder ( dataset , csList . get ( 0 ) , null ) ; /* Look for parameter names to assign values\r\n\t\t\t * in order to avoid casing issues with parameter names (such as a mismatch between reQUEST and request and REQUEST).\r\n\t\t\t */ for ( String paramName : paramNames ) { if ( paramName . equalsIgnoreCase ( \"REQUEST\" ) ) { request = hsreq . getParameter ( paramName ) ; } if ( paramName . equalsIgnoreCase ( \"VERSION\" ) ) { version = hsreq . getParameter ( paramName ) ; } if ( paramName . equalsIgnoreCase ( \"SERVICE\" ) ) { service = hsreq . getParameter ( paramName ) ; } if ( paramName . equalsIgnoreCase ( \"TYPENAMES\" ) || paramName . equalsIgnoreCase ( \"TYPENAME\" ) ) { typeNames = hsreq . getParameter ( paramName ) ; // Remove namespace header for getFeature\r if ( typeNames != null ) if ( typeNames . length ( ) > TDSNAMESPACE . length ( ) ) { actualFTName = typeNames . substring ( TDSNAMESPACE . length ( ) + 1 , typeNames . length ( ) ) ; } } } WFSExceptionWriter paramError = checkParametersForError ( request , version , service , typeNames ) ; WFSExceptionWriter requestProcessingError = null ; // If parameter checks all pass launch the request\r if ( paramError == null ) { WFSRequestType reqToProc = WFSRequestType . getWFSRequestType ( request ) ; switch ( reqToProc ) { case GetCapabilities : getCapabilities ( wr , hsreq , cs ) ; break ; case DescribeFeatureType : describeFeatureType ( wr , hsreq , actualFTName ) ; break ; case GetFeature : requestProcessingError = getFeature ( wr , hsreq , cs , actualFTName , typeNames ) ; break ; } } // Parameter checks did not all pass, print the error and return\r else { paramError . write ( hsres ) ; return ; } /* Specifically writes out exceptions that were incurred\r\n\t\t\t * while processing requests.\r\n\t\t\t */ if ( requestProcessingError != null ) { requestProcessingError . write ( hsres ) ; return ; } } catch ( IOException io ) { throw new RuntimeException ( \"The writer may not have been able to been have retrieved\" + \" or the requested dataset was not found\" , io ) ; } }", "nl": "A handler for WFS based HTTP requests that sends to other request handlers to handle the request ."}}
{"translation": {"code": "public void writeOperations ( ) { fileOutput += \"<ows:OperationsMetadata> \" ; for ( WFSRequestType rt : operationList ) { writeAOperation ( rt ) ; } // Write parameters\r fileOutput += \"<ows:Parameter name=\\\"AcceptVersions\\\"> \" + \"<ows:AllowedValues> \" + \"<ows:Value>2.0.0</ows:Value>\" + \"</ows:AllowedValues>\" + \"</ows:Parameter>\" ; fileOutput += \"<ows:Parameter name=\\\"AcceptFormats\\\">\" + \"<ows:AllowedValues> \" + \"<ows:Value>text/xml</ows:Value>\" + \"</ows:AllowedValues>\" + \"</ows:Parameter>\" ; fileOutput += \"<ows:Parameter name=\\\"Sections\\\"> \" + \"<ows:AllowedValues> \" + \"<ows:Value>ServiceIdentification</ows:Value> \" + \"<ows:Value>ServiceProvider</ows:Value> \" + \"<ows:Value>OperationsMetadata</ows:Value> \" + \"<ows:Value>FeatureTypeList</ows:Value> \" + \"</ows:AllowedValues>\" + \"</ows:Parameter>\" ; fileOutput += \"<ows:Parameter name=\\\"version\\\"> \" + \"<ows:AllowedValues> \" + \"<ows:Value>2.0.0</ows:Value>\" + \"</ows:AllowedValues>\" + \"</ows:Parameter>\" ; // Write constraints\r writeAConstraint ( \"ImplementsBasicWFS\" , true ) ; writeAConstraint ( \"ImplementsTransactionalWFS\" , false ) ; writeAConstraint ( \"ImplementsLockingWFS\" , false ) ; writeAConstraint ( \"KVPEncoding\" , false ) ; writeAConstraint ( \"XMLEncoding\" , true ) ; writeAConstraint ( \"SOAPEncoding\" , false ) ; writeAConstraint ( \"ImplementsInheritance\" , false ) ; writeAConstraint ( \"ImplementsRemoteResolve\" , false ) ; writeAConstraint ( \"ImplementsResultPaging\" , false ) ; writeAConstraint ( \"ImplementsStandardJoins\" , false ) ; writeAConstraint ( \"ImplementsSpatialJoins\" , false ) ; writeAConstraint ( \"ImplementsTemporalJoins\" , false ) ; writeAConstraint ( \"ImplementsFeatureVersioning\" , false ) ; writeAConstraint ( \"ManageStoredQueries\" , false ) ; writeAConstraint ( \"PagingIsTransactionSafe\" , false ) ; writeAConstraint ( \"QueryExpressions\" , false ) ; fileOutput += \"</ows:OperationsMetadata>\" ; }", "nl": "Takes all added operations and writes an operations metadata section ."}}
{"translation": {"code": "public int getBeginning ( int index ) { //Test if the last end is the new beginning\r if ( index == ( pastIndex + 1 ) ) { return previousEnd + 1 ; } // Otherwise, find it!\r int newBeginning = 0 ; for ( int i = 0 ; i < index ; i ++ ) { newBeginning += getNodeCount ( i ) ; } pastIndex = index ; previousBegin = newBeginning ; return newBeginning ; }", "nl": "Gets the beginning index of a geometry s points given the index of the geometry within the array ."}}
{"translation": {"code": "public static String getSubsetString ( Variable var , int beginInd , int endInd , int id ) { if ( var == null ) return null ; String subStr = \"\" ; List < Dimension > dimList = var . getDimensions ( ) ; // Enforce two dimension arrays\r if ( dimList . size ( ) > 2 || dimList . size ( ) < 1 ) { return null ; } for ( int i = 0 ; i < dimList . size ( ) ; i ++ ) { Dimension dim = dimList . get ( i ) ; if ( dim == null ) continue ; // If not CF Time then select only that ID\r if ( ! CF . TIME . equalsIgnoreCase ( dim . getShortName ( ) ) && ! CF . TIME . equalsIgnoreCase ( dim . getFullNameEscaped ( ) ) ) { subStr += id ; } // Otherwise subset based on time\r else { if ( beginInd < 0 || endInd < 0 ) subStr += \":\" ; else subStr += ( beginInd + \":\" + endInd ) ; } if ( i < dimList . size ( ) - 1 ) { subStr += \",\" ; } } return subStr ; }", "nl": "Gets the subset string to be used in NetCDFFile . read given a variable and some indicies . useful for subsetting timeseries"}}
{"translation": {"code": "void finishInit ( ) { // some widgets from the GridUI\r np = ui . panz ; vertPanel = ui . vertPanel ; dataValueLabel = ui . dataValueLabel ; posLabel = ui . positionLabel ; // get last saved Projection\r project = ( ProjectionImpl ) store . getBean ( LastProjectionName , null ) ; if ( project != null ) setProjection ( project ) ; // get last saved MapArea\r ProjectionRect ma = ( ProjectionRect ) store . getBean ( LastMapAreaName , null ) ; if ( ma != null ) np . setMapArea ( ma ) ; makeEventManagement ( ) ; // last thing\r /* get last dataset filename and reopen it\r\n    String filename = (String) store.get(LastDatasetName);\r\n    if (filename != null)\r\n      setDataset(filename); */ }", "nl": "stuff to do after UI is complete"}}
{"translation": {"code": "public void setPrev ( Polygon prev ) { if ( prev instanceof CFPolygon ) { setPrev ( ( CFPolygon ) prev ) ; } else this . prev = prev ; }", "nl": "Sets the previous polygon which makes up the multipolygon which this polygon is a part of . If prev is a CFPolygon automatically connect the other polygon to this polygon as well ."}}
{"translation": {"code": "private void writeAConstraint ( String name , boolean isImplemented ) { String defValue ; if ( isImplemented ) defValue = \"TRUE\" ; else defValue = \"FALSE\" ; fileOutput += \"<ows:Constraint name=\\\"\" + name + \"\\\"> \" + \"<ows:NoValues/> \" + \"<ows:DefaultValue>\" + defValue + \"</ows:DefaultValue> \" + \"</ows:Constraint>\" ; }", "nl": "Writes a constraint OWS element out ."}}
{"translation": {"code": "public void addPoint ( double x , double y ) { Point ptPrev = null ; if ( points . size ( ) > 0 ) { ptPrev = points . get ( points . size ( ) - 1 ) ; } this . points . add ( new CFPoint ( x , y , ptPrev , null , null ) ) ; }", "nl": "Add a point to the end of the line ."}}
{"translation": {"code": "private String writePolygon ( Polygon poly ) { String xml = \"\" ; xml += \"<gml:Polygon>\" ; Polygon polygon = poly ; //    while (polygon != null) {\r if ( ! polygon . getInteriorRing ( ) ) { xml += \"<gml:exterior><gml:LinearRing><gml:posList>\" ; for ( Point point : polygon . getPoints ( ) ) { xml += point . getX ( ) + \" \" + point . getY ( ) + \" \" ; } xml += \"</gml:posList></gml:LinearRing></gml:exterior>\" ; } else { xml += \"<gml:interior><gml:LinearRing><gml:posList>\" ; for ( Point point : polygon . getPoints ( ) ) { xml += point . getX ( ) + \" \" + point . getY ( ) + \" \" ; } xml += \"</gml:posList></gml:LinearRing></gml:interior>\" ; } //      polygon = polygon.getNext();\r // }\r xml += \"</gml:Polygon>\" ; return xml ; }", "nl": "Takes in a polygon checks whether it is an interior or exterior ring and writes the corresponding xml . Iterates through all linked polygons"}}
{"translation": {"code": "public double [ ] getBBLower ( ) { double [ ] bbLower = new double [ 2 ] ; List < Point > ptList = this . getPoints ( ) ; if ( ptList . isEmpty ( ) ) return null ; bbLower [ 0 ] = ptList . get ( 0 ) . getY ( ) ; bbLower [ 1 ] = ptList . get ( 0 ) . getY ( ) ; for ( Point pt : this . getPoints ( ) ) { if ( bbLower [ 0 ] > pt . getX ( ) ) { bbLower [ 0 ] = pt . getX ( ) ; } if ( bbLower [ 1 ] > pt . getY ( ) ) { bbLower [ 1 ] = pt . getY ( ) ; } } // Got minimum points, add some padding.\r bbLower [ 0 ] -= 10 ; bbLower [ 1 ] -= 10 ; return bbLower ; }", "nl": "Gets the lower bounding box coordinate on the line ."}}
{"translation": {"code": "public void writeMembers ( ) { int index = 1 ; GMLFeatureWriter writer = new GMLFeatureWriter ( ) ; for ( SimpleGeometry geometryItem : geometries ) { // Find bounding box information\r double [ ] lowerCorner = geometryItem . getBBLower ( ) ; double [ ] upperCorner = geometryItem . getBBUpper ( ) ; fileOutput += \"<wfs:member>\" // Write Geometry Information\r + \"<\" + WFSController . TDSNAMESPACE + \":\" + ftName + \" gml:id=\\\"\" + ftName + \".\" + index + \"\\\">\" // GML Bounding Box\r + \"<gml:boundedBy>\" + \"<gml:Envelope srsName=\" + \"\\\"urn:ogc:def:crs:EPSG::4326\\\"\" + \">\" + \"<gml:lowerCorner>\" + lowerCorner [ 0 ] + \" \" + lowerCorner [ 1 ] + \"</gml:lowerCorner>\" + \"<gml:upperCorner>\" + upperCorner [ 0 ] + \" \" + upperCorner [ 1 ] + \"</gml:upperCorner>\" + \"</gml:Envelope>\" + \"</gml:boundedBy>\" + \"<\" + WFSController . TDSNAMESPACE + \":geometryInformation>\" ; //write GML features\r fileOutput += writer . writeFeature ( geometryItem ) ; // Cap off headers\r fileOutput += \"</\" + WFSController . TDSNAMESPACE + \":geometryInformation>\" + \"</\" + WFSController . TDSNAMESPACE + \":\" + ftName + \">\" + \"</wfs:member>\" ; index ++ ; } }", "nl": "In the WFS specification for GetFeature each feature type is its own member and so writeMembers add each member to the fileOutput"}}
{"translation": {"code": "public int getEnd ( int index ) { // Test if the last beginning is the new end\r if ( index == ( pastIndex - 1 ) ) { return previousBegin - 1 ; } // Otherwise find it!\r int new_end = 0 ; for ( int i = 0 ; i < index + 1 ; i ++ ) { new_end += getNodeCount ( i ) ; } pastIndex = index ; previousEnd = new_end ; return new_end - 1 ; }", "nl": "Gets the ending index of a geometry s points given the index of the geometry within the array ."}}
{"translation": {"code": "public void setNetcdfFile ( NetcdfFile ncf ) { this . ncfile = ncf ; this . filename = ncf . getLocation ( ) ; final GetDataRunnable runner = new GetDataRunnable ( ) { public void run ( Object o ) throws IOException { final StringWriter sw = new StringWriter ( 50000 ) ; NCdumpW . print ( ncfile , command , sw , task ) ; result = sw . toString ( ) ; } } ; task = new GetDataTask ( runner , filename , null ) ; stopButton . startProgressMonitorTask ( task ) ; }", "nl": "allow calling from outside"}}