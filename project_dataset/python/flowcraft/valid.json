{"translation": {"code": "def main ( sample_id , assembly , min_size ) : logger . info ( \"Starting script\" ) f_open = open ( assembly , \"rU\" ) entry = ( x [ 1 ] for x in groupby ( f_open , lambda line : line [ 0 ] == \">\" ) ) success = 0 for header in entry : headerStr = header . __next__ ( ) [ 1 : ] . strip ( ) seq = \"\" . join ( s . strip ( ) for s in entry . __next__ ( ) ) if len ( seq ) >= min_size : with open ( sample_id + '_' + headerStr . replace ( \" \" , \"_\" ) . replace ( \"=\" , \"_\" ) + '.fasta' , \"w\" ) as output_file : output_file . write ( \">\" + sample_id + \"_\" + headerStr . replace ( \" \" , \"_\" ) . replace ( \"=\" , \"_\" ) + \"\\\\n\" + seq + \"\\\\n\" ) success += 1 f_open . close ( ) logger . info ( \"{} sequences sucessfully splitted.\" . format ( success ) )", "nl": "Main executor of the split_fasta template ."}}
{"translation": {"code": "def fix_contig_names ( asseembly_path ) : fixed_assembly = \"fixed_assembly.fa\" with open ( asseembly_path ) as in_hf , open ( fixed_assembly , \"w\" ) as ou_fh : for line in in_hf : if line . startswith ( \">\" ) : fixed_line = line . replace ( \" \" , \"_\" ) ou_fh . write ( fixed_line ) else : ou_fh . write ( line ) return fixed_assembly", "nl": "Removes whitespace from the assembly contig names"}}
{"translation": {"code": "def _close_connection ( self , report_id ) : logger . debug ( \"Closing connection and sending DELETE request to {}\" . format ( self . broadcast_address ) ) try : r = requests . delete ( self . broadcast_address , json = { \"run_id\" : report_id } ) if r . status_code != 202 : logger . error ( colored_print ( \"ERROR: There was a problem sending data to the server\" \"with reason: {}\" . format ( r . reason ) ) ) except requests . exceptions . ConnectionError : logger . error ( colored_print ( \"ERROR: Could not establish connection with server. The server\" \" may be down or there is a problem with your internet \" \"connection.\" , \"red_bold\" ) ) sys . exit ( 1 )", "nl": "Sends a delete request for the report JSON hash"}}
{"translation": {"code": "def parse_log ( self , bowtie_log ) : print ( \"is here!\" ) # Regexes - thanks to https://github.com/ewels/MultiQC/blob/master/multiqc/modules/bowtie2/bowtie2.py regexes = { 'unpaired' : { 'unpaired_aligned_none' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned 0 times\" , 'unpaired_aligned_one' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned exactly 1 time\" , 'unpaired_aligned_multi' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned >1 times\" } , 'paired' : { 'paired_aligned_none' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned concordantly 0 times\" , 'paired_aligned_one' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned concordantly exactly 1 time\" , 'paired_aligned_multi' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned concordantly >1 times\" , 'paired_aligned_discord_one' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned discordantly 1 time\" , 'paired_aligned_discord_multi' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned discordantly >1 times\" , 'paired_aligned_mate_one' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned exactly 1 time\" , 'paired_aligned_mate_multi' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned >1 times\" , 'paired_aligned_mate_none' : r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) aligned 0 times\" } } #Missing parser for unpaired (not implemented in flowcraft yet) with open ( bowtie_log , \"r\" ) as f : #Go through log file line by line for l in f : print ( l ) #total reads total = re . search ( r\"(\\\\d+) reads; of these:\" , l ) print ( total ) if total : print ( total ) self . set_n_reads ( total . group ( 1 ) ) # Paired end reads aka the pain paired = re . search ( r\"(\\\\d+) \\\\([\\\\d\\\\.]+%\\\\) were paired; of these:\" , l ) if paired : paired_total = int ( paired . group ( 1 ) ) paired_numbers = { } # Do nested loop whilst we have this level of indentation l = f . readline ( ) while l . startswith ( '    ' ) : for k , r in regexes [ 'paired' ] . items ( ) : match = re . search ( r , l ) if match : paired_numbers [ k ] = int ( match . group ( 1 ) ) l = f . readline ( ) align_zero_times = paired_numbers [ 'paired_aligned_none' ] + paired_numbers [ 'paired_aligned_mate_none' ] if align_zero_times : self . set_align_0x ( align_zero_times ) align_one_time = paired_numbers [ 'paired_aligned_one' ] + paired_numbers [ 'paired_aligned_mate_one' ] if align_one_time : self . set_align_1x ( align_one_time ) align_more_than_one_time = paired_numbers [ 'paired_aligned_multi' ] + paired_numbers [ 'paired_aligned_mate_multi' ] if align_more_than_one_time : self . set_align_mt1x ( align_more_than_one_time ) # Overall alignment rate overall = re . search ( r\"([\\\\d\\\\.]+)% overall alignment rate\" , l ) if overall : self . overall_rate = float ( overall . group ( 1 ) )", "nl": "Parse a bowtie log file ."}}
{"translation": {"code": "def write_assembly ( self , output_file , filtered = True ) : logger . debug ( \"Writing the filtered assembly into: {}\" . format ( output_file ) ) with open ( output_file , \"w\" ) as fh : for contig_id , contig in self . contigs . items ( ) : if contig_id not in self . filtered_ids and filtered : fh . write ( \">{}_{}\\\\n{}\\\\n\" . format ( self . sample , contig [ \"header\" ] , contig [ \"sequence\" ] ) )", "nl": "Writes the assembly to a new file ."}}
{"translation": {"code": "def _parse_coverage ( header_str ) : cov = None for i in header_str . split ( \"_\" ) [ : : - 1 ] : try : cov = float ( i ) break except ValueError : continue return cov", "nl": "Attempts to retrieve the coverage value from the header string ."}}
{"translation": {"code": "def get_assembly_length ( self ) : return sum ( [ vals [ \"length\" ] for contig_id , vals in self . contigs . items ( ) if contig_id not in self . filtered_ids ] )", "nl": "Returns the length of the assembly without the filtered contigs ."}}
{"translation": {"code": "def update_log_watch ( self ) : # Check the size stamp of the tracefile. Only proceed with the parsing # if it changed from the previous size. size_stamp = os . path . getsize ( self . log_file ) self . trace_retry = 0 if size_stamp and size_stamp == self . log_sizestamp : return else : logger . debug ( \"Updating log size stamp to: {}\" . format ( size_stamp ) ) self . log_sizestamp = size_stamp self . _update_pipeline_status ( )", "nl": "Parses nextflow log file and updates the run status"}}
{"translation": {"code": "def _get_component_str ( component , params = None , directives = None ) : final_directives = { } if directives : final_directives = directives if params : final_directives [ \"params\" ] = params if final_directives : return \"{}={}\" . format ( component , json . dumps ( final_directives , separators = ( \",\" , \":\" ) ) ) else : return component", "nl": "Generates a component string based on the provided parameters and directives"}}
{"translation": {"code": "def clean_up ( fastq ) : for fq in fastq : # Get real path of fastq files, following symlinks rp = os . path . realpath ( fq ) logger . debug ( \"Removing temporary fastq file path: {}\" . format ( rp ) ) if re . match ( \".*/work/.{2}/.{30}/.*\" , rp ) : os . remove ( rp )", "nl": "Cleans the temporary fastq files . If they are symlinks the link source is removed"}}
{"translation": {"code": "def collect_process_map ( ) : process_map = { } prefix = \"{}.\" . format ( components . __name__ ) for importer , modname , _ in pkgutil . iter_modules ( components . __path__ , prefix ) : _module = importer . find_module ( modname ) . load_module ( modname ) _component_classes = [ cls for cls in _module . __dict__ . values ( ) if isinstance ( cls , type ) and cls . __name__ != \"Process\" ] for cls in _component_classes : process_map [ convert_camel_case ( cls . __name__ ) ] = cls return process_map", "nl": "Collects Process classes and return dict mapping templates to classes"}}
{"translation": {"code": "def convert_camel_case ( name ) : s1 = re . sub ( '(.)([A-Z][a-z]+)' , r'\\1_\\2' , name ) return re . sub ( '([a-z0-9])([A-Z])' , r'\\1_\\2' , s1 ) . lower ( )", "nl": "Convers a CamelCase string into a snake_case one"}}
{"translation": {"code": "def get_nextflow_filepath ( log_file ) : with open ( log_file ) as fh : # Searches for the first occurence of the nextflow pipeline # file name in the .nextflow.log file while 1 : line = fh . readline ( ) if not line : # file is empty raise eh . LogError ( \"Nextflow command path could not be found - Is \" \".nextflow.log empty?\" ) try : # Regex supports absolute paths and relative paths pipeline_path = re . match ( \".*\\s(.*.nf).*\" , line ) . group ( 1 ) return pipeline_path except AttributeError : continue", "nl": "Gets the nextflow file path from the nextflow log file . It searches for the nextflow run command throughout the file ."}}
{"translation": {"code": "def _get_manifest_string ( self ) : config_str = \"\" config_str += '\\n\\tname = \"{}\"' . format ( self . pipeline_name ) config_str += '\\n\\tmainScript = \"{}\"' . format ( self . nf_file ) return config_str", "nl": "Returns the nextflow manifest config string to include in the config file from the information on the pipeline ."}}