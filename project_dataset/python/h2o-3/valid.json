{"translation": {"code": "def find_magic_in_file ( filename ) : with open ( filename , \"rt\" , encoding = \"utf-8\" ) as f : for line in f : if line . startswith ( \"#\" ) : comment = line [ 1 : ] . strip ( ) if comment . startswith ( \"~~~~* \" ) or comment . startswith ( \"----* \" ) or comment . startswith ( \"====* \" ) : spell = comment [ 5 : ] . strip ( ) return tuple ( spell . split ( ) ) else : break return None", "nl": "Search the file for any magic incantations ."}}
{"translation": {"code": "def parse_text ( text ) : assert isinstance ( text , _str_type ) , \"`text` parameter should be a string, got %r\" % type ( text ) gen = iter ( text . splitlines ( True ) ) # True = keep newlines readline = gen . next if hasattr ( gen , \"next\" ) else gen . __next__ return Code ( _tokenize ( readline ) )", "nl": "Parse code from a string of text ."}}
{"translation": {"code": "def locate_files ( root_dir ) : all_files = [ ] root_dir = os . path . abspath ( root_dir ) for dir_name , subdirs , files in os . walk ( root_dir ) : for f in files : if f . endswith ( \".py\" ) : all_files . append ( os . path . join ( dir_name , f ) ) return all_files", "nl": "Find all python files in the given directory and all subfolders ."}}
{"translation": {"code": "def get_params ( self , deep = True ) : out = dict ( ) for key , value in self . parms . items ( ) : if deep and isinstance ( value , H2OEstimator ) : deep_items = list ( value . get_params ( ) . items ( ) ) out . update ( ( key + \"__\" + k , val ) for k , val in deep_items ) out [ key ] = value return out", "nl": "Obtain parameters for this estimator ."}}
{"translation": {"code": "def fit ( self , X , y = None , * * params ) : stk = inspect . stack ( ) [ 1 : ] warn = True for s in stk : mod = inspect . getmodule ( s [ 0 ] ) if mod : warn = \"sklearn\" not in mod . __name__ if not warn : break if warn : warnings . warn ( \"\\n\\n\\t`fit` is not recommended outside of the sklearn framework. Use `train` instead.\" , UserWarning , stacklevel = 2 ) training_frame = X . cbind ( y ) if y is not None else X x = X . names y = y . names [ 0 ] if y is not None else None self . train ( x , y , training_frame , * * params ) return self", "nl": "Fit an H2O model as part of a scikit - learn pipeline or grid search ."}}
{"translation": {"code": "def download_mojo ( self , path = \".\" , get_genmodel_jar = False , genmodel_name = \"\" ) : assert_is_type ( path , str ) assert_is_type ( get_genmodel_jar , bool ) if not self . have_mojo : raise H2OValueError ( \"Export to MOJO not supported\" ) if get_genmodel_jar : if genmodel_name == \"\" : h2o . api ( \"GET /3/h2o-genmodel.jar\" , save_to = os . path . join ( path , \"h2o-genmodel.jar\" ) ) else : h2o . api ( \"GET /3/h2o-genmodel.jar\" , save_to = os . path . join ( path , genmodel_name ) ) return h2o . api ( \"GET /3/Models/%s/mojo\" % self . model_id , save_to = path )", "nl": "Download the model in MOJO format ."}}
{"translation": {"code": "def normalize_enum_constant ( s ) : if s . islower ( ) : return s if s . isupper ( ) : return s . lower ( ) return \"\" . join ( ch if ch . islower ( ) else \"_\" + ch . lower ( ) for ch in s ) . strip ( \"_\" )", "nl": "Return enum constant s converted to a canonical snake - case ."}}
{"translation": {"code": "def columns_by_type ( self , coltype = \"numeric\" ) : assert_is_type ( coltype , \"numeric\" , \"categorical\" , \"string\" , \"time\" , \"uuid\" , \"bad\" ) assert_is_type ( self , H2OFrame ) return ExprNode ( \"columnsByType\" , self , coltype ) . _eager_scalar ( )", "nl": "Extract columns of the specified type from the frame ."}}
{"translation": {"code": "def extractRunInto ( javaLogText ) : global g_initialXY global g_reguarlize_Y global g_regularize_X_objective global g_updateX global g_updateY global g_objective global g_stepsize global g_history if os . path . isfile ( javaLogText ) : run_result = dict ( ) run_result [ \"total time (ms)\" ] = [ ] run_result [ \"initialXY (ms)\" ] = [ ] run_result [ \"regularize Y (ms)\" ] = [ ] run_result [ \"regularize X and objective (ms)\" ] = [ ] run_result [ \"update X (ms)\" ] = [ ] run_result [ \"update Y (ms)\" ] = [ ] run_result [ \"objective (ms)\" ] = [ ] run_result [ \"step size (ms)\" ] = [ ] run_result [ \"update history (ms)\" ] = [ ] total_run_time = - 1 val = 0.0 with open ( javaLogText , 'r' ) as thefile : # go into tempfile and grab test run info for each_line in thefile : temp_string = each_line . split ( ) if len ( temp_string ) > 0 : val = temp_string [ - 1 ] . replace ( '\\\\' , '' ) if g_initialXY in each_line : # start of a new file if total_run_time > 0 : # update total run time run_result [ \"total time (ms)\" ] . append ( total_run_time ) total_run_time = 0.0 else : total_run_time = 0.0 run_result [ \"initialXY (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_reguarlize_Y in each_line : run_result [ \"regularize Y (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_regularize_X_objective in each_line : run_result [ \"regularize X and objective (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_updateX in each_line : run_result [ \"update X (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_updateY in each_line : run_result [ \"update Y (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_objective in each_line : run_result [ \"objective (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_stepsize in each_line : run_result [ \"step size (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) if g_history in each_line : run_result [ \"update history (ms)\" ] . append ( float ( val ) ) total_run_time = total_run_time + float ( val ) run_result [ \"total time (ms)\" ] . append ( total_run_time ) # save the last one print ( \"Run result summary: \\n {0}\" . format ( run_result ) ) else : print ( \"Cannot find your java log file.  Nothing is done.\\n\" )", "nl": "This function will extract the various operation time for GLRM model building iterations ."}}
{"translation": {"code": "def normalize_slice ( s , total ) : newstart = 0 if s . start is None else max ( 0 , s . start + total ) if s . start < 0 else min ( s . start , total ) newstop = total if s . stop is None else max ( 0 , s . stop + total ) if s . stop < 0 else min ( s . stop , total ) newstep = 1 if s . step is None else s . step return slice ( newstart , newstop , newstep )", "nl": "Return a canonical version of slice s ."}}
{"translation": {"code": "def slice_is_normalized ( s ) : return ( s . start is not None and s . stop is not None and s . step is not None and s . start <= s . stop )", "nl": "Return True if slice s in normalized form ."}}
{"translation": {"code": "def check_frame_id ( frame_id ) : if frame_id is None : return if frame_id . strip ( ) == \"\" : raise H2OValueError ( \"Frame id cannot be an empty string: %r\" % frame_id ) for i , ch in enumerate ( frame_id ) : # '$' character has special meaning at the beginning of the string; and prohibited anywhere else if ch == \"$\" and i == 0 : continue if ch not in _id_allowed_characters : raise H2OValueError ( \"Character '%s' is illegal in frame id: %s\" % ( ch , frame_id ) ) if re . match ( r\"-?[0-9]\" , frame_id ) : raise H2OValueError ( \"Frame id cannot start with a number: %s\" % frame_id )", "nl": "Check that the provided frame id is valid in Rapids language ."}}
{"translation": {"code": "def type ( self , col ) : assert_is_type ( col , int , str ) if not self . _ex . _cache . types_valid ( ) or not self . _ex . _cache . names_valid ( ) : self . _ex . _cache . flush ( ) self . _frame ( fill_cache = True ) types = self . _ex . _cache . types if is_type ( col , str ) : if col in types : return types [ col ] else : names = self . _ex . _cache . names if - len ( names ) <= col < len ( names ) : return types [ names [ col ] ] raise H2OValueError ( \"Column '%r' does not exist in the frame\" % col )", "nl": "The type for the given column ."}}
{"translation": {"code": "def distance ( self , y , measure = None ) : assert_is_type ( y , H2OFrame ) if measure is None : measure = \"l2\" return H2OFrame . _expr ( expr = ExprNode ( \"distance\" , self , y , measure ) ) . _frame ( )", "nl": "Compute a pairwise distance measure between all rows of two numeric H2OFrames ."}}
{"translation": {"code": "def idxmax ( self , skipna = True , axis = 0 ) : return H2OFrame . _expr ( expr = ExprNode ( \"which.max\" , self , skipna , axis ) )", "nl": "Get the index of the max value in a column or row"}}
{"translation": {"code": "def trim_data_back_to ( monthToKeep ) : global g_failed_tests_info_dict current_time = time . time ( ) # unit in seconds oldest_time_allowed = current_time - monthToKeep * 30 * 24 * 3600 # in seconds clean_up_failed_test_dict ( oldest_time_allowed ) clean_up_summary_text ( oldest_time_allowed )", "nl": "This method will remove data from the summary text file and the dictionary file for tests that occurs before the number of months specified by monthToKeep ."}}
{"translation": {"code": "def grep ( self , pattern , ignore_case = False , invert = False , output_logical = False ) : return H2OFrame . _expr ( expr = ExprNode ( \"grep\" , self , pattern , ignore_case , invert , output_logical ) )", "nl": "Searches for matches to argument pattern within each element of a string column ."}}
{"translation": {"code": "def varimp ( self , use_pandas = False ) : model = self . _model_json [ \"output\" ] if \"importance\" in list ( model . keys ( ) ) and model [ \"importance\" ] : vals = model [ \"importance\" ] . cell_values header = model [ \"importance\" ] . col_header if use_pandas and can_use_pandas ( ) : import pandas return pandas . DataFrame ( vals , columns = header ) else : return vals else : print ( \"Warning: This model doesn't have importances of components.\" )", "nl": "Return the Importance of components associcated with a pca model ."}}
{"translation": {"code": "def fillna ( self , method = \"forward\" , axis = 0 , maxlen = 1 ) : assert_is_type ( axis , 0 , 1 ) assert_is_type ( method , str ) assert_is_type ( maxlen , int ) return H2OFrame . _expr ( expr = ExprNode ( \"h2o.fillna\" , self , method , axis , maxlen ) )", "nl": "Return a new Frame that fills NA along a given axis and along a given direction with a maximum fill length"}}
{"translation": {"code": "def upload_custom_metric ( func , func_file = \"metrics.py\" , func_name = None , class_name = None , source_provider = None ) : import tempfile import inspect # Use default source provider if not source_provider : source_provider = _default_source_provider # The template wraps given metrics representation _CFUNC_CODE_TEMPLATE = \"\"\"# Generated code\nimport water.udf.CMetricFunc as MetricFunc\n\n# User given metric function as a class implementing\n# 3 methods defined by interface CMetricFunc\n{}\n\n# Generated user metric which satisfies the interface\n# of Java MetricFunc\nclass {}Wrapper({}, MetricFunc, object):\n    pass\n\n\"\"\" assert_satisfies ( func , inspect . isclass ( func ) or isinstance ( func , str ) , \"The argument func needs to be string or class !\" ) assert_satisfies ( func_file , func_file is not None , \"The argument func_file is missing!\" ) assert_satisfies ( func_file , func_file . endswith ( '.py' ) , \"The argument func_file needs to end with '.py'\" ) code = None derived_func_name = None module_name = func_file [ : - 3 ] if isinstance ( func , str ) : assert_satisfies ( class_name , class_name is not None , \"The argument class_name is missing! \" + \"It needs to reference the class in given string!\" ) code = _CFUNC_CODE_TEMPLATE . format ( func , class_name , class_name ) derived_func_name = \"metrics_{}\" . format ( class_name ) class_name = \"{}.{}Wrapper\" . format ( module_name , class_name ) else : assert_satisfies ( func , inspect . isclass ( func ) , \"The parameter `func` should be str or class\" ) for method in [ 'map' , 'reduce' , 'metric' ] : assert_satisfies ( func , method in func . __dict__ , \"The class `func` needs to define method `{}`\" . format ( method ) ) assert_satisfies ( class_name , class_name is None , \"If class is specified then class_name parameter needs to be None\" ) class_name = \"{}.{}Wrapper\" . format ( module_name , func . __name__ ) derived_func_name = \"metrics_{}\" . format ( func . __name__ ) code = _CFUNC_CODE_TEMPLATE . format ( source_provider ( func ) , func . __name__ , func . __name__ ) # If the func name is not given, use whatever we can derived from given definition if not func_name : func_name = derived_func_name # Saved into jar file tmpdir = tempfile . mkdtemp ( prefix = \"h2o-func\" ) func_arch_file = _create_zip_file ( \"{}/func.jar\" . format ( tmpdir ) , ( func_file , code ) ) # Upload into K/V dest_key = _put_key ( func_arch_file , dest_key = func_name ) # Reference return \"python:{}={}\" . format ( dest_key , class_name )", "nl": "Upload given metrics function into H2O cluster ."}}
{"translation": {"code": "def _put_key ( file_path , dest_key = None , overwrite = True ) : ret = api ( \"POST /3/PutKey?destination_key={}&overwrite={}\" . format ( dest_key if dest_key else '' , overwrite ) , filename = file_path ) return ret [ \"destination_key\" ]", "nl": "Upload given file into DKV and save it under give key as raw object ."}}
{"translation": {"code": "def _determine_vec_size ( self ) : first_column = self . pre_trained . types [ self . pre_trained . columns [ 0 ] ] if first_column != 'string' : raise H2OValueError ( \"First column of given pre_trained model %s is required to be a String\" , self . pre_trained . frame_id ) if list ( self . pre_trained . types . values ( ) ) . count ( 'string' ) > 1 : raise H2OValueError ( \"There are multiple columns in given pre_trained model %s with a String type.\" , self . pre_trained . frame_id ) self . vec_size = self . pre_trained . dim [ 1 ] - 1", "nl": "Determines vec_size for a pre - trained model after basic model verification ."}}
{"translation": {"code": "def download_mojo ( self , path = \".\" , get_genmodel_jar = False , genmodel_name = \"\" ) : return ModelBase . download_mojo ( self . leader , path , get_genmodel_jar , genmodel_name )", "nl": "Download the leader model in AutoML in MOJO format ."}}
{"translation": {"code": "def download_pojo ( self , path = \"\" , get_genmodel_jar = False , genmodel_name = \"\" ) : return h2o . download_pojo ( self . leader , path , get_jar = get_genmodel_jar , jar_name = genmodel_name )", "nl": "Download the POJO for the leader model in AutoML to the directory specified by path ."}}
{"translation": {"code": "def transform ( self , data , allow_timestamps = False ) : assert_is_type ( data , H2OFrame ) assert_is_type ( allow_timestamps , bool ) return H2OFrame . _expr ( ExprNode ( \"mojo.pipeline.transform\" , self . pipeline_id [ 0 ] , data , allow_timestamps ) )", "nl": "Transform H2OFrame using a MOJO Pipeline ."}}
{"translation": {"code": "def import_hive_table ( database = None , table = None , partitions = None , allow_multi_format = False ) : assert_is_type ( database , str , None ) assert_is_type ( table , str ) assert_is_type ( partitions , [ [ str ] ] , None ) p = { \"database\" : database , \"table\" : table , \"partitions\" : partitions , \"allow_multi_format\" : allow_multi_format } j = H2OJob ( api ( \"POST /3/ImportHiveTable\" , data = p ) , \"Import Hive Table\" ) . poll ( ) return get_frame ( j . dest_key )", "nl": "Import Hive table to H2OFrame in memory ."}}